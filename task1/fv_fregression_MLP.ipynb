{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import csv\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_selection import RFE, f_regression\n",
    "from sklearn.linear_model import (LinearRegression, Ridge, Lasso, RandomizedLasso)\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.feature_selection import f_regression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "TRAIN_FILE_PATH = \"data/X_train.csv\"\n",
    "TARGET_FILE_PATH =  \"data/y_train.csv\"\n",
    "TEST_FILE_PATH = \"data/X_test.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Data\n",
      "\n",
      "\n",
      "Test Data\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Load train and test set\n",
    "print(\"\\nTrain Data\\n\")\n",
    "\n",
    "train_data = pd.read_csv(TRAIN_FILE_PATH)\n",
    "train_data.drop(train_data.columns[0], axis=1, inplace=True)\n",
    "\n",
    "Y_train = pd.read_csv(TARGET_FILE_PATH)\n",
    "Y_train.drop(Y_train.columns[0], axis=1, inplace = True)\n",
    "\n",
    "print(\"\\nTest Data\\n\")\n",
    "\n",
    "test_data =  pd.read_csv(TEST_FILE_PATH)\n",
    "id_test = test_data.columns[0]\n",
    "#test_data.drop(test_data.columns[0], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill missing values with mean column values train and test set\n",
    "def fill_NaN(train, test):\n",
    "    print(\"Train shape: \", train.shape)\n",
    "    print(\"Test shape: \",test.shape)\n",
    "    train_mean_values = train.mean()\n",
    "    train =  train.fillna(train_mean_values)\n",
    "    test = test.fillna(train_mean_values)\n",
    "    \n",
    "    return train,test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape:  (1212, 887)\n",
      "Test shape:  (776, 887)\n"
     ]
    }
   ],
   "source": [
    "train_data_mean, test_data_mean = fill_NaN(train_data, test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Zero mean unit variance for train and test data\n",
    "def scale_data(train, test):\n",
    "    \n",
    "    print(\"Train shape: \", train.shape)\n",
    "    print(\"Test shape: \",test.shape)\n",
    "    scaler = StandardScaler().fit(train, Y_train)\n",
    "    #print(train_data_mean.shape)\n",
    "    #print(test_data_mean.shape)\n",
    "    train = scaler.transform(train)\n",
    "    test = scaler.transform(test)\n",
    "   \n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape:  (1212, 887)\n",
      "Test shape:  (776, 887)\n"
     ]
    }
   ],
   "source": [
    "X_train_scaled, X_test_scaled = scale_data(train_data_mean, test_data_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1212, 887)\n",
      "(1212, 1)\n",
      "[3.17463281e+02 3.09312060e+02 3.07583691e+02 2.85601310e+02\n",
      " 2.78761802e+02 2.78148971e+02 2.73253960e+02 2.52760516e+02\n",
      " 2.43972974e+02 2.43891857e+02 2.42925703e+02 2.38413283e+02\n",
      " 2.00450421e+02 1.88501078e+02 1.87394892e+02 1.85534631e+02\n",
      " 1.83031939e+02 1.77067457e+02 1.73985580e+02 1.72904968e+02\n",
      " 1.63621244e+02 1.59121648e+02 1.58715436e+02 1.58235651e+02\n",
      " 1.58076335e+02 1.54792017e+02 1.51246158e+02 1.50905309e+02\n",
      " 1.50059132e+02 1.44974863e+02 1.41936780e+02 1.41853063e+02\n",
      " 1.38327690e+02 1.37595239e+02 1.36981311e+02 1.33495247e+02\n",
      " 1.29886104e+02 1.27973959e+02 1.27868471e+02 1.27800779e+02\n",
      " 1.23643847e+02 1.21575634e+02 1.19960216e+02 1.17397751e+02\n",
      " 1.16924717e+02 1.16108916e+02 1.15126528e+02 1.14374064e+02\n",
      " 1.12846943e+02 1.11589434e+02 1.11331764e+02 1.09974839e+02\n",
      " 1.08125510e+02 1.05072321e+02 1.01706441e+02 9.78253813e+01\n",
      " 9.36728322e+01 9.31268014e+01 9.19324055e+01 8.80093999e+01\n",
      " 8.72718824e+01 8.72661510e+01 8.71275443e+01 8.69762456e+01\n",
      " 8.68645955e+01 8.55099219e+01 8.50443724e+01 8.06440325e+01\n",
      " 8.05646740e+01 7.84146923e+01 7.68576424e+01 7.68384004e+01\n",
      " 7.53617506e+01 7.44081608e+01 7.39634918e+01 7.16282924e+01\n",
      " 7.15200164e+01 7.11714036e+01 7.08866698e+01 6.97952426e+01\n",
      " 6.86722946e+01 6.83127280e+01 6.80871879e+01 6.77418318e+01\n",
      " 6.76317170e+01 6.72384378e+01 6.72313711e+01 6.71705679e+01\n",
      " 6.69290075e+01 6.66590259e+01 6.65711900e+01 6.64607161e+01\n",
      " 6.61563789e+01 6.61092024e+01 6.59369554e+01 6.52885004e+01\n",
      " 6.51129886e+01 6.49625405e+01 6.42661907e+01 6.42494335e+01\n",
      " 6.41829453e+01 6.40582614e+01 6.33370184e+01 6.32295885e+01\n",
      " 6.31258565e+01 6.24496078e+01 6.23156622e+01 6.21525243e+01\n",
      " 6.18159032e+01 6.17734295e+01 6.15198614e+01 6.10093556e+01\n",
      " 6.05048973e+01 6.00496105e+01 5.96652746e+01 5.92582258e+01\n",
      " 5.92182232e+01 5.91340796e+01 5.89862213e+01 5.86396500e+01\n",
      " 5.79539244e+01 5.78679185e+01 5.71484597e+01 5.69413600e+01\n",
      " 5.67269529e+01 5.65492831e+01 5.63985157e+01 5.63488901e+01\n",
      " 5.62899407e+01 5.62357282e+01 5.56351712e+01 5.53460020e+01\n",
      " 5.49612950e+01 5.49330629e+01 5.42939967e+01 5.41969143e+01\n",
      " 5.39640171e+01 5.39028834e+01 5.38521450e+01 5.38408479e+01\n",
      " 5.36232755e+01 5.25371986e+01 5.18614857e+01 5.15601763e+01\n",
      " 5.13704225e+01 5.13293891e+01 5.12487597e+01 5.11098319e+01\n",
      " 5.10041394e+01 5.09720141e+01 4.95028631e+01 4.84144474e+01\n",
      " 4.82310644e+01 4.70029364e+01 4.65340182e+01 4.64290649e+01\n",
      " 4.61466255e+01 4.61180482e+01 4.60906329e+01 4.49646820e+01\n",
      " 4.36634315e+01 4.32335679e+01 4.28233143e+01 4.15873109e+01\n",
      " 4.07013376e+01 4.06019339e+01 4.01445440e+01 3.99674148e+01\n",
      " 3.86166206e+01 3.69670842e+01 3.68482095e+01 3.66718382e+01\n",
      " 3.60727627e+01 3.59345907e+01 3.26831875e+01 3.08642734e+01\n",
      " 3.06215092e+01 2.73471504e+01 2.60898634e+01 2.60763752e+01\n",
      " 2.57844537e+01 2.49892703e+01 2.47241877e+01 2.42205418e+01\n",
      " 2.41657391e+01 2.38422170e+01 2.37651432e+01 2.33961905e+01\n",
      " 2.27744385e+01 2.27357305e+01 2.25205944e+01 2.24236744e+01\n",
      " 2.12491617e+01 1.99537452e+01 1.90041014e+01 1.89374084e+01\n",
      " 1.80127315e+01 1.66598478e+01 1.59464689e+01 1.58963927e+01\n",
      " 1.55600580e+01 1.48173085e+01 1.38003428e+01 1.33959657e+01\n",
      " 1.08627496e+01 1.04829733e+01 9.69697511e+00 9.21804894e+00\n",
      " 9.20065337e+00 8.62189165e+00 8.59404010e+00 8.44315410e+00\n",
      " 8.33098688e+00 8.21623929e+00 7.70099373e+00 7.59057460e+00\n",
      " 7.40138536e+00 7.34863492e+00 7.01859797e+00 6.65424170e+00\n",
      " 6.40242684e+00 6.00518930e+00 5.55851004e+00 5.36461722e+00\n",
      " 5.03723256e+00 5.01597460e+00 4.91014971e+00 4.71206769e+00\n",
      " 4.68971228e+00 4.59101297e+00 4.58300670e+00 4.56814784e+00\n",
      " 4.42976480e+00 4.40491635e+00 4.35977746e+00 4.33525125e+00\n",
      " 4.27954711e+00 4.26654331e+00 4.16053777e+00 4.08402527e+00\n",
      " 4.06282639e+00 3.94131986e+00 3.92146247e+00 3.79734925e+00\n",
      " 3.78907275e+00 3.78076272e+00 3.75929598e+00 3.62513109e+00\n",
      " 3.58570893e+00 3.58415725e+00 3.52074436e+00 3.48820590e+00\n",
      " 3.38513091e+00 3.37680901e+00 3.37091907e+00 3.34286812e+00\n",
      " 3.31711308e+00 3.31264382e+00 3.29889064e+00 3.29539593e+00\n",
      " 3.26080783e+00 3.14974687e+00 3.14649552e+00 3.13955824e+00\n",
      " 3.13500392e+00 3.12871533e+00 3.10820566e+00 3.05188564e+00\n",
      " 3.02129099e+00 2.97520443e+00 2.95828365e+00 2.92918235e+00\n",
      " 2.89532749e+00 2.88163101e+00 2.81347032e+00 2.73961346e+00\n",
      " 2.73472224e+00 2.72181451e+00 2.71635118e+00 2.69507209e+00\n",
      " 2.64282449e+00 2.62525793e+00 2.61029011e+00 2.58314507e+00\n",
      " 2.56489379e+00 2.50161732e+00 2.49458747e+00 2.48491194e+00\n",
      " 2.46284084e+00 2.45395111e+00 2.39479766e+00 2.35889100e+00\n",
      " 2.33422925e+00 2.32523268e+00 2.31965642e+00 2.30445410e+00\n",
      " 2.28387059e+00 2.26065388e+00 2.23924056e+00 2.23539072e+00\n",
      " 2.22297591e+00 2.22038346e+00 2.19752173e+00 2.16303099e+00\n",
      " 2.15390000e+00 2.14979260e+00 2.14602059e+00 2.14465207e+00\n",
      " 2.13628375e+00 2.13118444e+00 2.11689776e+00 2.08887381e+00\n",
      " 2.08171333e+00 2.05860918e+00 2.05046647e+00 2.04719871e+00\n",
      " 2.01412244e+00 2.01211016e+00 2.00864818e+00 1.94509877e+00\n",
      " 1.93393411e+00 1.92015841e+00 1.89943583e+00 1.88506567e+00\n",
      " 1.87144070e+00 1.85232694e+00 1.82710068e+00 1.82199936e+00\n",
      " 1.81037660e+00 1.80504302e+00 1.80022077e+00 1.76421203e+00\n",
      " 1.76017634e+00 1.75405954e+00 1.72695890e+00 1.69536545e+00\n",
      " 1.67986386e+00 1.67501723e+00 1.67324659e+00 1.66742816e+00\n",
      " 1.66523690e+00 1.63853491e+00 1.63175997e+00 1.62136489e+00\n",
      " 1.60846739e+00 1.60765478e+00 1.57377820e+00 1.56645370e+00\n",
      " 1.56202060e+00 1.54320174e+00 1.52376260e+00 1.52118551e+00\n",
      " 1.50925780e+00 1.50920348e+00 1.50851632e+00 1.48831197e+00\n",
      " 1.47407886e+00 1.44586896e+00 1.43301035e+00 1.43055567e+00\n",
      " 1.39814254e+00 1.39169607e+00 1.38924972e+00 1.38900472e+00\n",
      " 1.38209438e+00 1.37972586e+00 1.37917865e+00 1.37094592e+00\n",
      " 1.36212974e+00 1.36097976e+00 1.34300312e+00 1.34010583e+00\n",
      " 1.31644393e+00 1.28573173e+00 1.27354201e+00 1.26523132e+00\n",
      " 1.24786094e+00 1.24292510e+00 1.24096941e+00 1.22024617e+00\n",
      " 1.20290993e+00 1.18988748e+00 1.18790475e+00 1.18499171e+00\n",
      " 1.17752789e+00 1.17659955e+00 1.16875664e+00 1.15864169e+00\n",
      " 1.14955675e+00 1.14648161e+00 1.13745879e+00 1.13433446e+00\n",
      " 1.13224970e+00 1.13169062e+00 1.12428129e+00 1.11694277e+00\n",
      " 1.11352810e+00 1.10639487e+00 1.10587184e+00 1.10030233e+00\n",
      " 1.09083162e+00 1.08737995e+00 1.08551986e+00 1.07437964e+00\n",
      " 1.06147708e+00 1.03112049e+00 1.03098383e+00 1.01810228e+00\n",
      " 1.01414675e+00 1.01155039e+00 9.96908085e-01 9.94580309e-01\n",
      " 9.90944789e-01 9.90759226e-01 9.90342077e-01 9.89505909e-01\n",
      " 9.79377643e-01 9.75534046e-01 9.75114042e-01 9.68130440e-01\n",
      " 9.59032744e-01 9.58038017e-01 9.43616955e-01 9.41651337e-01\n",
      " 9.39210599e-01 9.26550443e-01 9.23888383e-01 9.18162479e-01\n",
      " 9.17956103e-01 9.02406685e-01 8.86558445e-01 8.85340948e-01\n",
      " 8.77142142e-01 8.72260126e-01 8.29506035e-01 8.26111948e-01\n",
      " 8.25799929e-01 8.24845406e-01 8.16214408e-01 8.04296304e-01\n",
      " 8.02759184e-01 8.02395760e-01 7.88886928e-01 7.86729452e-01\n",
      " 7.85116797e-01 7.81554404e-01 7.75515976e-01 7.75407607e-01\n",
      " 7.71555918e-01 7.63125845e-01 7.60519260e-01 7.57184244e-01\n",
      " 7.56500993e-01 7.55072395e-01 7.52463027e-01 7.51030209e-01\n",
      " 7.45613986e-01 7.40523543e-01 7.33371193e-01 7.28457973e-01\n",
      " 7.21533794e-01 7.14591445e-01 7.13598258e-01 7.10246322e-01\n",
      " 7.09619600e-01 7.06963805e-01 7.01447983e-01 6.99187331e-01\n",
      " 6.97012377e-01 6.91664181e-01 6.86902502e-01 6.83716924e-01\n",
      " 6.80958210e-01 6.78045096e-01 6.77106754e-01 6.70052801e-01\n",
      " 6.68519651e-01 6.67597012e-01 6.66658553e-01 6.65672476e-01\n",
      " 6.65012809e-01 6.63130072e-01 6.62874107e-01 6.56285487e-01\n",
      " 6.55975980e-01 6.54763004e-01 6.53044764e-01 6.52041198e-01\n",
      " 6.48689164e-01 6.47036216e-01 6.44038164e-01 6.38789004e-01\n",
      " 6.35244616e-01 6.29516241e-01 6.29261426e-01 6.20056196e-01\n",
      " 6.17318685e-01 6.13818221e-01 6.11151662e-01 6.10010591e-01\n",
      " 6.09195913e-01 6.07639006e-01 5.98578613e-01 5.86062611e-01\n",
      " 5.81973780e-01 5.80009864e-01 5.59215674e-01 5.53836709e-01\n",
      " 5.53440775e-01 5.53219842e-01 5.50976155e-01 5.49858468e-01\n",
      " 5.49572213e-01 5.49257896e-01 5.48019130e-01 5.46501761e-01\n",
      " 5.45531113e-01 5.45503636e-01 5.38304758e-01 5.36203255e-01\n",
      " 5.31998993e-01 5.22752575e-01 5.21222491e-01 5.20717351e-01\n",
      " 5.14675083e-01 5.14030867e-01 5.12511986e-01 5.07882124e-01\n",
      " 5.07708997e-01 4.96894180e-01 4.89644042e-01 4.88737478e-01\n",
      " 4.87721617e-01 4.87366389e-01 4.87284420e-01 4.86375381e-01\n",
      " 4.80312795e-01 4.78361207e-01 4.71502191e-01 4.68621103e-01\n",
      " 4.63399236e-01 4.62519559e-01 4.62192742e-01 4.56794671e-01\n",
      " 4.41257733e-01 4.40754425e-01 4.39828911e-01 4.37465087e-01\n",
      " 4.35323160e-01 4.32545735e-01 4.27923109e-01 4.23510055e-01\n",
      " 4.19915937e-01 4.17954112e-01 4.15025826e-01 4.10142186e-01\n",
      " 4.08663627e-01 4.04475679e-01 4.01265530e-01 4.00367711e-01\n",
      " 4.00004670e-01 3.93025362e-01 3.87315908e-01 3.86469093e-01\n",
      " 3.84958262e-01 3.80225800e-01 3.74124315e-01 3.73908675e-01\n",
      " 3.72015323e-01 3.71981236e-01 3.71100864e-01 3.66107415e-01\n",
      " 3.63517053e-01 3.61690528e-01 3.57218454e-01 3.55509660e-01\n",
      " 3.53952290e-01 3.52174595e-01 3.50706878e-01 3.50624840e-01\n",
      " 3.46088655e-01 3.45994167e-01 3.38307340e-01 3.36878247e-01\n",
      " 3.33941398e-01 3.32027522e-01 3.31237170e-01 3.30311531e-01\n",
      " 3.13597787e-01 3.06065296e-01 3.02774548e-01 3.02603554e-01\n",
      " 2.99661783e-01 2.97163327e-01 2.97037608e-01 2.95509907e-01\n",
      " 2.92359224e-01 2.91180201e-01 2.90557570e-01 2.87772693e-01\n",
      " 2.86787862e-01 2.85843098e-01 2.83998381e-01 2.83825636e-01\n",
      " 2.79743664e-01 2.74005937e-01 2.73878275e-01 2.68493745e-01\n",
      " 2.65167808e-01 2.63577909e-01 2.61430786e-01 2.57375499e-01\n",
      " 2.55318377e-01 2.53768069e-01 2.49259894e-01 2.44945146e-01\n",
      " 2.43066902e-01 2.41021070e-01 2.38461773e-01 2.37455545e-01\n",
      " 2.36357322e-01 2.35945485e-01 2.34857057e-01 2.34074786e-01\n",
      " 2.26139599e-01 2.23653401e-01 2.23318671e-01 2.18044575e-01\n",
      " 2.12622607e-01 2.11488032e-01 2.10211702e-01 2.08737616e-01\n",
      " 2.06792355e-01 2.04326609e-01 2.04028243e-01 2.03824054e-01\n",
      " 2.03556006e-01 2.01322155e-01 2.00819743e-01 1.97748238e-01\n",
      " 1.95394016e-01 1.94893806e-01 1.94359921e-01 1.93421707e-01\n",
      " 1.91245662e-01 1.90311714e-01 1.84350466e-01 1.83770267e-01\n",
      " 1.83728235e-01 1.80939877e-01 1.79583324e-01 1.77555162e-01\n",
      " 1.74185224e-01 1.69816023e-01 1.67424102e-01 1.66987139e-01\n",
      " 1.64806916e-01 1.64225322e-01 1.62422962e-01 1.55344999e-01\n",
      " 1.54243723e-01 1.53951916e-01 1.53747177e-01 1.53644668e-01\n",
      " 1.53469624e-01 1.53371564e-01 1.52336730e-01 1.52179785e-01\n",
      " 1.51691964e-01 1.49316017e-01 1.49118229e-01 1.47520867e-01\n",
      " 1.47344340e-01 1.46800408e-01 1.45783384e-01 1.45223590e-01\n",
      " 1.44595463e-01 1.44543554e-01 1.43503038e-01 1.42540150e-01\n",
      " 1.41387848e-01 1.41052429e-01 1.36026537e-01 1.35905167e-01\n",
      " 1.35757388e-01 1.34830845e-01 1.34276593e-01 1.32100127e-01\n",
      " 1.31462819e-01 1.31333465e-01 1.29468985e-01 1.27596457e-01\n",
      " 1.24626840e-01 1.23880754e-01 1.21311224e-01 1.20727579e-01\n",
      " 1.20059700e-01 1.18850430e-01 1.18013649e-01 1.16807053e-01\n",
      " 1.16050831e-01 1.14151174e-01 1.11536591e-01 1.08805868e-01\n",
      " 1.08628170e-01 1.08178377e-01 1.06043412e-01 1.05541359e-01\n",
      " 1.04727642e-01 1.00188441e-01 9.58811423e-02 9.44527315e-02\n",
      " 9.29376185e-02 9.11875338e-02 9.11479687e-02 9.11440371e-02\n",
      " 8.85473309e-02 8.73169617e-02 8.68928037e-02 8.64039922e-02\n",
      " 8.59554285e-02 8.52936773e-02 8.45971315e-02 8.39733931e-02\n",
      " 8.33337542e-02 8.11429580e-02 7.94176539e-02 7.91874238e-02\n",
      " 7.90253175e-02 7.88132786e-02 7.82684861e-02 7.54846131e-02\n",
      " 7.43602913e-02 7.38924923e-02 7.34853704e-02 7.07968990e-02\n",
      " 6.92185192e-02 6.76809345e-02 6.65844415e-02 6.59398461e-02\n",
      " 6.55226651e-02 6.53403903e-02 6.52163654e-02 6.43305700e-02\n",
      " 6.32783066e-02 6.12224986e-02 6.04606629e-02 6.04084585e-02\n",
      " 5.95530476e-02 5.94262483e-02 5.75281325e-02 5.71122584e-02\n",
      " 5.70034080e-02 5.65245131e-02 5.56761724e-02 5.49350463e-02\n",
      " 5.48853896e-02 5.29642129e-02 5.04422754e-02 4.99407186e-02\n",
      " 4.93307786e-02 4.84925313e-02 4.72131829e-02 4.69333476e-02\n",
      " 4.40180771e-02 4.21366110e-02 4.16682396e-02 4.12281307e-02\n",
      " 4.10912792e-02 4.08681779e-02 4.04896128e-02 3.71488245e-02\n",
      " 3.55365972e-02 3.44298374e-02 3.32603441e-02 3.31109807e-02\n",
      " 3.30105200e-02 3.25262786e-02 3.24794252e-02 3.23742401e-02\n",
      " 3.21494763e-02 3.05556112e-02 2.98688462e-02 2.96933210e-02\n",
      " 2.92181314e-02 2.87946036e-02 2.84066135e-02 2.81771113e-02\n",
      " 2.66975607e-02 2.66949994e-02 2.66530581e-02 2.58061500e-02\n",
      " 2.49890043e-02 2.45420278e-02 2.44668287e-02 2.41836440e-02\n",
      " 2.38504451e-02 2.25317887e-02 2.25027168e-02 2.23887256e-02\n",
      " 2.08290794e-02 2.03023755e-02 2.02049900e-02 2.01047535e-02\n",
      " 1.98215573e-02 1.88014772e-02 1.87759570e-02 1.79822582e-02\n",
      " 1.76260844e-02 1.73637986e-02 1.71821477e-02 1.66931178e-02\n",
      " 1.50447500e-02 1.47963989e-02 1.45846106e-02 1.35969293e-02\n",
      " 1.21719820e-02 1.19172290e-02 1.14852771e-02 1.12702246e-02\n",
      " 1.08964636e-02 1.05164634e-02 1.03856014e-02 1.01290128e-02\n",
      " 9.95064150e-03 9.47554752e-03 9.31165744e-03 8.94112183e-03\n",
      " 8.74823434e-03 7.82396880e-03 7.71633023e-03 7.65962377e-03\n",
      " 7.62649107e-03 7.35937845e-03 7.17362549e-03 7.07591717e-03\n",
      " 7.00921073e-03 6.54574038e-03 6.18872194e-03 5.80769387e-03\n",
      " 4.87056943e-03 4.13939287e-03 3.85360428e-03 3.84970923e-03\n",
      " 3.60067314e-03 3.40121562e-03 3.14713993e-03 3.10895499e-03\n",
      " 3.03654201e-03 2.84400824e-03 2.82440586e-03 2.77363261e-03\n",
      " 2.50427782e-03 2.48825812e-03 2.47966501e-03 2.37243417e-03\n",
      " 2.33418995e-03 2.21139515e-03 2.10684693e-03 1.78159263e-03\n",
      " 1.67223819e-03 1.39797034e-03 1.35971696e-03 1.27885456e-03\n",
      " 1.18812166e-03 9.05392199e-04 8.86107536e-04 8.56521434e-04\n",
      " 7.18570551e-04 4.38980332e-04 4.02622197e-04 3.69146727e-04\n",
      " 3.14335002e-04 2.68016054e-04 2.40644375e-04 9.48861553e-05\n",
      " 6.15573431e-05 4.51941262e-05 4.50657513e-05 3.30410008e-05\n",
      " 8.87765512e-06 2.72909488e-06 2.26606189e-06            nan\n",
      "            nan            nan            nan]\n",
      "[731 772 523 493 746  82 685 333 391 722 882 751 291   0  96 349 730 687\n",
      " 363 673 340 664 604 185 838 300 180 309 665 686 608 744 297 345 853 490\n",
      " 547 636  80 613 470 234 156 810 120 430 232 370 426  89]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/francesco/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/francesco/anaconda3/lib/python3.6/site-packages/sklearn/feature_selection/univariate_selection.py:298: RuntimeWarning: invalid value encountered in true_divide\n",
      "  corr /= X_norms\n",
      "/home/francesco/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater\n",
      "  return (self.a < x) & (x < self.b)\n",
      "/home/francesco/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less\n",
      "  return (self.a < x) & (x < self.b)\n",
      "/home/francesco/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal\n",
      "  cond2 = cond0 & (x <= self.a)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Extract the features to use\n",
    "\n",
    "n_features_fr = 50\n",
    "\n",
    "print(X_train_scaled.shape)\n",
    "print(Y_train.shape)\n",
    "features_scores = f_regression(X_train_scaled,Y_train)[0]\n",
    "#print(features_scores)\n",
    "y = list(features_scores)\n",
    "myarray = np.asarray(y)\n",
    "print(-1*np.sort(-1*myarray))\n",
    "#print(-1*np.sort(myarray-1))\n",
    "plt.plot(-1*np.sort(-1*myarray))\n",
    "\n",
    "indices_fr = myarray.argsort()[-50:][::-1]\n",
    "print(indices_fr)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/francesco/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:6: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 1 of 50\n",
      "building tree 2 of 50\n",
      "building tree 3 of 50\n",
      "building tree 4 of 50building tree 5 of 50\n",
      "building tree 6 of 50\n",
      "\n",
      "building tree 7 of 50\n",
      "building tree 8 of 50\n",
      "building tree 9 of 50\n",
      "building tree 10 of 50\n",
      "building tree 11 of 50\n",
      "building tree 12 of 50\n",
      "building tree 13 of 50\n",
      "building tree 14 of 50\n",
      "building tree 15 of 50\n",
      "building tree 16 of 50\n",
      "building tree 17 of 50\n",
      "building tree 18 of 50\n",
      "building tree 19 of 50\n",
      "building tree 20 of 50\n",
      "building tree 21 of 50\n",
      "building tree 22 of 50\n",
      "building tree 23 of 50\n",
      "building tree 24 of 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    1.9s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 25 of 50\n",
      "building tree 26 of 50\n",
      "building tree 27 of 50\n",
      "building tree 28 of 50\n",
      "building tree 29 of 50\n",
      "building tree 30 of 50\n",
      "building tree 31 of 50\n",
      "building tree 32 of 50\n",
      "building tree 33 of 50\n",
      "building tree 34 of 50\n",
      "building tree 35 of 50\n",
      "building tree 36 of 50\n",
      "building tree 37 of 50\n",
      "building tree 38 of 50\n",
      "building tree 39 of 50\n",
      "building tree 40 of 50\n",
      "building tree 41 of 50\n",
      "building tree 42 of 50\n",
      "building tree 43 of 50\n",
      "building tree 44 of 50\n",
      "building tree 45 of 50\n",
      "building tree 46 of 50\n",
      "building tree 47 of 50\n",
      "building tree 48 of 50\n",
      "building tree 49 of 50\n",
      "building tree 50 of 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:    5.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.11071161e-01 9.43825903e-02 4.43131986e-02 3.93068012e-02\n",
      " 1.74559783e-02 1.70167787e-02 1.43848408e-02 1.06187602e-02\n",
      " 9.02853957e-03 8.66229141e-03 8.62429446e-03 6.17836656e-03\n",
      " 5.98765925e-03 5.35135227e-03 4.92401100e-03 4.73049074e-03\n",
      " 4.62582256e-03 4.55336978e-03 4.51499917e-03 4.24726238e-03\n",
      " 3.88922438e-03 3.66027592e-03 3.58313095e-03 3.38521283e-03\n",
      " 3.32599604e-03 3.31456149e-03 2.92076494e-03 2.90918916e-03\n",
      " 2.86644553e-03 2.82972692e-03 2.65573745e-03 2.57063163e-03\n",
      " 2.50950381e-03 2.38168748e-03 2.36080079e-03 2.29201383e-03\n",
      " 2.26622522e-03 2.26524660e-03 2.23168961e-03 2.21310064e-03\n",
      " 2.15005181e-03 2.12852493e-03 2.11254173e-03 2.04778680e-03\n",
      " 2.04584388e-03 2.02829443e-03 1.99414013e-03 1.99065543e-03\n",
      " 1.92305173e-03 1.91250612e-03 1.90011198e-03 1.86498241e-03\n",
      " 1.84199214e-03 1.83413464e-03 1.78833706e-03 1.78105408e-03\n",
      " 1.74515721e-03 1.71525074e-03 1.67846648e-03 1.66183428e-03\n",
      " 1.65965665e-03 1.65489276e-03 1.60718825e-03 1.60692585e-03\n",
      " 1.60184809e-03 1.60143523e-03 1.57827386e-03 1.54570956e-03\n",
      " 1.53220461e-03 1.48699620e-03 1.46837929e-03 1.45247824e-03\n",
      " 1.39947236e-03 1.38384733e-03 1.36526352e-03 1.35179009e-03\n",
      " 1.32554191e-03 1.30440102e-03 1.29520943e-03 1.28195160e-03\n",
      " 1.26764458e-03 1.26196245e-03 1.24191305e-03 1.23589574e-03\n",
      " 1.20850135e-03 1.20255610e-03 1.18394048e-03 1.17939081e-03\n",
      " 1.17935419e-03 1.16536428e-03 1.16105547e-03 1.15123894e-03\n",
      " 1.15027438e-03 1.14811732e-03 1.13205723e-03 1.13057882e-03\n",
      " 1.11708193e-03 1.10923551e-03 1.09815553e-03 1.09239252e-03\n",
      " 1.08537513e-03 1.08138432e-03 1.07462302e-03 1.07444785e-03\n",
      " 1.06989130e-03 1.05818746e-03 1.05162689e-03 1.04222616e-03\n",
      " 1.03439747e-03 1.03160131e-03 1.02644848e-03 1.02501854e-03\n",
      " 1.02452460e-03 1.01165607e-03 9.98588093e-04 9.98362504e-04\n",
      " 9.95768455e-04 9.95180212e-04 9.93527453e-04 9.91163517e-04\n",
      " 9.90042996e-04 9.87619104e-04 9.82987282e-04 9.62985730e-04\n",
      " 9.46179174e-04 9.42108011e-04 9.34080602e-04 9.19998769e-04\n",
      " 9.19383275e-04 9.18241937e-04 9.16504014e-04 9.15783968e-04\n",
      " 9.15691038e-04 9.14753202e-04 9.14590850e-04 9.11431008e-04\n",
      " 9.09444894e-04 9.09389365e-04 9.03268841e-04 8.98591180e-04\n",
      " 8.94164784e-04 8.92883217e-04 8.91962410e-04 8.88282634e-04\n",
      " 8.87098336e-04 8.75428191e-04 8.75403253e-04 8.67933224e-04\n",
      " 8.66117248e-04 8.65769832e-04 8.63286898e-04 8.62856326e-04\n",
      " 8.57288487e-04 8.56598196e-04 8.52228079e-04 8.51591297e-04\n",
      " 8.38175066e-04 8.36110400e-04 8.32391843e-04 8.31016160e-04\n",
      " 8.29099635e-04 8.25998093e-04 8.24663284e-04 8.23241409e-04\n",
      " 8.22545782e-04 8.16931484e-04 8.16013440e-04 8.14628946e-04\n",
      " 8.11338785e-04 8.07959036e-04 8.06685129e-04 8.06540705e-04\n",
      " 8.04385098e-04 8.01944279e-04 8.01187647e-04 7.97328015e-04\n",
      " 7.95372175e-04 7.94794980e-04 7.94558017e-04 7.90498506e-04\n",
      " 7.89659541e-04 7.88940954e-04 7.81671809e-04 7.81356882e-04\n",
      " 7.78514963e-04 7.78066132e-04 7.76516271e-04 7.70355935e-04\n",
      " 7.69599918e-04 7.68632028e-04 7.61802038e-04 7.61028726e-04\n",
      " 7.58263656e-04 7.55216126e-04 7.54341240e-04 7.51994800e-04\n",
      " 7.51639936e-04 7.44962691e-04 7.41104197e-04 7.38449709e-04\n",
      " 7.37651641e-04 7.37145592e-04 7.36518564e-04 7.34622170e-04\n",
      " 7.32255939e-04 7.31662585e-04 7.30773889e-04 7.25615645e-04\n",
      " 7.23809289e-04 7.19713007e-04 7.17318620e-04 7.15244522e-04\n",
      " 7.13021306e-04 7.12580307e-04 7.12110375e-04 7.03082126e-04\n",
      " 7.00192921e-04 6.99287298e-04 6.97327894e-04 6.95805514e-04\n",
      " 6.84495249e-04 6.82362573e-04 6.81153745e-04 6.77375057e-04\n",
      " 6.77113412e-04 6.73496609e-04 6.72398862e-04 6.71760547e-04\n",
      " 6.70239270e-04 6.68093026e-04 6.63189757e-04 6.62798936e-04\n",
      " 6.59575773e-04 6.59331174e-04 6.54512571e-04 6.54508144e-04\n",
      " 6.53530023e-04 6.52814276e-04 6.51575120e-04 6.49416609e-04\n",
      " 6.47434088e-04 6.46600289e-04 6.42800205e-04 6.41994216e-04\n",
      " 6.39689436e-04 6.39623547e-04 6.38964495e-04 6.38118872e-04\n",
      " 6.35514179e-04 6.35382283e-04 6.34723116e-04 6.32754897e-04\n",
      " 6.31167610e-04 6.28138277e-04 6.24214961e-04 6.22710860e-04\n",
      " 6.22647745e-04 6.19797503e-04 6.19279677e-04 6.15357124e-04\n",
      " 6.15213392e-04 6.10566420e-04 6.08538484e-04 6.07294827e-04\n",
      " 6.07159568e-04 6.06145571e-04 6.05668586e-04 6.04219449e-04\n",
      " 6.03639282e-04 6.01833399e-04 6.01483813e-04 6.01426799e-04\n",
      " 5.97184671e-04 5.96719537e-04 5.94614107e-04 5.93835141e-04\n",
      " 5.93587750e-04 5.93097905e-04 5.92956929e-04 5.92194190e-04\n",
      " 5.91567543e-04 5.91243950e-04 5.88543939e-04 5.87714332e-04\n",
      " 5.86352671e-04 5.85600159e-04 5.84339032e-04 5.83260778e-04\n",
      " 5.82120713e-04 5.79977307e-04 5.77499430e-04 5.76147235e-04\n",
      " 5.75682380e-04 5.75039382e-04 5.74485538e-04 5.74102475e-04\n",
      " 5.73747419e-04 5.71838786e-04 5.71023712e-04 5.70682234e-04\n",
      " 5.68784131e-04 5.67840731e-04 5.66726943e-04 5.65352413e-04\n",
      " 5.65301794e-04 5.64149885e-04 5.63092048e-04 5.62451119e-04\n",
      " 5.62129077e-04 5.59879642e-04 5.58906550e-04 5.57474766e-04\n",
      " 5.57117826e-04 5.55794891e-04 5.55657598e-04 5.55048260e-04\n",
      " 5.54899746e-04 5.51385881e-04 5.50961332e-04 5.49530321e-04\n",
      " 5.46832508e-04 5.44177718e-04 5.38763101e-04 5.38073464e-04\n",
      " 5.36642753e-04 5.33739116e-04 5.29577640e-04 5.29411293e-04\n",
      " 5.28653846e-04 5.28523683e-04 5.27795525e-04 5.27301070e-04\n",
      " 5.27225551e-04 5.27215673e-04 5.27133680e-04 5.24005484e-04\n",
      " 5.23109498e-04 5.22270977e-04 5.21262124e-04 5.20717528e-04\n",
      " 5.18777209e-04 5.18440257e-04 5.18116694e-04 5.17529891e-04\n",
      " 5.14302105e-04 5.12488085e-04 5.12472062e-04 5.12067508e-04\n",
      " 5.11839936e-04 5.08237841e-04 5.04638306e-04 5.03304366e-04\n",
      " 5.03292029e-04 4.99991646e-04 4.98871862e-04 4.96713772e-04\n",
      " 4.95360404e-04 4.94902876e-04 4.94771894e-04 4.91180694e-04\n",
      " 4.89799211e-04 4.87700985e-04 4.87398052e-04 4.87393200e-04\n",
      " 4.87046999e-04 4.86183879e-04 4.85507153e-04 4.85253705e-04\n",
      " 4.85045752e-04 4.83358256e-04 4.83266674e-04 4.82203694e-04\n",
      " 4.77425332e-04 4.77194297e-04 4.76987735e-04 4.76877592e-04\n",
      " 4.75922030e-04 4.75106103e-04 4.74074239e-04 4.72881557e-04\n",
      " 4.72798566e-04 4.72675600e-04 4.70842545e-04 4.69828985e-04\n",
      " 4.69150722e-04 4.69093271e-04 4.68808534e-04 4.67681675e-04\n",
      " 4.67676962e-04 4.66870142e-04 4.66676054e-04 4.64329025e-04\n",
      " 4.63420327e-04 4.62965324e-04 4.62734894e-04 4.60992631e-04\n",
      " 4.57744309e-04 4.56860704e-04 4.56786421e-04 4.54463457e-04\n",
      " 4.53319567e-04 4.52687798e-04 4.51465424e-04 4.49137599e-04\n",
      " 4.48995529e-04 4.48406748e-04 4.47464774e-04 4.47354819e-04\n",
      " 4.46577144e-04 4.46450421e-04 4.46059847e-04 4.43412653e-04\n",
      " 4.41397200e-04 4.40881052e-04 4.40759418e-04 4.40357700e-04\n",
      " 4.39321759e-04 4.36933740e-04 4.36728829e-04 4.36693438e-04\n",
      " 4.36314126e-04 4.33799097e-04 4.31743282e-04 4.31030334e-04\n",
      " 4.30224627e-04 4.30217128e-04 4.29372232e-04 4.27480432e-04\n",
      " 4.27478804e-04 4.26564557e-04 4.23589586e-04 4.22024731e-04\n",
      " 4.20975775e-04 4.20961983e-04 4.19382832e-04 4.18690460e-04\n",
      " 4.17250698e-04 4.16913945e-04 4.16686874e-04 4.14654177e-04\n",
      " 4.13262883e-04 4.12855900e-04 4.12802165e-04 4.11752915e-04\n",
      " 4.11702218e-04 4.10095122e-04 4.09651195e-04 4.09537376e-04\n",
      " 4.09330484e-04 4.08576056e-04 4.07196208e-04 4.06757106e-04\n",
      " 4.06271679e-04 4.04670093e-04 4.04043389e-04 4.03740997e-04\n",
      " 4.03310119e-04 4.01739020e-04 4.01568296e-04 3.99645160e-04\n",
      " 3.99621271e-04 3.99449768e-04 3.98425075e-04 3.98111652e-04\n",
      " 3.93053244e-04 3.92253229e-04 3.91609181e-04 3.90384235e-04\n",
      " 3.90190475e-04 3.85150004e-04 3.84710031e-04 3.84650305e-04\n",
      " 3.84456499e-04 3.84383909e-04 3.84359575e-04 3.82798043e-04\n",
      " 3.80401085e-04 3.80303660e-04 3.80264905e-04 3.80090558e-04\n",
      " 3.78997638e-04 3.78094041e-04 3.76639097e-04 3.76485925e-04\n",
      " 3.75291204e-04 3.73817045e-04 3.73495054e-04 3.72714550e-04\n",
      " 3.72089589e-04 3.71952641e-04 3.71805704e-04 3.71616610e-04\n",
      " 3.70155258e-04 3.69971690e-04 3.68209976e-04 3.67844409e-04\n",
      " 3.66851145e-04 3.65825481e-04 3.65747235e-04 3.64428436e-04\n",
      " 3.63585450e-04 3.62970485e-04 3.61572586e-04 3.61527983e-04\n",
      " 3.61106622e-04 3.60973903e-04 3.60430234e-04 3.60222124e-04\n",
      " 3.60165440e-04 3.59676994e-04 3.58321896e-04 3.56816791e-04\n",
      " 3.54117885e-04 3.54018318e-04 3.53622493e-04 3.53552941e-04\n",
      " 3.52871304e-04 3.52454353e-04 3.51802389e-04 3.51759254e-04\n",
      " 3.51361724e-04 3.49765923e-04 3.45789015e-04 3.44395771e-04\n",
      " 3.44278925e-04 3.43526324e-04 3.43311986e-04 3.42612688e-04\n",
      " 3.41990235e-04 3.41224362e-04 3.41189369e-04 3.41056626e-04\n",
      " 3.39750015e-04 3.39529893e-04 3.37458399e-04 3.36919935e-04\n",
      " 3.35981049e-04 3.35662733e-04 3.34911875e-04 3.34474227e-04\n",
      " 3.32011149e-04 3.31957109e-04 3.31928250e-04 3.31024479e-04\n",
      " 3.30111981e-04 3.29888465e-04 3.28560285e-04 3.26976452e-04\n",
      " 3.26797769e-04 3.26790211e-04 3.25698941e-04 3.25612094e-04\n",
      " 3.25566796e-04 3.23438489e-04 3.23117326e-04 3.22909016e-04\n",
      " 3.22720820e-04 3.22302861e-04 3.22236890e-04 3.21330168e-04\n",
      " 3.20968766e-04 3.18863199e-04 3.18628020e-04 3.18521557e-04\n",
      " 3.18464102e-04 3.18402819e-04 3.17207598e-04 3.14820451e-04\n",
      " 3.14816905e-04 3.14396248e-04 3.13938800e-04 3.13446337e-04\n",
      " 3.13414700e-04 3.12517185e-04 3.12464007e-04 3.11741960e-04\n",
      " 3.10667719e-04 3.09207994e-04 3.07968113e-04 3.05932939e-04\n",
      " 3.05730433e-04 3.05359637e-04 3.05196815e-04 3.03566200e-04\n",
      " 3.01854870e-04 3.01599885e-04 3.00671392e-04 2.99876772e-04\n",
      " 2.99386346e-04 2.99352812e-04 2.98869502e-04 2.98685167e-04\n",
      " 2.96133100e-04 2.96102244e-04 2.96078078e-04 2.94246037e-04\n",
      " 2.93713949e-04 2.93463745e-04 2.92641618e-04 2.92554802e-04\n",
      " 2.92376394e-04 2.91978227e-04 2.91566422e-04 2.91504746e-04\n",
      " 2.91373605e-04 2.91286380e-04 2.90069524e-04 2.89585646e-04\n",
      " 2.89251291e-04 2.88905257e-04 2.87845647e-04 2.87536199e-04\n",
      " 2.87069840e-04 2.86032089e-04 2.85953113e-04 2.85752598e-04\n",
      " 2.85549145e-04 2.85441573e-04 2.85331592e-04 2.84140344e-04\n",
      " 2.83969659e-04 2.83816509e-04 2.83726447e-04 2.83007712e-04\n",
      " 2.82121332e-04 2.82119688e-04 2.81965128e-04 2.80944906e-04\n",
      " 2.79967662e-04 2.79859905e-04 2.78568472e-04 2.77824734e-04\n",
      " 2.76273385e-04 2.73765869e-04 2.73737803e-04 2.73494147e-04\n",
      " 2.72923941e-04 2.72071282e-04 2.71565476e-04 2.71357852e-04\n",
      " 2.71186772e-04 2.70043281e-04 2.68706528e-04 2.67866765e-04\n",
      " 2.67513023e-04 2.66896041e-04 2.66349263e-04 2.65373833e-04\n",
      " 2.64906250e-04 2.64613522e-04 2.64264914e-04 2.62561723e-04\n",
      " 2.62458199e-04 2.61857939e-04 2.59705237e-04 2.58802386e-04\n",
      " 2.57267187e-04 2.57008916e-04 2.56396899e-04 2.55511655e-04\n",
      " 2.55123650e-04 2.54822671e-04 2.54206435e-04 2.54115475e-04\n",
      " 2.54066467e-04 2.53983643e-04 2.53806184e-04 2.53707358e-04\n",
      " 2.53570025e-04 2.53562372e-04 2.52152390e-04 2.51855286e-04\n",
      " 2.51850424e-04 2.51843122e-04 2.51583087e-04 2.51185376e-04\n",
      " 2.50714921e-04 2.49859498e-04 2.49427177e-04 2.49163501e-04\n",
      " 2.49115725e-04 2.48137844e-04 2.48063264e-04 2.48043555e-04\n",
      " 2.47859949e-04 2.47235917e-04 2.46671914e-04 2.45474395e-04\n",
      " 2.45116571e-04 2.45021953e-04 2.44923500e-04 2.44867968e-04\n",
      " 2.42182763e-04 2.41571958e-04 2.40904290e-04 2.40663721e-04\n",
      " 2.40127708e-04 2.39546981e-04 2.39439438e-04 2.39385257e-04\n",
      " 2.37997365e-04 2.37635070e-04 2.37065933e-04 2.36088050e-04\n",
      " 2.35701822e-04 2.33945126e-04 2.33783980e-04 2.33339716e-04\n",
      " 2.32960533e-04 2.32379692e-04 2.32016635e-04 2.31285357e-04\n",
      " 2.29964798e-04 2.29745625e-04 2.29696340e-04 2.29688847e-04\n",
      " 2.28826129e-04 2.28000893e-04 2.27121640e-04 2.27105614e-04\n",
      " 2.27040196e-04 2.26947414e-04 2.26307128e-04 2.26174772e-04\n",
      " 2.24435553e-04 2.24285193e-04 2.22680902e-04 2.20167561e-04\n",
      " 2.19245049e-04 2.18975255e-04 2.18821974e-04 2.18422999e-04\n",
      " 2.18018912e-04 2.16793078e-04 2.16363936e-04 2.15877489e-04\n",
      " 2.15471734e-04 2.15400727e-04 2.14433819e-04 2.12975385e-04\n",
      " 2.12713696e-04 2.11488012e-04 2.11211201e-04 2.10795644e-04\n",
      " 2.10619831e-04 2.10580199e-04 2.10565822e-04 2.10019361e-04\n",
      " 2.06827511e-04 2.04678994e-04 2.02150863e-04 2.01344494e-04\n",
      " 2.00895037e-04 1.99561214e-04 1.99560153e-04 1.99305923e-04\n",
      " 1.98927499e-04 1.96154720e-04 1.94898092e-04 1.92939238e-04\n",
      " 1.92191633e-04 1.91879788e-04 1.91361849e-04 1.90266033e-04\n",
      " 1.89912175e-04 1.88037284e-04 1.86749227e-04 1.84337694e-04\n",
      " 1.81947324e-04 1.81511891e-04 1.81279974e-04 1.80641232e-04\n",
      " 1.80195214e-04 1.80084032e-04 1.79298678e-04 1.79131551e-04\n",
      " 1.77738328e-04 1.77593661e-04 1.77502457e-04 1.77279292e-04\n",
      " 1.76306982e-04 1.74820881e-04 1.74295109e-04 1.74071523e-04\n",
      " 1.73451031e-04 1.73052552e-04 1.71821425e-04 1.71324657e-04\n",
      " 1.70546078e-04 1.68826388e-04 1.68497257e-04 1.68185062e-04\n",
      " 1.67913927e-04 1.67684217e-04 1.67657460e-04 1.67239161e-04\n",
      " 1.66875635e-04 1.65858848e-04 1.63377956e-04 1.62568078e-04\n",
      " 1.62392797e-04 1.61453732e-04 1.60992950e-04 1.59813216e-04\n",
      " 1.59680396e-04 1.58845447e-04 1.56367634e-04 1.54784607e-04\n",
      " 1.54669998e-04 1.54036031e-04 1.53767218e-04 1.52001598e-04\n",
      " 1.49993385e-04 1.49111828e-04 1.48508849e-04 1.47370998e-04\n",
      " 1.47333469e-04 1.47127340e-04 1.45974868e-04 1.45920389e-04\n",
      " 1.44785027e-04 1.43011378e-04 1.41721388e-04 1.39273048e-04\n",
      " 1.38878751e-04 1.38037867e-04 1.37206003e-04 1.36592054e-04\n",
      " 1.36414445e-04 1.36029656e-04 1.34681064e-04 1.32604024e-04\n",
      " 1.30133040e-04 1.30120565e-04 1.28182989e-04 1.27471408e-04\n",
      " 1.27392066e-04 1.26563154e-04 1.25687293e-04 1.25420773e-04\n",
      " 1.23568007e-04 1.21603959e-04 1.20749224e-04 1.17544913e-04\n",
      " 1.16068375e-04 1.14161345e-04 1.11650796e-04 1.11390425e-04\n",
      " 1.10793501e-04 1.08717988e-04 1.08545596e-04 1.08195732e-04\n",
      " 1.08156314e-04 1.07697917e-04 1.05281692e-04 1.04472018e-04\n",
      " 1.03862284e-04 1.01843438e-04 9.84177930e-05 9.73684550e-05\n",
      " 9.68916508e-05 9.28517054e-05 9.22913677e-05 8.91124134e-05\n",
      " 8.41969636e-05 7.70073996e-05 7.45478243e-05 7.32826034e-05\n",
      " 6.97206498e-05 6.97204243e-05 6.85281493e-05 6.36354402e-05\n",
      " 6.16327339e-05 6.13103721e-05 5.72964491e-05 5.40290488e-05\n",
      " 4.96231637e-05 4.87303349e-05 4.49020131e-05 4.11320039e-05\n",
      " 3.25929331e-05 2.74801190e-05 1.91399196e-05 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      "[ 96 685 722  82 664 751 746 237 499 291  80 391 882 470 591 604 185   0\n",
      " 686 547 687 730 810 665 309 870 410 173 340 186 457 853 338 763  88 651\n",
      " 234 479 335 838 424 739 426 280 349 637 273 264 560 350 871 370 529 787\n",
      " 450 490 333 365 632 520 283 673 555 823 844 140 201  83 800 114 158 504\n",
      " 224 275 554 300 328 608 556 835 744  89  10 420 112 310 609 605 374 253\n",
      " 799  70 120 427 198 791 811 165 515 287 320  57 230 200 522 559 276 633\n",
      " 755  53 643 803 353 740 443 613 109 361 402 205 180 815 471 542 137 419\n",
      " 251 618 567 381 716 164 688  99 178   6 795 307 817  94 603 644 363 564\n",
      " 336  91 127 322 465 676 884 297 646 877 449 536 141 274 407  14 819 146\n",
      " 331 660 816 229 104 111 539 156 344 401 451 707 781 737  98 435 725 247\n",
      " 862 641 143 794 375 376 602 802 648  56  49 155 876 666 159  72 144 846\n",
      " 105 258]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Extract feature importance of Random Forest & find intersection with f_regression one\n",
    "\n",
    "n_features_rf = 100\n",
    "\n",
    "rf = RandomForestRegressor(n_jobs=-1, n_estimators=50, verbose=3)\n",
    "rf.fit(X_train_scaled,Y_train)\n",
    "\n",
    "scores = list(rf.feature_importances_)\n",
    "my_rf_features = np.asarray(scores)\n",
    "print(-1*np.sort(-1*my_rf_features))\n",
    "#print(-1*np.sort(myarray-1))\n",
    "plt.plot((-1*np.sort(-1*my_rf_features))[0:200])\n",
    "\n",
    "indices_rf = my_rf_features.argsort()[-200:][::-1]\n",
    "print(indices_rf)\n",
    "#print(-1*np.sort(-1*rf.feature_importances_));\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find intersection between best f_regression features and random forest's\n",
    "\n",
    "print(set(indices_rf).intersection(indices_fr))\n",
    "\n",
    "indices = set(indices_rf).intersection(indices_fr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape:  (1212, 50)\n",
      "Test shape:  (776, 50)\n",
      "Train shape:  (1212, 50)\n",
      "Test shape:  (776, 50)\n",
      "(1212, 50)\n"
     ]
    }
   ],
   "source": [
    "#Extract the feature selected from dataset\n",
    "\n",
    "#indices = indices_rf\n",
    "indices = indices_fr\n",
    "#indices = list(indices)\n",
    "\n",
    "X_train_subset = train_data_mean[train_data_mean.columns[indices]]\n",
    "X_test_subset = test_data_mean[train_data_mean.columns[indices]]\n",
    "\n",
    "#print(X_subset.head(1))\n",
    "\n",
    "X_train_subset, X_test_subset = fill_NaN(X_train_subset, X_test_subset)\n",
    "X_train_subset, X_test_subset = scale_data(X_train_subset, X_test_subset)\n",
    "\n",
    "print(X_train_subset.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/francesco/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:1306: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 2448.78627045\n",
      "Validation score: -52.883935\n",
      "Iteration 2, loss = 2329.22285537\n",
      "Validation score: -50.717433\n",
      "Iteration 3, loss = 2239.08660436\n",
      "Validation score: -48.813341\n",
      "Iteration 4, loss = 2154.98609248\n",
      "Validation score: -46.909513\n",
      "Iteration 5, loss = 2069.01342318\n",
      "Validation score: -44.904162\n",
      "Iteration 6, loss = 1979.02136627\n",
      "Validation score: -42.885823\n",
      "Iteration 7, loss = 1890.36114840\n",
      "Validation score: -40.929949\n",
      "Iteration 8, loss = 1805.41792614\n",
      "Validation score: -39.093777\n",
      "Iteration 9, loss = 1725.44342513\n",
      "Validation score: -37.338606\n",
      "Iteration 10, loss = 1648.59083859\n",
      "Validation score: -35.659618\n",
      "Iteration 11, loss = 1575.50996297\n",
      "Validation score: -34.046934\n",
      "Iteration 12, loss = 1505.10203614\n",
      "Validation score: -32.502340\n",
      "Iteration 13, loss = 1437.64526734\n",
      "Validation score: -30.998213\n",
      "Iteration 14, loss = 1370.39596577\n",
      "Validation score: -29.431636\n",
      "Iteration 15, loss = 1301.13837053\n",
      "Validation score: -27.923319\n",
      "Iteration 16, loss = 1235.92809213\n",
      "Validation score: -26.484707\n",
      "Iteration 17, loss = 1172.10093700\n",
      "Validation score: -25.004644\n",
      "Iteration 18, loss = 1106.29604127\n",
      "Validation score: -23.562110\n",
      "Iteration 19, loss = 1044.53983593\n",
      "Validation score: -22.212294\n",
      "Iteration 20, loss = 986.10569450\n",
      "Validation score: -20.934150\n",
      "Iteration 21, loss = 930.84792379\n",
      "Validation score: -19.725484\n",
      "Iteration 22, loss = 878.74635285\n",
      "Validation score: -18.581583\n",
      "Iteration 23, loss = 829.33649396\n",
      "Validation score: -17.500374\n",
      "Iteration 24, loss = 782.79929860\n",
      "Validation score: -16.471987\n",
      "Iteration 25, loss = 738.03447959\n",
      "Validation score: -15.457565\n",
      "Iteration 26, loss = 692.46170995\n",
      "Validation score: -14.407817\n",
      "Iteration 27, loss = 647.93954921\n",
      "Validation score: -13.437773\n",
      "Iteration 28, loss = 606.28173685\n",
      "Validation score: -12.526007\n",
      "Iteration 29, loss = 567.23813454\n",
      "Validation score: -11.670308\n",
      "Iteration 30, loss = 530.69344256\n",
      "Validation score: -10.867836\n",
      "Iteration 31, loss = 496.46714404\n",
      "Validation score: -10.119204\n",
      "Iteration 32, loss = 464.71986528\n",
      "Validation score: -9.418080\n",
      "Iteration 33, loss = 434.87631748\n",
      "Validation score: -8.764770\n",
      "Iteration 34, loss = 407.27930504\n",
      "Validation score: -8.153407\n",
      "Iteration 35, loss = 381.33372741\n",
      "Validation score: -7.581805\n",
      "Iteration 36, loss = 357.23018906\n",
      "Validation score: -7.046456\n",
      "Iteration 37, loss = 334.46890348\n",
      "Validation score: -6.547667\n",
      "Iteration 38, loss = 313.47312326\n",
      "Validation score: -6.079038\n",
      "Iteration 39, loss = 293.54203264\n",
      "Validation score: -5.642630\n",
      "Iteration 40, loss = 275.32566454\n",
      "Validation score: -5.232424\n",
      "Iteration 41, loss = 258.07591605\n",
      "Validation score: -4.850503\n",
      "Iteration 42, loss = 242.14110445\n",
      "Validation score: -4.492667\n",
      "Iteration 43, loss = 227.23227138\n",
      "Validation score: -4.158808\n",
      "Iteration 44, loss = 213.22148755\n",
      "Validation score: -3.849037\n",
      "Iteration 45, loss = 200.31712589\n",
      "Validation score: -3.559566\n",
      "Iteration 46, loss = 188.32305434\n",
      "Validation score: -3.289042\n",
      "Iteration 47, loss = 177.17177915\n",
      "Validation score: -3.037747\n",
      "Iteration 48, loss = 166.73353449\n",
      "Validation score: -2.803495\n",
      "Iteration 49, loss = 157.13245459\n",
      "Validation score: -2.582887\n",
      "Iteration 50, loss = 148.01825504\n",
      "Validation score: -2.377287\n",
      "Iteration 51, loss = 139.54962886\n",
      "Validation score: -2.177708\n",
      "Iteration 52, loss = 131.10979405\n",
      "Validation score: -1.975585\n",
      "Iteration 53, loss = 122.84808429\n",
      "Validation score: -1.785799\n",
      "Iteration 54, loss = 115.26452975\n",
      "Validation score: -1.611534\n",
      "Iteration 55, loss = 108.26546001\n",
      "Validation score: -1.452503\n",
      "Iteration 56, loss = 101.94712989\n",
      "Validation score: -1.307136\n",
      "Iteration 57, loss = 96.19148712\n",
      "Validation score: -1.175564\n",
      "Iteration 58, loss = 91.04951777\n",
      "Validation score: -1.056812\n",
      "Iteration 59, loss = 86.43502787\n",
      "Validation score: -0.949860\n",
      "Iteration 60, loss = 82.25757981\n",
      "Validation score: -0.853780\n",
      "Iteration 61, loss = 78.58251201\n",
      "Validation score: -0.766720\n",
      "Iteration 62, loss = 75.30071309\n",
      "Validation score: -0.688266\n",
      "Iteration 63, loss = 72.33101254\n",
      "Validation score: -0.617682\n",
      "Iteration 64, loss = 69.68733562\n",
      "Validation score: -0.553445\n",
      "Iteration 65, loss = 67.27424542\n",
      "Validation score: -0.494274\n",
      "Iteration 66, loss = 65.03773437\n",
      "Validation score: -0.438332\n",
      "Iteration 67, loss = 62.93712979\n",
      "Validation score: -0.383846\n",
      "Iteration 68, loss = 60.94952715\n",
      "Validation score: -0.335536\n",
      "Iteration 69, loss = 59.24333613\n",
      "Validation score: -0.293130\n",
      "Iteration 70, loss = 57.79474125\n",
      "Validation score: -0.254948\n",
      "Iteration 71, loss = 56.31668777\n",
      "Validation score: -0.221667\n",
      "Iteration 72, loss = 54.78316994\n",
      "Validation score: -0.188138\n",
      "Iteration 73, loss = 52.24446243\n",
      "Validation score: -0.122200\n",
      "Iteration 74, loss = 48.81195786\n",
      "Validation score: -0.071656\n",
      "Iteration 75, loss = 46.76580011\n",
      "Validation score: -0.017340\n",
      "Iteration 76, loss = 44.90856726\n",
      "Validation score: 0.029691\n",
      "Iteration 77, loss = 42.93285263\n",
      "Validation score: 0.064720\n",
      "Iteration 78, loss = 41.77956894\n",
      "Validation score: 0.102905\n",
      "Iteration 79, loss = 40.38307253\n",
      "Validation score: 0.128105\n",
      "Iteration 80, loss = 39.09356010\n",
      "Validation score: 0.154281\n",
      "Iteration 81, loss = 38.05296870\n",
      "Validation score: 0.186279\n",
      "Iteration 82, loss = 36.88756579\n",
      "Validation score: 0.212955\n",
      "Iteration 83, loss = 35.96858757\n",
      "Validation score: 0.231477\n",
      "Iteration 84, loss = 35.26221353\n",
      "Validation score: 0.247852\n",
      "Iteration 85, loss = 34.54310306\n",
      "Validation score: 0.263497\n",
      "Iteration 86, loss = 33.88776647\n",
      "Validation score: 0.280665\n",
      "Iteration 87, loss = 33.32410470\n",
      "Validation score: 0.294693\n",
      "Iteration 88, loss = 32.64852286\n",
      "Validation score: 0.307097\n",
      "Iteration 89, loss = 32.07449336\n",
      "Validation score: 0.320841\n",
      "Iteration 90, loss = 31.58221159\n",
      "Validation score: 0.333633\n",
      "Iteration 91, loss = 31.24452072\n",
      "Validation score: 0.343656\n",
      "Iteration 92, loss = 30.74809078\n",
      "Validation score: 0.351874\n",
      "Iteration 93, loss = 30.47595841\n",
      "Validation score: 0.362856\n",
      "Iteration 94, loss = 30.04431220\n",
      "Validation score: 0.371855\n",
      "Iteration 95, loss = 29.74230128\n",
      "Validation score: 0.379579\n",
      "Iteration 96, loss = 29.49330310\n",
      "Validation score: 0.384850\n",
      "Iteration 97, loss = 29.17298424\n",
      "Validation score: 0.391988\n",
      "Iteration 98, loss = 28.96056533\n",
      "Validation score: 0.400012\n",
      "Iteration 99, loss = 28.58763560\n",
      "Validation score: 0.405982\n",
      "Iteration 100, loss = 28.36494076\n",
      "Validation score: 0.411359\n",
      "Iteration 101, loss = 28.16880246\n",
      "Validation score: 0.417258\n",
      "Iteration 102, loss = 28.05947659\n",
      "Validation score: 0.418464\n",
      "Iteration 103, loss = 27.76801934\n",
      "Validation score: 0.421463\n",
      "Iteration 104, loss = 27.57953446\n",
      "Validation score: 0.430809\n",
      "Iteration 105, loss = 27.36320865\n",
      "Validation score: 0.437065\n",
      "Iteration 106, loss = 27.14919691\n",
      "Validation score: 0.441606\n",
      "Iteration 107, loss = 26.96377910\n",
      "Validation score: 0.445852\n",
      "Iteration 108, loss = 26.85386207\n",
      "Validation score: 0.449481\n",
      "Iteration 109, loss = 26.70962394\n",
      "Validation score: 0.452961\n",
      "Iteration 110, loss = 26.49602885\n",
      "Validation score: 0.457063\n",
      "Iteration 111, loss = 26.34234974\n",
      "Validation score: 0.460068\n",
      "Iteration 112, loss = 26.32350356\n",
      "Validation score: 0.461300\n",
      "Iteration 113, loss = 26.20742581\n",
      "Validation score: 0.464312\n",
      "Iteration 114, loss = 25.94141955\n",
      "Validation score: 0.468362\n",
      "Iteration 115, loss = 25.78833326\n",
      "Validation score: 0.472078\n",
      "Iteration 116, loss = 25.63751817\n",
      "Validation score: 0.474077\n",
      "Iteration 117, loss = 25.52390152\n",
      "Validation score: 0.474936\n",
      "Iteration 118, loss = 25.33543383\n",
      "Validation score: 0.476528\n",
      "Iteration 119, loss = 25.29989985\n",
      "Validation score: 0.481740\n",
      "Iteration 120, loss = 25.17099566\n",
      "Validation score: 0.483921\n",
      "Iteration 121, loss = 25.08781644\n",
      "Validation score: 0.483203\n",
      "Iteration 122, loss = 24.92843057\n",
      "Validation score: 0.482906\n",
      "Iteration 123, loss = 24.89711178\n",
      "Validation score: 0.485995\n",
      "Iteration 124, loss = 24.78927603\n",
      "Validation score: 0.488786\n",
      "Iteration 125, loss = 24.69406519\n",
      "Validation score: 0.489883\n",
      "Iteration 126, loss = 24.53560487\n",
      "Validation score: 0.493687\n",
      "Iteration 127, loss = 24.53883021\n",
      "Validation score: 0.494806\n",
      "Iteration 128, loss = 24.36824544\n",
      "Validation score: 0.497337\n",
      "Iteration 129, loss = 24.29731235\n",
      "Validation score: 0.498535\n",
      "Iteration 130, loss = 24.19902152\n",
      "Validation score: 0.498637\n",
      "Iteration 131, loss = 24.11344891\n",
      "Validation score: 0.499175\n",
      "Iteration 132, loss = 24.08098991\n",
      "Validation score: 0.499384\n",
      "Iteration 133, loss = 23.98605585\n",
      "Validation score: 0.499390\n",
      "Iteration 134, loss = 23.88641172\n",
      "Validation score: 0.500569\n",
      "Iteration 135, loss = 23.91426108\n",
      "Validation score: 0.503595\n",
      "Iteration 136, loss = 23.87057417\n",
      "Validation score: 0.504190\n",
      "Iteration 137, loss = 23.72269813\n",
      "Validation score: 0.505049\n",
      "Iteration 138, loss = 23.70888044\n",
      "Validation score: 0.503844\n",
      "Iteration 139, loss = 23.64058148\n",
      "Validation score: 0.504489\n",
      "Iteration 140, loss = 23.60319658\n",
      "Validation score: 0.504065\n",
      "Validation score did not improve more than tol=0.000000 for two consecutive epochs. Stopping.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPRegressor(activation='logistic', alpha=0.1, batch_size='auto', beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=True, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(50, 30), learning_rate='constant',\n",
       "       learning_rate_init=0.01, max_iter=15000, momentum=0.9,\n",
       "       nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
       "       shuffle=True, solver='adam', tol=1e-11, validation_fraction=0.1,\n",
       "       verbose=True, warm_start=False)"
      ]
     },
     "execution_count": 351,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model = MLPRegressor(batch_size = 200,validation_fraction=0.05, verbose=True, tol = 0.00000001,learning_rate_init=0.0001)\n",
    "\n",
    "model = MLPRegressor(learning_rate='constant', \n",
    "                         hidden_layer_sizes=(50,30),\n",
    "                         activation='logistic', \n",
    "                         learning_rate_init=0.01,\n",
    "                         max_iter=15000, \n",
    "                         early_stopping =True,\n",
    "                         validation_fraction=0.1,\n",
    "                         tol=0.00000000001,\n",
    "                         alpha=0.1,\n",
    "                         #n_iter_no_change=100,\n",
    "                         verbose=True)\n",
    "model.fit(X_train_subset,Y_train)\n",
    "\n",
    "#score = cross_val_score((model), X_train_subset, Y_train, scoring='r2', cv=4)\n",
    "#print(score.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_pred = model.predict(X_test_subset)\n",
    "test_data[\"y\"] = predictions\n",
    "#print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create submission\n",
    "test_data[[\"id\", \"y\"]].to_csv(\"submissions/keras_second.csv\", index= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         y\n",
      "0     0.75\n",
      "1     0.76\n",
      "2     0.74\n",
      "3     0.70\n",
      "4     0.74\n",
      "5     0.79\n",
      "6     0.90\n",
      "7     0.82\n",
      "8     0.64\n",
      "9     0.55\n",
      "10    0.48\n",
      "11    0.73\n",
      "12    0.72\n",
      "13    0.55\n",
      "14    0.80\n",
      "15    0.81\n",
      "16    0.69\n",
      "17    0.78\n",
      "18    0.70\n",
      "19    0.66\n",
      "20    0.76\n",
      "21    0.82\n",
      "22    0.75\n",
      "23    0.66\n",
      "24    0.67\n",
      "25    0.73\n",
      "26    0.82\n",
      "27    0.50\n",
      "28    0.72\n",
      "29    0.63\n",
      "...    ...\n",
      "1182  0.59\n",
      "1183  0.72\n",
      "1184  0.69\n",
      "1185  0.67\n",
      "1186  0.88\n",
      "1187  0.66\n",
      "1188  0.80\n",
      "1189  0.84\n",
      "1190  0.62\n",
      "1191  0.73\n",
      "1192  0.67\n",
      "1193  0.78\n",
      "1194  0.84\n",
      "1195  0.78\n",
      "1196  0.78\n",
      "1197  0.76\n",
      "1198  0.53\n",
      "1199  0.85\n",
      "1200  0.66\n",
      "1201  0.67\n",
      "1202  0.57\n",
      "1203  0.73\n",
      "1204  0.74\n",
      "1205  0.55\n",
      "1206  0.83\n",
      "1207  0.69\n",
      "1208  0.73\n",
      "1209  0.78\n",
      "1210  0.78\n",
      "1211  0.56\n",
      "\n",
      "[1212 rows x 1 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/francesco/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:10: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(100, input_dim=50, kernel_initializer=\"RandomUniform\")`\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "/home/francesco/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:12: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(50, kernel_initializer=\"RandomUniform\")`\n",
      "  if sys.path[0] == '':\n",
      "/home/francesco/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:14: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(100, kernel_initializer=\"RandomUniform\")`\n",
      "  \n",
      "/home/francesco/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:16: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(1, activation=\"sigmoid\", kernel_initializer=\"RandomUniform\")`\n",
      "  app.launch_new_instance()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1090 samples, validate on 122 samples\n",
      "Epoch 1/150\n",
      " - 2s - loss: 0.1995 - val_loss: 0.1972\n",
      "Epoch 2/150\n",
      " - 1s - loss: 0.1989 - val_loss: 0.1965\n",
      "Epoch 3/150\n",
      " - 1s - loss: 0.1982 - val_loss: 0.1957\n",
      "Epoch 4/150\n",
      " - 1s - loss: 0.1972 - val_loss: 0.1945\n",
      "Epoch 5/150\n",
      " - 1s - loss: 0.1960 - val_loss: 0.1930\n",
      "Epoch 6/150\n",
      " - 1s - loss: 0.1944 - val_loss: 0.1910\n",
      "Epoch 7/150\n",
      " - 1s - loss: 0.1924 - val_loss: 0.1884\n",
      "Epoch 8/150\n",
      " - 1s - loss: 0.1898 - val_loss: 0.1851\n",
      "Epoch 9/150\n",
      " - 1s - loss: 0.1865 - val_loss: 0.1809\n",
      "Epoch 10/150\n",
      " - 1s - loss: 0.1826 - val_loss: 0.1759\n",
      "Epoch 11/150\n",
      " - 1s - loss: 0.1778 - val_loss: 0.1700\n",
      "Epoch 12/150\n",
      " - 1s - loss: 0.1724 - val_loss: 0.1630\n",
      "Epoch 13/150\n",
      " - 1s - loss: 0.1664 - val_loss: 0.1551\n",
      "Epoch 14/150\n",
      " - 1s - loss: 0.1600 - val_loss: 0.1466\n",
      "Epoch 15/150\n",
      " - 1s - loss: 0.1529 - val_loss: 0.1375\n",
      "Epoch 16/150\n",
      " - 1s - loss: 0.1454 - val_loss: 0.1292\n",
      "Epoch 17/150\n",
      " - 1s - loss: 0.1376 - val_loss: 0.1217\n",
      "Epoch 18/150\n",
      " - 1s - loss: 0.1297 - val_loss: 0.1144\n",
      "Epoch 19/150\n",
      " - 1s - loss: 0.1219 - val_loss: 0.1083\n",
      "Epoch 20/150\n",
      " - 1s - loss: 0.1152 - val_loss: 0.1036\n",
      "Epoch 21/150\n",
      " - 1s - loss: 0.1095 - val_loss: 0.1003\n",
      "Epoch 22/150\n",
      " - 1s - loss: 0.1054 - val_loss: 0.0976\n",
      "Epoch 23/150\n",
      " - 1s - loss: 0.1023 - val_loss: 0.0952\n",
      "Epoch 24/150\n",
      " - 1s - loss: 0.0998 - val_loss: 0.0930\n",
      "Epoch 25/150\n",
      " - 1s - loss: 0.0978 - val_loss: 0.0910\n",
      "Epoch 26/150\n",
      " - 1s - loss: 0.0960 - val_loss: 0.0892\n",
      "Epoch 27/150\n",
      " - 1s - loss: 0.0946 - val_loss: 0.0876\n",
      "Epoch 28/150\n",
      " - 1s - loss: 0.0934 - val_loss: 0.0863\n",
      "Epoch 29/150\n",
      " - 1s - loss: 0.0923 - val_loss: 0.0851\n",
      "Epoch 30/150\n",
      " - 1s - loss: 0.0912 - val_loss: 0.0839\n",
      "Epoch 31/150\n",
      " - 1s - loss: 0.0902 - val_loss: 0.0827\n",
      "Epoch 32/150\n",
      " - 1s - loss: 0.0891 - val_loss: 0.0815\n",
      "Epoch 33/150\n",
      " - 1s - loss: 0.0881 - val_loss: 0.0803\n",
      "Epoch 34/150\n",
      " - 1s - loss: 0.0870 - val_loss: 0.0791\n",
      "Epoch 35/150\n",
      " - 1s - loss: 0.0859 - val_loss: 0.0780\n",
      "Epoch 36/150\n",
      " - 1s - loss: 0.0848 - val_loss: 0.0768\n",
      "Epoch 37/150\n",
      " - 1s - loss: 0.0837 - val_loss: 0.0757\n",
      "Epoch 38/150\n",
      " - 1s - loss: 0.0826 - val_loss: 0.0747\n",
      "Epoch 39/150\n",
      " - 1s - loss: 0.0814 - val_loss: 0.0737\n",
      "Epoch 40/150\n",
      " - 1s - loss: 0.0803 - val_loss: 0.0727\n",
      "Epoch 41/150\n",
      " - 1s - loss: 0.0791 - val_loss: 0.0716\n",
      "Epoch 42/150\n",
      " - 1s - loss: 0.0780 - val_loss: 0.0707\n",
      "Epoch 43/150\n",
      " - 1s - loss: 0.0768 - val_loss: 0.0696\n",
      "Epoch 44/150\n",
      " - 1s - loss: 0.0757 - val_loss: 0.0686\n",
      "Epoch 45/150\n",
      " - 1s - loss: 0.0745 - val_loss: 0.0676\n",
      "Epoch 46/150\n",
      " - 1s - loss: 0.0733 - val_loss: 0.0667\n",
      "Epoch 47/150\n",
      " - 1s - loss: 0.0722 - val_loss: 0.0657\n",
      "Epoch 48/150\n",
      " - 1s - loss: 0.0711 - val_loss: 0.0647\n",
      "Epoch 49/150\n",
      " - 1s - loss: 0.0701 - val_loss: 0.0639\n",
      "Epoch 50/150\n",
      " - 1s - loss: 0.0691 - val_loss: 0.0630\n",
      "Epoch 51/150\n",
      " - 1s - loss: 0.0682 - val_loss: 0.0623\n",
      "Epoch 52/150\n",
      " - 1s - loss: 0.0674 - val_loss: 0.0616\n",
      "Epoch 53/150\n",
      " - 1s - loss: 0.0666 - val_loss: 0.0609\n",
      "Epoch 54/150\n",
      " - 1s - loss: 0.0658 - val_loss: 0.0604\n",
      "Epoch 55/150\n",
      " - 1s - loss: 0.0651 - val_loss: 0.0601\n",
      "Epoch 56/150\n",
      " - 0s - loss: 0.0645 - val_loss: 0.0598\n",
      "Epoch 57/150\n",
      " - 1s - loss: 0.0639 - val_loss: 0.0597\n",
      "Epoch 58/150\n",
      " - 1s - loss: 0.0633 - val_loss: 0.0596\n",
      "Epoch 59/150\n",
      " - 1s - loss: 0.0628 - val_loss: 0.0594\n",
      "Epoch 60/150\n",
      " - 0s - loss: 0.0623 - val_loss: 0.0593\n",
      "Epoch 61/150\n",
      " - 0s - loss: 0.0619 - val_loss: 0.0591\n",
      "Epoch 62/150\n",
      " - 1s - loss: 0.0614 - val_loss: 0.0590\n",
      "Epoch 63/150\n",
      " - 1s - loss: 0.0610 - val_loss: 0.0589\n",
      "Epoch 64/150\n",
      " - 1s - loss: 0.0606 - val_loss: 0.0587\n",
      "Epoch 65/150\n",
      " - 1s - loss: 0.0602 - val_loss: 0.0585\n",
      "Epoch 66/150\n",
      " - 1s - loss: 0.0599 - val_loss: 0.0583\n",
      "Epoch 67/150\n",
      " - 1s - loss: 0.0595 - val_loss: 0.0582\n",
      "Epoch 68/150\n",
      " - 1s - loss: 0.0592 - val_loss: 0.0580\n",
      "Epoch 69/150\n",
      " - 1s - loss: 0.0588 - val_loss: 0.0579\n",
      "Epoch 70/150\n",
      " - 1s - loss: 0.0585 - val_loss: 0.0578\n",
      "Epoch 71/150\n",
      " - 1s - loss: 0.0582 - val_loss: 0.0576\n",
      "Epoch 72/150\n",
      " - 1s - loss: 0.0579 - val_loss: 0.0574\n",
      "Epoch 73/150\n",
      " - 1s - loss: 0.0576 - val_loss: 0.0572\n",
      "Epoch 74/150\n",
      " - 1s - loss: 0.0573 - val_loss: 0.0570\n",
      "Epoch 75/150\n",
      " - 1s - loss: 0.0571 - val_loss: 0.0569\n",
      "Epoch 76/150\n",
      " - 1s - loss: 0.0568 - val_loss: 0.0568\n",
      "Epoch 77/150\n",
      " - 1s - loss: 0.0565 - val_loss: 0.0567\n",
      "Epoch 78/150\n",
      " - 1s - loss: 0.0563 - val_loss: 0.0566\n",
      "Epoch 79/150\n",
      " - 1s - loss: 0.0560 - val_loss: 0.0565\n",
      "Epoch 80/150\n",
      " - 1s - loss: 0.0558 - val_loss: 0.0563\n",
      "Epoch 81/150\n",
      " - 1s - loss: 0.0555 - val_loss: 0.0561\n",
      "Epoch 82/150\n",
      " - 1s - loss: 0.0553 - val_loss: 0.0559\n",
      "Epoch 83/150\n",
      " - 1s - loss: 0.0550 - val_loss: 0.0557\n",
      "Epoch 84/150\n",
      " - 1s - loss: 0.0548 - val_loss: 0.0556\n",
      "Epoch 85/150\n",
      " - 1s - loss: 0.0546 - val_loss: 0.0554\n",
      "Epoch 86/150\n",
      " - 1s - loss: 0.0543 - val_loss: 0.0553\n",
      "Epoch 87/150\n",
      " - 1s - loss: 0.0541 - val_loss: 0.0552\n",
      "Epoch 88/150\n",
      " - 1s - loss: 0.0539 - val_loss: 0.0551\n",
      "Epoch 89/150\n",
      " - 1s - loss: 0.0537 - val_loss: 0.0550\n",
      "Epoch 90/150\n",
      " - 1s - loss: 0.0535 - val_loss: 0.0549\n",
      "Epoch 91/150\n",
      " - 0s - loss: 0.0533 - val_loss: 0.0548\n",
      "Epoch 92/150\n",
      " - 1s - loss: 0.0531 - val_loss: 0.0547\n",
      "Epoch 93/150\n",
      " - 1s - loss: 0.0529 - val_loss: 0.0547\n",
      "Epoch 94/150\n",
      " - 1s - loss: 0.0528 - val_loss: 0.0546\n",
      "Epoch 95/150\n",
      " - 1s - loss: 0.0526 - val_loss: 0.0545\n",
      "Epoch 96/150\n",
      " - 1s - loss: 0.0524 - val_loss: 0.0545\n",
      "Epoch 97/150\n",
      " - 1s - loss: 0.0522 - val_loss: 0.0544\n",
      "Epoch 98/150\n",
      " - 1s - loss: 0.0521 - val_loss: 0.0544\n",
      "Epoch 99/150\n",
      " - 1s - loss: 0.0519 - val_loss: 0.0543\n",
      "Epoch 100/150\n",
      " - 1s - loss: 0.0517 - val_loss: 0.0543\n",
      "Epoch 101/150\n",
      " - 1s - loss: 0.0515 - val_loss: 0.0543\n",
      "Epoch 102/150\n",
      " - 1s - loss: 0.0514 - val_loss: 0.0543\n",
      "Epoch 103/150\n",
      " - 1s - loss: 0.0512 - val_loss: 0.0543\n",
      "Epoch 104/150\n",
      " - 1s - loss: 0.0510 - val_loss: 0.0542\n",
      "Epoch 105/150\n",
      " - 1s - loss: 0.0508 - val_loss: 0.0542\n",
      "Epoch 106/150\n",
      " - 1s - loss: 0.0507 - val_loss: 0.0542\n",
      "Epoch 107/150\n",
      " - 1s - loss: 0.0505 - val_loss: 0.0542\n",
      "Epoch 108/150\n",
      " - 1s - loss: 0.0503 - val_loss: 0.0542\n",
      "Epoch 109/150\n",
      " - 1s - loss: 0.0501 - val_loss: 0.0541\n",
      "Epoch 110/150\n",
      " - 1s - loss: 0.0500 - val_loss: 0.0541\n",
      "Epoch 111/150\n",
      " - 1s - loss: 0.0498 - val_loss: 0.0541\n",
      "Epoch 112/150\n",
      " - 1s - loss: 0.0496 - val_loss: 0.0541\n",
      "Epoch 113/150\n",
      " - 1s - loss: 0.0494 - val_loss: 0.0541\n",
      "Epoch 114/150\n",
      " - 1s - loss: 0.0492 - val_loss: 0.0541\n",
      "Epoch 115/150\n",
      " - 1s - loss: 0.0491 - val_loss: 0.0540\n",
      "Epoch 116/150\n",
      " - 1s - loss: 0.0489 - val_loss: 0.0540\n",
      "Epoch 117/150\n",
      " - 1s - loss: 0.0487 - val_loss: 0.0540\n",
      "Epoch 118/150\n",
      " - 1s - loss: 0.0485 - val_loss: 0.0540\n",
      "Epoch 119/150\n",
      " - 1s - loss: 0.0483 - val_loss: 0.0540\n",
      "Epoch 120/150\n",
      " - 1s - loss: 0.0482 - val_loss: 0.0540\n",
      "Epoch 121/150\n",
      " - 1s - loss: 0.0480 - val_loss: 0.0540\n",
      "Epoch 122/150\n",
      " - 1s - loss: 0.0478 - val_loss: 0.0540\n",
      "Epoch 123/150\n",
      " - 1s - loss: 0.0476 - val_loss: 0.0540\n",
      "Epoch 124/150\n",
      " - 1s - loss: 0.0475 - val_loss: 0.0540\n",
      "Epoch 125/150\n",
      " - 1s - loss: 0.0473 - val_loss: 0.0540\n",
      "Epoch 126/150\n",
      " - 1s - loss: 0.0471 - val_loss: 0.0540\n",
      "Epoch 127/150\n",
      " - 1s - loss: 0.0469 - val_loss: 0.0540\n",
      "Epoch 128/150\n",
      " - 1s - loss: 0.0467 - val_loss: 0.0540\n",
      "Epoch 129/150\n",
      " - 1s - loss: 0.0465 - val_loss: 0.0540\n",
      "Epoch 130/150\n",
      " - 1s - loss: 0.0464 - val_loss: 0.0540\n",
      "Epoch 131/150\n",
      " - 1s - loss: 0.0462 - val_loss: 0.0539\n",
      "Epoch 132/150\n",
      " - 1s - loss: 0.0460 - val_loss: 0.0539\n",
      "Epoch 133/150\n",
      " - 1s - loss: 0.0458 - val_loss: 0.0539\n",
      "Epoch 134/150\n",
      " - 1s - loss: 0.0456 - val_loss: 0.0538\n",
      "Epoch 135/150\n",
      " - 1s - loss: 0.0454 - val_loss: 0.0538\n",
      "Epoch 136/150\n",
      " - 1s - loss: 0.0452 - val_loss: 0.0538\n",
      "Epoch 137/150\n",
      " - 1s - loss: 0.0450 - val_loss: 0.0539\n",
      "Epoch 138/150\n",
      " - 1s - loss: 0.0448 - val_loss: 0.0539\n",
      "Epoch 139/150\n",
      " - 1s - loss: 0.0446 - val_loss: 0.0539\n",
      "Epoch 140/150\n",
      " - 1s - loss: 0.0444 - val_loss: 0.0539\n",
      "Epoch 141/150\n",
      " - 1s - loss: 0.0442 - val_loss: 0.0539\n",
      "Epoch 142/150\n",
      " - 1s - loss: 0.0440 - val_loss: 0.0540\n",
      "Epoch 143/150\n",
      " - 1s - loss: 0.0438 - val_loss: 0.0540\n",
      "Epoch 144/150\n",
      " - 1s - loss: 0.0436 - val_loss: 0.0540\n",
      "Epoch 145/150\n",
      " - 1s - loss: 0.0434 - val_loss: 0.0541\n",
      "Epoch 146/150\n",
      " - 1s - loss: 0.0433 - val_loss: 0.0541\n",
      "Epoch 147/150\n",
      " - 1s - loss: 0.0431 - val_loss: 0.0541\n",
      "Epoch 148/150\n",
      " - 1s - loss: 0.0430 - val_loss: 0.0541\n",
      "Epoch 149/150\n",
      " - 1s - loss: 0.0428 - val_loss: 0.0542\n",
      "Epoch 150/150\n",
      " - 1s - loss: 0.0426 - val_loss: 0.0542\n",
      "[[ 0.          0.          0.         ... -1.66966356 -1.52595206\n",
      "   0.42910665]\n",
      " [ 0.          0.          0.         ... -0.68518995  0.18382914\n",
      "  -1.44451497]\n",
      " [ 0.          0.          0.         ... -0.27519047 -0.15611924\n",
      "  -0.88312418]\n",
      " ...\n",
      " [ 0.          0.          0.         ... -1.30920304 -1.39887744\n",
      "   1.01524034]\n",
      " [ 0.          0.          0.         ... -0.22766691  0.6711982\n",
      "   0.494433  ]\n",
      " [ 0.          0.          0.         ...  0.53791672  0.34693627\n",
      "   0.04429739]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[74.87093 ]\n",
      " [77.0924  ]\n",
      " [70.81241 ]\n",
      " [61.117847]\n",
      " [72.06407 ]\n",
      " [62.60753 ]\n",
      " [83.95675 ]\n",
      " [64.82088 ]\n",
      " [76.78029 ]\n",
      " [63.637226]\n",
      " [72.85804 ]\n",
      " [59.793587]\n",
      " [63.913525]\n",
      " [74.261665]\n",
      " [71.42836 ]\n",
      " [75.52963 ]\n",
      " [64.0994  ]\n",
      " [84.03121 ]\n",
      " [64.42637 ]\n",
      " [63.1882  ]\n",
      " [68.111595]\n",
      " [63.792793]\n",
      " [83.99524 ]\n",
      " [68.79386 ]\n",
      " [70.44969 ]\n",
      " [57.311565]\n",
      " [61.389088]\n",
      " [83.01357 ]\n",
      " [80.45956 ]\n",
      " [65.098366]\n",
      " [53.181828]\n",
      " [74.25245 ]\n",
      " [64.75328 ]\n",
      " [66.32595 ]\n",
      " [64.12046 ]\n",
      " [66.76507 ]\n",
      " [75.38709 ]\n",
      " [58.62745 ]\n",
      " [69.91357 ]\n",
      " [72.65422 ]\n",
      " [71.51096 ]\n",
      " [76.81411 ]\n",
      " [59.225327]\n",
      " [61.644447]\n",
      " [64.33907 ]\n",
      " [59.841393]\n",
      " [74.61882 ]\n",
      " [75.517746]\n",
      " [74.00392 ]\n",
      " [76.29652 ]\n",
      " [57.903408]\n",
      " [68.32003 ]\n",
      " [63.168854]\n",
      " [57.34187 ]\n",
      " [59.569942]\n",
      " [70.99272 ]\n",
      " [79.98103 ]\n",
      " [56.288876]\n",
      " [59.89615 ]\n",
      " [78.63417 ]\n",
      " [77.98239 ]\n",
      " [78.86535 ]\n",
      " [77.662346]\n",
      " [69.30898 ]\n",
      " [59.699707]\n",
      " [65.497055]\n",
      " [73.397446]\n",
      " [79.85325 ]\n",
      " [57.66905 ]\n",
      " [62.960606]\n",
      " [71.02245 ]\n",
      " [68.53978 ]\n",
      " [81.69659 ]\n",
      " [74.75214 ]\n",
      " [63.003033]\n",
      " [71.42739 ]\n",
      " [71.15842 ]\n",
      " [69.75289 ]\n",
      " [78.19136 ]\n",
      " [63.019306]\n",
      " [67.57144 ]\n",
      " [68.57036 ]\n",
      " [74.25625 ]\n",
      " [66.58899 ]\n",
      " [73.336006]\n",
      " [75.44464 ]\n",
      " [72.43231 ]\n",
      " [86.9908  ]\n",
      " [75.01876 ]\n",
      " [69.58171 ]\n",
      " [72.50184 ]\n",
      " [67.68812 ]\n",
      " [81.45721 ]\n",
      " [66.91558 ]\n",
      " [77.645065]\n",
      " [67.92513 ]\n",
      " [70.71141 ]\n",
      " [79.78692 ]\n",
      " [62.95036 ]\n",
      " [65.23414 ]\n",
      " [77.56773 ]\n",
      " [77.20117 ]\n",
      " [73.105225]\n",
      " [72.26966 ]\n",
      " [81.369095]\n",
      " [71.881966]\n",
      " [82.34614 ]\n",
      " [73.22855 ]\n",
      " [87.98251 ]\n",
      " [81.9493  ]\n",
      " [63.756126]\n",
      " [79.47703 ]\n",
      " [53.726643]\n",
      " [82.01167 ]\n",
      " [65.363205]\n",
      " [67.10795 ]\n",
      " [77.54937 ]\n",
      " [63.983543]\n",
      " [58.13128 ]\n",
      " [76.34134 ]\n",
      " [72.96296 ]\n",
      " [67.445305]\n",
      " [69.92739 ]\n",
      " [79.90313 ]\n",
      " [57.609684]\n",
      " [62.770134]\n",
      " [58.921814]\n",
      " [71.69498 ]\n",
      " [71.12161 ]\n",
      " [83.37222 ]\n",
      " [72.81319 ]\n",
      " [72.56803 ]\n",
      " [71.633316]\n",
      " [62.558407]\n",
      " [70.54399 ]\n",
      " [73.79015 ]\n",
      " [72.48095 ]\n",
      " [60.329777]\n",
      " [55.03144 ]\n",
      " [67.54585 ]\n",
      " [63.399853]\n",
      " [66.88531 ]\n",
      " [66.6821  ]\n",
      " [74.65005 ]\n",
      " [76.79778 ]\n",
      " [76.98438 ]\n",
      " [76.5358  ]\n",
      " [74.62444 ]\n",
      " [67.56508 ]\n",
      " [73.106575]\n",
      " [74.146774]\n",
      " [71.49464 ]\n",
      " [59.128822]\n",
      " [68.77849 ]\n",
      " [74.07757 ]\n",
      " [74.56448 ]\n",
      " [82.73325 ]\n",
      " [79.81995 ]\n",
      " [63.30473 ]\n",
      " [69.99481 ]\n",
      " [67.75206 ]\n",
      " [67.65196 ]\n",
      " [74.38254 ]\n",
      " [55.69667 ]\n",
      " [71.99332 ]\n",
      " [63.51738 ]\n",
      " [71.60221 ]\n",
      " [65.262764]\n",
      " [78.897705]\n",
      " [73.35298 ]\n",
      " [75.80936 ]\n",
      " [76.974144]\n",
      " [64.34491 ]\n",
      " [64.84153 ]\n",
      " [74.09013 ]\n",
      " [61.463295]\n",
      " [73.41553 ]\n",
      " [69.97371 ]\n",
      " [64.311905]\n",
      " [68.41736 ]\n",
      " [69.79701 ]\n",
      " [79.73475 ]\n",
      " [85.699356]\n",
      " [75.00691 ]\n",
      " [81.70912 ]\n",
      " [74.47186 ]\n",
      " [66.03466 ]\n",
      " [60.564224]\n",
      " [73.36435 ]\n",
      " [61.40461 ]\n",
      " [73.045364]\n",
      " [72.64082 ]\n",
      " [76.49    ]\n",
      " [61.38099 ]\n",
      " [71.046974]\n",
      " [77.600655]\n",
      " [72.920616]\n",
      " [82.461296]\n",
      " [84.43601 ]\n",
      " [76.32145 ]\n",
      " [61.857372]\n",
      " [67.31368 ]\n",
      " [70.75865 ]\n",
      " [75.444016]\n",
      " [67.98675 ]\n",
      " [80.26419 ]\n",
      " [82.159874]\n",
      " [57.62005 ]\n",
      " [59.03809 ]\n",
      " [64.46222 ]\n",
      " [70.31045 ]\n",
      " [72.937744]\n",
      " [70.287674]\n",
      " [76.62901 ]\n",
      " [63.13699 ]\n",
      " [60.85279 ]\n",
      " [70.31154 ]\n",
      " [70.97057 ]\n",
      " [60.94728 ]\n",
      " [79.45981 ]\n",
      " [70.64093 ]\n",
      " [80.61029 ]\n",
      " [60.756374]\n",
      " [61.077095]\n",
      " [74.16613 ]\n",
      " [87.15215 ]\n",
      " [70.49193 ]\n",
      " [73.59285 ]\n",
      " [64.85581 ]\n",
      " [75.32304 ]\n",
      " [69.75457 ]\n",
      " [68.03117 ]\n",
      " [57.70542 ]\n",
      " [78.37901 ]\n",
      " [56.328373]\n",
      " [69.72872 ]\n",
      " [64.952614]\n",
      " [60.238934]\n",
      " [73.33831 ]\n",
      " [68.54552 ]\n",
      " [72.2474  ]\n",
      " [65.61738 ]\n",
      " [68.17706 ]\n",
      " [71.64294 ]\n",
      " [67.36541 ]\n",
      " [60.03452 ]\n",
      " [64.08797 ]\n",
      " [75.26576 ]\n",
      " [73.20242 ]\n",
      " [70.10895 ]\n",
      " [67.744736]\n",
      " [67.93805 ]\n",
      " [74.811226]\n",
      " [66.47255 ]\n",
      " [64.91104 ]\n",
      " [72.40738 ]\n",
      " [80.65789 ]\n",
      " [82.04221 ]\n",
      " [63.40311 ]\n",
      " [68.426254]\n",
      " [67.609924]\n",
      " [87.88863 ]\n",
      " [60.086857]\n",
      " [68.17788 ]\n",
      " [78.55885 ]\n",
      " [69.0189  ]\n",
      " [77.55617 ]\n",
      " [73.584854]\n",
      " [71.171265]\n",
      " [76.18182 ]\n",
      " [75.188416]\n",
      " [61.968716]\n",
      " [64.86567 ]\n",
      " [56.40477 ]\n",
      " [69.4053  ]\n",
      " [68.74571 ]\n",
      " [74.40503 ]\n",
      " [73.94781 ]\n",
      " [75.92205 ]\n",
      " [70.461655]\n",
      " [69.22731 ]\n",
      " [84.50536 ]\n",
      " [68.17632 ]\n",
      " [68.603065]\n",
      " [71.62909 ]\n",
      " [80.23266 ]\n",
      " [88.20766 ]\n",
      " [75.94092 ]\n",
      " [78.44659 ]\n",
      " [65.522835]\n",
      " [66.74744 ]\n",
      " [72.77221 ]\n",
      " [71.26004 ]\n",
      " [81.853615]\n",
      " [70.72559 ]\n",
      " [67.78225 ]\n",
      " [59.072052]\n",
      " [63.613373]\n",
      " [74.166275]\n",
      " [67.16935 ]\n",
      " [71.80113 ]\n",
      " [69.57627 ]\n",
      " [78.45379 ]\n",
      " [70.75805 ]\n",
      " [76.601265]\n",
      " [63.87527 ]\n",
      " [73.63022 ]\n",
      " [61.209972]\n",
      " [73.607124]\n",
      " [73.16165 ]\n",
      " [57.6229  ]\n",
      " [73.880974]\n",
      " [81.41417 ]\n",
      " [74.64571 ]\n",
      " [79.357834]\n",
      " [66.02921 ]\n",
      " [56.68762 ]\n",
      " [75.053314]\n",
      " [64.62292 ]\n",
      " [66.04353 ]\n",
      " [62.94275 ]\n",
      " [73.66926 ]\n",
      " [66.52759 ]\n",
      " [70.81093 ]\n",
      " [77.49178 ]\n",
      " [64.8124  ]\n",
      " [77.73918 ]\n",
      " [70.72434 ]\n",
      " [62.44897 ]\n",
      " [65.71753 ]\n",
      " [77.065544]\n",
      " [63.24292 ]\n",
      " [78.97588 ]\n",
      " [78.01101 ]\n",
      " [79.96733 ]\n",
      " [64.44521 ]\n",
      " [64.70124 ]\n",
      " [70.91031 ]\n",
      " [69.87715 ]\n",
      " [74.86684 ]\n",
      " [66.19112 ]\n",
      " [76.63831 ]\n",
      " [63.26509 ]\n",
      " [71.25858 ]\n",
      " [70.81126 ]\n",
      " [66.83637 ]\n",
      " [77.09316 ]\n",
      " [66.08961 ]\n",
      " [64.46036 ]\n",
      " [69.185074]\n",
      " [58.719124]\n",
      " [70.53192 ]\n",
      " [76.11516 ]\n",
      " [70.45182 ]\n",
      " [66.556656]\n",
      " [78.369675]\n",
      " [74.461655]\n",
      " [57.130466]\n",
      " [72.608826]\n",
      " [79.69728 ]\n",
      " [67.68741 ]\n",
      " [62.887306]\n",
      " [62.74772 ]\n",
      " [61.644382]\n",
      " [83.433624]\n",
      " [61.179607]\n",
      " [67.47029 ]\n",
      " [56.041424]\n",
      " [61.845642]\n",
      " [73.61948 ]\n",
      " [64.23306 ]\n",
      " [69.52902 ]\n",
      " [72.44152 ]\n",
      " [71.06377 ]\n",
      " [82.463684]\n",
      " [61.36087 ]\n",
      " [78.72677 ]\n",
      " [73.23558 ]\n",
      " [73.67085 ]\n",
      " [73.24881 ]\n",
      " [71.07158 ]\n",
      " [78.23805 ]\n",
      " [78.2672  ]\n",
      " [66.51066 ]\n",
      " [71.51198 ]\n",
      " [81.48669 ]\n",
      " [67.73316 ]\n",
      " [68.97077 ]\n",
      " [57.39109 ]\n",
      " [74.8835  ]\n",
      " [69.45026 ]\n",
      " [58.253487]\n",
      " [69.51875 ]\n",
      " [65.51409 ]\n",
      " [74.67538 ]\n",
      " [67.7012  ]\n",
      " [68.272934]\n",
      " [77.07306 ]\n",
      " [56.316845]\n",
      " [86.34584 ]\n",
      " [71.76667 ]\n",
      " [60.198147]\n",
      " [74.12618 ]\n",
      " [71.90979 ]\n",
      " [76.281425]\n",
      " [61.0006  ]\n",
      " [57.61422 ]\n",
      " [77.0379  ]\n",
      " [70.74353 ]\n",
      " [81.102905]\n",
      " [71.540054]\n",
      " [62.216854]\n",
      " [64.02481 ]\n",
      " [82.12786 ]\n",
      " [64.818344]\n",
      " [68.55219 ]\n",
      " [68.398865]\n",
      " [81.76451 ]\n",
      " [74.43508 ]\n",
      " [56.0884  ]\n",
      " [77.142456]\n",
      " [66.29981 ]\n",
      " [71.12286 ]\n",
      " [72.24319 ]\n",
      " [71.5064  ]\n",
      " [72.36504 ]\n",
      " [64.15456 ]\n",
      " [74.68487 ]\n",
      " [75.52716 ]\n",
      " [79.55857 ]\n",
      " [60.291405]\n",
      " [61.607903]\n",
      " [72.24286 ]\n",
      " [60.72034 ]\n",
      " [59.75998 ]\n",
      " [66.07759 ]\n",
      " [72.54648 ]\n",
      " [58.643944]\n",
      " [83.30521 ]\n",
      " [75.53795 ]\n",
      " [63.818634]\n",
      " [58.869957]\n",
      " [54.60068 ]\n",
      " [71.260155]\n",
      " [59.339714]\n",
      " [75.927025]\n",
      " [73.11285 ]\n",
      " [78.351524]\n",
      " [74.5849  ]\n",
      " [59.982162]\n",
      " [74.74935 ]\n",
      " [64.196625]\n",
      " [70.90337 ]\n",
      " [67.0824  ]\n",
      " [68.96894 ]\n",
      " [57.415676]\n",
      " [61.857105]\n",
      " [72.60531 ]\n",
      " [87.2142  ]\n",
      " [69.54913 ]\n",
      " [83.494446]\n",
      " [64.791466]\n",
      " [67.89082 ]\n",
      " [82.86032 ]\n",
      " [70.30113 ]\n",
      " [72.54866 ]\n",
      " [76.44587 ]\n",
      " [63.88024 ]\n",
      " [66.02668 ]\n",
      " [79.08239 ]\n",
      " [70.4875  ]\n",
      " [60.865063]\n",
      " [71.03025 ]\n",
      " [70.429   ]\n",
      " [77.18844 ]\n",
      " [69.5468  ]\n",
      " [77.38291 ]\n",
      " [66.692764]\n",
      " [78.57953 ]\n",
      " [63.930065]\n",
      " [63.51718 ]\n",
      " [68.13809 ]\n",
      " [74.12166 ]\n",
      " [62.19032 ]\n",
      " [73.56824 ]\n",
      " [68.96177 ]\n",
      " [66.86954 ]\n",
      " [68.97386 ]\n",
      " [64.91812 ]\n",
      " [76.45006 ]\n",
      " [72.40884 ]\n",
      " [71.53295 ]\n",
      " [86.481926]\n",
      " [64.15922 ]\n",
      " [83.48947 ]\n",
      " [70.421616]\n",
      " [58.349514]\n",
      " [70.431015]\n",
      " [68.533554]\n",
      " [70.56148 ]\n",
      " [66.91324 ]\n",
      " [68.511894]\n",
      " [79.74656 ]\n",
      " [76.08086 ]\n",
      " [70.17292 ]\n",
      " [77.50361 ]\n",
      " [68.81887 ]\n",
      " [76.61821 ]\n",
      " [72.61253 ]\n",
      " [67.82171 ]\n",
      " [72.264084]\n",
      " [67.79948 ]\n",
      " [60.220737]\n",
      " [64.26717 ]\n",
      " [76.29989 ]\n",
      " [73.09463 ]\n",
      " [71.74932 ]\n",
      " [75.35771 ]\n",
      " [66.65915 ]\n",
      " [58.552162]\n",
      " [79.41092 ]\n",
      " [61.637424]\n",
      " [66.83569 ]\n",
      " [69.114624]\n",
      " [61.436607]\n",
      " [73.25393 ]\n",
      " [64.09835 ]\n",
      " [70.71892 ]\n",
      " [70.85659 ]\n",
      " [64.94854 ]\n",
      " [91.197426]\n",
      " [66.31251 ]\n",
      " [60.36341 ]\n",
      " [71.47804 ]\n",
      " [68.14693 ]\n",
      " [59.722813]\n",
      " [74.44336 ]\n",
      " [76.76191 ]\n",
      " [69.27742 ]\n",
      " [66.142365]\n",
      " [61.99825 ]\n",
      " [78.5636  ]\n",
      " [67.17014 ]\n",
      " [69.971695]\n",
      " [67.64788 ]\n",
      " [66.93145 ]\n",
      " [71.4088  ]\n",
      " [71.840866]\n",
      " [67.06438 ]\n",
      " [68.21522 ]\n",
      " [87.555   ]\n",
      " [66.05708 ]\n",
      " [64.257416]\n",
      " [63.249134]\n",
      " [72.35477 ]\n",
      " [76.69868 ]\n",
      " [66.36144 ]\n",
      " [64.55742 ]\n",
      " [54.533733]\n",
      " [82.18232 ]\n",
      " [72.77007 ]\n",
      " [73.35953 ]\n",
      " [67.727394]\n",
      " [62.473984]\n",
      " [70.24734 ]\n",
      " [72.16348 ]\n",
      " [79.84826 ]\n",
      " [60.869987]\n",
      " [67.83575 ]\n",
      " [66.71656 ]\n",
      " [69.57365 ]\n",
      " [63.092743]\n",
      " [71.75664 ]\n",
      " [68.3829  ]\n",
      " [59.940964]\n",
      " [70.98513 ]\n",
      " [60.79215 ]\n",
      " [70.073784]\n",
      " [78.37465 ]\n",
      " [67.42327 ]\n",
      " [80.47307 ]\n",
      " [60.88931 ]\n",
      " [66.364426]\n",
      " [67.8393  ]\n",
      " [81.89739 ]\n",
      " [76.67853 ]\n",
      " [67.28094 ]\n",
      " [81.79222 ]\n",
      " [64.67728 ]\n",
      " [76.17191 ]\n",
      " [73.18531 ]\n",
      " [71.58263 ]\n",
      " [77.36758 ]\n",
      " [74.04223 ]\n",
      " [64.40889 ]\n",
      " [67.52947 ]\n",
      " [67.10857 ]\n",
      " [75.71248 ]\n",
      " [78.1254  ]\n",
      " [76.36284 ]\n",
      " [65.00593 ]\n",
      " [84.034   ]\n",
      " [55.489357]\n",
      " [60.751915]\n",
      " [55.196552]\n",
      " [63.06951 ]\n",
      " [71.83444 ]\n",
      " [86.63062 ]\n",
      " [81.27801 ]\n",
      " [63.826435]\n",
      " [59.566986]\n",
      " [70.78341 ]\n",
      " [78.03831 ]\n",
      " [60.701435]\n",
      " [75.06224 ]\n",
      " [63.08955 ]\n",
      " [57.870518]\n",
      " [59.840317]\n",
      " [60.75926 ]\n",
      " [66.591484]\n",
      " [79.896866]\n",
      " [59.863304]\n",
      " [81.182465]\n",
      " [72.70161 ]\n",
      " [65.58388 ]\n",
      " [64.3401  ]\n",
      " [76.185814]\n",
      " [73.37279 ]\n",
      " [65.77918 ]\n",
      " [66.39157 ]\n",
      " [76.15665 ]\n",
      " [71.45474 ]\n",
      " [63.453083]\n",
      " [66.04825 ]\n",
      " [76.09097 ]\n",
      " [78.39871 ]\n",
      " [62.36679 ]\n",
      " [74.485275]\n",
      " [71.87951 ]\n",
      " [58.24954 ]\n",
      " [84.60669 ]\n",
      " [73.66362 ]\n",
      " [64.64645 ]\n",
      " [68.66906 ]\n",
      " [59.717007]\n",
      " [83.35448 ]\n",
      " [81.72235 ]\n",
      " [63.91715 ]\n",
      " [71.43482 ]\n",
      " [64.02623 ]\n",
      " [74.843765]\n",
      " [71.77837 ]\n",
      " [84.77689 ]\n",
      " [67.10288 ]\n",
      " [59.904182]\n",
      " [65.995415]\n",
      " [72.021225]\n",
      " [65.42069 ]\n",
      " [77.73534 ]\n",
      " [73.87345 ]\n",
      " [62.817825]\n",
      " [69.73419 ]\n",
      " [58.10489 ]\n",
      " [86.623985]\n",
      " [65.1284  ]\n",
      " [73.058304]\n",
      " [70.29319 ]\n",
      " [85.69296 ]\n",
      " [79.33249 ]\n",
      " [72.25345 ]\n",
      " [53.034657]\n",
      " [74.88686 ]\n",
      " [59.300285]\n",
      " [52.073963]\n",
      " [73.038445]\n",
      " [58.986073]\n",
      " [71.1832  ]\n",
      " [57.7944  ]\n",
      " [65.03658 ]\n",
      " [67.26373 ]\n",
      " [65.11199 ]\n",
      " [64.627014]\n",
      " [78.813324]\n",
      " [75.8305  ]\n",
      " [63.655544]\n",
      " [67.87228 ]\n",
      " [80.148224]\n",
      " [60.514034]\n",
      " [64.55956 ]\n",
      " [78.19381 ]\n",
      " [67.5971  ]\n",
      " [72.34936 ]\n",
      " [58.640213]\n",
      " [76.75336 ]\n",
      " [75.730545]\n",
      " [58.767384]\n",
      " [84.63071 ]\n",
      " [66.30476 ]\n",
      " [80.96728 ]\n",
      " [75.69112 ]\n",
      " [81.62982 ]\n",
      " [86.02997 ]\n",
      " [63.044327]\n",
      " [59.66816 ]\n",
      " [70.37671 ]\n",
      " [72.229   ]\n",
      " [64.730736]\n",
      " [64.07923 ]\n",
      " [71.32074 ]\n",
      " [63.27935 ]\n",
      " [74.900345]\n",
      " [77.994804]\n",
      " [56.016167]\n",
      " [70.62815 ]\n",
      " [70.23856 ]\n",
      " [69.12969 ]\n",
      " [64.278946]\n",
      " [67.99386 ]\n",
      " [71.89543 ]\n",
      " [72.15237 ]\n",
      " [71.36823 ]\n",
      " [86.53416 ]\n",
      " [65.60696 ]\n",
      " [75.53865 ]\n",
      " [71.00441 ]\n",
      " [70.89448 ]\n",
      " [62.5268  ]\n",
      " [55.489414]\n",
      " [64.019875]\n",
      " [61.731922]\n",
      " [70.74677 ]\n",
      " [72.955055]\n",
      " [78.84848 ]\n",
      " [70.01851 ]\n",
      " [80.46956 ]\n",
      " [71.526596]\n",
      " [67.18593 ]\n",
      " [64.27151 ]\n",
      " [73.80218 ]\n",
      " [91.40247 ]\n",
      " [62.587494]\n",
      " [59.74065 ]\n",
      " [69.75066 ]\n",
      " [55.93633 ]\n",
      " [65.21679 ]\n",
      " [68.08351 ]\n",
      " [66.24986 ]\n",
      " [71.74511 ]\n",
      " [82.93249 ]\n",
      " [69.14982 ]\n",
      " [78.42144 ]\n",
      " [67.451515]\n",
      " [64.7241  ]\n",
      " [70.40544 ]\n",
      " [66.27211 ]\n",
      " [83.92172 ]\n",
      " [72.09426 ]\n",
      " [82.14707 ]\n",
      " [58.824158]\n",
      " [64.75839 ]\n",
      " [70.93142 ]\n",
      " [71.15653 ]\n",
      " [72.05022 ]\n",
      " [62.049763]\n",
      " [77.98044 ]\n",
      " [72.36299 ]\n",
      " [69.61899 ]\n",
      " [74.035034]\n",
      " [68.55616 ]\n",
      " [65.72027 ]\n",
      " [81.1334  ]\n",
      " [64.82274 ]\n",
      " [65.33036 ]\n",
      " [83.13399 ]\n",
      " [61.571026]\n",
      " [66.94183 ]]\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LeakyReLU\n",
    "from keras.optimizers import Adam\n",
    "# fix random seed for reproducibility\n",
    "Y = Y_train/100\n",
    "print(Y)\n",
    "# create model\n",
    "model = Sequential()\n",
    "model.add(Dense(100, input_dim=50, init='RandomUniform'))\n",
    "model.add(LeakyReLU(alpha=0.1))\n",
    "model.add(Dense(50, init='RandomUniform'))\n",
    "model.add(LeakyReLU(alpha=0.1))\n",
    "model.add(Dense(100, init='RandomUniform'))\n",
    "model.add(LeakyReLU(alpha=0.1))\n",
    "model.add(Dense(1, init='RandomUniform', activation='sigmoid'))\n",
    "# Compile model\n",
    "optimizer = Adam(lr=0.000005, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
    "\n",
    "model.compile(loss='mean_absolute_error', optimizer=optimizer)\n",
    "# Fit the model\n",
    "model.fit(x=X_train_subset, y=Y, epochs=150, verbose=2, validation_split=0.1, shuffle=False, steps_per_epoch=100, initial_epoch=0, validation_steps=10)\n",
    "# calculate predictions\n",
    "print(X_test_subset)\n",
    "predictions = model.predict(X_test_subset)\n",
    "# round predictions\n",
    "#ages = [x*100 for x in predictions]\n",
    "predictions = predictions*100\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
