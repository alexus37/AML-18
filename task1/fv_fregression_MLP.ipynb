{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import csv\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_selection import RFE, f_regression\n",
    "from sklearn.linear_model import (LinearRegression, Ridge, Lasso, RandomizedLasso)\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.feature_selection import f_regression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "TRAIN_FILE_PATH = \"data/X_train.csv\"\n",
    "TARGET_FILE_PATH =  \"data/y_train.csv\"\n",
    "TEST_FILE_PATH = \"data/X_test.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Data\n",
      "\n",
      "\n",
      "Test Data\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Load train and test set\n",
    "print(\"\\nTrain Data\\n\")\n",
    "\n",
    "train_data = pd.read_csv(TRAIN_FILE_PATH)\n",
    "train_data.drop(train_data.columns[0], axis=1, inplace=True)\n",
    "\n",
    "Y_train = pd.read_csv(TARGET_FILE_PATH)\n",
    "Y_train.drop(Y_train.columns[0], axis=1, inplace = True)\n",
    "\n",
    "print(\"\\nTest Data\\n\")\n",
    "\n",
    "test_data =  pd.read_csv(TEST_FILE_PATH)\n",
    "id_test = test_data.columns[0]\n",
    "#test_data.drop(test_data.columns[0], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill missing values with mean column values train and test set\n",
    "def fill_NaN(train, test):\n",
    "    print(\"Train shape: \", train.shape)\n",
    "    print(\"Test shape: \",test.shape)\n",
    "    train_mean_values = train.mean()\n",
    "    train =  train.fillna(train_mean_values)\n",
    "    test = test.fillna(train_mean_values)\n",
    "    \n",
    "    return train,test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape:  (1212, 887)\n",
      "Test shape:  (776, 887)\n"
     ]
    }
   ],
   "source": [
    "train_data_mean, test_data_mean = fill_NaN(train_data, test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Zero mean unit variance for train and test data\n",
    "def scale_data(train, test):\n",
    "    \n",
    "    print(\"Train shape: \", train.shape)\n",
    "    print(\"Test shape: \",test.shape)\n",
    "    scaler = StandardScaler().fit(train, Y_train)\n",
    "    #print(train_data_mean.shape)\n",
    "    #print(test_data_mean.shape)\n",
    "    train = scaler.transform(train)\n",
    "    test = scaler.transform(test)\n",
    "   \n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape:  (1212, 887)\n",
      "Test shape:  (776, 887)\n"
     ]
    }
   ],
   "source": [
    "X_train_scaled, X_test_scaled = scale_data(train_data_mean, test_data_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1212, 887)\n",
      "(1212, 1)\n",
      "[3.17463281e+02 3.09312060e+02 3.07583691e+02 2.85601310e+02\n",
      " 2.78761802e+02 2.78148971e+02 2.73253960e+02 2.52760516e+02\n",
      " 2.43972974e+02 2.43891857e+02 2.42925703e+02 2.38413283e+02\n",
      " 2.00450421e+02 1.88501078e+02 1.87394892e+02 1.85534631e+02\n",
      " 1.83031939e+02 1.77067457e+02 1.73985580e+02 1.72904968e+02\n",
      " 1.63621244e+02 1.59121648e+02 1.58715436e+02 1.58235651e+02\n",
      " 1.58076335e+02 1.54792017e+02 1.51246158e+02 1.50905309e+02\n",
      " 1.50059132e+02 1.44974863e+02 1.41936780e+02 1.41853063e+02\n",
      " 1.38327690e+02 1.37595239e+02 1.36981311e+02 1.33495247e+02\n",
      " 1.29886104e+02 1.27973959e+02 1.27868471e+02 1.27800779e+02\n",
      " 1.23643847e+02 1.21575634e+02 1.19960216e+02 1.17397751e+02\n",
      " 1.16924717e+02 1.16108916e+02 1.15126528e+02 1.14374064e+02\n",
      " 1.12846943e+02 1.11589434e+02 1.11331764e+02 1.09974839e+02\n",
      " 1.08125510e+02 1.05072321e+02 1.01706441e+02 9.78253813e+01\n",
      " 9.36728322e+01 9.31268014e+01 9.19324055e+01 8.80093999e+01\n",
      " 8.72718824e+01 8.72661510e+01 8.71275443e+01 8.69762456e+01\n",
      " 8.68645955e+01 8.55099219e+01 8.50443724e+01 8.06440325e+01\n",
      " 8.05646740e+01 7.84146923e+01 7.68576424e+01 7.68384004e+01\n",
      " 7.53617506e+01 7.44081608e+01 7.39634918e+01 7.16282924e+01\n",
      " 7.15200164e+01 7.11714036e+01 7.08866698e+01 6.97952426e+01\n",
      " 6.86722946e+01 6.83127280e+01 6.80871879e+01 6.77418318e+01\n",
      " 6.76317170e+01 6.72384378e+01 6.72313711e+01 6.71705679e+01\n",
      " 6.69290075e+01 6.66590259e+01 6.65711900e+01 6.64607161e+01\n",
      " 6.61563789e+01 6.61092024e+01 6.59369554e+01 6.52885004e+01\n",
      " 6.51129886e+01 6.49625405e+01 6.42661907e+01 6.42494335e+01\n",
      " 6.41829453e+01 6.40582614e+01 6.33370184e+01 6.32295885e+01\n",
      " 6.31258565e+01 6.24496078e+01 6.23156622e+01 6.21525243e+01\n",
      " 6.18159032e+01 6.17734295e+01 6.15198614e+01 6.10093556e+01\n",
      " 6.05048973e+01 6.00496105e+01 5.96652746e+01 5.92582258e+01\n",
      " 5.92182232e+01 5.91340796e+01 5.89862213e+01 5.86396500e+01\n",
      " 5.79539244e+01 5.78679185e+01 5.71484597e+01 5.69413600e+01\n",
      " 5.67269529e+01 5.65492831e+01 5.63985157e+01 5.63488901e+01\n",
      " 5.62899407e+01 5.62357282e+01 5.56351712e+01 5.53460020e+01\n",
      " 5.49612950e+01 5.49330629e+01 5.42939967e+01 5.41969143e+01\n",
      " 5.39640171e+01 5.39028834e+01 5.38521450e+01 5.38408479e+01\n",
      " 5.36232755e+01 5.25371986e+01 5.18614857e+01 5.15601763e+01\n",
      " 5.13704225e+01 5.13293891e+01 5.12487597e+01 5.11098319e+01\n",
      " 5.10041394e+01 5.09720141e+01 4.95028631e+01 4.84144474e+01\n",
      " 4.82310644e+01 4.70029364e+01 4.65340182e+01 4.64290649e+01\n",
      " 4.61466255e+01 4.61180482e+01 4.60906329e+01 4.49646820e+01\n",
      " 4.36634315e+01 4.32335679e+01 4.28233143e+01 4.15873109e+01\n",
      " 4.07013376e+01 4.06019339e+01 4.01445440e+01 3.99674148e+01\n",
      " 3.86166206e+01 3.69670842e+01 3.68482095e+01 3.66718382e+01\n",
      " 3.60727627e+01 3.59345907e+01 3.26831875e+01 3.08642734e+01\n",
      " 3.06215092e+01 2.73471504e+01 2.60898634e+01 2.60763752e+01\n",
      " 2.57844537e+01 2.49892703e+01 2.47241877e+01 2.42205418e+01\n",
      " 2.41657391e+01 2.38422170e+01 2.37651432e+01 2.33961905e+01\n",
      " 2.27744385e+01 2.27357305e+01 2.25205944e+01 2.24236744e+01\n",
      " 2.12491617e+01 1.99537452e+01 1.90041014e+01 1.89374084e+01\n",
      " 1.80127315e+01 1.66598478e+01 1.59464689e+01 1.58963927e+01\n",
      " 1.55600580e+01 1.48173085e+01 1.38003428e+01 1.33959657e+01\n",
      " 1.08627496e+01 1.04829733e+01 9.69697511e+00 9.21804894e+00\n",
      " 9.20065337e+00 8.62189165e+00 8.59404010e+00 8.44315410e+00\n",
      " 8.33098688e+00 8.21623929e+00 7.70099373e+00 7.59057460e+00\n",
      " 7.40138536e+00 7.34863492e+00 7.01859797e+00 6.65424170e+00\n",
      " 6.40242684e+00 6.00518930e+00 5.55851004e+00 5.36461722e+00\n",
      " 5.03723256e+00 5.01597460e+00 4.91014971e+00 4.71206769e+00\n",
      " 4.68971228e+00 4.59101297e+00 4.58300670e+00 4.56814784e+00\n",
      " 4.42976480e+00 4.40491635e+00 4.35977746e+00 4.33525125e+00\n",
      " 4.27954711e+00 4.26654331e+00 4.16053777e+00 4.08402527e+00\n",
      " 4.06282639e+00 3.94131986e+00 3.92146247e+00 3.79734925e+00\n",
      " 3.78907275e+00 3.78076272e+00 3.75929598e+00 3.62513109e+00\n",
      " 3.58570893e+00 3.58415725e+00 3.52074436e+00 3.48820590e+00\n",
      " 3.38513091e+00 3.37680901e+00 3.37091907e+00 3.34286812e+00\n",
      " 3.31711308e+00 3.31264382e+00 3.29889064e+00 3.29539593e+00\n",
      " 3.26080783e+00 3.14974687e+00 3.14649552e+00 3.13955824e+00\n",
      " 3.13500392e+00 3.12871533e+00 3.10820566e+00 3.05188564e+00\n",
      " 3.02129099e+00 2.97520443e+00 2.95828365e+00 2.92918235e+00\n",
      " 2.89532749e+00 2.88163101e+00 2.81347032e+00 2.73961346e+00\n",
      " 2.73472224e+00 2.72181451e+00 2.71635118e+00 2.69507209e+00\n",
      " 2.64282449e+00 2.62525793e+00 2.61029011e+00 2.58314507e+00\n",
      " 2.56489379e+00 2.50161732e+00 2.49458747e+00 2.48491194e+00\n",
      " 2.46284084e+00 2.45395111e+00 2.39479766e+00 2.35889100e+00\n",
      " 2.33422925e+00 2.32523268e+00 2.31965642e+00 2.30445410e+00\n",
      " 2.28387059e+00 2.26065388e+00 2.23924056e+00 2.23539072e+00\n",
      " 2.22297591e+00 2.22038346e+00 2.19752173e+00 2.16303099e+00\n",
      " 2.15390000e+00 2.14979260e+00 2.14602059e+00 2.14465207e+00\n",
      " 2.13628375e+00 2.13118444e+00 2.11689776e+00 2.08887381e+00\n",
      " 2.08171333e+00 2.05860918e+00 2.05046647e+00 2.04719871e+00\n",
      " 2.01412244e+00 2.01211016e+00 2.00864818e+00 1.94509877e+00\n",
      " 1.93393411e+00 1.92015841e+00 1.89943583e+00 1.88506567e+00\n",
      " 1.87144070e+00 1.85232694e+00 1.82710068e+00 1.82199936e+00\n",
      " 1.81037660e+00 1.80504302e+00 1.80022077e+00 1.76421203e+00\n",
      " 1.76017634e+00 1.75405954e+00 1.72695890e+00 1.69536545e+00\n",
      " 1.67986386e+00 1.67501723e+00 1.67324659e+00 1.66742816e+00\n",
      " 1.66523690e+00 1.63853491e+00 1.63175997e+00 1.62136489e+00\n",
      " 1.60846739e+00 1.60765478e+00 1.57377820e+00 1.56645370e+00\n",
      " 1.56202060e+00 1.54320174e+00 1.52376260e+00 1.52118551e+00\n",
      " 1.50925780e+00 1.50920348e+00 1.50851632e+00 1.48831197e+00\n",
      " 1.47407886e+00 1.44586896e+00 1.43301035e+00 1.43055567e+00\n",
      " 1.39814254e+00 1.39169607e+00 1.38924972e+00 1.38900472e+00\n",
      " 1.38209438e+00 1.37972586e+00 1.37917865e+00 1.37094592e+00\n",
      " 1.36212974e+00 1.36097976e+00 1.34300312e+00 1.34010583e+00\n",
      " 1.31644393e+00 1.28573173e+00 1.27354201e+00 1.26523132e+00\n",
      " 1.24786094e+00 1.24292510e+00 1.24096941e+00 1.22024617e+00\n",
      " 1.20290993e+00 1.18988748e+00 1.18790475e+00 1.18499171e+00\n",
      " 1.17752789e+00 1.17659955e+00 1.16875664e+00 1.15864169e+00\n",
      " 1.14955675e+00 1.14648161e+00 1.13745879e+00 1.13433446e+00\n",
      " 1.13224970e+00 1.13169062e+00 1.12428129e+00 1.11694277e+00\n",
      " 1.11352810e+00 1.10639487e+00 1.10587184e+00 1.10030233e+00\n",
      " 1.09083162e+00 1.08737995e+00 1.08551986e+00 1.07437964e+00\n",
      " 1.06147708e+00 1.03112049e+00 1.03098383e+00 1.01810228e+00\n",
      " 1.01414675e+00 1.01155039e+00 9.96908085e-01 9.94580309e-01\n",
      " 9.90944789e-01 9.90759226e-01 9.90342077e-01 9.89505909e-01\n",
      " 9.79377643e-01 9.75534046e-01 9.75114042e-01 9.68130440e-01\n",
      " 9.59032744e-01 9.58038017e-01 9.43616955e-01 9.41651337e-01\n",
      " 9.39210599e-01 9.26550443e-01 9.23888383e-01 9.18162479e-01\n",
      " 9.17956103e-01 9.02406685e-01 8.86558445e-01 8.85340948e-01\n",
      " 8.77142142e-01 8.72260126e-01 8.29506035e-01 8.26111948e-01\n",
      " 8.25799929e-01 8.24845406e-01 8.16214408e-01 8.04296304e-01\n",
      " 8.02759184e-01 8.02395760e-01 7.88886928e-01 7.86729452e-01\n",
      " 7.85116797e-01 7.81554404e-01 7.75515976e-01 7.75407607e-01\n",
      " 7.71555918e-01 7.63125845e-01 7.60519260e-01 7.57184244e-01\n",
      " 7.56500993e-01 7.55072395e-01 7.52463027e-01 7.51030209e-01\n",
      " 7.45613986e-01 7.40523543e-01 7.33371193e-01 7.28457973e-01\n",
      " 7.21533794e-01 7.14591445e-01 7.13598258e-01 7.10246322e-01\n",
      " 7.09619600e-01 7.06963805e-01 7.01447983e-01 6.99187331e-01\n",
      " 6.97012377e-01 6.91664181e-01 6.86902502e-01 6.83716924e-01\n",
      " 6.80958210e-01 6.78045096e-01 6.77106754e-01 6.70052801e-01\n",
      " 6.68519651e-01 6.67597012e-01 6.66658553e-01 6.65672476e-01\n",
      " 6.65012809e-01 6.63130072e-01 6.62874107e-01 6.56285487e-01\n",
      " 6.55975980e-01 6.54763004e-01 6.53044764e-01 6.52041198e-01\n",
      " 6.48689164e-01 6.47036216e-01 6.44038164e-01 6.38789004e-01\n",
      " 6.35244616e-01 6.29516241e-01 6.29261426e-01 6.20056196e-01\n",
      " 6.17318685e-01 6.13818221e-01 6.11151662e-01 6.10010591e-01\n",
      " 6.09195913e-01 6.07639006e-01 5.98578613e-01 5.86062611e-01\n",
      " 5.81973780e-01 5.80009864e-01 5.59215674e-01 5.53836709e-01\n",
      " 5.53440775e-01 5.53219842e-01 5.50976155e-01 5.49858468e-01\n",
      " 5.49572213e-01 5.49257896e-01 5.48019130e-01 5.46501761e-01\n",
      " 5.45531113e-01 5.45503636e-01 5.38304758e-01 5.36203255e-01\n",
      " 5.31998993e-01 5.22752575e-01 5.21222491e-01 5.20717351e-01\n",
      " 5.14675083e-01 5.14030867e-01 5.12511986e-01 5.07882124e-01\n",
      " 5.07708997e-01 4.96894180e-01 4.89644042e-01 4.88737478e-01\n",
      " 4.87721617e-01 4.87366389e-01 4.87284420e-01 4.86375381e-01\n",
      " 4.80312795e-01 4.78361207e-01 4.71502191e-01 4.68621103e-01\n",
      " 4.63399236e-01 4.62519559e-01 4.62192742e-01 4.56794671e-01\n",
      " 4.41257733e-01 4.40754425e-01 4.39828911e-01 4.37465087e-01\n",
      " 4.35323160e-01 4.32545735e-01 4.27923109e-01 4.23510055e-01\n",
      " 4.19915937e-01 4.17954112e-01 4.15025826e-01 4.10142186e-01\n",
      " 4.08663627e-01 4.04475679e-01 4.01265530e-01 4.00367711e-01\n",
      " 4.00004670e-01 3.93025362e-01 3.87315908e-01 3.86469093e-01\n",
      " 3.84958262e-01 3.80225800e-01 3.74124315e-01 3.73908675e-01\n",
      " 3.72015323e-01 3.71981236e-01 3.71100864e-01 3.66107415e-01\n",
      " 3.63517053e-01 3.61690528e-01 3.57218454e-01 3.55509660e-01\n",
      " 3.53952290e-01 3.52174595e-01 3.50706878e-01 3.50624840e-01\n",
      " 3.46088655e-01 3.45994167e-01 3.38307340e-01 3.36878247e-01\n",
      " 3.33941398e-01 3.32027522e-01 3.31237170e-01 3.30311531e-01\n",
      " 3.13597787e-01 3.06065296e-01 3.02774548e-01 3.02603554e-01\n",
      " 2.99661783e-01 2.97163327e-01 2.97037608e-01 2.95509907e-01\n",
      " 2.92359224e-01 2.91180201e-01 2.90557570e-01 2.87772693e-01\n",
      " 2.86787862e-01 2.85843098e-01 2.83998381e-01 2.83825636e-01\n",
      " 2.79743664e-01 2.74005937e-01 2.73878275e-01 2.68493745e-01\n",
      " 2.65167808e-01 2.63577909e-01 2.61430786e-01 2.57375499e-01\n",
      " 2.55318377e-01 2.53768069e-01 2.49259894e-01 2.44945146e-01\n",
      " 2.43066902e-01 2.41021070e-01 2.38461773e-01 2.37455545e-01\n",
      " 2.36357322e-01 2.35945485e-01 2.34857057e-01 2.34074786e-01\n",
      " 2.26139599e-01 2.23653401e-01 2.23318671e-01 2.18044575e-01\n",
      " 2.12622607e-01 2.11488032e-01 2.10211702e-01 2.08737616e-01\n",
      " 2.06792355e-01 2.04326609e-01 2.04028243e-01 2.03824054e-01\n",
      " 2.03556006e-01 2.01322155e-01 2.00819743e-01 1.97748238e-01\n",
      " 1.95394016e-01 1.94893806e-01 1.94359921e-01 1.93421707e-01\n",
      " 1.91245662e-01 1.90311714e-01 1.84350466e-01 1.83770267e-01\n",
      " 1.83728235e-01 1.80939877e-01 1.79583324e-01 1.77555162e-01\n",
      " 1.74185224e-01 1.69816023e-01 1.67424102e-01 1.66987139e-01\n",
      " 1.64806916e-01 1.64225322e-01 1.62422962e-01 1.55344999e-01\n",
      " 1.54243723e-01 1.53951916e-01 1.53747177e-01 1.53644668e-01\n",
      " 1.53469624e-01 1.53371564e-01 1.52336730e-01 1.52179785e-01\n",
      " 1.51691964e-01 1.49316017e-01 1.49118229e-01 1.47520867e-01\n",
      " 1.47344340e-01 1.46800408e-01 1.45783384e-01 1.45223590e-01\n",
      " 1.44595463e-01 1.44543554e-01 1.43503038e-01 1.42540150e-01\n",
      " 1.41387848e-01 1.41052429e-01 1.36026537e-01 1.35905167e-01\n",
      " 1.35757388e-01 1.34830845e-01 1.34276593e-01 1.32100127e-01\n",
      " 1.31462819e-01 1.31333465e-01 1.29468985e-01 1.27596457e-01\n",
      " 1.24626840e-01 1.23880754e-01 1.21311224e-01 1.20727579e-01\n",
      " 1.20059700e-01 1.18850430e-01 1.18013649e-01 1.16807053e-01\n",
      " 1.16050831e-01 1.14151174e-01 1.11536591e-01 1.08805868e-01\n",
      " 1.08628170e-01 1.08178377e-01 1.06043412e-01 1.05541359e-01\n",
      " 1.04727642e-01 1.00188441e-01 9.58811423e-02 9.44527315e-02\n",
      " 9.29376185e-02 9.11875338e-02 9.11479687e-02 9.11440371e-02\n",
      " 8.85473309e-02 8.73169617e-02 8.68928037e-02 8.64039922e-02\n",
      " 8.59554285e-02 8.52936773e-02 8.45971315e-02 8.39733931e-02\n",
      " 8.33337542e-02 8.11429580e-02 7.94176539e-02 7.91874238e-02\n",
      " 7.90253175e-02 7.88132786e-02 7.82684861e-02 7.54846131e-02\n",
      " 7.43602913e-02 7.38924923e-02 7.34853704e-02 7.07968990e-02\n",
      " 6.92185192e-02 6.76809345e-02 6.65844415e-02 6.59398461e-02\n",
      " 6.55226651e-02 6.53403903e-02 6.52163654e-02 6.43305700e-02\n",
      " 6.32783066e-02 6.12224986e-02 6.04606629e-02 6.04084585e-02\n",
      " 5.95530476e-02 5.94262483e-02 5.75281325e-02 5.71122584e-02\n",
      " 5.70034080e-02 5.65245131e-02 5.56761724e-02 5.49350463e-02\n",
      " 5.48853896e-02 5.29642129e-02 5.04422754e-02 4.99407186e-02\n",
      " 4.93307786e-02 4.84925313e-02 4.72131829e-02 4.69333476e-02\n",
      " 4.40180771e-02 4.21366110e-02 4.16682396e-02 4.12281307e-02\n",
      " 4.10912792e-02 4.08681779e-02 4.04896128e-02 3.71488245e-02\n",
      " 3.55365972e-02 3.44298374e-02 3.32603441e-02 3.31109807e-02\n",
      " 3.30105200e-02 3.25262786e-02 3.24794252e-02 3.23742401e-02\n",
      " 3.21494763e-02 3.05556112e-02 2.98688462e-02 2.96933210e-02\n",
      " 2.92181314e-02 2.87946036e-02 2.84066135e-02 2.81771113e-02\n",
      " 2.66975607e-02 2.66949994e-02 2.66530581e-02 2.58061500e-02\n",
      " 2.49890043e-02 2.45420278e-02 2.44668287e-02 2.41836440e-02\n",
      " 2.38504451e-02 2.25317887e-02 2.25027168e-02 2.23887256e-02\n",
      " 2.08290794e-02 2.03023755e-02 2.02049900e-02 2.01047535e-02\n",
      " 1.98215573e-02 1.88014772e-02 1.87759570e-02 1.79822582e-02\n",
      " 1.76260844e-02 1.73637986e-02 1.71821477e-02 1.66931178e-02\n",
      " 1.50447500e-02 1.47963989e-02 1.45846106e-02 1.35969293e-02\n",
      " 1.21719820e-02 1.19172290e-02 1.14852771e-02 1.12702246e-02\n",
      " 1.08964636e-02 1.05164634e-02 1.03856014e-02 1.01290128e-02\n",
      " 9.95064150e-03 9.47554752e-03 9.31165744e-03 8.94112183e-03\n",
      " 8.74823434e-03 7.82396880e-03 7.71633023e-03 7.65962377e-03\n",
      " 7.62649107e-03 7.35937845e-03 7.17362549e-03 7.07591717e-03\n",
      " 7.00921073e-03 6.54574038e-03 6.18872194e-03 5.80769387e-03\n",
      " 4.87056943e-03 4.13939287e-03 3.85360428e-03 3.84970923e-03\n",
      " 3.60067314e-03 3.40121562e-03 3.14713993e-03 3.10895499e-03\n",
      " 3.03654201e-03 2.84400824e-03 2.82440586e-03 2.77363261e-03\n",
      " 2.50427782e-03 2.48825812e-03 2.47966501e-03 2.37243417e-03\n",
      " 2.33418995e-03 2.21139515e-03 2.10684693e-03 1.78159263e-03\n",
      " 1.67223819e-03 1.39797034e-03 1.35971696e-03 1.27885456e-03\n",
      " 1.18812166e-03 9.05392199e-04 8.86107536e-04 8.56521434e-04\n",
      " 7.18570551e-04 4.38980332e-04 4.02622197e-04 3.69146727e-04\n",
      " 3.14335002e-04 2.68016054e-04 2.40644375e-04 9.48861553e-05\n",
      " 6.15573431e-05 4.51941262e-05 4.50657513e-05 3.30410008e-05\n",
      " 8.87765512e-06 2.72909488e-06 2.26606189e-06            nan\n",
      "            nan            nan            nan]\n",
      "[731 772 523 493 746  82 685 333 391 722 882 751 291   0  96 349 730 687\n",
      " 363 673 340 664 604 185 838 300 180 309 665 686 608 744 297 345 853 490\n",
      " 547 636  80 613 470 234 156 810 120 430 232 370 426  89 142 137 196 736\n",
      "  42 237 332 634 111 201  85 871 505 520 229 460 224 560 554 205 372 643\n",
      "  83 666  52 735 644 556 273 646 607 633   5 298 251  94 335 787 741 398\n",
      " 716 388 186  88 739 326 158 615 484 632 840 638 652 637 791 660 609 618\n",
      " 752 266 833 794   7 605 367  28 763 299 424 504 351 804 371 275 870 879\n",
      " 795  66 198  32 457 823 611 151 781 450 697 269 277 599 209 479 844 135\n",
      " 374 369 336 166 428  20]\n",
      "150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/francesco/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/francesco/anaconda3/lib/python3.6/site-packages/sklearn/feature_selection/univariate_selection.py:298: RuntimeWarning: invalid value encountered in true_divide\n",
      "  corr /= X_norms\n",
      "/home/francesco/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater\n",
      "  return (self.a < x) & (x < self.b)\n",
      "/home/francesco/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less\n",
      "  return (self.a < x) & (x < self.b)\n",
      "/home/francesco/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal\n",
      "  cond2 = cond0 & (x <= self.a)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Extract the features to use\n",
    "\n",
    "n_features_fr = 150\n",
    "\n",
    "print(X_train_scaled.shape)\n",
    "print(Y_train.shape)\n",
    "features_scores = f_regression(X_train_scaled,Y_train)[0]\n",
    "#print(features_scores)\n",
    "y = list(features_scores)\n",
    "myarray = np.asarray(y)\n",
    "print(-1*np.sort(-1*myarray))\n",
    "#print(-1*np.sort(myarray-1))\n",
    "plt.plot(-1*np.sort(-1*myarray))\n",
    "\n",
    "indices_fr = myarray.argsort()[-n_features_fr:][::-1]\n",
    "print(indices_fr)\n",
    "print(len(indices_fr))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/francesco/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:6: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 1 of 50building tree 2 of 50\n",
      "building tree 3 of 50\n",
      "building tree 4 of 50\n",
      "building tree 5 of 50\n",
      "\n",
      "building tree 6 of 50\n",
      "building tree 7 of 50\n",
      "building tree 8 of 50\n",
      "building tree 9 of 50\n",
      "building tree 10 of 50\n",
      "building tree 11 of 50\n",
      "building tree 12 of 50\n",
      "building tree 13 of 50\n",
      "building tree 14 of 50\n",
      "building tree 15 of 50\n",
      "building tree 16 of 50\n",
      "building tree 17 of 50\n",
      "building tree 18 of 50\n",
      "building tree 19 of 50\n",
      "building tree 20 of 50\n",
      "building tree 21 of 50\n",
      "building tree 22 of 50\n",
      "building tree 23 of 50\n",
      "building tree 24 of 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    1.6s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 25 of 50\n",
      "building tree 26 of 50\n",
      "building tree 27 of 50\n",
      "building tree 28 of 50\n",
      "building tree 29 of 50\n",
      "building tree 30 of 50\n",
      "building tree 31 of 50\n",
      "building tree 32 of 50\n",
      "building tree 33 of 50\n",
      "building tree 34 of 50\n",
      "building tree 35 of 50\n",
      "building tree 36 of 50\n",
      "building tree 37 of 50\n",
      "building tree 38 of 50\n",
      "building tree 39 of 50\n",
      "building tree 40 of 50\n",
      "building tree 41 of 50\n",
      "building tree 42 of 50\n",
      "building tree 43 of 50\n",
      "building tree 44 of 50\n",
      "building tree 45 of 50\n",
      "building tree 46 of 50\n",
      "building tree 47 of 50\n",
      "building tree 48 of 50\n",
      "building tree 49 of 50\n",
      "building tree 50 of 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:    5.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.28394970e-01 7.30731801e-02 4.26041065e-02 3.12476385e-02\n",
      " 1.78416624e-02 1.43293849e-02 1.33050657e-02 1.08193317e-02\n",
      " 1.07282115e-02 1.04330796e-02 9.81135699e-03 9.69823351e-03\n",
      " 6.41281727e-03 6.07811729e-03 4.73579108e-03 4.57249844e-03\n",
      " 4.56533185e-03 4.36602201e-03 4.11366518e-03 3.77652732e-03\n",
      " 3.69093724e-03 3.44975713e-03 3.42902632e-03 3.33829596e-03\n",
      " 3.21770449e-03 3.08304645e-03 3.06977910e-03 3.02269079e-03\n",
      " 2.95235887e-03 2.84707023e-03 2.75106418e-03 2.58615638e-03\n",
      " 2.54747034e-03 2.54616279e-03 2.53715935e-03 2.45018968e-03\n",
      " 2.31774206e-03 2.31491715e-03 2.30882487e-03 2.30633847e-03\n",
      " 2.29245116e-03 2.19278182e-03 2.08859299e-03 2.07879392e-03\n",
      " 2.05089143e-03 2.04468112e-03 2.03494910e-03 1.98423878e-03\n",
      " 1.93460860e-03 1.93037611e-03 1.89971061e-03 1.88055364e-03\n",
      " 1.86348384e-03 1.86333520e-03 1.85306055e-03 1.84838101e-03\n",
      " 1.83376812e-03 1.80648146e-03 1.73731289e-03 1.73325079e-03\n",
      " 1.73187170e-03 1.73032809e-03 1.72938690e-03 1.72854430e-03\n",
      " 1.71859803e-03 1.65390855e-03 1.63348518e-03 1.62983002e-03\n",
      " 1.62043911e-03 1.61252680e-03 1.57806591e-03 1.54001827e-03\n",
      " 1.53787527e-03 1.51874725e-03 1.50942879e-03 1.49940282e-03\n",
      " 1.49166619e-03 1.48108739e-03 1.45582299e-03 1.44965099e-03\n",
      " 1.43931956e-03 1.42132326e-03 1.41872193e-03 1.38788667e-03\n",
      " 1.36006461e-03 1.33682716e-03 1.31908932e-03 1.29375628e-03\n",
      " 1.28943585e-03 1.25246946e-03 1.24212815e-03 1.23468454e-03\n",
      " 1.22281343e-03 1.22063937e-03 1.20757888e-03 1.19887175e-03\n",
      " 1.18040474e-03 1.17735050e-03 1.16941715e-03 1.16875877e-03\n",
      " 1.15547586e-03 1.15413096e-03 1.15205734e-03 1.14757848e-03\n",
      " 1.14152531e-03 1.13523943e-03 1.13196165e-03 1.12805744e-03\n",
      " 1.11174657e-03 1.10943393e-03 1.10655328e-03 1.10017339e-03\n",
      " 1.09119579e-03 1.08651822e-03 1.06533565e-03 1.06496977e-03\n",
      " 1.06108953e-03 1.05138205e-03 1.04670067e-03 1.04483374e-03\n",
      " 1.03923304e-03 1.03486863e-03 1.03155388e-03 1.03119198e-03\n",
      " 1.02626258e-03 1.02603411e-03 1.02439054e-03 1.01981981e-03\n",
      " 1.01679862e-03 1.01611041e-03 1.00479314e-03 1.00243425e-03\n",
      " 9.91405203e-04 9.90190230e-04 9.89055213e-04 9.82461691e-04\n",
      " 9.80353166e-04 9.77726660e-04 9.67609453e-04 9.55466173e-04\n",
      " 9.48445477e-04 9.34366072e-04 9.30244534e-04 9.30089307e-04\n",
      " 9.26401321e-04 9.23532596e-04 9.21548235e-04 9.20820438e-04\n",
      " 9.12341552e-04 9.05996633e-04 8.95956906e-04 8.85630528e-04\n",
      " 8.79023961e-04 8.77492377e-04 8.73876948e-04 8.69517522e-04\n",
      " 8.66227105e-04 8.65249003e-04 8.58540971e-04 8.53265169e-04\n",
      " 8.50878343e-04 8.43878569e-04 8.43433861e-04 8.41945531e-04\n",
      " 8.39952376e-04 8.38800625e-04 8.38586362e-04 8.36683785e-04\n",
      " 8.35616123e-04 8.35140673e-04 8.24994421e-04 8.24609865e-04\n",
      " 8.23135424e-04 8.21806430e-04 8.20051854e-04 8.18180029e-04\n",
      " 7.99479621e-04 7.96053855e-04 7.85471014e-04 7.84530095e-04\n",
      " 7.83459598e-04 7.81371436e-04 7.77219825e-04 7.76020061e-04\n",
      " 7.73599995e-04 7.64440142e-04 7.64350650e-04 7.63609955e-04\n",
      " 7.61155780e-04 7.56837839e-04 7.53615832e-04 7.50512336e-04\n",
      " 7.48003147e-04 7.46299645e-04 7.36661148e-04 7.36289737e-04\n",
      " 7.34980724e-04 7.34002831e-04 7.25951835e-04 7.25108951e-04\n",
      " 7.22901687e-04 7.19666155e-04 7.18105411e-04 7.17719621e-04\n",
      " 7.17620063e-04 7.17099401e-04 7.14816500e-04 7.13834527e-04\n",
      " 7.10065050e-04 7.09386188e-04 7.08587833e-04 7.04061136e-04\n",
      " 7.01942885e-04 7.01735311e-04 6.98175144e-04 6.96958750e-04\n",
      " 6.95256670e-04 6.94945678e-04 6.92153175e-04 6.91639518e-04\n",
      " 6.88327776e-04 6.87720601e-04 6.85715119e-04 6.82696174e-04\n",
      " 6.80835723e-04 6.79047780e-04 6.77207088e-04 6.76778319e-04\n",
      " 6.76573394e-04 6.75748749e-04 6.73868316e-04 6.72163663e-04\n",
      " 6.71284430e-04 6.70596051e-04 6.70515295e-04 6.69716550e-04\n",
      " 6.69421044e-04 6.68812115e-04 6.63877432e-04 6.61367138e-04\n",
      " 6.60598966e-04 6.57951443e-04 6.55758492e-04 6.53080151e-04\n",
      " 6.52618274e-04 6.52045092e-04 6.50681717e-04 6.50607722e-04\n",
      " 6.48235303e-04 6.47319576e-04 6.46537331e-04 6.45990743e-04\n",
      " 6.44451900e-04 6.43773779e-04 6.42019356e-04 6.41953411e-04\n",
      " 6.41318663e-04 6.41010055e-04 6.37585342e-04 6.36300116e-04\n",
      " 6.35808363e-04 6.35780465e-04 6.33829945e-04 6.33805137e-04\n",
      " 6.27179483e-04 6.26636559e-04 6.25470308e-04 6.24112923e-04\n",
      " 6.22366485e-04 6.20361370e-04 6.19688224e-04 6.19340880e-04\n",
      " 6.19195040e-04 6.19021129e-04 6.18443517e-04 6.17038807e-04\n",
      " 6.14871281e-04 6.14720889e-04 6.13921573e-04 6.13117841e-04\n",
      " 6.11794727e-04 6.10161947e-04 6.09712307e-04 6.07953271e-04\n",
      " 6.03977342e-04 6.03056025e-04 5.99503912e-04 5.99208133e-04\n",
      " 5.97163400e-04 5.92587287e-04 5.89959649e-04 5.85062337e-04\n",
      " 5.84993465e-04 5.80261574e-04 5.79749065e-04 5.77901160e-04\n",
      " 5.75204763e-04 5.74201167e-04 5.71300365e-04 5.71229228e-04\n",
      " 5.67547936e-04 5.67360162e-04 5.65573358e-04 5.64634055e-04\n",
      " 5.63987532e-04 5.62970363e-04 5.62778244e-04 5.60404766e-04\n",
      " 5.57254742e-04 5.56160153e-04 5.56141696e-04 5.53027436e-04\n",
      " 5.52301630e-04 5.51752884e-04 5.51682600e-04 5.49538910e-04\n",
      " 5.47507631e-04 5.46336618e-04 5.44978558e-04 5.44396283e-04\n",
      " 5.44040025e-04 5.42570084e-04 5.42430533e-04 5.39586810e-04\n",
      " 5.39272170e-04 5.34728147e-04 5.29960056e-04 5.29084234e-04\n",
      " 5.27891965e-04 5.27195179e-04 5.26757996e-04 5.25291281e-04\n",
      " 5.24192799e-04 5.24045797e-04 5.21913985e-04 5.20953184e-04\n",
      " 5.18935136e-04 5.18562219e-04 5.18337286e-04 5.17274143e-04\n",
      " 5.15475909e-04 5.15341857e-04 5.15135309e-04 5.14889087e-04\n",
      " 5.14569822e-04 5.14567316e-04 5.11251085e-04 5.09979281e-04\n",
      " 5.09347826e-04 5.07990004e-04 5.06566823e-04 5.06546412e-04\n",
      " 5.06266538e-04 5.05092670e-04 5.04712450e-04 5.03731073e-04\n",
      " 5.01431039e-04 4.96311913e-04 4.95864594e-04 4.94547216e-04\n",
      " 4.93326342e-04 4.92694507e-04 4.92675501e-04 4.92646176e-04\n",
      " 4.92566854e-04 4.91238622e-04 4.89881256e-04 4.88973118e-04\n",
      " 4.88661501e-04 4.88382146e-04 4.87422459e-04 4.86541376e-04\n",
      " 4.84062016e-04 4.83743289e-04 4.80836407e-04 4.80496007e-04\n",
      " 4.80066849e-04 4.78933991e-04 4.77325157e-04 4.76131510e-04\n",
      " 4.76007050e-04 4.74318210e-04 4.74204658e-04 4.73524552e-04\n",
      " 4.73273765e-04 4.73044075e-04 4.72340039e-04 4.72101955e-04\n",
      " 4.71337618e-04 4.68693896e-04 4.67178774e-04 4.65851482e-04\n",
      " 4.65034414e-04 4.64768796e-04 4.63117366e-04 4.62270042e-04\n",
      " 4.60940608e-04 4.60799542e-04 4.60541619e-04 4.59095695e-04\n",
      " 4.58930932e-04 4.58895609e-04 4.56620634e-04 4.55152253e-04\n",
      " 4.55090893e-04 4.54849774e-04 4.54282701e-04 4.53693010e-04\n",
      " 4.52859812e-04 4.52053064e-04 4.50042896e-04 4.49235109e-04\n",
      " 4.48875215e-04 4.47439114e-04 4.47382468e-04 4.47264688e-04\n",
      " 4.45321839e-04 4.45062631e-04 4.44937923e-04 4.43839594e-04\n",
      " 4.43629232e-04 4.42036790e-04 4.40251269e-04 4.37774494e-04\n",
      " 4.36128558e-04 4.33483899e-04 4.32251812e-04 4.31641733e-04\n",
      " 4.29967414e-04 4.29888253e-04 4.29381942e-04 4.29190590e-04\n",
      " 4.29073732e-04 4.29071238e-04 4.28790615e-04 4.28430342e-04\n",
      " 4.27866674e-04 4.27706922e-04 4.25138072e-04 4.24894338e-04\n",
      " 4.21675418e-04 4.20708511e-04 4.20660908e-04 4.19539931e-04\n",
      " 4.18167915e-04 4.17213340e-04 4.14327080e-04 4.13295274e-04\n",
      " 4.10061257e-04 4.09770664e-04 4.09635463e-04 4.08873719e-04\n",
      " 4.06658745e-04 4.06220905e-04 4.04290987e-04 4.03743152e-04\n",
      " 4.03171080e-04 4.03083971e-04 4.00349048e-04 3.99489239e-04\n",
      " 3.99147997e-04 3.96935293e-04 3.96386165e-04 3.95618330e-04\n",
      " 3.94495543e-04 3.93571166e-04 3.93245434e-04 3.92927367e-04\n",
      " 3.92865283e-04 3.92452817e-04 3.92449257e-04 3.91724704e-04\n",
      " 3.91589580e-04 3.90821040e-04 3.90693244e-04 3.89664591e-04\n",
      " 3.88966521e-04 3.88508886e-04 3.87929424e-04 3.85481245e-04\n",
      " 3.85318290e-04 3.85065525e-04 3.84871435e-04 3.84713669e-04\n",
      " 3.84378547e-04 3.84267045e-04 3.82787553e-04 3.82307779e-04\n",
      " 3.81837876e-04 3.81740054e-04 3.81503942e-04 3.80801066e-04\n",
      " 3.80643236e-04 3.80507045e-04 3.80316414e-04 3.80211948e-04\n",
      " 3.75972024e-04 3.75841639e-04 3.75229394e-04 3.74618304e-04\n",
      " 3.74405154e-04 3.74178096e-04 3.74096395e-04 3.72259230e-04\n",
      " 3.71750175e-04 3.69977010e-04 3.69444108e-04 3.67336053e-04\n",
      " 3.66281299e-04 3.66259529e-04 3.65836691e-04 3.65604636e-04\n",
      " 3.65468771e-04 3.64483125e-04 3.64377182e-04 3.62833545e-04\n",
      " 3.61154237e-04 3.61094980e-04 3.60912798e-04 3.58480769e-04\n",
      " 3.56276157e-04 3.53846419e-04 3.53482491e-04 3.50772655e-04\n",
      " 3.50186862e-04 3.49998229e-04 3.49248780e-04 3.48269464e-04\n",
      " 3.46809488e-04 3.44185754e-04 3.44099272e-04 3.43454056e-04\n",
      " 3.43312524e-04 3.42660069e-04 3.42019873e-04 3.41908766e-04\n",
      " 3.39358384e-04 3.38299023e-04 3.38199871e-04 3.38069616e-04\n",
      " 3.36488153e-04 3.36412636e-04 3.36411548e-04 3.36272759e-04\n",
      " 3.35898166e-04 3.35346027e-04 3.34466832e-04 3.34424869e-04\n",
      " 3.32870382e-04 3.32534571e-04 3.31919193e-04 3.31464332e-04\n",
      " 3.29747219e-04 3.29713729e-04 3.29259470e-04 3.28911604e-04\n",
      " 3.25857259e-04 3.25558913e-04 3.25494130e-04 3.25255348e-04\n",
      " 3.24674990e-04 3.23625393e-04 3.22448445e-04 3.22435751e-04\n",
      " 3.22372640e-04 3.22104249e-04 3.22000547e-04 3.21603119e-04\n",
      " 3.21280542e-04 3.21043027e-04 3.20980362e-04 3.20842039e-04\n",
      " 3.20174353e-04 3.19594476e-04 3.19464251e-04 3.18979898e-04\n",
      " 3.18863939e-04 3.18301137e-04 3.17268262e-04 3.16017991e-04\n",
      " 3.15944703e-04 3.15489513e-04 3.14608998e-04 3.13320045e-04\n",
      " 3.12304493e-04 3.09564101e-04 3.09378805e-04 3.08644897e-04\n",
      " 3.08106831e-04 3.07505302e-04 3.07433907e-04 3.07122925e-04\n",
      " 3.06745093e-04 3.06477584e-04 3.06294531e-04 3.04288878e-04\n",
      " 3.03933737e-04 3.03369168e-04 3.02801798e-04 3.02214972e-04\n",
      " 3.01862010e-04 3.00095337e-04 2.98500836e-04 2.98294870e-04\n",
      " 2.97526365e-04 2.97146280e-04 2.97027121e-04 2.96057086e-04\n",
      " 2.95790862e-04 2.94775544e-04 2.94704376e-04 2.94396899e-04\n",
      " 2.92690436e-04 2.92068972e-04 2.90772355e-04 2.90574174e-04\n",
      " 2.90442101e-04 2.89456774e-04 2.88466815e-04 2.88117282e-04\n",
      " 2.86048829e-04 2.83841444e-04 2.83049561e-04 2.82651020e-04\n",
      " 2.80400885e-04 2.80229709e-04 2.79764349e-04 2.79611653e-04\n",
      " 2.79560096e-04 2.78743036e-04 2.78633131e-04 2.78439983e-04\n",
      " 2.77431562e-04 2.76918520e-04 2.75852862e-04 2.75610746e-04\n",
      " 2.73800297e-04 2.73372759e-04 2.72358826e-04 2.71869236e-04\n",
      " 2.71311861e-04 2.71083104e-04 2.70723719e-04 2.70008233e-04\n",
      " 2.70000339e-04 2.69374203e-04 2.69329458e-04 2.67244592e-04\n",
      " 2.65507019e-04 2.65120272e-04 2.62893229e-04 2.62207147e-04\n",
      " 2.62052494e-04 2.61073825e-04 2.61066836e-04 2.58587009e-04\n",
      " 2.57452133e-04 2.55411343e-04 2.52897867e-04 2.52684400e-04\n",
      " 2.52501960e-04 2.52388231e-04 2.51808420e-04 2.51794833e-04\n",
      " 2.51294407e-04 2.50829288e-04 2.49817446e-04 2.49689387e-04\n",
      " 2.48467393e-04 2.47598484e-04 2.46892175e-04 2.45783687e-04\n",
      " 2.45720427e-04 2.45318853e-04 2.44005269e-04 2.43146414e-04\n",
      " 2.43010467e-04 2.42818054e-04 2.41585264e-04 2.41469880e-04\n",
      " 2.41386227e-04 2.39187361e-04 2.36445591e-04 2.34764372e-04\n",
      " 2.34386427e-04 2.31668695e-04 2.31619778e-04 2.31603209e-04\n",
      " 2.31334461e-04 2.30310755e-04 2.28405266e-04 2.28311359e-04\n",
      " 2.27302301e-04 2.27067648e-04 2.26874696e-04 2.25971023e-04\n",
      " 2.25122798e-04 2.25038373e-04 2.24723893e-04 2.23946860e-04\n",
      " 2.23671119e-04 2.23540914e-04 2.21144751e-04 2.19680677e-04\n",
      " 2.19246981e-04 2.17642580e-04 2.17453294e-04 2.17306333e-04\n",
      " 2.17197289e-04 2.16340519e-04 2.16156257e-04 2.15834800e-04\n",
      " 2.15053334e-04 2.15050422e-04 2.14939923e-04 2.14876585e-04\n",
      " 2.14098715e-04 2.11141124e-04 2.10920062e-04 2.10389804e-04\n",
      " 2.10331033e-04 2.09509153e-04 2.08988913e-04 2.08567671e-04\n",
      " 2.07238045e-04 2.05995976e-04 2.03307447e-04 2.02300964e-04\n",
      " 1.98432239e-04 1.97972065e-04 1.97878819e-04 1.97627838e-04\n",
      " 1.97382574e-04 1.96419484e-04 1.95444492e-04 1.94650223e-04\n",
      " 1.94459211e-04 1.94370885e-04 1.94186469e-04 1.93068492e-04\n",
      " 1.92580558e-04 1.92194299e-04 1.88548934e-04 1.84487809e-04\n",
      " 1.84213540e-04 1.83338522e-04 1.82851776e-04 1.82635602e-04\n",
      " 1.82537857e-04 1.82520166e-04 1.82314298e-04 1.81635462e-04\n",
      " 1.81410384e-04 1.80628875e-04 1.80379556e-04 1.77686548e-04\n",
      " 1.77556730e-04 1.75469842e-04 1.75175040e-04 1.74896970e-04\n",
      " 1.74569761e-04 1.74018125e-04 1.73980640e-04 1.73647884e-04\n",
      " 1.72927750e-04 1.72530544e-04 1.72500781e-04 1.71595360e-04\n",
      " 1.71397185e-04 1.70917095e-04 1.70165224e-04 1.69805301e-04\n",
      " 1.66496255e-04 1.65966233e-04 1.65181481e-04 1.65097355e-04\n",
      " 1.65027371e-04 1.64598871e-04 1.63961551e-04 1.63437010e-04\n",
      " 1.63198384e-04 1.62212996e-04 1.62072466e-04 1.61587262e-04\n",
      " 1.61187970e-04 1.60801463e-04 1.60716156e-04 1.59756782e-04\n",
      " 1.57233301e-04 1.53374888e-04 1.53278452e-04 1.52746197e-04\n",
      " 1.51657635e-04 1.50215612e-04 1.49406864e-04 1.49067290e-04\n",
      " 1.48659470e-04 1.47828615e-04 1.47475680e-04 1.46450641e-04\n",
      " 1.46054192e-04 1.45989829e-04 1.45710471e-04 1.45057392e-04\n",
      " 1.43243526e-04 1.41260978e-04 1.41019397e-04 1.40712853e-04\n",
      " 1.40299487e-04 1.40264453e-04 1.39891509e-04 1.36946700e-04\n",
      " 1.35297646e-04 1.34618331e-04 1.34609361e-04 1.33748021e-04\n",
      " 1.33376231e-04 1.33348754e-04 1.33271929e-04 1.32275506e-04\n",
      " 1.31688807e-04 1.30717004e-04 1.30176098e-04 1.29907769e-04\n",
      " 1.27708795e-04 1.27149497e-04 1.25798385e-04 1.25427944e-04\n",
      " 1.24560796e-04 1.24530010e-04 1.24330467e-04 1.22092792e-04\n",
      " 1.20991808e-04 1.20258930e-04 1.17593025e-04 1.17467099e-04\n",
      " 1.16904692e-04 1.16699656e-04 1.14493104e-04 1.14254639e-04\n",
      " 1.11778856e-04 1.10301000e-04 1.10041829e-04 1.09745430e-04\n",
      " 1.08989837e-04 1.08585558e-04 1.08404188e-04 1.08401824e-04\n",
      " 1.08349082e-04 1.08260874e-04 1.07012257e-04 1.05105073e-04\n",
      " 1.02882721e-04 1.00691524e-04 9.82265767e-05 9.68469459e-05\n",
      " 9.32454999e-05 9.18162375e-05 9.11393168e-05 9.07908207e-05\n",
      " 9.04111850e-05 9.03992772e-05 9.00055718e-05 8.94162009e-05\n",
      " 8.13728499e-05 8.11628129e-05 7.78187999e-05 7.63233119e-05\n",
      " 7.52815514e-05 7.48939812e-05 7.12122418e-05 6.71699914e-05\n",
      " 6.64097729e-05 6.22327818e-05 6.19160095e-05 5.86835829e-05\n",
      " 5.73550176e-05 5.72199942e-05 5.64122886e-05 5.53073264e-05\n",
      " 3.62791359e-05 2.99173423e-05 2.68983146e-05 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      "[ 96 685 722  82 664 291 746 499 751 882 391  80 237 687 470 651 547 604\n",
      " 185 686 871 763 349 234 400 273 340 853 410 810 555   0 744 142 665 426\n",
      " 835 591  89 224 309 450 716 430 559 644 618 479   5 424 186 238 838 484\n",
      " 196 673 350 816 546 334 730 697 609 529 811 823 643 300 522 198 536 388\n",
      "  12  94 140 520 457  88 178 370  39 363 250 135 800 870 750 817 739 205\n",
      " 554 613 608 201  18 792  60 752  32 326]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Extract feature importance of Random Forest & find intersection with f_regression one\n",
    "\n",
    "n_features_rf = 100\n",
    "\n",
    "rf = RandomForestRegressor(n_jobs=-1, n_estimators=50, verbose=3)\n",
    "rf.fit(X_train_scaled,Y_train)\n",
    "\n",
    "scores = list(rf.feature_importances_)\n",
    "my_rf_features = np.asarray(scores)\n",
    "print(-1*np.sort(-1*my_rf_features))\n",
    "#print(-1*np.sort(myarray-1))\n",
    "plt.plot((-1*np.sort(-1*my_rf_features))[0:200])\n",
    "\n",
    "indices_rf = my_rf_features.argsort()[-n_features_rf:][::-1]\n",
    "print(indices_rf)\n",
    "#print(-1*np.sort(-1*rf.feature_importances_));\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  0   5   7  12  18  20  28  32  39  42  52  60  66  80  82  83  85  88\n",
      "  89  94  96 111 120 135 137 140 142 151 156 158 166 178 180 185 186 196\n",
      " 198 201 205 209 224 229 232 234 237 238 250 251 266 269 273 275 277 291\n",
      " 297 298 299 300 309 326 332 333 334 335 336 340 345 349 350 351 363 367\n",
      " 369 370 371 372 374 388 391 398 400 410 424 426 428 430 450 457 460 470\n",
      " 479 484 490 493 499 504 505 520 522 523 529 536 546 547 554 555 556 559\n",
      " 560 591 599 604 605 607 608 609 611 613 615 618 632 633 634 636 637 638\n",
      " 643 644 646 651 652 660 664 665 666 673 685 686 687 697 716 722 730 731\n",
      " 735 736 739 741 744 746 750 751 752 763 772 781 787 791 792 794 795 800\n",
      " 804 810 811 816 817 823 833 835 838 840 844 853 870 871 879 882]\n"
     ]
    }
   ],
   "source": [
    "# Find intersection between best f_regression features and random forest's\n",
    "\n",
    "#print(set(indices_rf).intersection(indices_fr))\n",
    "\n",
    "#indices = set(indices_rf).intersection(indices_fr)\n",
    "indices = np.union1d(indices_rf, indices_fr)\n",
    "print(indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape:  (1212, 178)\n",
      "Test shape:  (776, 178)\n",
      "Train shape:  (1212, 178)\n",
      "Test shape:  (776, 178)\n",
      "(1212, 178)\n"
     ]
    }
   ],
   "source": [
    "#Extract the feature selected from dataset\n",
    "\n",
    "#indices = indices_rf\n",
    "#indices = indices_fr\n",
    "indices = list(indices)\n",
    "\n",
    "X_train_subset = train_data_mean[train_data_mean.columns[indices]]\n",
    "X_test_subset = test_data_mean[train_data_mean.columns[indices]]\n",
    "\n",
    "#print(X_subset.head(1))\n",
    "\n",
    "X_train_subset, X_test_subset = fill_NaN(X_train_subset, X_test_subset)\n",
    "X_train_subset, X_test_subset = scale_data(X_train_subset, X_test_subset)\n",
    "\n",
    "print(X_train_subset.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/francesco/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:1306: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 2448.78627045\n",
      "Validation score: -52.883935\n",
      "Iteration 2, loss = 2329.22285537\n",
      "Validation score: -50.717433\n",
      "Iteration 3, loss = 2239.08660436\n",
      "Validation score: -48.813341\n",
      "Iteration 4, loss = 2154.98609248\n",
      "Validation score: -46.909513\n",
      "Iteration 5, loss = 2069.01342318\n",
      "Validation score: -44.904162\n",
      "Iteration 6, loss = 1979.02136627\n",
      "Validation score: -42.885823\n",
      "Iteration 7, loss = 1890.36114840\n",
      "Validation score: -40.929949\n",
      "Iteration 8, loss = 1805.41792614\n",
      "Validation score: -39.093777\n",
      "Iteration 9, loss = 1725.44342513\n",
      "Validation score: -37.338606\n",
      "Iteration 10, loss = 1648.59083859\n",
      "Validation score: -35.659618\n",
      "Iteration 11, loss = 1575.50996297\n",
      "Validation score: -34.046934\n",
      "Iteration 12, loss = 1505.10203614\n",
      "Validation score: -32.502340\n",
      "Iteration 13, loss = 1437.64526734\n",
      "Validation score: -30.998213\n",
      "Iteration 14, loss = 1370.39596577\n",
      "Validation score: -29.431636\n",
      "Iteration 15, loss = 1301.13837053\n",
      "Validation score: -27.923319\n",
      "Iteration 16, loss = 1235.92809213\n",
      "Validation score: -26.484707\n",
      "Iteration 17, loss = 1172.10093700\n",
      "Validation score: -25.004644\n",
      "Iteration 18, loss = 1106.29604127\n",
      "Validation score: -23.562110\n",
      "Iteration 19, loss = 1044.53983593\n",
      "Validation score: -22.212294\n",
      "Iteration 20, loss = 986.10569450\n",
      "Validation score: -20.934150\n",
      "Iteration 21, loss = 930.84792379\n",
      "Validation score: -19.725484\n",
      "Iteration 22, loss = 878.74635285\n",
      "Validation score: -18.581583\n",
      "Iteration 23, loss = 829.33649396\n",
      "Validation score: -17.500374\n",
      "Iteration 24, loss = 782.79929860\n",
      "Validation score: -16.471987\n",
      "Iteration 25, loss = 738.03447959\n",
      "Validation score: -15.457565\n",
      "Iteration 26, loss = 692.46170995\n",
      "Validation score: -14.407817\n",
      "Iteration 27, loss = 647.93954921\n",
      "Validation score: -13.437773\n",
      "Iteration 28, loss = 606.28173685\n",
      "Validation score: -12.526007\n",
      "Iteration 29, loss = 567.23813454\n",
      "Validation score: -11.670308\n",
      "Iteration 30, loss = 530.69344256\n",
      "Validation score: -10.867836\n",
      "Iteration 31, loss = 496.46714404\n",
      "Validation score: -10.119204\n",
      "Iteration 32, loss = 464.71986528\n",
      "Validation score: -9.418080\n",
      "Iteration 33, loss = 434.87631748\n",
      "Validation score: -8.764770\n",
      "Iteration 34, loss = 407.27930504\n",
      "Validation score: -8.153407\n",
      "Iteration 35, loss = 381.33372741\n",
      "Validation score: -7.581805\n",
      "Iteration 36, loss = 357.23018906\n",
      "Validation score: -7.046456\n",
      "Iteration 37, loss = 334.46890348\n",
      "Validation score: -6.547667\n",
      "Iteration 38, loss = 313.47312326\n",
      "Validation score: -6.079038\n",
      "Iteration 39, loss = 293.54203264\n",
      "Validation score: -5.642630\n",
      "Iteration 40, loss = 275.32566454\n",
      "Validation score: -5.232424\n",
      "Iteration 41, loss = 258.07591605\n",
      "Validation score: -4.850503\n",
      "Iteration 42, loss = 242.14110445\n",
      "Validation score: -4.492667\n",
      "Iteration 43, loss = 227.23227138\n",
      "Validation score: -4.158808\n",
      "Iteration 44, loss = 213.22148755\n",
      "Validation score: -3.849037\n",
      "Iteration 45, loss = 200.31712589\n",
      "Validation score: -3.559566\n",
      "Iteration 46, loss = 188.32305434\n",
      "Validation score: -3.289042\n",
      "Iteration 47, loss = 177.17177915\n",
      "Validation score: -3.037747\n",
      "Iteration 48, loss = 166.73353449\n",
      "Validation score: -2.803495\n",
      "Iteration 49, loss = 157.13245459\n",
      "Validation score: -2.582887\n",
      "Iteration 50, loss = 148.01825504\n",
      "Validation score: -2.377287\n",
      "Iteration 51, loss = 139.54962886\n",
      "Validation score: -2.177708\n",
      "Iteration 52, loss = 131.10979405\n",
      "Validation score: -1.975585\n",
      "Iteration 53, loss = 122.84808429\n",
      "Validation score: -1.785799\n",
      "Iteration 54, loss = 115.26452975\n",
      "Validation score: -1.611534\n",
      "Iteration 55, loss = 108.26546001\n",
      "Validation score: -1.452503\n",
      "Iteration 56, loss = 101.94712989\n",
      "Validation score: -1.307136\n",
      "Iteration 57, loss = 96.19148712\n",
      "Validation score: -1.175564\n",
      "Iteration 58, loss = 91.04951777\n",
      "Validation score: -1.056812\n",
      "Iteration 59, loss = 86.43502787\n",
      "Validation score: -0.949860\n",
      "Iteration 60, loss = 82.25757981\n",
      "Validation score: -0.853780\n",
      "Iteration 61, loss = 78.58251201\n",
      "Validation score: -0.766720\n",
      "Iteration 62, loss = 75.30071309\n",
      "Validation score: -0.688266\n",
      "Iteration 63, loss = 72.33101254\n",
      "Validation score: -0.617682\n",
      "Iteration 64, loss = 69.68733562\n",
      "Validation score: -0.553445\n",
      "Iteration 65, loss = 67.27424542\n",
      "Validation score: -0.494274\n",
      "Iteration 66, loss = 65.03773437\n",
      "Validation score: -0.438332\n",
      "Iteration 67, loss = 62.93712979\n",
      "Validation score: -0.383846\n",
      "Iteration 68, loss = 60.94952715\n",
      "Validation score: -0.335536\n",
      "Iteration 69, loss = 59.24333613\n",
      "Validation score: -0.293130\n",
      "Iteration 70, loss = 57.79474125\n",
      "Validation score: -0.254948\n",
      "Iteration 71, loss = 56.31668777\n",
      "Validation score: -0.221667\n",
      "Iteration 72, loss = 54.78316994\n",
      "Validation score: -0.188138\n",
      "Iteration 73, loss = 52.24446243\n",
      "Validation score: -0.122200\n",
      "Iteration 74, loss = 48.81195786\n",
      "Validation score: -0.071656\n",
      "Iteration 75, loss = 46.76580011\n",
      "Validation score: -0.017340\n",
      "Iteration 76, loss = 44.90856726\n",
      "Validation score: 0.029691\n",
      "Iteration 77, loss = 42.93285263\n",
      "Validation score: 0.064720\n",
      "Iteration 78, loss = 41.77956894\n",
      "Validation score: 0.102905\n",
      "Iteration 79, loss = 40.38307253\n",
      "Validation score: 0.128105\n",
      "Iteration 80, loss = 39.09356010\n",
      "Validation score: 0.154281\n",
      "Iteration 81, loss = 38.05296870\n",
      "Validation score: 0.186279\n",
      "Iteration 82, loss = 36.88756579\n",
      "Validation score: 0.212955\n",
      "Iteration 83, loss = 35.96858757\n",
      "Validation score: 0.231477\n",
      "Iteration 84, loss = 35.26221353\n",
      "Validation score: 0.247852\n",
      "Iteration 85, loss = 34.54310306\n",
      "Validation score: 0.263497\n",
      "Iteration 86, loss = 33.88776647\n",
      "Validation score: 0.280665\n",
      "Iteration 87, loss = 33.32410470\n",
      "Validation score: 0.294693\n",
      "Iteration 88, loss = 32.64852286\n",
      "Validation score: 0.307097\n",
      "Iteration 89, loss = 32.07449336\n",
      "Validation score: 0.320841\n",
      "Iteration 90, loss = 31.58221159\n",
      "Validation score: 0.333633\n",
      "Iteration 91, loss = 31.24452072\n",
      "Validation score: 0.343656\n",
      "Iteration 92, loss = 30.74809078\n",
      "Validation score: 0.351874\n",
      "Iteration 93, loss = 30.47595841\n",
      "Validation score: 0.362856\n",
      "Iteration 94, loss = 30.04431220\n",
      "Validation score: 0.371855\n",
      "Iteration 95, loss = 29.74230128\n",
      "Validation score: 0.379579\n",
      "Iteration 96, loss = 29.49330310\n",
      "Validation score: 0.384850\n",
      "Iteration 97, loss = 29.17298424\n",
      "Validation score: 0.391988\n",
      "Iteration 98, loss = 28.96056533\n",
      "Validation score: 0.400012\n",
      "Iteration 99, loss = 28.58763560\n",
      "Validation score: 0.405982\n",
      "Iteration 100, loss = 28.36494076\n",
      "Validation score: 0.411359\n",
      "Iteration 101, loss = 28.16880246\n",
      "Validation score: 0.417258\n",
      "Iteration 102, loss = 28.05947659\n",
      "Validation score: 0.418464\n",
      "Iteration 103, loss = 27.76801934\n",
      "Validation score: 0.421463\n",
      "Iteration 104, loss = 27.57953446\n",
      "Validation score: 0.430809\n",
      "Iteration 105, loss = 27.36320865\n",
      "Validation score: 0.437065\n",
      "Iteration 106, loss = 27.14919691\n",
      "Validation score: 0.441606\n",
      "Iteration 107, loss = 26.96377910\n",
      "Validation score: 0.445852\n",
      "Iteration 108, loss = 26.85386207\n",
      "Validation score: 0.449481\n",
      "Iteration 109, loss = 26.70962394\n",
      "Validation score: 0.452961\n",
      "Iteration 110, loss = 26.49602885\n",
      "Validation score: 0.457063\n",
      "Iteration 111, loss = 26.34234974\n",
      "Validation score: 0.460068\n",
      "Iteration 112, loss = 26.32350356\n",
      "Validation score: 0.461300\n",
      "Iteration 113, loss = 26.20742581\n",
      "Validation score: 0.464312\n",
      "Iteration 114, loss = 25.94141955\n",
      "Validation score: 0.468362\n",
      "Iteration 115, loss = 25.78833326\n",
      "Validation score: 0.472078\n",
      "Iteration 116, loss = 25.63751817\n",
      "Validation score: 0.474077\n",
      "Iteration 117, loss = 25.52390152\n",
      "Validation score: 0.474936\n",
      "Iteration 118, loss = 25.33543383\n",
      "Validation score: 0.476528\n",
      "Iteration 119, loss = 25.29989985\n",
      "Validation score: 0.481740\n",
      "Iteration 120, loss = 25.17099566\n",
      "Validation score: 0.483921\n",
      "Iteration 121, loss = 25.08781644\n",
      "Validation score: 0.483203\n",
      "Iteration 122, loss = 24.92843057\n",
      "Validation score: 0.482906\n",
      "Iteration 123, loss = 24.89711178\n",
      "Validation score: 0.485995\n",
      "Iteration 124, loss = 24.78927603\n",
      "Validation score: 0.488786\n",
      "Iteration 125, loss = 24.69406519\n",
      "Validation score: 0.489883\n",
      "Iteration 126, loss = 24.53560487\n",
      "Validation score: 0.493687\n",
      "Iteration 127, loss = 24.53883021\n",
      "Validation score: 0.494806\n",
      "Iteration 128, loss = 24.36824544\n",
      "Validation score: 0.497337\n",
      "Iteration 129, loss = 24.29731235\n",
      "Validation score: 0.498535\n",
      "Iteration 130, loss = 24.19902152\n",
      "Validation score: 0.498637\n",
      "Iteration 131, loss = 24.11344891\n",
      "Validation score: 0.499175\n",
      "Iteration 132, loss = 24.08098991\n",
      "Validation score: 0.499384\n",
      "Iteration 133, loss = 23.98605585\n",
      "Validation score: 0.499390\n",
      "Iteration 134, loss = 23.88641172\n",
      "Validation score: 0.500569\n",
      "Iteration 135, loss = 23.91426108\n",
      "Validation score: 0.503595\n",
      "Iteration 136, loss = 23.87057417\n",
      "Validation score: 0.504190\n",
      "Iteration 137, loss = 23.72269813\n",
      "Validation score: 0.505049\n",
      "Iteration 138, loss = 23.70888044\n",
      "Validation score: 0.503844\n",
      "Iteration 139, loss = 23.64058148\n",
      "Validation score: 0.504489\n",
      "Iteration 140, loss = 23.60319658\n",
      "Validation score: 0.504065\n",
      "Validation score did not improve more than tol=0.000000 for two consecutive epochs. Stopping.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPRegressor(activation='logistic', alpha=0.1, batch_size='auto', beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=True, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(50, 30), learning_rate='constant',\n",
       "       learning_rate_init=0.01, max_iter=15000, momentum=0.9,\n",
       "       nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
       "       shuffle=True, solver='adam', tol=1e-11, validation_fraction=0.1,\n",
       "       verbose=True, warm_start=False)"
      ]
     },
     "execution_count": 351,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model = MLPRegressor(batch_size = 200,validation_fraction=0.05, verbose=True, tol = 0.00000001,learning_rate_init=0.0001)\n",
    "\n",
    "model = MLPRegressor(learning_rate='constant', \n",
    "                         hidden_layer_sizes=(50,30),\n",
    "                         activation='logistic', \n",
    "                         learning_rate_init=0.01,\n",
    "                         max_iter=15000, \n",
    "                         early_stopping =True,\n",
    "                         validation_fraction=0.1,\n",
    "                         tol=0.00000000001,\n",
    "                         alpha=0.1,\n",
    "                         #n_iter_no_change=100,\n",
    "                         verbose=True)\n",
    "model.fit(X_train_subset,Y_train)\n",
    "\n",
    "#score = cross_val_score((model), X_train_subset, Y_train, scoring='r2', cv=4)\n",
    "#print(score.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_pred = model.predict(X_test_subset)\n",
    "test_data[\"y\"] = predictions\n",
    "#print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create submission\n",
    "test_data[[\"id\", \"y\"]].to_csv(\"submissions/keras_deep_dropout_regul.csv\", index= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.47870539796991196\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_train_subset)\n",
    "from sklearn.metrics import r2_score\n",
    "score = r2_score(Y, y_pred)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/francesco/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:20: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(30, input_dim=178, kernel_regularizer=<keras.reg..., kernel_initializer=\"RandomUniform\")`\n",
      "/home/francesco/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:23: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(30, input_dim=72, kernel_regularizer=<keras.reg..., kernel_initializer=\"RandomUniform\")`\n",
      "/home/francesco/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:26: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(30, input_dim=72, kernel_regularizer=<keras.reg..., kernel_initializer=\"RandomUniform\")`\n",
      "/home/francesco/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:29: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(30, input_dim=72, kernel_regularizer=<keras.reg..., kernel_initializer=\"RandomUniform\")`\n",
      "/home/francesco/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:32: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(30, input_dim=72, kernel_regularizer=<keras.reg..., kernel_initializer=\"RandomUniform\")`\n",
      "/home/francesco/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:35: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(30, input_dim=72, kernel_regularizer=<keras.reg..., kernel_initializer=\"RandomUniform\")`\n",
      "/home/francesco/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:38: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(30, input_dim=72, kernel_regularizer=<keras.reg..., kernel_initializer=\"RandomUniform\")`\n",
      "/home/francesco/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:41: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(30, input_dim=72, kernel_regularizer=<keras.reg..., kernel_initializer=\"RandomUniform\")`\n",
      "/home/francesco/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:45: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(1, kernel_initializer=\"RandomUniform\")`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1090 samples, validate on 122 samples\n",
      "Epoch 1/80\n",
      " - 2s - loss: 3875.2985 - coeff_determination: -3.7919e+01 - val_loss: 219.7609 - val_coeff_determination: -6.5776e-01\n",
      "Epoch 2/80\n",
      " - 0s - loss: 303.4930 - coeff_determination: -1.4598e+00 - val_loss: 100.2047 - val_coeff_determination: 0.5318\n",
      "Epoch 3/80\n",
      " - 0s - loss: 244.1433 - coeff_determination: -9.3584e-01 - val_loss: 86.0929 - val_coeff_determination: 0.6224\n",
      "Epoch 4/80\n",
      " - 0s - loss: 223.5158 - coeff_determination: -7.6545e-01 - val_loss: 81.5962 - val_coeff_determination: 0.6380\n",
      "Epoch 5/80\n",
      " - 0s - loss: 211.0848 - coeff_determination: -6.7211e-01 - val_loss: 89.8660 - val_coeff_determination: 0.5202\n",
      "Epoch 6/80\n",
      " - 0s - loss: 202.0537 - coeff_determination: -6.0246e-01 - val_loss: 80.9346 - val_coeff_determination: 0.5952\n",
      "Epoch 7/80\n",
      " - 0s - loss: 195.0695 - coeff_determination: -5.4764e-01 - val_loss: 76.7336 - val_coeff_determination: 0.6270\n",
      "Epoch 8/80\n",
      " - 0s - loss: 186.7333 - coeff_determination: -4.7632e-01 - val_loss: 76.0812 - val_coeff_determination: 0.6211\n",
      "Epoch 9/80\n",
      " - 0s - loss: 177.7909 - coeff_determination: -3.9626e-01 - val_loss: 73.7257 - val_coeff_determination: 0.6367\n",
      "Epoch 10/80\n",
      " - 0s - loss: 169.8926 - coeff_determination: -3.2627e-01 - val_loss: 75.7488 - val_coeff_determination: 0.6019\n",
      "Epoch 11/80\n",
      " - 0s - loss: 162.0548 - coeff_determination: -2.5781e-01 - val_loss: 72.0313 - val_coeff_determination: 0.6352\n",
      "Epoch 12/80\n",
      " - 0s - loss: 156.9054 - coeff_determination: -2.1340e-01 - val_loss: 66.8614 - val_coeff_determination: 0.6807\n",
      "Epoch 13/80\n",
      " - 0s - loss: 149.7611 - coeff_determination: -1.5114e-01 - val_loss: 73.5805 - val_coeff_determination: 0.6011\n",
      "Epoch 14/80\n",
      " - 0s - loss: 144.3394 - coeff_determination: -1.0434e-01 - val_loss: 66.7345 - val_coeff_determination: 0.6621\n",
      "Epoch 15/80\n",
      " - 0s - loss: 138.6441 - coeff_determination: -5.4826e-02 - val_loss: 69.4534 - val_coeff_determination: 0.6276\n",
      "Epoch 16/80\n",
      " - 0s - loss: 136.8012 - coeff_determination: -4.3595e-02 - val_loss: 68.9282 - val_coeff_determination: 0.6255\n",
      "Epoch 17/80\n",
      " - 0s - loss: 130.8390 - coeff_determination: 0.0080 - val_loss: 64.2464 - val_coeff_determination: 0.6650\n",
      "Epoch 18/80\n",
      " - 0s - loss: 126.5794 - coeff_determination: 0.0423 - val_loss: 69.9955 - val_coeff_determination: 0.5948\n",
      "Epoch 19/80\n",
      " - 0s - loss: 123.2374 - coeff_determination: 0.0673 - val_loss: 67.8032 - val_coeff_determination: 0.6100\n",
      "Epoch 20/80\n",
      " - 0s - loss: 120.8743 - coeff_determination: 0.0824 - val_loss: 66.2805 - val_coeff_determination: 0.6182\n",
      "Epoch 21/80\n",
      " - 0s - loss: 117.8012 - coeff_determination: 0.1048 - val_loss: 61.9821 - val_coeff_determination: 0.6536\n",
      "Epoch 22/80\n",
      " - 0s - loss: 114.3736 - coeff_determination: 0.1308 - val_loss: 61.9755 - val_coeff_determination: 0.6435\n",
      "Epoch 23/80\n",
      " - 0s - loss: 109.3362 - coeff_determination: 0.1734 - val_loss: 56.7070 - val_coeff_determination: 0.6925\n",
      "Epoch 24/80\n",
      " - 0s - loss: 107.0143 - coeff_determination: 0.1890 - val_loss: 59.8103 - val_coeff_determination: 0.6499\n",
      "Epoch 25/80\n",
      " - 0s - loss: 104.3177 - coeff_determination: 0.2087 - val_loss: 58.5982 - val_coeff_determination: 0.6560\n",
      "Epoch 26/80\n",
      " - 0s - loss: 100.5292 - coeff_determination: 0.2400 - val_loss: 55.6769 - val_coeff_determination: 0.6787\n",
      "Epoch 27/80\n",
      " - 0s - loss: 98.2447 - coeff_determination: 0.2564 - val_loss: 57.0517 - val_coeff_determination: 0.6563\n",
      "Epoch 28/80\n",
      " - 0s - loss: 95.5097 - coeff_determination: 0.2770 - val_loss: 54.7399 - val_coeff_determination: 0.6738\n",
      "Epoch 29/80\n",
      " - 0s - loss: 91.8814 - coeff_determination: 0.3062 - val_loss: 64.7114 - val_coeff_determination: 0.5610\n",
      "Epoch 30/80\n",
      " - 0s - loss: 89.2392 - coeff_determination: 0.3281 - val_loss: 61.9944 - val_coeff_determination: 0.5852\n",
      "Epoch 31/80\n",
      " - 1s - loss: 86.4198 - coeff_determination: 0.3501 - val_loss: 54.4711 - val_coeff_determination: 0.6567\n",
      "Epoch 32/80\n",
      " - 0s - loss: 84.9433 - coeff_determination: 0.3602 - val_loss: 54.2839 - val_coeff_determination: 0.6579\n",
      "Epoch 33/80\n",
      " - 0s - loss: 82.5788 - coeff_determination: 0.3800 - val_loss: 54.9137 - val_coeff_determination: 0.6457\n",
      "Epoch 34/80\n",
      " - 0s - loss: 81.3639 - coeff_determination: 0.3900 - val_loss: 53.0957 - val_coeff_determination: 0.6613\n",
      "Epoch 35/80\n",
      " - 0s - loss: 77.8062 - coeff_determination: 0.4229 - val_loss: 51.3340 - val_coeff_determination: 0.6766\n",
      "Epoch 36/80\n",
      " - 0s - loss: 77.7268 - coeff_determination: 0.4215 - val_loss: 52.9207 - val_coeff_determination: 0.6598\n",
      "Epoch 37/80\n",
      " - 0s - loss: 76.2428 - coeff_determination: 0.4362 - val_loss: 52.8281 - val_coeff_determination: 0.6620\n",
      "Epoch 38/80\n",
      " - 0s - loss: 74.4393 - coeff_determination: 0.4533 - val_loss: 57.3067 - val_coeff_determination: 0.6120\n",
      "Epoch 39/80\n",
      " - 0s - loss: 72.8645 - coeff_determination: 0.4697 - val_loss: 51.2924 - val_coeff_determination: 0.6768\n",
      "Epoch 40/80\n",
      " - 0s - loss: 73.1436 - coeff_determination: 0.4673 - val_loss: 50.5060 - val_coeff_determination: 0.6838\n",
      "Epoch 41/80\n",
      " - 0s - loss: 72.2442 - coeff_determination: 0.4762 - val_loss: 49.7527 - val_coeff_determination: 0.6928\n",
      "Epoch 42/80\n",
      " - 0s - loss: 70.9198 - coeff_determination: 0.4912 - val_loss: 55.3170 - val_coeff_determination: 0.6369\n",
      "Epoch 43/80\n",
      " - 0s - loss: 70.6261 - coeff_determination: 0.4940 - val_loss: 50.8040 - val_coeff_determination: 0.6830\n",
      "Epoch 44/80\n",
      " - 0s - loss: 70.9429 - coeff_determination: 0.4909 - val_loss: 51.2747 - val_coeff_determination: 0.6787\n",
      "Epoch 45/80\n",
      " - 0s - loss: 69.1283 - coeff_determination: 0.5103 - val_loss: 53.1595 - val_coeff_determination: 0.6598\n",
      "Epoch 46/80\n",
      " - 0s - loss: 69.2956 - coeff_determination: 0.5077 - val_loss: 52.0742 - val_coeff_determination: 0.6711\n",
      "Epoch 47/80\n",
      " - 0s - loss: 68.3276 - coeff_determination: 0.5163 - val_loss: 53.0397 - val_coeff_determination: 0.6588\n",
      "Epoch 48/80\n",
      " - 0s - loss: 68.6829 - coeff_determination: 0.5119 - val_loss: 61.1152 - val_coeff_determination: 0.5738\n",
      "Epoch 49/80\n",
      " - 0s - loss: 69.4792 - coeff_determination: 0.5031 - val_loss: 59.8552 - val_coeff_determination: 0.5861\n",
      "Epoch 50/80\n",
      " - 0s - loss: 68.1345 - coeff_determination: 0.5177 - val_loss: 57.3544 - val_coeff_determination: 0.6124\n",
      "Epoch 51/80\n",
      " - 0s - loss: 69.2520 - coeff_determination: 0.5048 - val_loss: 50.6243 - val_coeff_determination: 0.6825\n",
      "Epoch 52/80\n",
      " - 0s - loss: 68.1435 - coeff_determination: 0.5154 - val_loss: 51.7060 - val_coeff_determination: 0.6694\n",
      "Epoch 53/80\n",
      " - 0s - loss: 68.1215 - coeff_determination: 0.5155 - val_loss: 50.5388 - val_coeff_determination: 0.6833\n",
      "Epoch 54/80\n",
      " - 0s - loss: 67.2026 - coeff_determination: 0.5251 - val_loss: 57.6828 - val_coeff_determination: 0.6059\n",
      "Epoch 55/80\n",
      " - 0s - loss: 67.6150 - coeff_determination: 0.5183 - val_loss: 50.5714 - val_coeff_determination: 0.6805\n",
      "Epoch 56/80\n",
      " - 0s - loss: 66.5006 - coeff_determination: 0.5294 - val_loss: 51.5931 - val_coeff_determination: 0.6690\n",
      "Epoch 57/80\n",
      " - 0s - loss: 66.9148 - coeff_determination: 0.5242 - val_loss: 51.4255 - val_coeff_determination: 0.6676\n",
      "Epoch 58/80\n",
      " - 1s - loss: 66.6150 - coeff_determination: 0.5257 - val_loss: 51.8161 - val_coeff_determination: 0.6613\n",
      "Epoch 59/80\n",
      " - 0s - loss: 66.7211 - coeff_determination: 0.5235 - val_loss: 50.3524 - val_coeff_determination: 0.6766\n",
      "Epoch 60/80\n",
      " - 0s - loss: 66.7612 - coeff_determination: 0.5227 - val_loss: 54.6392 - val_coeff_determination: 0.6306\n",
      "Epoch 61/80\n",
      " - 0s - loss: 65.8950 - coeff_determination: 0.5304 - val_loss: 51.0537 - val_coeff_determination: 0.6691\n",
      "Epoch 62/80\n",
      " - 0s - loss: 67.3465 - coeff_determination: 0.5156 - val_loss: 49.1853 - val_coeff_determination: 0.6879\n",
      "Epoch 63/80\n",
      " - 0s - loss: 67.8716 - coeff_determination: 0.5087 - val_loss: 48.5743 - val_coeff_determination: 0.6943\n",
      "Epoch 64/80\n",
      " - 0s - loss: 65.3314 - coeff_determination: 0.5355 - val_loss: 51.2057 - val_coeff_determination: 0.6641\n",
      "Epoch 65/80\n",
      " - 0s - loss: 65.9580 - coeff_determination: 0.5269 - val_loss: 51.3904 - val_coeff_determination: 0.6619\n",
      "Epoch 66/80\n",
      " - 0s - loss: 65.3392 - coeff_determination: 0.5321 - val_loss: 48.4198 - val_coeff_determination: 0.6924\n",
      "Epoch 67/80\n",
      " - 0s - loss: 65.2978 - coeff_determination: 0.5315 - val_loss: 56.1656 - val_coeff_determination: 0.6077\n",
      "Epoch 68/80\n",
      " - 0s - loss: 65.4859 - coeff_determination: 0.5289 - val_loss: 49.2915 - val_coeff_determination: 0.6835\n",
      "Epoch 69/80\n",
      " - 0s - loss: 66.8081 - coeff_determination: 0.5157 - val_loss: 61.7692 - val_coeff_determination: 0.5457\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 70/80\n",
      " - 0s - loss: 65.6819 - coeff_determination: 0.5274 - val_loss: 51.0549 - val_coeff_determination: 0.6633\n",
      "Epoch 71/80\n",
      " - 0s - loss: 64.0721 - coeff_determination: 0.5430 - val_loss: 57.6074 - val_coeff_determination: 0.5932\n",
      "Epoch 72/80\n",
      " - 0s - loss: 63.6700 - coeff_determination: 0.5454 - val_loss: 47.7967 - val_coeff_determination: 0.6952\n",
      "Epoch 73/80\n",
      " - 0s - loss: 64.8793 - coeff_determination: 0.5320 - val_loss: 60.5893 - val_coeff_determination: 0.5600\n",
      "Epoch 74/80\n",
      " - 0s - loss: 63.8529 - coeff_determination: 0.5424 - val_loss: 49.8999 - val_coeff_determination: 0.6723\n",
      "Epoch 75/80\n",
      " - 0s - loss: 62.7783 - coeff_determination: 0.5527 - val_loss: 64.9229 - val_coeff_determination: 0.5129\n",
      "Epoch 76/80\n",
      " - 0s - loss: 63.5979 - coeff_determination: 0.5434 - val_loss: 48.8776 - val_coeff_determination: 0.6808\n",
      "Epoch 77/80\n",
      " - 0s - loss: 63.0314 - coeff_determination: 0.5494 - val_loss: 51.0272 - val_coeff_determination: 0.6564\n",
      "Epoch 78/80\n",
      " - 0s - loss: 62.7038 - coeff_determination: 0.5519 - val_loss: 49.4912 - val_coeff_determination: 0.6732\n",
      "Epoch 79/80\n",
      " - 0s - loss: 62.7327 - coeff_determination: 0.5500 - val_loss: 50.3510 - val_coeff_determination: 0.6643\n",
      "Epoch 80/80\n",
      " - 0s - loss: 62.7246 - coeff_determination: 0.5494 - val_loss: 51.4311 - val_coeff_determination: 0.6533\n",
      "[[-5.91048651e-01  2.30444540e-01  8.49205592e-01 ...  4.60876757e-15\n",
      "  -8.07061728e-01 -4.12493090e-01]\n",
      " [-1.07934984e+00 -6.08877507e-01 -5.25939050e-01 ... -1.54452876e-01\n",
      "   5.52065643e-01 -1.70098106e+00]\n",
      " [-6.75338185e-01 -7.94497986e-01 -7.15544080e-01 ... -3.16536987e-01\n",
      "   6.92904080e-01 -7.46275192e-01]\n",
      " ...\n",
      " [-1.55913212e+00  3.36795236e-01  3.27582790e-01 ... -3.77194323e-01\n",
      "  -3.45564717e-01 -1.46485839e+00]\n",
      " [ 9.61812168e-01 -1.23994208e-01  7.70358505e-02 ...  4.59513037e-01\n",
      "  -7.24546592e-02  9.81605531e-01]\n",
      " [ 7.24401563e-01  1.40887526e+00  9.10837558e-01 ...  3.89953944e-01\n",
      "  -8.97664424e-01  8.25835018e-01]]\n",
      "[[72.75744 ]\n",
      " [69.92517 ]\n",
      " [72.93284 ]\n",
      " [60.414436]\n",
      " [67.28331 ]\n",
      " [65.53546 ]\n",
      " [76.58651 ]\n",
      " [74.91583 ]\n",
      " [76.85017 ]\n",
      " [58.68241 ]\n",
      " [72.881096]\n",
      " [62.098778]\n",
      " [69.76192 ]\n",
      " [73.401794]\n",
      " [78.39021 ]\n",
      " [74.4929  ]\n",
      " [62.873978]\n",
      " [64.93624 ]\n",
      " [66.337   ]\n",
      " [69.61496 ]\n",
      " [68.082726]\n",
      " [66.998886]\n",
      " [79.27518 ]\n",
      " [70.99656 ]\n",
      " [71.898544]\n",
      " [69.42689 ]\n",
      " [58.65918 ]\n",
      " [84.29179 ]\n",
      " [77.25283 ]\n",
      " [78.85903 ]\n",
      " [58.574516]\n",
      " [72.08552 ]\n",
      " [61.71087 ]\n",
      " [63.628937]\n",
      " [68.064095]\n",
      " [70.93654 ]\n",
      " [77.45545 ]\n",
      " [58.5884  ]\n",
      " [72.64645 ]\n",
      " [77.028076]\n",
      " [74.469574]\n",
      " [75.21177 ]\n",
      " [64.45954 ]\n",
      " [75.273254]\n",
      " [62.865265]\n",
      " [66.069214]\n",
      " [77.78352 ]\n",
      " [77.09756 ]\n",
      " [73.04043 ]\n",
      " [72.55842 ]\n",
      " [58.696213]\n",
      " [60.17917 ]\n",
      " [64.245636]\n",
      " [63.086014]\n",
      " [58.67926 ]\n",
      " [70.72268 ]\n",
      " [81.70743 ]\n",
      " [64.36926 ]\n",
      " [60.21042 ]\n",
      " [65.68675 ]\n",
      " [78.809875]\n",
      " [73.68322 ]\n",
      " [76.14347 ]\n",
      " [70.2569  ]\n",
      " [66.60648 ]\n",
      " [66.77838 ]\n",
      " [76.986145]\n",
      " [77.236565]\n",
      " [61.48008 ]\n",
      " [58.60515 ]\n",
      " [70.19444 ]\n",
      " [66.658775]\n",
      " [84.364655]\n",
      " [74.06242 ]\n",
      " [58.576294]\n",
      " [65.10622 ]\n",
      " [69.700005]\n",
      " [70.20791 ]\n",
      " [74.879974]\n",
      " [60.24716 ]\n",
      " [66.98473 ]\n",
      " [64.15629 ]\n",
      " [73.06052 ]\n",
      " [58.7164  ]\n",
      " [68.45543 ]\n",
      " [75.24426 ]\n",
      " [72.55518 ]\n",
      " [92.138435]\n",
      " [72.26492 ]\n",
      " [71.16186 ]\n",
      " [81.148865]\n",
      " [72.74373 ]\n",
      " [77.329285]\n",
      " [72.06013 ]\n",
      " [72.055595]\n",
      " [66.769264]\n",
      " [79.07873 ]\n",
      " [78.08095 ]\n",
      " [58.938675]\n",
      " [60.64724 ]\n",
      " [69.628265]\n",
      " [79.13124 ]\n",
      " [73.476074]\n",
      " [71.959076]\n",
      " [81.6368  ]\n",
      " [71.41522 ]\n",
      " [78.038826]\n",
      " [78.32193 ]\n",
      " [80.2506  ]\n",
      " [78.860886]\n",
      " [59.9682  ]\n",
      " [68.80703 ]\n",
      " [62.37799 ]\n",
      " [78.76397 ]\n",
      " [66.15045 ]\n",
      " [70.5717  ]\n",
      " [80.53037 ]\n",
      " [64.28649 ]\n",
      " [58.93409 ]\n",
      " [72.40094 ]\n",
      " [68.69519 ]\n",
      " [67.52614 ]\n",
      " [65.21985 ]\n",
      " [62.283012]\n",
      " [59.174294]\n",
      " [62.628403]\n",
      " [65.74897 ]\n",
      " [76.68275 ]\n",
      " [58.592842]\n",
      " [83.701   ]\n",
      " [74.946045]\n",
      " [70.47085 ]\n",
      " [65.41603 ]\n",
      " [62.076317]\n",
      " [70.58607 ]\n",
      " [77.6889  ]\n",
      " [71.1876  ]\n",
      " [62.619904]\n",
      " [58.57415 ]\n",
      " [68.34341 ]\n",
      " [60.07788 ]\n",
      " [66.03308 ]\n",
      " [70.335396]\n",
      " [83.90699 ]\n",
      " [71.50583 ]\n",
      " [72.82248 ]\n",
      " [76.76774 ]\n",
      " [72.65998 ]\n",
      " [67.793304]\n",
      " [69.67863 ]\n",
      " [68.78295 ]\n",
      " [65.71956 ]\n",
      " [59.39821 ]\n",
      " [71.30931 ]\n",
      " [73.81705 ]\n",
      " [75.63047 ]\n",
      " [61.563713]\n",
      " [83.57491 ]\n",
      " [58.75157 ]\n",
      " [67.28663 ]\n",
      " [65.78738 ]\n",
      " [65.84618 ]\n",
      " [79.40666 ]\n",
      " [63.45475 ]\n",
      " [68.78623 ]\n",
      " [60.561737]\n",
      " [70.345634]\n",
      " [61.0559  ]\n",
      " [61.081238]\n",
      " [71.97113 ]\n",
      " [72.22015 ]\n",
      " [68.93979 ]\n",
      " [66.65062 ]\n",
      " [58.575203]\n",
      " [74.42855 ]\n",
      " [58.59945 ]\n",
      " [72.218094]\n",
      " [69.842415]\n",
      " [64.906784]\n",
      " [67.568184]\n",
      " [71.35396 ]\n",
      " [76.7169  ]\n",
      " [79.99274 ]\n",
      " [74.40269 ]\n",
      " [78.796715]\n",
      " [73.9108  ]\n",
      " [60.887375]\n",
      " [62.96924 ]\n",
      " [61.86541 ]\n",
      " [60.916924]\n",
      " [73.9316  ]\n",
      " [78.79191 ]\n",
      " [78.11831 ]\n",
      " [59.68251 ]\n",
      " [67.54161 ]\n",
      " [78.23643 ]\n",
      " [70.50647 ]\n",
      " [75.86887 ]\n",
      " [81.1713  ]\n",
      " [75.928276]\n",
      " [58.574837]\n",
      " [76.13043 ]\n",
      " [72.02294 ]\n",
      " [77.2539  ]\n",
      " [74.331184]\n",
      " [74.2644  ]\n",
      " [73.0618  ]\n",
      " [58.578995]\n",
      " [58.58705 ]\n",
      " [65.433105]\n",
      " [73.25459 ]\n",
      " [68.47225 ]\n",
      " [67.17749 ]\n",
      " [60.23713 ]\n",
      " [59.145523]\n",
      " [58.692055]\n",
      " [68.05698 ]\n",
      " [72.76868 ]\n",
      " [62.130905]\n",
      " [75.83774 ]\n",
      " [75.56737 ]\n",
      " [74.58021 ]\n",
      " [58.572517]\n",
      " [63.939934]\n",
      " [71.27048 ]\n",
      " [93.42274 ]\n",
      " [75.05858 ]\n",
      " [78.93001 ]\n",
      " [73.631775]\n",
      " [75.817795]\n",
      " [71.647224]\n",
      " [74.76767 ]\n",
      " [62.331696]\n",
      " [73.22001 ]\n",
      " [58.5765  ]\n",
      " [69.14305 ]\n",
      " [68.19134 ]\n",
      " [58.574562]\n",
      " [75.39984 ]\n",
      " [69.3985  ]\n",
      " [72.08281 ]\n",
      " [71.417015]\n",
      " [59.152237]\n",
      " [71.67516 ]\n",
      " [69.56531 ]\n",
      " [58.60388 ]\n",
      " [69.91247 ]\n",
      " [77.717735]\n",
      " [74.01552 ]\n",
      " [63.734276]\n",
      " [71.259   ]\n",
      " [72.767944]\n",
      " [75.564316]\n",
      " [58.57843 ]\n",
      " [61.893364]\n",
      " [71.84703 ]\n",
      " [80.20519 ]\n",
      " [74.26656 ]\n",
      " [61.99314 ]\n",
      " [70.915955]\n",
      " [58.575882]\n",
      " [84.43118 ]\n",
      " [61.60549 ]\n",
      " [63.6696  ]\n",
      " [66.56617 ]\n",
      " [66.29728 ]\n",
      " [86.58842 ]\n",
      " [74.921425]\n",
      " [66.527664]\n",
      " [62.56752 ]\n",
      " [79.252754]\n",
      " [58.588295]\n",
      " [63.40509 ]\n",
      " [63.080086]\n",
      " [68.25643 ]\n",
      " [69.68567 ]\n",
      " [69.691376]\n",
      " [76.10913 ]\n",
      " [78.17314 ]\n",
      " [72.70907 ]\n",
      " [71.39096 ]\n",
      " [80.10598 ]\n",
      " [67.44147 ]\n",
      " [67.298256]\n",
      " [64.58756 ]\n",
      " [84.59529 ]\n",
      " [82.0564  ]\n",
      " [74.23719 ]\n",
      " [80.18889 ]\n",
      " [63.721863]\n",
      " [67.61059 ]\n",
      " [77.60834 ]\n",
      " [66.76943 ]\n",
      " [82.05311 ]\n",
      " [62.809784]\n",
      " [66.80511 ]\n",
      " [58.63243 ]\n",
      " [65.47478 ]\n",
      " [66.30982 ]\n",
      " [72.47199 ]\n",
      " [71.85142 ]\n",
      " [67.372765]\n",
      " [70.753525]\n",
      " [71.25799 ]\n",
      " [77.70536 ]\n",
      " [59.91005 ]\n",
      " [77.58321 ]\n",
      " [58.573204]\n",
      " [74.38313 ]\n",
      " [73.939644]\n",
      " [62.532883]\n",
      " [68.58985 ]\n",
      " [74.81209 ]\n",
      " [77.11309 ]\n",
      " [77.478584]\n",
      " [62.926575]\n",
      " [59.29165 ]\n",
      " [78.18605 ]\n",
      " [60.28132 ]\n",
      " [75.75596 ]\n",
      " [58.575676]\n",
      " [78.25899 ]\n",
      " [66.1124  ]\n",
      " [76.353935]\n",
      " [80.47461 ]\n",
      " [72.20213 ]\n",
      " [79.69188 ]\n",
      " [79.51994 ]\n",
      " [63.5383  ]\n",
      " [69.94357 ]\n",
      " [74.589424]\n",
      " [58.623863]\n",
      " [64.62051 ]\n",
      " [77.31138 ]\n",
      " [76.41435 ]\n",
      " [62.10749 ]\n",
      " [74.92183 ]\n",
      " [71.47348 ]\n",
      " [68.80962 ]\n",
      " [78.52062 ]\n",
      " [66.63695 ]\n",
      " [76.18599 ]\n",
      " [60.572296]\n",
      " [74.4541  ]\n",
      " [72.42616 ]\n",
      " [58.713066]\n",
      " [59.187584]\n",
      " [65.90532 ]\n",
      " [58.622276]\n",
      " [70.1934  ]\n",
      " [70.391556]\n",
      " [69.766945]\n",
      " [74.99434 ]\n",
      " [75.1409  ]\n",
      " [67.91628 ]\n",
      " [77.68604 ]\n",
      " [72.47528 ]\n",
      " [58.575066]\n",
      " [75.37626 ]\n",
      " [70.78936 ]\n",
      " [83.59132 ]\n",
      " [64.95946 ]\n",
      " [64.45679 ]\n",
      " [71.53727 ]\n",
      " [79.29318 ]\n",
      " [58.5754  ]\n",
      " [67.91219 ]\n",
      " [58.572227]\n",
      " [69.19014 ]\n",
      " [74.86891 ]\n",
      " [63.619995]\n",
      " [58.609116]\n",
      " [76.203514]\n",
      " [67.65676 ]\n",
      " [70.29422 ]\n",
      " [58.630318]\n",
      " [77.73367 ]\n",
      " [70.98759 ]\n",
      " [70.34868 ]\n",
      " [66.41894 ]\n",
      " [68.28515 ]\n",
      " [71.52225 ]\n",
      " [75.71433 ]\n",
      " [70.94198 ]\n",
      " [71.366486]\n",
      " [80.44948 ]\n",
      " [66.10587 ]\n",
      " [62.222687]\n",
      " [58.800957]\n",
      " [76.76345 ]\n",
      " [77.343895]\n",
      " [58.64849 ]\n",
      " [81.42537 ]\n",
      " [63.67933 ]\n",
      " [79.87182 ]\n",
      " [70.135544]\n",
      " [62.721985]\n",
      " [79.968254]\n",
      " [58.580193]\n",
      " [79.95274 ]\n",
      " [78.10895 ]\n",
      " [58.64724 ]\n",
      " [74.62933 ]\n",
      " [77.18145 ]\n",
      " [79.59034 ]\n",
      " [72.74735 ]\n",
      " [59.53292 ]\n",
      " [66.22852 ]\n",
      " [74.22662 ]\n",
      " [82.98372 ]\n",
      " [76.60739 ]\n",
      " [65.527794]\n",
      " [64.19076 ]\n",
      " [78.79338 ]\n",
      " [58.769974]\n",
      " [66.7396  ]\n",
      " [69.53348 ]\n",
      " [74.53271 ]\n",
      " [71.584595]\n",
      " [58.63173 ]\n",
      " [76.29605 ]\n",
      " [69.88543 ]\n",
      " [67.07931 ]\n",
      " [72.18479 ]\n",
      " [72.29542 ]\n",
      " [77.20792 ]\n",
      " [72.497696]\n",
      " [76.92845 ]\n",
      " [74.90882 ]\n",
      " [77.21397 ]\n",
      " [64.66707 ]\n",
      " [60.568382]\n",
      " [74.16794 ]\n",
      " [67.64335 ]\n",
      " [65.81621 ]\n",
      " [61.71118 ]\n",
      " [70.6372  ]\n",
      " [61.536575]\n",
      " [74.941826]\n",
      " [78.3485  ]\n",
      " [62.77038 ]\n",
      " [60.614494]\n",
      " [62.150894]\n",
      " [62.73294 ]\n",
      " [63.07898 ]\n",
      " [66.66477 ]\n",
      " [74.64334 ]\n",
      " [78.077545]\n",
      " [75.67115 ]\n",
      " [63.97515 ]\n",
      " [74.90424 ]\n",
      " [68.61192 ]\n",
      " [68.78297 ]\n",
      " [70.82534 ]\n",
      " [70.65565 ]\n",
      " [58.5766  ]\n",
      " [61.092278]\n",
      " [75.53851 ]\n",
      " [81.367516]\n",
      " [69.40207 ]\n",
      " [78.51809 ]\n",
      " [67.31934 ]\n",
      " [63.10987 ]\n",
      " [88.27885 ]\n",
      " [68.237976]\n",
      " [74.356255]\n",
      " [58.815414]\n",
      " [69.76516 ]\n",
      " [58.60044 ]\n",
      " [80.71353 ]\n",
      " [66.04272 ]\n",
      " [61.28334 ]\n",
      " [77.58745 ]\n",
      " [73.329765]\n",
      " [82.98603 ]\n",
      " [65.94941 ]\n",
      " [79.17373 ]\n",
      " [69.74636 ]\n",
      " [73.01854 ]\n",
      " [62.73552 ]\n",
      " [67.31697 ]\n",
      " [66.59151 ]\n",
      " [75.06875 ]\n",
      " [59.166397]\n",
      " [76.657196]\n",
      " [68.22412 ]\n",
      " [68.11382 ]\n",
      " [74.39479 ]\n",
      " [58.62374 ]\n",
      " [66.305504]\n",
      " [74.64058 ]\n",
      " [75.31403 ]\n",
      " [72.7763  ]\n",
      " [58.77455 ]\n",
      " [85.198006]\n",
      " [62.27549 ]\n",
      " [66.036095]\n",
      " [64.94404 ]\n",
      " [71.276375]\n",
      " [67.510826]\n",
      " [71.287926]\n",
      " [74.107704]\n",
      " [73.451996]\n",
      " [78.32471 ]\n",
      " [76.990585]\n",
      " [76.88217 ]\n",
      " [74.077484]\n",
      " [79.617935]\n",
      " [75.598854]\n",
      " [69.543   ]\n",
      " [65.52379 ]\n",
      " [59.930046]\n",
      " [58.709656]\n",
      " [66.12104 ]\n",
      " [76.07376 ]\n",
      " [70.921715]\n",
      " [69.780754]\n",
      " [73.61384 ]\n",
      " [63.6344  ]\n",
      " [66.8713  ]\n",
      " [80.48699 ]\n",
      " [58.574585]\n",
      " [67.470375]\n",
      " [69.15783 ]\n",
      " [61.798943]\n",
      " [75.06243 ]\n",
      " [66.076775]\n",
      " [70.027306]\n",
      " [68.081276]\n",
      " [67.01363 ]\n",
      " [83.328224]\n",
      " [58.620308]\n",
      " [59.416977]\n",
      " [75.73749 ]\n",
      " [65.39105 ]\n",
      " [61.785324]\n",
      " [69.03247 ]\n",
      " [77.36019 ]\n",
      " [77.618164]\n",
      " [58.582016]\n",
      " [58.66533 ]\n",
      " [82.57187 ]\n",
      " [63.26551 ]\n",
      " [70.75004 ]\n",
      " [71.40268 ]\n",
      " [62.998505]\n",
      " [80.328766]\n",
      " [68.65088 ]\n",
      " [67.90647 ]\n",
      " [65.155624]\n",
      " [83.43063 ]\n",
      " [61.051056]\n",
      " [67.6638  ]\n",
      " [58.66413 ]\n",
      " [65.627594]\n",
      " [69.52308 ]\n",
      " [69.18355 ]\n",
      " [68.4922  ]\n",
      " [58.57776 ]\n",
      " [79.88581 ]\n",
      " [69.65601 ]\n",
      " [81.07634 ]\n",
      " [68.58055 ]\n",
      " [63.77897 ]\n",
      " [77.09267 ]\n",
      " [67.136566]\n",
      " [70.20202 ]\n",
      " [59.39289 ]\n",
      " [62.94378 ]\n",
      " [71.351944]\n",
      " [77.58183 ]\n",
      " [68.93619 ]\n",
      " [73.95622 ]\n",
      " [71.208565]\n",
      " [59.70156 ]\n",
      " [71.67989 ]\n",
      " [65.3024  ]\n",
      " [74.92594 ]\n",
      " [77.452065]\n",
      " [58.58262 ]\n",
      " [83.38561 ]\n",
      " [63.229477]\n",
      " [69.725204]\n",
      " [71.76398 ]\n",
      " [76.68785 ]\n",
      " [74.6649  ]\n",
      " [58.902664]\n",
      " [71.85036 ]\n",
      " [71.46621 ]\n",
      " [74.73565 ]\n",
      " [64.61569 ]\n",
      " [72.56163 ]\n",
      " [73.05659 ]\n",
      " [76.379395]\n",
      " [58.595604]\n",
      " [70.55682 ]\n",
      " [61.858948]\n",
      " [68.37394 ]\n",
      " [84.82669 ]\n",
      " [75.83113 ]\n",
      " [58.685013]\n",
      " [78.61247 ]\n",
      " [58.64499 ]\n",
      " [67.21907 ]\n",
      " [59.036896]\n",
      " [64.88444 ]\n",
      " [67.15468 ]\n",
      " [78.352936]\n",
      " [82.09602 ]\n",
      " [63.83519 ]\n",
      " [58.78119 ]\n",
      " [71.89579 ]\n",
      " [78.25838 ]\n",
      " [67.914116]\n",
      " [77.59145 ]\n",
      " [62.415565]\n",
      " [66.23108 ]\n",
      " [59.948425]\n",
      " [58.57759 ]\n",
      " [65.38643 ]\n",
      " [76.290306]\n",
      " [59.533577]\n",
      " [86.82684 ]\n",
      " [74.71493 ]\n",
      " [68.017715]\n",
      " [62.626038]\n",
      " [74.95026 ]\n",
      " [73.77981 ]\n",
      " [66.07873 ]\n",
      " [61.34118 ]\n",
      " [73.52736 ]\n",
      " [81.58223 ]\n",
      " [70.692154]\n",
      " [65.49947 ]\n",
      " [73.4738  ]\n",
      " [77.95283 ]\n",
      " [58.58304 ]\n",
      " [77.55762 ]\n",
      " [65.0629  ]\n",
      " [61.293076]\n",
      " [79.91149 ]\n",
      " [62.50255 ]\n",
      " [68.02078 ]\n",
      " [72.48145 ]\n",
      " [58.614075]\n",
      " [77.44714 ]\n",
      " [74.788025]\n",
      " [68.89092 ]\n",
      " [60.587364]\n",
      " [58.677208]\n",
      " [70.88267 ]\n",
      " [67.72768 ]\n",
      " [86.31352 ]\n",
      " [64.56677 ]\n",
      " [62.19275 ]\n",
      " [64.36508 ]\n",
      " [70.34656 ]\n",
      " [67.65054 ]\n",
      " [85.51984 ]\n",
      " [72.61404 ]\n",
      " [66.27682 ]\n",
      " [66.75837 ]\n",
      " [58.57444 ]\n",
      " [77.709885]\n",
      " [63.419525]\n",
      " [74.02318 ]\n",
      " [74.26823 ]\n",
      " [89.11188 ]\n",
      " [86.40898 ]\n",
      " [65.95064 ]\n",
      " [58.57476 ]\n",
      " [74.77785 ]\n",
      " [58.65042 ]\n",
      " [58.57325 ]\n",
      " [74.59968 ]\n",
      " [58.57701 ]\n",
      " [75.23504 ]\n",
      " [58.57856 ]\n",
      " [67.11381 ]\n",
      " [58.61125 ]\n",
      " [65.38312 ]\n",
      " [58.659134]\n",
      " [78.61846 ]\n",
      " [78.30598 ]\n",
      " [59.272774]\n",
      " [71.23133 ]\n",
      " [77.54097 ]\n",
      " [58.578712]\n",
      " [58.918465]\n",
      " [77.04714 ]\n",
      " [68.2135  ]\n",
      " [78.79761 ]\n",
      " [58.57534 ]\n",
      " [85.850296]\n",
      " [72.03671 ]\n",
      " [58.575974]\n",
      " [70.85588 ]\n",
      " [67.1197  ]\n",
      " [81.101105]\n",
      " [72.157425]\n",
      " [70.76031 ]\n",
      " [74.294586]\n",
      " [62.201836]\n",
      " [60.511864]\n",
      " [73.70421 ]\n",
      " [80.50218 ]\n",
      " [73.05241 ]\n",
      " [70.85374 ]\n",
      " [64.220985]\n",
      " [63.97123 ]\n",
      " [72.74032 ]\n",
      " [77.25958 ]\n",
      " [58.575325]\n",
      " [69.77463 ]\n",
      " [67.685486]\n",
      " [70.30489 ]\n",
      " [60.93566 ]\n",
      " [65.65155 ]\n",
      " [70.618385]\n",
      " [71.74294 ]\n",
      " [75.83314 ]\n",
      " [84.067154]\n",
      " [70.04486 ]\n",
      " [70.03961 ]\n",
      " [70.70265 ]\n",
      " [71.949585]\n",
      " [70.127655]\n",
      " [62.84749 ]\n",
      " [66.15972 ]\n",
      " [58.57493 ]\n",
      " [81.57536 ]\n",
      " [70.280914]\n",
      " [76.75194 ]\n",
      " [69.42523 ]\n",
      " [84.251076]\n",
      " [65.84314 ]\n",
      " [67.49704 ]\n",
      " [62.795418]\n",
      " [77.52027 ]\n",
      " [73.64413 ]\n",
      " [59.2978  ]\n",
      " [58.59987 ]\n",
      " [76.476685]\n",
      " [58.662857]\n",
      " [66.36046 ]\n",
      " [63.431107]\n",
      " [58.6268  ]\n",
      " [68.64528 ]\n",
      " [64.44905 ]\n",
      " [73.531624]\n",
      " [67.70762 ]\n",
      " [63.938904]\n",
      " [58.57466 ]\n",
      " [72.50566 ]\n",
      " [63.919487]\n",
      " [80.23669 ]\n",
      " [66.52626 ]\n",
      " [82.09207 ]\n",
      " [62.11576 ]\n",
      " [66.0658  ]\n",
      " [71.17952 ]\n",
      " [73.248055]\n",
      " [58.769966]\n",
      " [61.136078]\n",
      " [76.03317 ]\n",
      " [70.20426 ]\n",
      " [70.97449 ]\n",
      " [68.60265 ]\n",
      " [70.80091 ]\n",
      " [62.7228  ]\n",
      " [76.08003 ]\n",
      " [66.18242 ]\n",
      " [61.745056]\n",
      " [78.97471 ]\n",
      " [71.19391 ]\n",
      " [69.18798 ]]\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LeakyReLU\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers import Dropout\n",
    "from keras import regularizers\n",
    "# fix random seed for reproducibility\n",
    "\n",
    "def coeff_determination(y_true, y_pred):\n",
    "    from keras import backend as K\n",
    "    SS_res =  K.sum(K.square( y_true-y_pred ))\n",
    "    SS_tot = K.sum(K.square( y_true - K.mean(y_true) ) )\n",
    "    return ( 1 - SS_res/(SS_tot + K.epsilon()) )\n",
    "\n",
    "Y = Y_train\n",
    "dropout = 0.1\n",
    "#print(Y)\n",
    "# create model\n",
    "model = Sequential()\n",
    "model.add(Dense(30, input_dim=178, kernel_regularizer = regularizers.l2(1), init='RandomUniform'))\n",
    "model.add(LeakyReLU(alpha=0.1))\n",
    "model.add(Dropout(rate = dropout))\n",
    "model.add(Dense(30, input_dim=72, kernel_regularizer = regularizers.l2(1), init='RandomUniform'))\n",
    "model.add(LeakyReLU(alpha=0.1))\n",
    "model.add(Dropout(rate = dropout))\n",
    "model.add(Dense(30, input_dim=72, kernel_regularizer = regularizers.l2(1), init='RandomUniform'))\n",
    "model.add(LeakyReLU(alpha=0.1))\n",
    "model.add(Dropout(rate = dropout))\n",
    "model.add(Dense(30, input_dim=72, kernel_regularizer = regularizers.l2(1), init='RandomUniform'))\n",
    "model.add(LeakyReLU(alpha=0.1))\n",
    "model.add(Dropout(rate = dropout))\n",
    "model.add(Dense(30, input_dim=72, kernel_regularizer = regularizers.l2(1), init='RandomUniform'))\n",
    "model.add(LeakyReLU(alpha=0.1))\n",
    "model.add(Dropout(rate = dropout))\n",
    "model.add(Dense(30, input_dim=72, kernel_regularizer = regularizers.l2(1), init='RandomUniform'))\n",
    "model.add(LeakyReLU(alpha=0.1))\n",
    "model.add(Dropout(rate = dropout))\n",
    "model.add(Dense(30, input_dim=72, kernel_regularizer = regularizers.l2(1), init='RandomUniform'))\n",
    "model.add(LeakyReLU(alpha=0.1))\n",
    "model.add(Dropout(rate = dropout))\n",
    "model.add(Dense(30, input_dim=72, kernel_regularizer = regularizers.l2(1), init='RandomUniform'))\n",
    "model.add(LeakyReLU(alpha=0.1))\n",
    "model.add(Dropout(rate = dropout))\n",
    "\n",
    "model.add(Dense(1, init='RandomUniform'))\n",
    "# Compile model\n",
    "optimizer = Adam(lr=0.005, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
    "\n",
    "model.compile(loss='mean_squared_error', optimizer=optimizer, metrics=[coeff_determination])\n",
    "# Fit the model\n",
    "model.fit(x=X_train_subset, y=Y, epochs=80, verbose=2, validation_split=0.1, shuffle=True, steps_per_epoch=50, initial_epoch=0, validation_steps=5)\n",
    "# calculate predictions\n",
    "print(X_test_subset)\n",
    "predictions = model.predict(X_test_subset)\n",
    "# round predictions\n",
    "#ages = [x*100 for x in predictions]\n",
    "#predictions = predictions*100\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
