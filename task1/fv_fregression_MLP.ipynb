{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import csv\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_selection import RFE, f_regression\n",
    "from sklearn.linear_model import (LinearRegression, Ridge, Lasso, RandomizedLasso)\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.feature_selection import f_regression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "TRAIN_FILE_PATH = \"data/X_train.csv\"\n",
    "TARGET_FILE_PATH =  \"data/y_train.csv\"\n",
    "TEST_FILE_PATH = \"data/X_test.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Data\n",
      "\n",
      "(1212, 887)\n",
      "            x0             x1            x2           x3         x4  \\\n",
      "0  7077.537454  926681.139285  1.076365e+06  1029.624479  105.87744   \n",
      "\n",
      "              x5          x6             x7             x8            x9  \\\n",
      "0  180486.413011  1084.60481  296933.955135  104840.111208  10736.380544   \n",
      "\n",
      "       ...               x877          x878           x879        x880  \\\n",
      "0      ...       3.921803e+11  1.040522e+06 -437724.358877  957.470031   \n",
      "\n",
      "            x881         x882       x883         x884          x885  \\\n",
      "0  988877.247939  3830.501971  98.622927  1771.079992  10008.297422   \n",
      "\n",
      "           x886  \n",
      "0  65052.593208  \n",
      "\n",
      "[1 rows x 887 columns]\n",
      "\n",
      "Test Data\n",
      "\n",
      "(776, 887)\n",
      "Amount of observations: 1212\n"
     ]
    }
   ],
   "source": [
    "#Load train and test set\n",
    "print(\"\\nTrain Data\\n\")\n",
    "\n",
    "train_data = pd.read_csv(TRAIN_FILE_PATH)\n",
    "train_data.drop(train_data.columns[0], axis=1, inplace=True)\n",
    "\n",
    "Y_train = pd.read_csv(TARGET_FILE_PATH)\n",
    "Y_train.drop(Y_train.columns[0], axis=1, inplace = True)\n",
    "\n",
    "print(\"\\nTest Data\\n\")\n",
    "\n",
    "test_data =  pd.read_csv(TEST_FILE_PATH)\n",
    "id_test = test_data.columns[0]\n",
    "test_data.drop(test_data.columns[0], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill missing values with mean column values train and test set\n",
    "def fill_NaN(train, test):\n",
    "    print(\"Train shape: \", train.shape)\n",
    "    print(\"Test shape: \",test.shape)\n",
    "    train_mean_values = train.mean()\n",
    "    train =  train.fillna(train_mean_values)\n",
    "    test = test.fillna(train_mean_values)\n",
    "    \n",
    "    return train,test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_mean, test_data_mean = fill_NaN(train_data, test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Zero mean unit variance for train and test data\n",
    "def scale_data(train, test):\n",
    "    \n",
    "    print(\"Train shape: \", train.shape)\n",
    "    print(\"Test shape: \",test.shape)\n",
    "    scaler = StandardScaler().fit(train, Y_train)\n",
    "    #print(train_data_mean.shape)\n",
    "    #print(test_data_mean.shape)\n",
    "    train = scaler.transform(train)\n",
    "    test = scaler.transform(test)\n",
    "   \n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled, X_test_scaled = scale_data(train_data_mean, test_data_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1212, 887)\n",
      "(1212, 1)\n",
      "[3.17463281e+02 3.09312060e+02 3.07583691e+02 2.85601310e+02\n",
      " 2.78761802e+02 2.78148971e+02 2.73253960e+02 2.52760516e+02\n",
      " 2.43972974e+02 2.43891857e+02 2.42925703e+02 2.38413283e+02\n",
      " 2.00450421e+02 1.88501078e+02 1.87394892e+02 1.85534631e+02\n",
      " 1.83031939e+02 1.77067457e+02 1.73985580e+02 1.72904968e+02\n",
      " 1.63621244e+02 1.59121648e+02 1.58715436e+02 1.58235651e+02\n",
      " 1.58076335e+02 1.54792017e+02 1.51246158e+02 1.50905309e+02\n",
      " 1.50059132e+02 1.44974863e+02 1.41936780e+02 1.41853063e+02\n",
      " 1.38327690e+02 1.37595239e+02 1.36981311e+02 1.33495247e+02\n",
      " 1.29886104e+02 1.27973959e+02 1.27868471e+02 1.27800779e+02\n",
      " 1.23643847e+02 1.21575634e+02 1.19960216e+02 1.17397751e+02\n",
      " 1.16924717e+02 1.16108916e+02 1.15126528e+02 1.14374064e+02\n",
      " 1.12846943e+02 1.11589434e+02 1.11331764e+02 1.09974839e+02\n",
      " 1.08125510e+02 1.05072321e+02 1.01706441e+02 9.78253813e+01\n",
      " 9.36728322e+01 9.31268014e+01 9.19324055e+01 8.80093999e+01\n",
      " 8.72718824e+01 8.72661510e+01 8.71275443e+01 8.69762456e+01\n",
      " 8.68645955e+01 8.55099219e+01 8.50443724e+01 8.06440325e+01\n",
      " 8.05646740e+01 7.84146923e+01 7.68576424e+01 7.68384004e+01\n",
      " 7.53617506e+01 7.44081608e+01 7.39634918e+01 7.16282924e+01\n",
      " 7.15200164e+01 7.11714036e+01 7.08866698e+01 6.97952426e+01\n",
      " 6.86722946e+01 6.83127280e+01 6.80871879e+01 6.77418318e+01\n",
      " 6.76317170e+01 6.72384378e+01 6.72313711e+01 6.71705679e+01\n",
      " 6.69290075e+01 6.66590259e+01 6.65711900e+01 6.64607161e+01\n",
      " 6.61563789e+01 6.61092024e+01 6.59369554e+01 6.52885004e+01\n",
      " 6.51129886e+01 6.49625405e+01 6.42661907e+01 6.42494335e+01\n",
      " 6.41829453e+01 6.40582614e+01 6.33370184e+01 6.32295885e+01\n",
      " 6.31258565e+01 6.24496078e+01 6.23156622e+01 6.21525243e+01\n",
      " 6.18159032e+01 6.17734295e+01 6.15198614e+01 6.10093556e+01\n",
      " 6.05048973e+01 6.00496105e+01 5.96652746e+01 5.92582258e+01\n",
      " 5.92182232e+01 5.91340796e+01 5.89862213e+01 5.86396500e+01\n",
      " 5.79539244e+01 5.78679185e+01 5.71484597e+01 5.69413600e+01\n",
      " 5.67269529e+01 5.65492831e+01 5.63985157e+01 5.63488901e+01\n",
      " 5.62899407e+01 5.62357282e+01 5.56351712e+01 5.53460020e+01\n",
      " 5.49612950e+01 5.49330629e+01 5.42939967e+01 5.41969143e+01\n",
      " 5.39640171e+01 5.39028834e+01 5.38521450e+01 5.38408479e+01\n",
      " 5.36232755e+01 5.25371986e+01 5.18614857e+01 5.15601763e+01\n",
      " 5.13704225e+01 5.13293891e+01 5.12487597e+01 5.11098319e+01\n",
      " 5.10041394e+01 5.09720141e+01 4.95028631e+01 4.84144474e+01\n",
      " 4.82310644e+01 4.70029364e+01 4.65340182e+01 4.64290649e+01\n",
      " 4.61466255e+01 4.61180482e+01 4.60906329e+01 4.49646820e+01\n",
      " 4.36634315e+01 4.32335679e+01 4.28233143e+01 4.15873109e+01\n",
      " 4.07013376e+01 4.06019339e+01 4.01445440e+01 3.99674148e+01\n",
      " 3.86166206e+01 3.69670842e+01 3.68482095e+01 3.66718382e+01\n",
      " 3.60727627e+01 3.59345907e+01 3.26831875e+01 3.08642734e+01\n",
      " 3.06215092e+01 2.73471504e+01 2.60898634e+01 2.60763752e+01\n",
      " 2.57844537e+01 2.49892703e+01 2.47241877e+01 2.42205418e+01\n",
      " 2.41657391e+01 2.38422170e+01 2.37651432e+01 2.33961905e+01\n",
      " 2.27744385e+01 2.27357305e+01 2.25205944e+01 2.24236744e+01\n",
      " 2.12491617e+01 1.99537452e+01 1.90041014e+01 1.89374084e+01\n",
      " 1.80127315e+01 1.66598478e+01 1.59464689e+01 1.58963927e+01\n",
      " 1.55600580e+01 1.48173085e+01 1.38003428e+01 1.33959657e+01\n",
      " 1.08627496e+01 1.04829733e+01 9.69697511e+00 9.21804894e+00\n",
      " 9.20065337e+00 8.62189165e+00 8.59404010e+00 8.44315410e+00\n",
      " 8.33098688e+00 8.21623929e+00 7.70099373e+00 7.59057460e+00\n",
      " 7.40138536e+00 7.34863492e+00 7.01859797e+00 6.65424170e+00\n",
      " 6.40242684e+00 6.00518930e+00 5.55851004e+00 5.36461722e+00\n",
      " 5.03723256e+00 5.01597460e+00 4.91014971e+00 4.71206769e+00\n",
      " 4.68971228e+00 4.59101297e+00 4.58300670e+00 4.56814784e+00\n",
      " 4.42976480e+00 4.40491635e+00 4.35977746e+00 4.33525125e+00\n",
      " 4.27954711e+00 4.26654331e+00 4.16053777e+00 4.08402527e+00\n",
      " 4.06282639e+00 3.94131986e+00 3.92146247e+00 3.79734925e+00\n",
      " 3.78907275e+00 3.78076272e+00 3.75929598e+00 3.62513109e+00\n",
      " 3.58570893e+00 3.58415725e+00 3.52074436e+00 3.48820590e+00\n",
      " 3.38513091e+00 3.37680901e+00 3.37091907e+00 3.34286812e+00\n",
      " 3.31711308e+00 3.31264382e+00 3.29889064e+00 3.29539593e+00\n",
      " 3.26080783e+00 3.14974687e+00 3.14649552e+00 3.13955824e+00\n",
      " 3.13500392e+00 3.12871533e+00 3.10820566e+00 3.05188564e+00\n",
      " 3.02129099e+00 2.97520443e+00 2.95828365e+00 2.92918235e+00\n",
      " 2.89532749e+00 2.88163101e+00 2.81347032e+00 2.73961346e+00\n",
      " 2.73472224e+00 2.72181451e+00 2.71635118e+00 2.69507209e+00\n",
      " 2.64282449e+00 2.62525793e+00 2.61029011e+00 2.58314507e+00\n",
      " 2.56489379e+00 2.50161732e+00 2.49458747e+00 2.48491194e+00\n",
      " 2.46284084e+00 2.45395111e+00 2.39479766e+00 2.35889100e+00\n",
      " 2.33422925e+00 2.32523268e+00 2.31965642e+00 2.30445410e+00\n",
      " 2.28387059e+00 2.26065388e+00 2.23924056e+00 2.23539072e+00\n",
      " 2.22297591e+00 2.22038346e+00 2.19752173e+00 2.16303099e+00\n",
      " 2.15390000e+00 2.14979260e+00 2.14602059e+00 2.14465207e+00\n",
      " 2.13628375e+00 2.13118444e+00 2.11689776e+00 2.08887381e+00\n",
      " 2.08171333e+00 2.05860918e+00 2.05046647e+00 2.04719871e+00\n",
      " 2.01412244e+00 2.01211016e+00 2.00864818e+00 1.94509877e+00\n",
      " 1.93393411e+00 1.92015841e+00 1.89943583e+00 1.88506567e+00\n",
      " 1.87144070e+00 1.85232694e+00 1.82710068e+00 1.82199936e+00\n",
      " 1.81037660e+00 1.80504302e+00 1.80022077e+00 1.76421203e+00\n",
      " 1.76017634e+00 1.75405954e+00 1.72695890e+00 1.69536545e+00\n",
      " 1.67986386e+00 1.67501723e+00 1.67324659e+00 1.66742816e+00\n",
      " 1.66523690e+00 1.63853491e+00 1.63175997e+00 1.62136489e+00\n",
      " 1.60846739e+00 1.60765478e+00 1.57377820e+00 1.56645370e+00\n",
      " 1.56202060e+00 1.54320174e+00 1.52376260e+00 1.52118551e+00\n",
      " 1.50925780e+00 1.50920348e+00 1.50851632e+00 1.48831197e+00\n",
      " 1.47407886e+00 1.44586896e+00 1.43301035e+00 1.43055567e+00\n",
      " 1.39814254e+00 1.39169607e+00 1.38924972e+00 1.38900472e+00\n",
      " 1.38209438e+00 1.37972586e+00 1.37917865e+00 1.37094592e+00\n",
      " 1.36212974e+00 1.36097976e+00 1.34300312e+00 1.34010583e+00\n",
      " 1.31644393e+00 1.28573173e+00 1.27354201e+00 1.26523132e+00\n",
      " 1.24786094e+00 1.24292510e+00 1.24096941e+00 1.22024617e+00\n",
      " 1.20290993e+00 1.18988748e+00 1.18790475e+00 1.18499171e+00\n",
      " 1.17752789e+00 1.17659955e+00 1.16875664e+00 1.15864169e+00\n",
      " 1.14955675e+00 1.14648161e+00 1.13745879e+00 1.13433446e+00\n",
      " 1.13224970e+00 1.13169062e+00 1.12428129e+00 1.11694277e+00\n",
      " 1.11352810e+00 1.10639487e+00 1.10587184e+00 1.10030233e+00\n",
      " 1.09083162e+00 1.08737995e+00 1.08551986e+00 1.07437964e+00\n",
      " 1.06147708e+00 1.03112049e+00 1.03098383e+00 1.01810228e+00\n",
      " 1.01414675e+00 1.01155039e+00 9.96908085e-01 9.94580309e-01\n",
      " 9.90944789e-01 9.90759226e-01 9.90342077e-01 9.89505909e-01\n",
      " 9.79377643e-01 9.75534046e-01 9.75114042e-01 9.68130440e-01\n",
      " 9.59032744e-01 9.58038017e-01 9.43616955e-01 9.41651337e-01\n",
      " 9.39210599e-01 9.26550443e-01 9.23888383e-01 9.18162479e-01\n",
      " 9.17956103e-01 9.02406685e-01 8.86558445e-01 8.85340948e-01\n",
      " 8.77142142e-01 8.72260126e-01 8.29506035e-01 8.26111948e-01\n",
      " 8.25799929e-01 8.24845406e-01 8.16214408e-01 8.04296304e-01\n",
      " 8.02759184e-01 8.02395760e-01 7.88886928e-01 7.86729452e-01\n",
      " 7.85116797e-01 7.81554404e-01 7.75515976e-01 7.75407607e-01\n",
      " 7.71555918e-01 7.63125845e-01 7.60519260e-01 7.57184244e-01\n",
      " 7.56500993e-01 7.55072395e-01 7.52463027e-01 7.51030209e-01\n",
      " 7.45613986e-01 7.40523543e-01 7.33371193e-01 7.28457973e-01\n",
      " 7.21533794e-01 7.14591445e-01 7.13598258e-01 7.10246322e-01\n",
      " 7.09619600e-01 7.06963805e-01 7.01447983e-01 6.99187331e-01\n",
      " 6.97012377e-01 6.91664181e-01 6.86902502e-01 6.83716924e-01\n",
      " 6.80958210e-01 6.78045096e-01 6.77106754e-01 6.70052801e-01\n",
      " 6.68519651e-01 6.67597012e-01 6.66658553e-01 6.65672476e-01\n",
      " 6.65012809e-01 6.63130072e-01 6.62874107e-01 6.56285487e-01\n",
      " 6.55975980e-01 6.54763004e-01 6.53044764e-01 6.52041198e-01\n",
      " 6.48689164e-01 6.47036216e-01 6.44038164e-01 6.38789004e-01\n",
      " 6.35244616e-01 6.29516241e-01 6.29261426e-01 6.20056196e-01\n",
      " 6.17318685e-01 6.13818221e-01 6.11151662e-01 6.10010591e-01\n",
      " 6.09195913e-01 6.07639006e-01 5.98578613e-01 5.86062611e-01\n",
      " 5.81973780e-01 5.80009864e-01 5.59215674e-01 5.53836709e-01\n",
      " 5.53440775e-01 5.53219842e-01 5.50976155e-01 5.49858468e-01\n",
      " 5.49572213e-01 5.49257896e-01 5.48019130e-01 5.46501761e-01\n",
      " 5.45531113e-01 5.45503636e-01 5.38304758e-01 5.36203255e-01\n",
      " 5.31998993e-01 5.22752575e-01 5.21222491e-01 5.20717351e-01\n",
      " 5.14675083e-01 5.14030867e-01 5.12511986e-01 5.07882124e-01\n",
      " 5.07708997e-01 4.96894180e-01 4.89644042e-01 4.88737478e-01\n",
      " 4.87721617e-01 4.87366389e-01 4.87284420e-01 4.86375381e-01\n",
      " 4.80312795e-01 4.78361207e-01 4.71502191e-01 4.68621103e-01\n",
      " 4.63399236e-01 4.62519559e-01 4.62192742e-01 4.56794671e-01\n",
      " 4.41257733e-01 4.40754425e-01 4.39828911e-01 4.37465087e-01\n",
      " 4.35323160e-01 4.32545735e-01 4.27923109e-01 4.23510055e-01\n",
      " 4.19915937e-01 4.17954112e-01 4.15025826e-01 4.10142186e-01\n",
      " 4.08663627e-01 4.04475679e-01 4.01265530e-01 4.00367711e-01\n",
      " 4.00004670e-01 3.93025362e-01 3.87315908e-01 3.86469093e-01\n",
      " 3.84958262e-01 3.80225800e-01 3.74124315e-01 3.73908675e-01\n",
      " 3.72015323e-01 3.71981236e-01 3.71100864e-01 3.66107415e-01\n",
      " 3.63517053e-01 3.61690528e-01 3.57218454e-01 3.55509660e-01\n",
      " 3.53952290e-01 3.52174595e-01 3.50706878e-01 3.50624840e-01\n",
      " 3.46088655e-01 3.45994167e-01 3.38307340e-01 3.36878247e-01\n",
      " 3.33941398e-01 3.32027522e-01 3.31237170e-01 3.30311531e-01\n",
      " 3.13597787e-01 3.06065296e-01 3.02774548e-01 3.02603554e-01\n",
      " 2.99661783e-01 2.97163327e-01 2.97037608e-01 2.95509907e-01\n",
      " 2.92359224e-01 2.91180201e-01 2.90557570e-01 2.87772693e-01\n",
      " 2.86787862e-01 2.85843098e-01 2.83998381e-01 2.83825636e-01\n",
      " 2.79743664e-01 2.74005937e-01 2.73878275e-01 2.68493745e-01\n",
      " 2.65167808e-01 2.63577909e-01 2.61430786e-01 2.57375499e-01\n",
      " 2.55318377e-01 2.53768069e-01 2.49259894e-01 2.44945146e-01\n",
      " 2.43066902e-01 2.41021070e-01 2.38461773e-01 2.37455545e-01\n",
      " 2.36357322e-01 2.35945485e-01 2.34857057e-01 2.34074786e-01\n",
      " 2.26139599e-01 2.23653401e-01 2.23318671e-01 2.18044575e-01\n",
      " 2.12622607e-01 2.11488032e-01 2.10211702e-01 2.08737616e-01\n",
      " 2.06792355e-01 2.04326609e-01 2.04028243e-01 2.03824054e-01\n",
      " 2.03556006e-01 2.01322155e-01 2.00819743e-01 1.97748238e-01\n",
      " 1.95394016e-01 1.94893806e-01 1.94359921e-01 1.93421707e-01\n",
      " 1.91245662e-01 1.90311714e-01 1.84350466e-01 1.83770267e-01\n",
      " 1.83728235e-01 1.80939877e-01 1.79583324e-01 1.77555162e-01\n",
      " 1.74185224e-01 1.69816023e-01 1.67424102e-01 1.66987139e-01\n",
      " 1.64806916e-01 1.64225322e-01 1.62422962e-01 1.55344999e-01\n",
      " 1.54243723e-01 1.53951916e-01 1.53747177e-01 1.53644668e-01\n",
      " 1.53469624e-01 1.53371564e-01 1.52336730e-01 1.52179785e-01\n",
      " 1.51691964e-01 1.49316017e-01 1.49118229e-01 1.47520867e-01\n",
      " 1.47344340e-01 1.46800408e-01 1.45783384e-01 1.45223590e-01\n",
      " 1.44595463e-01 1.44543554e-01 1.43503038e-01 1.42540150e-01\n",
      " 1.41387848e-01 1.41052429e-01 1.36026537e-01 1.35905167e-01\n",
      " 1.35757388e-01 1.34830845e-01 1.34276593e-01 1.32100127e-01\n",
      " 1.31462819e-01 1.31333465e-01 1.29468985e-01 1.27596457e-01\n",
      " 1.24626840e-01 1.23880754e-01 1.21311224e-01 1.20727579e-01\n",
      " 1.20059700e-01 1.18850430e-01 1.18013649e-01 1.16807053e-01\n",
      " 1.16050831e-01 1.14151174e-01 1.11536591e-01 1.08805868e-01\n",
      " 1.08628170e-01 1.08178377e-01 1.06043412e-01 1.05541359e-01\n",
      " 1.04727642e-01 1.00188441e-01 9.58811423e-02 9.44527315e-02\n",
      " 9.29376185e-02 9.11875338e-02 9.11479687e-02 9.11440371e-02\n",
      " 8.85473309e-02 8.73169617e-02 8.68928037e-02 8.64039922e-02\n",
      " 8.59554285e-02 8.52936773e-02 8.45971315e-02 8.39733931e-02\n",
      " 8.33337542e-02 8.11429580e-02 7.94176539e-02 7.91874238e-02\n",
      " 7.90253175e-02 7.88132786e-02 7.82684861e-02 7.54846131e-02\n",
      " 7.43602913e-02 7.38924923e-02 7.34853704e-02 7.07968990e-02\n",
      " 6.92185192e-02 6.76809345e-02 6.65844415e-02 6.59398461e-02\n",
      " 6.55226651e-02 6.53403903e-02 6.52163654e-02 6.43305700e-02\n",
      " 6.32783066e-02 6.12224986e-02 6.04606629e-02 6.04084585e-02\n",
      " 5.95530476e-02 5.94262483e-02 5.75281325e-02 5.71122584e-02\n",
      " 5.70034080e-02 5.65245131e-02 5.56761724e-02 5.49350463e-02\n",
      " 5.48853896e-02 5.29642129e-02 5.04422754e-02 4.99407186e-02\n",
      " 4.93307786e-02 4.84925313e-02 4.72131829e-02 4.69333476e-02\n",
      " 4.40180771e-02 4.21366110e-02 4.16682396e-02 4.12281307e-02\n",
      " 4.10912792e-02 4.08681779e-02 4.04896128e-02 3.71488245e-02\n",
      " 3.55365972e-02 3.44298374e-02 3.32603441e-02 3.31109807e-02\n",
      " 3.30105200e-02 3.25262786e-02 3.24794252e-02 3.23742401e-02\n",
      " 3.21494763e-02 3.05556112e-02 2.98688462e-02 2.96933210e-02\n",
      " 2.92181314e-02 2.87946036e-02 2.84066135e-02 2.81771113e-02\n",
      " 2.66975607e-02 2.66949994e-02 2.66530581e-02 2.58061500e-02\n",
      " 2.49890043e-02 2.45420278e-02 2.44668287e-02 2.41836440e-02\n",
      " 2.38504451e-02 2.25317887e-02 2.25027168e-02 2.23887256e-02\n",
      " 2.08290794e-02 2.03023755e-02 2.02049900e-02 2.01047535e-02\n",
      " 1.98215573e-02 1.88014772e-02 1.87759570e-02 1.79822582e-02\n",
      " 1.76260844e-02 1.73637986e-02 1.71821477e-02 1.66931178e-02\n",
      " 1.50447500e-02 1.47963989e-02 1.45846106e-02 1.35969293e-02\n",
      " 1.21719820e-02 1.19172290e-02 1.14852771e-02 1.12702246e-02\n",
      " 1.08964636e-02 1.05164634e-02 1.03856014e-02 1.01290128e-02\n",
      " 9.95064150e-03 9.47554752e-03 9.31165744e-03 8.94112183e-03\n",
      " 8.74823434e-03 7.82396880e-03 7.71633023e-03 7.65962377e-03\n",
      " 7.62649107e-03 7.35937845e-03 7.17362549e-03 7.07591717e-03\n",
      " 7.00921073e-03 6.54574038e-03 6.18872194e-03 5.80769387e-03\n",
      " 4.87056943e-03 4.13939287e-03 3.85360428e-03 3.84970923e-03\n",
      " 3.60067314e-03 3.40121562e-03 3.14713993e-03 3.10895499e-03\n",
      " 3.03654201e-03 2.84400824e-03 2.82440586e-03 2.77363261e-03\n",
      " 2.50427782e-03 2.48825812e-03 2.47966501e-03 2.37243417e-03\n",
      " 2.33418995e-03 2.21139515e-03 2.10684693e-03 1.78159263e-03\n",
      " 1.67223819e-03 1.39797034e-03 1.35971696e-03 1.27885456e-03\n",
      " 1.18812166e-03 9.05392199e-04 8.86107536e-04 8.56521434e-04\n",
      " 7.18570551e-04 4.38980332e-04 4.02622197e-04 3.69146727e-04\n",
      " 3.14335002e-04 2.68016054e-04 2.40644375e-04 9.48861553e-05\n",
      " 6.15573431e-05 4.51941262e-05 4.50657513e-05 3.30410008e-05\n",
      " 8.87765512e-06 2.72909488e-06 2.26606189e-06            nan\n",
      "            nan            nan            nan]\n",
      "[731 772 523 493 746  82 685 333 391 722 882 751 291   0  96 349 730 687\n",
      " 363 673 340 664 604 185 838 300 180 309 665 686 608 744 297 345 853 490\n",
      " 547 636  80 613 470 234 156 810 120 430 232 370 426  89]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/francesco/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/francesco/anaconda3/lib/python3.6/site-packages/sklearn/feature_selection/univariate_selection.py:298: RuntimeWarning: invalid value encountered in true_divide\n",
      "  corr /= X_norms\n",
      "/home/francesco/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater\n",
      "  return (self.a < x) & (x < self.b)\n",
      "/home/francesco/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less\n",
      "  return (self.a < x) & (x < self.b)\n",
      "/home/francesco/anaconda3/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal\n",
      "  cond2 = cond0 & (x <= self.a)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(X_train_scaled.shape)\n",
    "print(Y_train.shape)\n",
    "features_scores = f_regression(X_train_scaled,Y_train)[0]\n",
    "#print(features_scores)\n",
    "y = list(features_scores)\n",
    "myarray = np.asarray(y)\n",
    "print(-1*np.sort(-1*myarray))\n",
    "#print(-1*np.sort(myarray-1))\n",
    "plt.plot(-1*np.sort(-1*myarray))\n",
    "\n",
    "indices = myarray.argsort()[-50:][::-1]\n",
    "print(indices)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape:  (1212, 50)\n",
      "Test shape:  (776, 50)\n",
      "Train shape:  (1212, 50)\n",
      "Test shape:  (776, 50)\n",
      "(1212, 50)\n"
     ]
    }
   ],
   "source": [
    "X_train_subset = train_data_mean[train_data_mean.columns[indices]]\n",
    "X_test_subset = test_data_mean[train_data_mean.columns[indices]]\n",
    "\n",
    "#print(X_subset.head(1))\n",
    "\n",
    "X_train_subset, X_test_subset = fill_NaN(X_train_subset, X_test_subset)\n",
    "X_train_subset, X_test_subset = scale_data(X_train_subset, X_test_subset)\n",
    "\n",
    "print(X_train_subset.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/francesco/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:1306: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 2448.42178018\n",
      "Validation score: -51.726343\n",
      "Iteration 2, loss = 2444.70529660\n",
      "Validation score: -51.647951\n",
      "Iteration 3, loss = 2441.00777183\n",
      "Validation score: -51.569600\n",
      "Iteration 4, loss = 2437.30749103\n",
      "Validation score: -51.491409\n",
      "Iteration 5, loss = 2433.62304545\n",
      "Validation score: -51.413345\n",
      "Iteration 6, loss = 2429.93646943\n",
      "Validation score: -51.335516\n",
      "Iteration 7, loss = 2426.25697270\n",
      "Validation score: -51.257874\n",
      "Iteration 8, loss = 2422.59529853\n",
      "Validation score: -51.180351\n",
      "Iteration 9, loss = 2418.93133497\n",
      "Validation score: -51.103045\n",
      "Iteration 10, loss = 2415.28006973\n",
      "Validation score: -51.025899\n",
      "Iteration 11, loss = 2411.63409805\n",
      "Validation score: -50.948960\n",
      "Iteration 12, loss = 2408.00670727\n",
      "Validation score: -50.872037\n",
      "Iteration 13, loss = 2404.37727825\n",
      "Validation score: -50.795418\n",
      "Iteration 14, loss = 2400.76220329\n",
      "Validation score: -50.718996\n",
      "Iteration 15, loss = 2397.16179783\n",
      "Validation score: -50.642771\n",
      "Iteration 16, loss = 2393.56558398\n",
      "Validation score: -50.566843\n",
      "Iteration 17, loss = 2389.98490771\n",
      "Validation score: -50.491104\n",
      "Iteration 18, loss = 2386.41380011\n",
      "Validation score: -50.415584\n",
      "Iteration 19, loss = 2382.85961928\n",
      "Validation score: -50.340435\n",
      "Iteration 20, loss = 2379.30699042\n",
      "Validation score: -50.265664\n",
      "Iteration 21, loss = 2375.78755258\n",
      "Validation score: -50.191121\n",
      "Iteration 22, loss = 2372.26224453\n",
      "Validation score: -50.116986\n",
      "Iteration 23, loss = 2368.77300868\n",
      "Validation score: -50.043130\n",
      "Iteration 24, loss = 2365.28736819\n",
      "Validation score: -49.969713\n",
      "Iteration 25, loss = 2361.82463568\n",
      "Validation score: -49.896576\n",
      "Iteration 26, loss = 2358.37207771\n",
      "Validation score: -49.823814\n",
      "Iteration 27, loss = 2354.93854327\n",
      "Validation score: -49.751351\n",
      "Iteration 28, loss = 2351.52141854\n",
      "Validation score: -49.679293\n",
      "Iteration 29, loss = 2348.13070837\n",
      "Validation score: -49.607502\n",
      "Iteration 30, loss = 2344.73963522\n",
      "Validation score: -49.536375\n",
      "Iteration 31, loss = 2341.37629032\n",
      "Validation score: -49.465716\n",
      "Iteration 32, loss = 2338.03838602\n",
      "Validation score: -49.395110\n",
      "Iteration 33, loss = 2334.70481300\n",
      "Validation score: -49.324939\n",
      "Iteration 34, loss = 2331.39886455\n",
      "Validation score: -49.255018\n",
      "Iteration 35, loss = 2328.09550491\n",
      "Validation score: -49.185721\n",
      "Iteration 36, loss = 2324.82446381\n",
      "Validation score: -49.116757\n",
      "Iteration 37, loss = 2321.57517753\n",
      "Validation score: -49.048194\n",
      "Iteration 38, loss = 2318.33791995\n",
      "Validation score: -48.980205\n",
      "Iteration 39, loss = 2315.11998028\n",
      "Validation score: -48.912752\n",
      "Iteration 40, loss = 2311.93783094\n",
      "Validation score: -48.845540\n",
      "Iteration 41, loss = 2308.76928036\n",
      "Validation score: -48.778784\n",
      "Iteration 42, loss = 2305.61804027\n",
      "Validation score: -48.712587\n",
      "Iteration 43, loss = 2302.48863662\n",
      "Validation score: -48.646943\n",
      "Iteration 44, loss = 2299.37727628\n",
      "Validation score: -48.581732\n",
      "Iteration 45, loss = 2296.29657532\n",
      "Validation score: -48.516797\n",
      "Iteration 46, loss = 2293.22998684\n",
      "Validation score: -48.452264\n",
      "Iteration 47, loss = 2290.17883020\n",
      "Validation score: -48.388136\n",
      "Iteration 48, loss = 2287.14859579\n",
      "Validation score: -48.324517\n",
      "Iteration 49, loss = 2284.14811565\n",
      "Validation score: -48.261331\n",
      "Iteration 50, loss = 2281.15531465\n",
      "Validation score: -48.198696\n",
      "Iteration 51, loss = 2278.19473339\n",
      "Validation score: -48.136432\n",
      "Iteration 52, loss = 2275.25380029\n",
      "Validation score: -48.074571\n",
      "Iteration 53, loss = 2272.32735210\n",
      "Validation score: -48.013246\n",
      "Iteration 54, loss = 2269.42853000\n",
      "Validation score: -47.952302\n",
      "Iteration 55, loss = 2266.54015208\n",
      "Validation score: -47.891832\n",
      "Iteration 56, loss = 2263.68456289\n",
      "Validation score: -47.831748\n",
      "Iteration 57, loss = 2260.84143456\n",
      "Validation score: -47.772058\n",
      "Iteration 58, loss = 2258.02181209\n",
      "Validation score: -47.712775\n",
      "Iteration 59, loss = 2255.21629758\n",
      "Validation score: -47.653901\n",
      "Iteration 60, loss = 2252.43082262\n",
      "Validation score: -47.595441\n",
      "Iteration 61, loss = 2249.66903946\n",
      "Validation score: -47.537414\n",
      "Iteration 62, loss = 2246.92166066\n",
      "Validation score: -47.479893\n",
      "Iteration 63, loss = 2244.20420180\n",
      "Validation score: -47.422698\n",
      "Iteration 64, loss = 2241.50103804\n",
      "Validation score: -47.365863\n",
      "Iteration 65, loss = 2238.81408975\n",
      "Validation score: -47.309404\n",
      "Iteration 66, loss = 2236.14875237\n",
      "Validation score: -47.253324\n",
      "Iteration 67, loss = 2233.49803922\n",
      "Validation score: -47.197727\n",
      "Iteration 68, loss = 2230.86805356\n",
      "Validation score: -47.142467\n",
      "Iteration 69, loss = 2228.25948360\n",
      "Validation score: -47.087513\n",
      "Iteration 70, loss = 2225.66062188\n",
      "Validation score: -47.032976\n",
      "Iteration 71, loss = 2223.08783242\n",
      "Validation score: -46.978746\n",
      "Iteration 72, loss = 2220.52641511\n",
      "Validation score: -46.924945\n",
      "Iteration 73, loss = 2217.97881643\n",
      "Validation score: -46.871517\n",
      "Iteration 74, loss = 2215.45707951\n",
      "Validation score: -46.818344\n",
      "Iteration 75, loss = 2212.94443105\n",
      "Validation score: -46.765594\n",
      "Iteration 76, loss = 2210.45184164\n",
      "Validation score: -46.713121\n",
      "Iteration 77, loss = 2207.96724453\n",
      "Validation score: -46.660947\n",
      "Iteration 78, loss = 2205.50248775\n",
      "Validation score: -46.609071\n",
      "Iteration 79, loss = 2203.04901454\n",
      "Validation score: -46.557580\n",
      "Iteration 80, loss = 2200.61389541\n",
      "Validation score: -46.506353\n",
      "Iteration 81, loss = 2198.19347609\n",
      "Validation score: -46.455403\n",
      "Iteration 82, loss = 2195.79068628\n",
      "Validation score: -46.404716\n",
      "Iteration 83, loss = 2193.39512972\n",
      "Validation score: -46.354367\n",
      "Iteration 84, loss = 2191.01221302\n",
      "Validation score: -46.304319\n",
      "Iteration 85, loss = 2188.64463225\n",
      "Validation score: -46.254560\n",
      "Iteration 86, loss = 2186.29815074\n",
      "Validation score: -46.204862\n",
      "Iteration 87, loss = 2183.95162725\n",
      "Validation score: -46.155469\n",
      "Iteration 88, loss = 2181.61530588\n",
      "Validation score: -46.106377\n",
      "Iteration 89, loss = 2179.29718973\n",
      "Validation score: -46.057480\n",
      "Iteration 90, loss = 2176.98568088\n",
      "Validation score: -46.008899\n",
      "Iteration 91, loss = 2174.69250147\n",
      "Validation score: -45.960495\n",
      "Iteration 92, loss = 2172.40862777\n",
      "Validation score: -45.912285\n",
      "Iteration 93, loss = 2170.13031411\n",
      "Validation score: -45.864408\n",
      "Iteration 94, loss = 2167.86526904\n",
      "Validation score: -45.816665\n",
      "Iteration 95, loss = 2165.61602070\n",
      "Validation score: -45.769099\n",
      "Iteration 96, loss = 2163.36922557\n",
      "Validation score: -45.721754\n",
      "Iteration 97, loss = 2161.13667565\n",
      "Validation score: -45.674620\n",
      "Iteration 98, loss = 2158.90921019\n",
      "Validation score: -45.627782\n",
      "Iteration 99, loss = 2156.69990125\n",
      "Validation score: -45.581047\n",
      "Iteration 100, loss = 2154.49239778\n",
      "Validation score: -45.534552\n",
      "Iteration 101, loss = 2152.29462977\n",
      "Validation score: -45.488191\n",
      "Iteration 102, loss = 2150.11118345\n",
      "Validation score: -45.441933\n",
      "Iteration 103, loss = 2147.93172947\n",
      "Validation score: -45.395915\n",
      "Iteration 104, loss = 2145.75509257\n",
      "Validation score: -45.350150\n",
      "Iteration 105, loss = 2143.59056214\n",
      "Validation score: -45.304505\n",
      "Iteration 106, loss = 2141.43893242\n",
      "Validation score: -45.258979\n",
      "Iteration 107, loss = 2139.28897168\n",
      "Validation score: -45.213651\n",
      "Iteration 108, loss = 2137.14811667\n",
      "Validation score: -45.168477\n",
      "Iteration 109, loss = 2135.01385197\n",
      "Validation score: -45.123405\n",
      "Iteration 110, loss = 2132.88763202\n",
      "Validation score: -45.078504\n",
      "Iteration 111, loss = 2130.76595108\n",
      "Validation score: -45.033702\n",
      "Iteration 112, loss = 2128.65359503\n",
      "Validation score: -44.989004\n",
      "Iteration 113, loss = 2126.54736817\n",
      "Validation score: -44.944478\n",
      "Iteration 114, loss = 2124.44672061\n",
      "Validation score: -44.900100\n",
      "Iteration 115, loss = 2122.35121587\n",
      "Validation score: -44.855913\n",
      "Iteration 116, loss = 2120.26130557\n",
      "Validation score: -44.811850\n",
      "Iteration 117, loss = 2118.18753382\n",
      "Validation score: -44.767757\n",
      "Iteration 118, loss = 2116.10372651\n",
      "Validation score: -44.723874\n",
      "Iteration 119, loss = 2114.03314993\n",
      "Validation score: -44.680068\n",
      "Iteration 120, loss = 2111.96189039\n",
      "Validation score: -44.636376\n",
      "Iteration 121, loss = 2109.90479698\n",
      "Validation score: -44.592706\n",
      "Iteration 122, loss = 2107.84147265\n",
      "Validation score: -44.549188\n",
      "Iteration 123, loss = 2105.78897570\n",
      "Validation score: -44.505732\n",
      "Iteration 124, loss = 2103.73510102\n",
      "Validation score: -44.462382\n",
      "Iteration 125, loss = 2101.69220395\n",
      "Validation score: -44.419090\n",
      "Iteration 126, loss = 2099.65202666\n",
      "Validation score: -44.375851\n",
      "Iteration 127, loss = 2097.60873044\n",
      "Validation score: -44.332736\n",
      "Iteration 128, loss = 2095.57305353\n",
      "Validation score: -44.289683\n",
      "Iteration 129, loss = 2093.54626023\n",
      "Validation score: -44.246668\n",
      "Iteration 130, loss = 2091.51507284\n",
      "Validation score: -44.203827\n",
      "Iteration 131, loss = 2089.49278146\n",
      "Validation score: -44.161051\n",
      "Iteration 132, loss = 2087.47580913\n",
      "Validation score: -44.118278\n",
      "Iteration 133, loss = 2085.45570903\n",
      "Validation score: -44.075606\n",
      "Iteration 134, loss = 2083.44431661\n",
      "Validation score: -44.032946\n",
      "Iteration 135, loss = 2081.42724943\n",
      "Validation score: -43.990404\n",
      "Iteration 136, loss = 2079.41808332\n",
      "Validation score: -43.947879\n",
      "Iteration 137, loss = 2077.41214185\n",
      "Validation score: -43.905382\n",
      "Iteration 138, loss = 2075.40700980\n",
      "Validation score: -43.862940\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 139, loss = 2073.40419690\n",
      "Validation score: -43.820531\n",
      "Iteration 140, loss = 2071.40778531\n",
      "Validation score: -43.778216\n",
      "Iteration 141, loss = 2069.41277858\n",
      "Validation score: -43.735999\n",
      "Iteration 142, loss = 2067.42057520\n",
      "Validation score: -43.693956\n",
      "Iteration 143, loss = 2065.43623387\n",
      "Validation score: -43.651968\n",
      "Iteration 144, loss = 2063.45551847\n",
      "Validation score: -43.610028\n",
      "Iteration 145, loss = 2061.47318572\n",
      "Validation score: -43.568159\n",
      "Iteration 146, loss = 2059.49868011\n",
      "Validation score: -43.526368\n",
      "Iteration 147, loss = 2057.52608514\n",
      "Validation score: -43.484620\n",
      "Iteration 148, loss = 2055.55713787\n",
      "Validation score: -43.442951\n",
      "Iteration 149, loss = 2053.58998325\n",
      "Validation score: -43.401387\n",
      "Iteration 150, loss = 2051.63319743\n",
      "Validation score: -43.359880\n",
      "Iteration 151, loss = 2049.67576480\n",
      "Validation score: -43.318523\n",
      "Iteration 152, loss = 2047.72584212\n",
      "Validation score: -43.277254\n",
      "Iteration 153, loss = 2045.78084598\n",
      "Validation score: -43.236052\n",
      "Iteration 154, loss = 2043.83541433\n",
      "Validation score: -43.195021\n",
      "Iteration 155, loss = 2041.89670521\n",
      "Validation score: -43.154037\n",
      "Iteration 156, loss = 2039.96482840\n",
      "Validation score: -43.113081\n",
      "Iteration 157, loss = 2038.03583175\n",
      "Validation score: -43.072212\n",
      "Iteration 158, loss = 2036.10988549\n",
      "Validation score: -43.031447\n",
      "Iteration 159, loss = 2034.18932480\n",
      "Validation score: -42.990802\n",
      "Iteration 160, loss = 2032.27161241\n",
      "Validation score: -42.950240\n",
      "Iteration 161, loss = 2030.36103135\n",
      "Validation score: -42.909789\n",
      "Iteration 162, loss = 2028.45462517\n",
      "Validation score: -42.869430\n",
      "Iteration 163, loss = 2026.55215557\n",
      "Validation score: -42.829174\n",
      "Iteration 164, loss = 2024.65020418\n",
      "Validation score: -42.789053\n",
      "Iteration 165, loss = 2022.76218128\n",
      "Validation score: -42.748960\n",
      "Iteration 166, loss = 2020.87413924\n",
      "Validation score: -42.708977\n",
      "Iteration 167, loss = 2018.98964266\n",
      "Validation score: -42.669121\n",
      "Iteration 168, loss = 2017.11381702\n",
      "Validation score: -42.629351\n",
      "Iteration 169, loss = 2015.23582957\n",
      "Validation score: -42.589721\n",
      "Iteration 170, loss = 2013.36885562\n",
      "Validation score: -42.550127\n",
      "Iteration 171, loss = 2011.50325109\n",
      "Validation score: -42.510632\n",
      "Iteration 172, loss = 2009.64270583\n",
      "Validation score: -42.471154\n",
      "Iteration 173, loss = 2007.78235629\n",
      "Validation score: -42.431797\n",
      "Iteration 174, loss = 2005.92642033\n",
      "Validation score: -42.392534\n",
      "Iteration 175, loss = 2004.07478879\n",
      "Validation score: -42.353355\n",
      "Iteration 176, loss = 2002.22982320\n",
      "Validation score: -42.314259\n",
      "Iteration 177, loss = 2000.38634033\n",
      "Validation score: -42.275242\n",
      "Iteration 178, loss = 1998.55019169\n",
      "Validation score: -42.236250\n",
      "Iteration 179, loss = 1996.71209465\n",
      "Validation score: -42.197341\n",
      "Iteration 180, loss = 1994.87677449\n",
      "Validation score: -42.158511\n",
      "Iteration 181, loss = 1993.04116254\n",
      "Validation score: -42.119709\n",
      "Iteration 182, loss = 1991.21341473\n",
      "Validation score: -42.080909\n",
      "Iteration 183, loss = 1989.38710655\n",
      "Validation score: -42.042174\n",
      "Iteration 184, loss = 1987.56088825\n",
      "Validation score: -42.003501\n",
      "Iteration 185, loss = 1985.73764322\n",
      "Validation score: -41.964873\n",
      "Iteration 186, loss = 1983.91785926\n",
      "Validation score: -41.926247\n",
      "Iteration 187, loss = 1982.09349125\n",
      "Validation score: -41.887693\n",
      "Iteration 188, loss = 1980.27600044\n",
      "Validation score: -41.849093\n",
      "Iteration 189, loss = 1978.46000164\n",
      "Validation score: -41.810457\n",
      "Iteration 190, loss = 1976.63140826\n",
      "Validation score: -41.771988\n",
      "Iteration 191, loss = 1974.82325526\n",
      "Validation score: -41.733330\n",
      "Iteration 192, loss = 1972.99806619\n",
      "Validation score: -41.694764\n",
      "Iteration 193, loss = 1971.17876333\n",
      "Validation score: -41.656130\n",
      "Iteration 194, loss = 1969.35854779\n",
      "Validation score: -41.617460\n",
      "Iteration 195, loss = 1967.53393026\n",
      "Validation score: -41.578810\n",
      "Iteration 196, loss = 1965.70700105\n",
      "Validation score: -41.540084\n",
      "Iteration 197, loss = 1963.88437516\n",
      "Validation score: -41.501241\n",
      "Iteration 198, loss = 1962.04993412\n",
      "Validation score: -41.462390\n",
      "Iteration 199, loss = 1960.21742337\n",
      "Validation score: -41.423462\n",
      "Iteration 200, loss = 1958.38056775\n",
      "Validation score: -41.384420\n",
      "Iteration 201, loss = 1956.53398859\n",
      "Validation score: -41.345341\n",
      "Iteration 202, loss = 1954.68876345\n",
      "Validation score: -41.306162\n",
      "Iteration 203, loss = 1952.83969562\n",
      "Validation score: -41.266845\n",
      "Iteration 204, loss = 1950.98709331\n",
      "Validation score: -41.227430\n",
      "Iteration 205, loss = 1949.12530246\n",
      "Validation score: -41.187979\n",
      "Iteration 206, loss = 1947.26551892\n",
      "Validation score: -41.148400\n",
      "Iteration 207, loss = 1945.39907575\n",
      "Validation score: -41.108713\n",
      "Iteration 208, loss = 1943.52617352\n",
      "Validation score: -41.068966\n",
      "Iteration 209, loss = 1941.64724231\n",
      "Validation score: -41.029179\n",
      "Iteration 210, loss = 1939.77417555\n",
      "Validation score: -40.989232\n",
      "Iteration 211, loss = 1937.88728691\n",
      "Validation score: -40.949241\n",
      "Iteration 212, loss = 1935.99514862\n",
      "Validation score: -40.909186\n",
      "Iteration 213, loss = 1934.10910678\n",
      "Validation score: -40.868924\n",
      "Iteration 214, loss = 1932.20733823\n",
      "Validation score: -40.828654\n",
      "Iteration 215, loss = 1930.30663386\n",
      "Validation score: -40.788293\n",
      "Iteration 216, loss = 1928.40287574\n",
      "Validation score: -40.747803\n",
      "Iteration 217, loss = 1926.49332809\n",
      "Validation score: -40.707329\n",
      "Iteration 218, loss = 1924.58537708\n",
      "Validation score: -40.666763\n",
      "Iteration 219, loss = 1922.66864410\n",
      "Validation score: -40.626100\n",
      "Iteration 220, loss = 1920.74655519\n",
      "Validation score: -40.585359\n",
      "Iteration 221, loss = 1918.82544564\n",
      "Validation score: -40.544578\n",
      "Iteration 222, loss = 1916.90688620\n",
      "Validation score: -40.503642\n",
      "Iteration 223, loss = 1914.97064367\n",
      "Validation score: -40.462723\n",
      "Iteration 224, loss = 1913.03690539\n",
      "Validation score: -40.421708\n",
      "Iteration 225, loss = 1911.10635497\n",
      "Validation score: -40.380569\n",
      "Iteration 226, loss = 1909.15908256\n",
      "Validation score: -40.339457\n",
      "Iteration 227, loss = 1907.22245843\n",
      "Validation score: -40.298177\n",
      "Iteration 228, loss = 1905.27735593\n",
      "Validation score: -40.256805\n",
      "Iteration 229, loss = 1903.32171644\n",
      "Validation score: -40.215423\n",
      "Iteration 230, loss = 1901.36888578\n",
      "Validation score: -40.173938\n",
      "Iteration 231, loss = 1899.40849985\n",
      "Validation score: -40.132357\n",
      "Iteration 232, loss = 1897.44638797\n",
      "Validation score: -40.090628\n",
      "Iteration 233, loss = 1895.47986086\n",
      "Validation score: -40.048767\n",
      "Iteration 234, loss = 1893.50051761\n",
      "Validation score: -40.006927\n",
      "Iteration 235, loss = 1891.52762213\n",
      "Validation score: -39.964879\n",
      "Iteration 236, loss = 1889.54711230\n",
      "Validation score: -39.922700\n",
      "Iteration 237, loss = 1887.55356494\n",
      "Validation score: -39.880449\n",
      "Iteration 238, loss = 1885.56257609\n",
      "Validation score: -39.838046\n",
      "Iteration 239, loss = 1883.55948573\n",
      "Validation score: -39.795577\n",
      "Iteration 240, loss = 1881.55310029\n",
      "Validation score: -39.753025\n",
      "Iteration 241, loss = 1879.54441015\n",
      "Validation score: -39.710404\n",
      "Iteration 242, loss = 1877.53288614\n",
      "Validation score: -39.667626\n",
      "Iteration 243, loss = 1875.51532183\n",
      "Validation score: -39.624656\n",
      "Iteration 244, loss = 1873.48892826\n",
      "Validation score: -39.581574\n",
      "Iteration 245, loss = 1871.45334891\n",
      "Validation score: -39.538470\n",
      "Iteration 246, loss = 1869.41926583\n",
      "Validation score: -39.495239\n",
      "Iteration 247, loss = 1867.37975332\n",
      "Validation score: -39.451930\n",
      "Iteration 248, loss = 1865.33668189\n",
      "Validation score: -39.408554\n",
      "Iteration 249, loss = 1863.28668938\n",
      "Validation score: -39.365172\n",
      "Iteration 250, loss = 1861.24096909\n",
      "Validation score: -39.321746\n",
      "Iteration 251, loss = 1859.19789219\n",
      "Validation score: -39.278199\n",
      "Iteration 252, loss = 1857.13978957\n",
      "Validation score: -39.234728\n",
      "Iteration 253, loss = 1855.08970473\n",
      "Validation score: -39.191196\n",
      "Iteration 254, loss = 1853.03731438\n",
      "Validation score: -39.147689\n",
      "Iteration 255, loss = 1850.98436891\n",
      "Validation score: -39.104196\n",
      "Iteration 256, loss = 1848.94049207\n",
      "Validation score: -39.060652\n",
      "Iteration 257, loss = 1846.88266382\n",
      "Validation score: -39.017264\n",
      "Iteration 258, loss = 1844.83846507\n",
      "Validation score: -38.973857\n",
      "Iteration 259, loss = 1842.79349710\n",
      "Validation score: -38.930548\n",
      "Iteration 260, loss = 1840.75043560\n",
      "Validation score: -38.887340\n",
      "Iteration 261, loss = 1838.71621284\n",
      "Validation score: -38.844171\n",
      "Iteration 262, loss = 1836.68559776\n",
      "Validation score: -38.801085\n",
      "Iteration 263, loss = 1834.65740761\n",
      "Validation score: -38.758084\n",
      "Iteration 264, loss = 1832.62929835\n",
      "Validation score: -38.715285\n",
      "Iteration 265, loss = 1830.61281788\n",
      "Validation score: -38.672561\n",
      "Iteration 266, loss = 1828.59862081\n",
      "Validation score: -38.629926\n",
      "Iteration 267, loss = 1826.59008482\n",
      "Validation score: -38.587340\n",
      "Iteration 268, loss = 1824.58835026\n",
      "Validation score: -38.544833\n",
      "Iteration 269, loss = 1822.58306502\n",
      "Validation score: -38.502500\n",
      "Iteration 270, loss = 1820.59201155\n",
      "Validation score: -38.460231\n",
      "Iteration 271, loss = 1818.59954976\n",
      "Validation score: -38.418150\n",
      "Iteration 272, loss = 1816.61985755\n",
      "Validation score: -38.376182\n",
      "Iteration 273, loss = 1814.64065196\n",
      "Validation score: -38.334354\n",
      "Iteration 274, loss = 1812.67479033\n",
      "Validation score: -38.292600\n",
      "Iteration 275, loss = 1810.70637479\n",
      "Validation score: -38.251057\n",
      "Iteration 276, loss = 1808.74830972\n",
      "Validation score: -38.209562\n",
      "Iteration 277, loss = 1806.79672485\n",
      "Validation score: -38.168115\n",
      "Iteration 278, loss = 1804.84768586\n",
      "Validation score: -38.126837\n",
      "Iteration 279, loss = 1802.90401592\n",
      "Validation score: -38.085698\n",
      "Iteration 280, loss = 1800.96384173\n",
      "Validation score: -38.044668\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 281, loss = 1799.03492247\n",
      "Validation score: -38.003664\n",
      "Iteration 282, loss = 1797.10299664\n",
      "Validation score: -37.962736\n",
      "Iteration 283, loss = 1795.17554177\n",
      "Validation score: -37.921976\n",
      "Iteration 284, loss = 1793.25999367\n",
      "Validation score: -37.881288\n",
      "Iteration 285, loss = 1791.34631687\n",
      "Validation score: -37.840745\n",
      "Iteration 286, loss = 1789.43521597\n",
      "Validation score: -37.800362\n",
      "Iteration 287, loss = 1787.53766668\n",
      "Validation score: -37.759946\n",
      "Iteration 288, loss = 1785.63114951\n",
      "Validation score: -37.719662\n",
      "Iteration 289, loss = 1783.73378948\n",
      "Validation score: -37.679456\n",
      "Iteration 290, loss = 1781.83999378\n",
      "Validation score: -37.639300\n",
      "Iteration 291, loss = 1779.95207413\n",
      "Validation score: -37.599162\n",
      "Iteration 292, loss = 1778.06117633\n",
      "Validation score: -37.559090\n",
      "Iteration 293, loss = 1776.17316525\n",
      "Validation score: -37.519030\n",
      "Iteration 294, loss = 1774.28551979\n",
      "Validation score: -37.479030\n",
      "Iteration 295, loss = 1772.40147736\n",
      "Validation score: -37.439045\n",
      "Iteration 296, loss = 1770.51884453\n",
      "Validation score: -37.399057\n",
      "Iteration 297, loss = 1768.63577739\n",
      "Validation score: -37.359041\n",
      "Iteration 298, loss = 1766.74719144\n",
      "Validation score: -37.319077\n",
      "Iteration 299, loss = 1764.86416668\n",
      "Validation score: -37.278973\n",
      "Iteration 300, loss = 1762.97319174\n",
      "Validation score: -37.238809\n",
      "Iteration 301, loss = 1761.08174674\n",
      "Validation score: -37.198570\n",
      "Iteration 302, loss = 1759.18457111\n",
      "Validation score: -37.158283\n",
      "Iteration 303, loss = 1757.28842662\n",
      "Validation score: -37.117961\n",
      "Iteration 304, loss = 1755.38518907\n",
      "Validation score: -37.077538\n",
      "Iteration 305, loss = 1753.48046884\n",
      "Validation score: -37.037001\n",
      "Iteration 306, loss = 1751.56895878\n",
      "Validation score: -36.996420\n",
      "Iteration 307, loss = 1749.65250897\n",
      "Validation score: -36.955775\n",
      "Iteration 308, loss = 1747.73811788\n",
      "Validation score: -36.915002\n",
      "Iteration 309, loss = 1745.81622940\n",
      "Validation score: -36.874113\n",
      "Iteration 310, loss = 1743.88991765\n",
      "Validation score: -36.833101\n",
      "Iteration 311, loss = 1741.95317373\n",
      "Validation score: -36.792027\n",
      "Iteration 312, loss = 1740.01556064\n",
      "Validation score: -36.750850\n",
      "Iteration 313, loss = 1738.07408107\n",
      "Validation score: -36.709525\n",
      "Iteration 314, loss = 1736.12244169\n",
      "Validation score: -36.668147\n",
      "Iteration 315, loss = 1734.17297611\n",
      "Validation score: -36.626611\n",
      "Iteration 316, loss = 1732.21522721\n",
      "Validation score: -36.585043\n",
      "Iteration 317, loss = 1730.25857108\n",
      "Validation score: -36.543431\n",
      "Iteration 318, loss = 1728.30149937\n",
      "Validation score: -36.501802\n",
      "Iteration 319, loss = 1726.33333691\n",
      "Validation score: -36.460240\n",
      "Iteration 320, loss = 1724.37884635\n",
      "Validation score: -36.418581\n",
      "Iteration 321, loss = 1722.41340133\n",
      "Validation score: -36.376951\n",
      "Iteration 322, loss = 1720.45229668\n",
      "Validation score: -36.335245\n",
      "Iteration 323, loss = 1718.48746936\n",
      "Validation score: -36.293549\n",
      "Iteration 324, loss = 1716.52461883\n",
      "Validation score: -36.251847\n",
      "Iteration 325, loss = 1714.56335110\n",
      "Validation score: -36.210167\n",
      "Iteration 326, loss = 1712.60030311\n",
      "Validation score: -36.168559\n",
      "Iteration 327, loss = 1710.63538101\n",
      "Validation score: -36.127052\n",
      "Iteration 328, loss = 1708.68697118\n",
      "Validation score: -36.085488\n",
      "Iteration 329, loss = 1706.72846201\n",
      "Validation score: -36.044086\n",
      "Iteration 330, loss = 1704.77425951\n",
      "Validation score: -36.002733\n",
      "Iteration 331, loss = 1702.83033674\n",
      "Validation score: -35.961353\n",
      "Iteration 332, loss = 1700.87887941\n",
      "Validation score: -35.920155\n",
      "Iteration 333, loss = 1698.94461464\n",
      "Validation score: -35.878970\n",
      "Iteration 334, loss = 1697.00430252\n",
      "Validation score: -35.837932\n",
      "Iteration 335, loss = 1695.07504937\n",
      "Validation score: -35.796963\n",
      "Iteration 336, loss = 1693.14736272\n",
      "Validation score: -35.756176\n",
      "Iteration 337, loss = 1691.22967387\n",
      "Validation score: -35.715509\n",
      "Iteration 338, loss = 1689.32009992\n",
      "Validation score: -35.674935\n",
      "Iteration 339, loss = 1687.40847935\n",
      "Validation score: -35.634545\n",
      "Iteration 340, loss = 1685.50684978\n",
      "Validation score: -35.594219\n",
      "Iteration 341, loss = 1683.61349891\n",
      "Validation score: -35.553973\n",
      "Iteration 342, loss = 1681.71978128\n",
      "Validation score: -35.513900\n",
      "Iteration 343, loss = 1679.83460204\n",
      "Validation score: -35.474018\n",
      "Iteration 344, loss = 1677.95789930\n",
      "Validation score: -35.434269\n",
      "Iteration 345, loss = 1676.08613117\n",
      "Validation score: -35.394648\n",
      "Iteration 346, loss = 1674.22502800\n",
      "Validation score: -35.355116\n",
      "Iteration 347, loss = 1672.36777866\n",
      "Validation score: -35.315691\n",
      "Iteration 348, loss = 1670.51578503\n",
      "Validation score: -35.276367\n",
      "Iteration 349, loss = 1668.66444344\n",
      "Validation score: -35.237220\n",
      "Iteration 350, loss = 1666.82426878\n",
      "Validation score: -35.198197\n",
      "Iteration 351, loss = 1664.99053784\n",
      "Validation score: -35.159323\n",
      "Iteration 352, loss = 1663.16244965\n",
      "Validation score: -35.120574\n",
      "Iteration 353, loss = 1661.33939588\n",
      "Validation score: -35.081934\n",
      "Iteration 354, loss = 1659.52222175\n",
      "Validation score: -35.043394\n",
      "Iteration 355, loss = 1657.70904123\n",
      "Validation score: -35.005020\n",
      "Iteration 356, loss = 1655.90669470\n",
      "Validation score: -34.966746\n",
      "Iteration 357, loss = 1654.10683116\n",
      "Validation score: -34.928581\n",
      "Iteration 358, loss = 1652.31422103\n",
      "Validation score: -34.890538\n",
      "Iteration 359, loss = 1650.52474881\n",
      "Validation score: -34.852613\n",
      "Iteration 360, loss = 1648.74076773\n",
      "Validation score: -34.814821\n",
      "Iteration 361, loss = 1646.96581686\n",
      "Validation score: -34.777109\n",
      "Iteration 362, loss = 1645.19554895\n",
      "Validation score: -34.739523\n",
      "Iteration 363, loss = 1643.42562732\n",
      "Validation score: -34.702117\n",
      "Iteration 364, loss = 1641.66598206\n",
      "Validation score: -34.664751\n",
      "Iteration 365, loss = 1639.91144428\n",
      "Validation score: -34.627420\n",
      "Iteration 366, loss = 1638.15700065\n",
      "Validation score: -34.590200\n",
      "Iteration 367, loss = 1636.40578074\n",
      "Validation score: -34.553089\n",
      "Iteration 368, loss = 1634.65923624\n",
      "Validation score: -34.516043\n",
      "Iteration 369, loss = 1632.91883077\n",
      "Validation score: -34.479094\n",
      "Iteration 370, loss = 1631.18311821\n",
      "Validation score: -34.442232\n",
      "Iteration 371, loss = 1629.44765595\n",
      "Validation score: -34.405540\n",
      "Iteration 372, loss = 1627.72411896\n",
      "Validation score: -34.368855\n",
      "Iteration 373, loss = 1625.99815339\n",
      "Validation score: -34.332266\n",
      "Iteration 374, loss = 1624.27969748\n",
      "Validation score: -34.295731\n",
      "Iteration 375, loss = 1622.56146533\n",
      "Validation score: -34.259292\n",
      "Iteration 376, loss = 1620.84755299\n",
      "Validation score: -34.222975\n",
      "Iteration 377, loss = 1619.13816935\n",
      "Validation score: -34.186774\n",
      "Iteration 378, loss = 1617.43900843\n",
      "Validation score: -34.150569\n",
      "Iteration 379, loss = 1615.73776649\n",
      "Validation score: -34.114427\n",
      "Iteration 380, loss = 1614.03976577\n",
      "Validation score: -34.078378\n",
      "Iteration 381, loss = 1612.34363705\n",
      "Validation score: -34.042431\n",
      "Iteration 382, loss = 1610.64875592\n",
      "Validation score: -34.006614\n",
      "Iteration 383, loss = 1608.96957209\n",
      "Validation score: -33.970753\n",
      "Iteration 384, loss = 1607.28116252\n",
      "Validation score: -33.935038\n",
      "Iteration 385, loss = 1605.60373941\n",
      "Validation score: -33.899319\n",
      "Iteration 386, loss = 1603.92048858\n",
      "Validation score: -33.863718\n",
      "Iteration 387, loss = 1602.24784003\n",
      "Validation score: -33.828132\n",
      "Iteration 388, loss = 1600.57293182\n",
      "Validation score: -33.792573\n",
      "Iteration 389, loss = 1598.90345856\n",
      "Validation score: -33.757115\n",
      "Iteration 390, loss = 1597.23717275\n",
      "Validation score: -33.721736\n",
      "Iteration 391, loss = 1595.57704184\n",
      "Validation score: -33.686410\n",
      "Iteration 392, loss = 1593.92050257\n",
      "Validation score: -33.651175\n",
      "Iteration 393, loss = 1592.26351479\n",
      "Validation score: -33.616059\n",
      "Iteration 394, loss = 1590.61062654\n",
      "Validation score: -33.581011\n",
      "Iteration 395, loss = 1588.96116556\n",
      "Validation score: -33.546012\n",
      "Iteration 396, loss = 1587.31132922\n",
      "Validation score: -33.511087\n",
      "Iteration 397, loss = 1585.66852575\n",
      "Validation score: -33.476131\n",
      "Iteration 398, loss = 1584.02824820\n",
      "Validation score: -33.441173\n",
      "Iteration 399, loss = 1582.38552158\n",
      "Validation score: -33.406318\n",
      "Iteration 400, loss = 1580.74669142\n",
      "Validation score: -33.371574\n",
      "Iteration 401, loss = 1579.11436205\n",
      "Validation score: -33.336845\n",
      "Iteration 402, loss = 1577.48412483\n",
      "Validation score: -33.302143\n",
      "Iteration 403, loss = 1575.85116628\n",
      "Validation score: -33.267568\n",
      "Iteration 404, loss = 1574.22304305\n",
      "Validation score: -33.233037\n",
      "Iteration 405, loss = 1572.59729036\n",
      "Validation score: -33.198542\n",
      "Iteration 406, loss = 1570.97829923\n",
      "Validation score: -33.164014\n",
      "Iteration 407, loss = 1569.35422522\n",
      "Validation score: -33.129556\n",
      "Iteration 408, loss = 1567.73695820\n",
      "Validation score: -33.095123\n",
      "Iteration 409, loss = 1566.11494796\n",
      "Validation score: -33.060785\n",
      "Iteration 410, loss = 1564.50077019\n",
      "Validation score: -33.026469\n",
      "Iteration 411, loss = 1562.88777026\n",
      "Validation score: -32.992199\n",
      "Iteration 412, loss = 1561.27491004\n",
      "Validation score: -32.957985\n",
      "Iteration 413, loss = 1559.66935298\n",
      "Validation score: -32.923741\n",
      "Iteration 414, loss = 1558.05822992\n",
      "Validation score: -32.889586\n",
      "Iteration 415, loss = 1556.45183048\n",
      "Validation score: -32.855444\n",
      "Iteration 416, loss = 1554.84702460\n",
      "Validation score: -32.821310\n",
      "Iteration 417, loss = 1553.24299496\n",
      "Validation score: -32.787205\n",
      "Iteration 418, loss = 1551.63961020\n",
      "Validation score: -32.753165\n",
      "Iteration 419, loss = 1550.03902605\n",
      "Validation score: -32.719115\n",
      "Iteration 420, loss = 1548.43940524\n",
      "Validation score: -32.685096\n",
      "Iteration 421, loss = 1546.83656520\n",
      "Validation score: -32.651116\n",
      "Iteration 422, loss = 1545.23806496\n",
      "Validation score: -32.617139\n",
      "Iteration 423, loss = 1543.64302280\n",
      "Validation score: -32.583125\n",
      "Iteration 424, loss = 1542.04378015\n",
      "Validation score: -32.549168\n",
      "Iteration 425, loss = 1540.44758332\n",
      "Validation score: -32.515214\n",
      "Iteration 426, loss = 1538.85194060\n",
      "Validation score: -32.481231\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 427, loss = 1537.25314215\n",
      "Validation score: -32.447306\n",
      "Iteration 428, loss = 1535.65843799\n",
      "Validation score: -32.413366\n",
      "Iteration 429, loss = 1534.06315352\n",
      "Validation score: -32.379355\n",
      "Iteration 430, loss = 1532.46494853\n",
      "Validation score: -32.345331\n",
      "Iteration 431, loss = 1530.86616224\n",
      "Validation score: -32.311321\n",
      "Iteration 432, loss = 1529.26390687\n",
      "Validation score: -32.277316\n",
      "Iteration 433, loss = 1527.66656706\n",
      "Validation score: -32.243213\n",
      "Iteration 434, loss = 1526.05487557\n",
      "Validation score: -32.209116\n",
      "Iteration 435, loss = 1524.45754480\n",
      "Validation score: -32.174789\n",
      "Iteration 436, loss = 1522.83743930\n",
      "Validation score: -32.140529\n",
      "Iteration 437, loss = 1521.22570504\n",
      "Validation score: -32.106127\n",
      "Iteration 438, loss = 1519.60742923\n",
      "Validation score: -32.071647\n",
      "Iteration 439, loss = 1517.98517468\n",
      "Validation score: -32.037067\n",
      "Iteration 440, loss = 1516.35626782\n",
      "Validation score: -32.002408\n",
      "Iteration 441, loss = 1514.72724096\n",
      "Validation score: -31.967669\n",
      "Iteration 442, loss = 1513.08956466\n",
      "Validation score: -31.932838\n",
      "Iteration 443, loss = 1511.45189780\n",
      "Validation score: -31.897839\n",
      "Iteration 444, loss = 1509.80466683\n",
      "Validation score: -31.862723\n",
      "Iteration 445, loss = 1508.14959876\n",
      "Validation score: -31.827521\n",
      "Iteration 446, loss = 1506.49068003\n",
      "Validation score: -31.792215\n",
      "Iteration 447, loss = 1504.82891816\n",
      "Validation score: -31.756808\n",
      "Iteration 448, loss = 1503.16513544\n",
      "Validation score: -31.721278\n",
      "Iteration 449, loss = 1501.49435549\n",
      "Validation score: -31.685733\n",
      "Iteration 450, loss = 1499.82170361\n",
      "Validation score: -31.650167\n",
      "Iteration 451, loss = 1498.14624188\n",
      "Validation score: -31.614572\n",
      "Iteration 452, loss = 1496.47393104\n",
      "Validation score: -31.578885\n",
      "Iteration 453, loss = 1494.79596757\n",
      "Validation score: -31.543215\n",
      "Iteration 454, loss = 1493.11865540\n",
      "Validation score: -31.507537\n",
      "Iteration 455, loss = 1491.43329185\n",
      "Validation score: -31.471935\n",
      "Iteration 456, loss = 1489.76309848\n",
      "Validation score: -31.436271\n",
      "Iteration 457, loss = 1488.08730351\n",
      "Validation score: -31.400679\n",
      "Iteration 458, loss = 1486.41457074\n",
      "Validation score: -31.365158\n",
      "Iteration 459, loss = 1484.74608023\n",
      "Validation score: -31.329679\n",
      "Iteration 460, loss = 1483.08291175\n",
      "Validation score: -31.294296\n",
      "Iteration 461, loss = 1481.41661215\n",
      "Validation score: -31.259019\n",
      "Iteration 462, loss = 1479.75597544\n",
      "Validation score: -31.223863\n",
      "Iteration 463, loss = 1478.11104579\n",
      "Validation score: -31.188642\n",
      "Iteration 464, loss = 1476.45652488\n",
      "Validation score: -31.153653\n",
      "Iteration 465, loss = 1474.81351458\n",
      "Validation score: -31.118745\n",
      "Iteration 466, loss = 1473.17318035\n",
      "Validation score: -31.083919\n",
      "Iteration 467, loss = 1471.54002803\n",
      "Validation score: -31.049168\n",
      "Iteration 468, loss = 1469.90472469\n",
      "Validation score: -31.014597\n",
      "Iteration 469, loss = 1468.28058195\n",
      "Validation score: -30.980106\n",
      "Iteration 470, loss = 1466.66255549\n",
      "Validation score: -30.945676\n",
      "Iteration 471, loss = 1465.04512921\n",
      "Validation score: -30.911378\n",
      "Iteration 472, loss = 1463.43329277\n",
      "Validation score: -30.877159\n",
      "Iteration 473, loss = 1461.82991084\n",
      "Validation score: -30.843001\n",
      "Iteration 474, loss = 1460.22758637\n",
      "Validation score: -30.808916\n",
      "Iteration 475, loss = 1458.62377405\n",
      "Validation score: -30.774966\n",
      "Iteration 476, loss = 1457.03081474\n",
      "Validation score: -30.741091\n",
      "Iteration 477, loss = 1455.44006251\n",
      "Validation score: -30.707326\n",
      "Iteration 478, loss = 1453.85687124\n",
      "Validation score: -30.673657\n",
      "Iteration 479, loss = 1452.27266561\n",
      "Validation score: -30.640108\n",
      "Iteration 480, loss = 1450.70080255\n",
      "Validation score: -30.606578\n",
      "Iteration 481, loss = 1449.12444997\n",
      "Validation score: -30.573153\n",
      "Iteration 482, loss = 1447.55512700\n",
      "Validation score: -30.539777\n",
      "Iteration 483, loss = 1445.98600842\n",
      "Validation score: -30.506496\n",
      "Iteration 484, loss = 1444.42680161\n",
      "Validation score: -30.473252\n",
      "Iteration 485, loss = 1442.86575171\n",
      "Validation score: -30.440125\n",
      "Iteration 486, loss = 1441.31067464\n",
      "Validation score: -30.407049\n",
      "Iteration 487, loss = 1439.75429170\n",
      "Validation score: -30.374060\n",
      "Iteration 488, loss = 1438.20696539\n",
      "Validation score: -30.341071\n",
      "Iteration 489, loss = 1436.65567817\n",
      "Validation score: -30.308182\n",
      "Iteration 490, loss = 1435.11458514\n",
      "Validation score: -30.275273\n",
      "Iteration 491, loss = 1433.56983341\n",
      "Validation score: -30.242447\n",
      "Iteration 492, loss = 1432.02941421\n",
      "Validation score: -30.209682\n",
      "Iteration 493, loss = 1430.49308942\n",
      "Validation score: -30.177000\n",
      "Iteration 494, loss = 1428.95584906\n",
      "Validation score: -30.144399\n",
      "Iteration 495, loss = 1427.42179106\n",
      "Validation score: -30.111822\n",
      "Iteration 496, loss = 1425.89037543\n",
      "Validation score: -30.079283\n",
      "Iteration 497, loss = 1424.36484638\n",
      "Validation score: -30.046757\n",
      "Iteration 498, loss = 1422.84155672\n",
      "Validation score: -30.014273\n",
      "Iteration 499, loss = 1421.31162023\n",
      "Validation score: -29.981976\n",
      "Iteration 500, loss = 1419.79827859\n",
      "Validation score: -29.949609\n",
      "Iteration 501, loss = 1418.27677829\n",
      "Validation score: -29.917317\n",
      "Iteration 502, loss = 1416.75960197\n",
      "Validation score: -29.885067\n",
      "Iteration 503, loss = 1415.24631166\n",
      "Validation score: -29.852849\n",
      "Iteration 504, loss = 1413.73426206\n",
      "Validation score: -29.820654\n",
      "Iteration 505, loss = 1412.22355651\n",
      "Validation score: -29.788532\n",
      "Iteration 506, loss = 1410.71772564\n",
      "Validation score: -29.756462\n",
      "Iteration 507, loss = 1409.20837171\n",
      "Validation score: -29.724482\n",
      "Iteration 508, loss = 1407.71148276\n",
      "Validation score: -29.692464\n",
      "Iteration 509, loss = 1406.20717757\n",
      "Validation score: -29.660574\n",
      "Iteration 510, loss = 1404.71045660\n",
      "Validation score: -29.628716\n",
      "Iteration 511, loss = 1403.20966660\n",
      "Validation score: -29.596949\n",
      "Iteration 512, loss = 1401.72235168\n",
      "Validation score: -29.565093\n",
      "Iteration 513, loss = 1400.22778574\n",
      "Validation score: -29.533307\n",
      "Iteration 514, loss = 1398.73484975\n",
      "Validation score: -29.501600\n",
      "Iteration 515, loss = 1397.24180685\n",
      "Validation score: -29.469975\n",
      "Iteration 516, loss = 1395.75767175\n",
      "Validation score: -29.438354\n",
      "Iteration 517, loss = 1394.27162670\n",
      "Validation score: -29.406723\n",
      "Iteration 518, loss = 1392.78569345\n",
      "Validation score: -29.375128\n",
      "Iteration 519, loss = 1391.30449832\n",
      "Validation score: -29.343539\n",
      "Iteration 520, loss = 1389.82430478\n",
      "Validation score: -29.311944\n",
      "Iteration 521, loss = 1388.34345406\n",
      "Validation score: -29.280466\n",
      "Iteration 522, loss = 1386.86518004\n",
      "Validation score: -29.249090\n",
      "Iteration 523, loss = 1385.38963545\n",
      "Validation score: -29.217768\n",
      "Iteration 524, loss = 1383.91963453\n",
      "Validation score: -29.186412\n",
      "Iteration 525, loss = 1382.44542756\n",
      "Validation score: -29.155103\n",
      "Iteration 526, loss = 1380.97705926\n",
      "Validation score: -29.123808\n",
      "Iteration 527, loss = 1379.50738002\n",
      "Validation score: -29.092549\n",
      "Iteration 528, loss = 1378.04218308\n",
      "Validation score: -29.061333\n",
      "Iteration 529, loss = 1376.57626438\n",
      "Validation score: -29.030157\n",
      "Iteration 530, loss = 1375.11483129\n",
      "Validation score: -28.998999\n",
      "Iteration 531, loss = 1373.65227210\n",
      "Validation score: -28.967867\n",
      "Iteration 532, loss = 1372.19224403\n",
      "Validation score: -28.936757\n",
      "Iteration 533, loss = 1370.72817460\n",
      "Validation score: -28.905748\n",
      "Iteration 534, loss = 1369.27265976\n",
      "Validation score: -28.874713\n",
      "Iteration 535, loss = 1367.81569272\n",
      "Validation score: -28.843698\n",
      "Iteration 536, loss = 1366.36227833\n",
      "Validation score: -28.812679\n",
      "Iteration 537, loss = 1364.90793733\n",
      "Validation score: -28.781721\n",
      "Iteration 538, loss = 1363.45318776\n",
      "Validation score: -28.750771\n",
      "Iteration 539, loss = 1362.00098614\n",
      "Validation score: -28.719839\n",
      "Iteration 540, loss = 1360.54965934\n",
      "Validation score: -28.688919\n",
      "Iteration 541, loss = 1359.09781295\n",
      "Validation score: -28.658052\n",
      "Iteration 542, loss = 1357.64792799\n",
      "Validation score: -28.627215\n",
      "Iteration 543, loss = 1356.19742198\n",
      "Validation score: -28.596406\n",
      "Iteration 544, loss = 1354.74983753\n",
      "Validation score: -28.565577\n",
      "Iteration 545, loss = 1353.30777517\n",
      "Validation score: -28.534691\n",
      "Iteration 546, loss = 1351.85945001\n",
      "Validation score: -28.503865\n",
      "Iteration 547, loss = 1350.41226013\n",
      "Validation score: -28.473084\n",
      "Iteration 548, loss = 1348.96631248\n",
      "Validation score: -28.442357\n",
      "Iteration 549, loss = 1347.52462137\n",
      "Validation score: -28.411606\n",
      "Iteration 550, loss = 1346.07747824\n",
      "Validation score: -28.380872\n",
      "Iteration 551, loss = 1344.63358301\n",
      "Validation score: -28.350102\n",
      "Iteration 552, loss = 1343.19031506\n",
      "Validation score: -28.319281\n",
      "Iteration 553, loss = 1341.74690622\n",
      "Validation score: -28.288465\n",
      "Iteration 554, loss = 1340.29649710\n",
      "Validation score: -28.257756\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 555, loss = 1338.86302543\n",
      "Validation score: -28.226871\n",
      "Iteration 556, loss = 1337.40768483\n",
      "Validation score: -28.196070\n",
      "Iteration 557, loss = 1335.96020825\n",
      "Validation score: -28.165168\n",
      "Iteration 558, loss = 1334.50429615\n",
      "Validation score: -28.134310\n",
      "Iteration 559, loss = 1333.05844919\n",
      "Validation score: -28.103305\n",
      "Iteration 560, loss = 1331.60239199\n",
      "Validation score: -28.072313\n",
      "Iteration 561, loss = 1330.14521381\n",
      "Validation score: -28.041276\n",
      "Iteration 562, loss = 1328.69085104\n",
      "Validation score: -28.010073\n",
      "Iteration 563, loss = 1327.22411484\n",
      "Validation score: -27.978854\n",
      "Iteration 564, loss = 1325.75591047\n",
      "Validation score: -27.947552\n",
      "Iteration 565, loss = 1324.28584128\n",
      "Validation score: -27.916094\n",
      "Iteration 566, loss = 1322.80673103\n",
      "Validation score: -27.884589\n",
      "Iteration 567, loss = 1321.32435531\n",
      "Validation score: -27.852977\n",
      "Iteration 568, loss = 1319.83963150\n",
      "Validation score: -27.821236\n",
      "Iteration 569, loss = 1318.34868427\n",
      "Validation score: -27.789322\n",
      "Iteration 570, loss = 1316.84665292\n",
      "Validation score: -27.757307\n",
      "Iteration 571, loss = 1315.34104510\n",
      "Validation score: -27.725148\n",
      "Iteration 572, loss = 1313.82874041\n",
      "Validation score: -27.692805\n",
      "Iteration 573, loss = 1312.30649506\n",
      "Validation score: -27.660284\n",
      "Iteration 574, loss = 1310.77688292\n",
      "Validation score: -27.627610\n",
      "Iteration 575, loss = 1309.24276368\n",
      "Validation score: -27.594794\n",
      "Iteration 576, loss = 1307.70194897\n",
      "Validation score: -27.561928\n",
      "Iteration 577, loss = 1306.15532413\n",
      "Validation score: -27.529012\n",
      "Iteration 578, loss = 1304.60944345\n",
      "Validation score: -27.495956\n",
      "Iteration 579, loss = 1303.05260872\n",
      "Validation score: -27.462862\n",
      "Iteration 580, loss = 1301.50108815\n",
      "Validation score: -27.429697\n",
      "Iteration 581, loss = 1299.94357904\n",
      "Validation score: -27.396554\n",
      "Iteration 582, loss = 1298.38731582\n",
      "Validation score: -27.363423\n",
      "Iteration 583, loss = 1296.83473796\n",
      "Validation score: -27.330306\n",
      "Iteration 584, loss = 1295.27867991\n",
      "Validation score: -27.297285\n",
      "Iteration 585, loss = 1293.72948222\n",
      "Validation score: -27.264246\n",
      "Iteration 586, loss = 1292.18234306\n",
      "Validation score: -27.231278\n",
      "Iteration 587, loss = 1290.63469449\n",
      "Validation score: -27.198420\n",
      "Iteration 588, loss = 1289.09439634\n",
      "Validation score: -27.165640\n",
      "Iteration 589, loss = 1287.55823949\n",
      "Validation score: -27.132993\n",
      "Iteration 590, loss = 1286.02301470\n",
      "Validation score: -27.100500\n",
      "Iteration 591, loss = 1284.50442431\n",
      "Validation score: -27.067959\n",
      "Iteration 592, loss = 1282.97987479\n",
      "Validation score: -27.035594\n",
      "Iteration 593, loss = 1281.46497985\n",
      "Validation score: -27.003345\n",
      "Iteration 594, loss = 1279.95340054\n",
      "Validation score: -26.971265\n",
      "Iteration 595, loss = 1278.44908415\n",
      "Validation score: -26.939299\n",
      "Iteration 596, loss = 1276.94965727\n",
      "Validation score: -26.907393\n",
      "Iteration 597, loss = 1275.45559037\n",
      "Validation score: -26.875581\n",
      "Iteration 598, loss = 1273.96693015\n",
      "Validation score: -26.843849\n",
      "Iteration 599, loss = 1272.47865984\n",
      "Validation score: -26.812232\n",
      "Iteration 600, loss = 1270.99901141\n",
      "Validation score: -26.780707\n",
      "Iteration 601, loss = 1269.52039505\n",
      "Validation score: -26.749302\n",
      "Iteration 602, loss = 1268.04929972\n",
      "Validation score: -26.717992\n",
      "Iteration 603, loss = 1266.58402455\n",
      "Validation score: -26.686698\n",
      "Iteration 604, loss = 1265.11486834\n",
      "Validation score: -26.655543\n",
      "Iteration 605, loss = 1263.65425421\n",
      "Validation score: -26.624461\n",
      "Iteration 606, loss = 1262.20073291\n",
      "Validation score: -26.593392\n",
      "Iteration 607, loss = 1260.74056329\n",
      "Validation score: -26.562444\n",
      "Iteration 608, loss = 1259.29005924\n",
      "Validation score: -26.531543\n",
      "Iteration 609, loss = 1257.84567643\n",
      "Validation score: -26.500694\n",
      "Iteration 610, loss = 1256.40010767\n",
      "Validation score: -26.469995\n",
      "Iteration 611, loss = 1254.96239378\n",
      "Validation score: -26.439393\n",
      "Iteration 612, loss = 1253.52782811\n",
      "Validation score: -26.408824\n",
      "Iteration 613, loss = 1252.09561625\n",
      "Validation score: -26.378294\n",
      "Iteration 614, loss = 1250.66752782\n",
      "Validation score: -26.347831\n",
      "Iteration 615, loss = 1249.23787072\n",
      "Validation score: -26.317513\n",
      "Iteration 616, loss = 1247.81741307\n",
      "Validation score: -26.287210\n",
      "Iteration 617, loss = 1246.39704498\n",
      "Validation score: -26.256914\n",
      "Iteration 618, loss = 1244.97586812\n",
      "Validation score: -26.226675\n",
      "Iteration 619, loss = 1243.55788358\n",
      "Validation score: -26.196533\n",
      "Iteration 620, loss = 1242.14731186\n",
      "Validation score: -26.166392\n",
      "Iteration 621, loss = 1240.73446290\n",
      "Validation score: -26.136313\n",
      "Iteration 622, loss = 1239.32655149\n",
      "Validation score: -26.106280\n",
      "Iteration 623, loss = 1237.92134413\n",
      "Validation score: -26.076329\n",
      "Iteration 624, loss = 1236.51747741\n",
      "Validation score: -26.046451\n",
      "Iteration 625, loss = 1235.11469691\n",
      "Validation score: -26.016585\n",
      "Iteration 626, loss = 1233.71694285\n",
      "Validation score: -25.986701\n",
      "Iteration 627, loss = 1232.31622918\n",
      "Validation score: -25.956926\n",
      "Iteration 628, loss = 1230.92120715\n",
      "Validation score: -25.927191\n",
      "Iteration 629, loss = 1229.52660449\n",
      "Validation score: -25.897503\n",
      "Iteration 630, loss = 1228.13950437\n",
      "Validation score: -25.867828\n",
      "Iteration 631, loss = 1226.74715149\n",
      "Validation score: -25.838250\n",
      "Iteration 632, loss = 1225.36045823\n",
      "Validation score: -25.808689\n",
      "Iteration 633, loss = 1223.97848332\n",
      "Validation score: -25.779127\n",
      "Iteration 634, loss = 1222.59223478\n",
      "Validation score: -25.749662\n",
      "Iteration 635, loss = 1221.20947046\n",
      "Validation score: -25.720270\n",
      "Iteration 636, loss = 1219.83016476\n",
      "Validation score: -25.690888\n",
      "Iteration 637, loss = 1218.45217426\n",
      "Validation score: -25.661518\n",
      "Iteration 638, loss = 1217.07747467\n",
      "Validation score: -25.632153\n",
      "Iteration 639, loss = 1215.70366396\n",
      "Validation score: -25.602806\n",
      "Iteration 640, loss = 1214.32858366\n",
      "Validation score: -25.573508\n",
      "Iteration 641, loss = 1212.95615998\n",
      "Validation score: -25.544283\n",
      "Iteration 642, loss = 1211.58447926\n",
      "Validation score: -25.515133\n",
      "Iteration 643, loss = 1210.21976129\n",
      "Validation score: -25.485948\n",
      "Iteration 644, loss = 1208.85236122\n",
      "Validation score: -25.456786\n",
      "Iteration 645, loss = 1207.48882372\n",
      "Validation score: -25.427631\n",
      "Iteration 646, loss = 1206.12097667\n",
      "Validation score: -25.398604\n",
      "Iteration 647, loss = 1204.76636976\n",
      "Validation score: -25.369582\n",
      "Iteration 648, loss = 1203.40348090\n",
      "Validation score: -25.340677\n",
      "Iteration 649, loss = 1202.05097910\n",
      "Validation score: -25.311748\n",
      "Iteration 650, loss = 1200.69347324\n",
      "Validation score: -25.282872\n",
      "Iteration 651, loss = 1199.34091815\n",
      "Validation score: -25.254036\n",
      "Iteration 652, loss = 1197.98750749\n",
      "Validation score: -25.225266\n",
      "Iteration 653, loss = 1196.64078179\n",
      "Validation score: -25.196449\n",
      "Iteration 654, loss = 1195.29041666\n",
      "Validation score: -25.167641\n",
      "Iteration 655, loss = 1193.94298594\n",
      "Validation score: -25.138813\n",
      "Iteration 656, loss = 1192.59190807\n",
      "Validation score: -25.110075\n",
      "Iteration 657, loss = 1191.24563451\n",
      "Validation score: -25.081413\n",
      "Iteration 658, loss = 1189.90421002\n",
      "Validation score: -25.052728\n",
      "Iteration 659, loss = 1188.55785459\n",
      "Validation score: -25.024053\n",
      "Iteration 660, loss = 1187.21269257\n",
      "Validation score: -24.995477\n",
      "Iteration 661, loss = 1185.87744831\n",
      "Validation score: -24.966874\n",
      "Iteration 662, loss = 1184.53910867\n",
      "Validation score: -24.938320\n",
      "Iteration 663, loss = 1183.19539176\n",
      "Validation score: -24.909862\n",
      "Iteration 664, loss = 1181.86440680\n",
      "Validation score: -24.881313\n",
      "Iteration 665, loss = 1180.52883358\n",
      "Validation score: -24.852780\n",
      "Iteration 666, loss = 1179.19293729\n",
      "Validation score: -24.824316\n",
      "Iteration 667, loss = 1177.85718218\n",
      "Validation score: -24.795944\n",
      "Iteration 668, loss = 1176.52847345\n",
      "Validation score: -24.767596\n",
      "Iteration 669, loss = 1175.20026572\n",
      "Validation score: -24.739241\n",
      "Iteration 670, loss = 1173.87407454\n",
      "Validation score: -24.710863\n",
      "Iteration 671, loss = 1172.54451606\n",
      "Validation score: -24.682503\n",
      "Iteration 672, loss = 1171.21513639\n",
      "Validation score: -24.654228\n",
      "Iteration 673, loss = 1169.89114174\n",
      "Validation score: -24.625952\n",
      "Iteration 674, loss = 1168.56777934\n",
      "Validation score: -24.597632\n",
      "Iteration 675, loss = 1167.24142896\n",
      "Validation score: -24.569389\n",
      "Iteration 676, loss = 1165.91948175\n",
      "Validation score: -24.541152\n",
      "Iteration 677, loss = 1164.59826623\n",
      "Validation score: -24.512937\n",
      "Iteration 678, loss = 1163.27466387\n",
      "Validation score: -24.484780\n",
      "Iteration 679, loss = 1161.95689224\n",
      "Validation score: -24.456633\n",
      "Iteration 680, loss = 1160.63754992\n",
      "Validation score: -24.428497\n",
      "Iteration 681, loss = 1159.32270668\n",
      "Validation score: -24.400381\n",
      "Iteration 682, loss = 1158.00656160\n",
      "Validation score: -24.372343\n",
      "Iteration 683, loss = 1156.69486018\n",
      "Validation score: -24.344308\n",
      "Iteration 684, loss = 1155.38026583\n",
      "Validation score: -24.316319\n",
      "Iteration 685, loss = 1154.06664261\n",
      "Validation score: -24.288361\n",
      "Iteration 686, loss = 1152.75836021\n",
      "Validation score: -24.260370\n",
      "Iteration 687, loss = 1151.44773203\n",
      "Validation score: -24.232421\n",
      "Iteration 688, loss = 1150.14055706\n",
      "Validation score: -24.204476\n",
      "Iteration 689, loss = 1148.83090830\n",
      "Validation score: -24.176598\n",
      "Iteration 690, loss = 1147.52253284\n",
      "Validation score: -24.148735\n",
      "Iteration 691, loss = 1146.22042023\n",
      "Validation score: -24.120804\n",
      "Iteration 692, loss = 1144.91364833\n",
      "Validation score: -24.092905\n",
      "Iteration 693, loss = 1143.60723759\n",
      "Validation score: -24.065082\n",
      "Iteration 694, loss = 1142.30765961\n",
      "Validation score: -24.037219\n",
      "Iteration 695, loss = 1141.00149574\n",
      "Validation score: -24.009451\n",
      "Iteration 696, loss = 1139.70004795\n",
      "Validation score: -23.981682\n",
      "Iteration 697, loss = 1138.40010370\n",
      "Validation score: -23.953887\n",
      "Iteration 698, loss = 1137.10003632\n",
      "Validation score: -23.926099\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 699, loss = 1135.79645577\n",
      "Validation score: -23.898354\n",
      "Iteration 700, loss = 1134.50002466\n",
      "Validation score: -23.870541\n",
      "Iteration 701, loss = 1133.19732262\n",
      "Validation score: -23.842806\n",
      "Iteration 702, loss = 1131.89816789\n",
      "Validation score: -23.815088\n",
      "Iteration 703, loss = 1130.60252136\n",
      "Validation score: -23.787327\n",
      "Iteration 704, loss = 1129.29824282\n",
      "Validation score: -23.759576\n",
      "Iteration 705, loss = 1127.99931728\n",
      "Validation score: -23.731754\n",
      "Iteration 706, loss = 1126.69286530\n",
      "Validation score: -23.703959\n",
      "Iteration 707, loss = 1125.39382631\n",
      "Validation score: -23.676066\n",
      "Iteration 708, loss = 1124.08887092\n",
      "Validation score: -23.648171\n",
      "Iteration 709, loss = 1122.78108158\n",
      "Validation score: -23.620270\n",
      "Iteration 710, loss = 1121.47663127\n",
      "Validation score: -23.592301\n",
      "Iteration 711, loss = 1120.16672954\n",
      "Validation score: -23.564278\n",
      "Iteration 712, loss = 1118.85077618\n",
      "Validation score: -23.536246\n",
      "Iteration 713, loss = 1117.54044365\n",
      "Validation score: -23.508082\n",
      "Iteration 714, loss = 1116.22316187\n",
      "Validation score: -23.479853\n",
      "Iteration 715, loss = 1114.89496825\n",
      "Validation score: -23.451621\n",
      "Iteration 716, loss = 1113.56843836\n",
      "Validation score: -23.423286\n",
      "Iteration 717, loss = 1112.23846307\n",
      "Validation score: -23.394733\n",
      "Iteration 718, loss = 1110.90243719\n",
      "Validation score: -23.365957\n",
      "Iteration 719, loss = 1109.55292072\n",
      "Validation score: -23.337054\n",
      "Iteration 720, loss = 1108.19667378\n",
      "Validation score: -23.308023\n",
      "Iteration 721, loss = 1106.83420454\n",
      "Validation score: -23.278829\n",
      "Iteration 722, loss = 1105.46318486\n",
      "Validation score: -23.249443\n",
      "Iteration 723, loss = 1104.08444792\n",
      "Validation score: -23.219863\n",
      "Iteration 724, loss = 1102.69667542\n",
      "Validation score: -23.190056\n",
      "Iteration 725, loss = 1101.29524713\n",
      "Validation score: -23.160070\n",
      "Iteration 726, loss = 1099.89063117\n",
      "Validation score: -23.129857\n",
      "Iteration 727, loss = 1098.47261503\n",
      "Validation score: -23.099495\n",
      "Iteration 728, loss = 1097.04311236\n",
      "Validation score: -23.069062\n",
      "Iteration 729, loss = 1095.62195183\n",
      "Validation score: -23.038433\n",
      "Iteration 730, loss = 1094.18439635\n",
      "Validation score: -23.007778\n",
      "Iteration 731, loss = 1092.74924479\n",
      "Validation score: -22.977071\n",
      "Iteration 732, loss = 1091.31399648\n",
      "Validation score: -22.946362\n",
      "Iteration 733, loss = 1089.87422463\n",
      "Validation score: -22.915697\n",
      "Iteration 734, loss = 1088.44096004\n",
      "Validation score: -22.885047\n",
      "Iteration 735, loss = 1087.00667566\n",
      "Validation score: -22.854492\n",
      "Iteration 736, loss = 1085.57693943\n",
      "Validation score: -22.824048\n",
      "Iteration 737, loss = 1084.15603528\n",
      "Validation score: -22.793665\n",
      "Iteration 738, loss = 1082.73269244\n",
      "Validation score: -22.763414\n",
      "Iteration 739, loss = 1081.32131392\n",
      "Validation score: -22.733230\n",
      "Iteration 740, loss = 1079.90744540\n",
      "Validation score: -22.703194\n",
      "Iteration 741, loss = 1078.50443485\n",
      "Validation score: -22.673261\n",
      "Iteration 742, loss = 1077.10679523\n",
      "Validation score: -22.643445\n",
      "Iteration 743, loss = 1075.71375241\n",
      "Validation score: -22.613768\n",
      "Iteration 744, loss = 1074.32709741\n",
      "Validation score: -22.584213\n",
      "Iteration 745, loss = 1072.94488314\n",
      "Validation score: -22.554816\n",
      "Iteration 746, loss = 1071.57136505\n",
      "Validation score: -22.525503\n",
      "Iteration 747, loss = 1070.20087691\n",
      "Validation score: -22.496282\n",
      "Iteration 748, loss = 1068.83517838\n",
      "Validation score: -22.467126\n",
      "Iteration 749, loss = 1067.47417356\n",
      "Validation score: -22.438071\n",
      "Iteration 750, loss = 1066.11421573\n",
      "Validation score: -22.409199\n",
      "Iteration 751, loss = 1064.76640924\n",
      "Validation score: -22.380396\n",
      "Iteration 752, loss = 1063.42267385\n",
      "Validation score: -22.351714\n",
      "Iteration 753, loss = 1062.08086764\n",
      "Validation score: -22.323164\n",
      "Iteration 754, loss = 1060.74994541\n",
      "Validation score: -22.294647\n",
      "Iteration 755, loss = 1059.41708373\n",
      "Validation score: -22.266290\n",
      "Iteration 756, loss = 1058.09065111\n",
      "Validation score: -22.238009\n",
      "Iteration 757, loss = 1056.77086134\n",
      "Validation score: -22.209750\n",
      "Iteration 758, loss = 1055.45083358\n",
      "Validation score: -22.181576\n",
      "Iteration 759, loss = 1054.13306065\n",
      "Validation score: -22.153474\n",
      "Iteration 760, loss = 1052.81613526\n",
      "Validation score: -22.125462\n",
      "Iteration 761, loss = 1051.51216644\n",
      "Validation score: -22.097450\n",
      "Iteration 762, loss = 1050.19945442\n",
      "Validation score: -22.069560\n",
      "Iteration 763, loss = 1048.89536274\n",
      "Validation score: -22.041682\n",
      "Iteration 764, loss = 1047.59431861\n",
      "Validation score: -22.013835\n",
      "Iteration 765, loss = 1046.29195787\n",
      "Validation score: -21.986124\n",
      "Iteration 766, loss = 1044.99526109\n",
      "Validation score: -21.958445\n",
      "Iteration 767, loss = 1043.70204384\n",
      "Validation score: -21.930822\n",
      "Iteration 768, loss = 1042.41339850\n",
      "Validation score: -21.903214\n",
      "Iteration 769, loss = 1041.12300782\n",
      "Validation score: -21.875689\n",
      "Iteration 770, loss = 1039.83646464\n",
      "Validation score: -21.848232\n",
      "Iteration 771, loss = 1038.55508072\n",
      "Validation score: -21.820819\n",
      "Iteration 772, loss = 1037.27067887\n",
      "Validation score: -21.793498\n",
      "Iteration 773, loss = 1035.99723796\n",
      "Validation score: -21.766152\n",
      "Iteration 774, loss = 1034.71991818\n",
      "Validation score: -21.738872\n",
      "Iteration 775, loss = 1033.44561542\n",
      "Validation score: -21.711663\n",
      "Iteration 776, loss = 1032.17305211\n",
      "Validation score: -21.684510\n",
      "Iteration 777, loss = 1030.90213154\n",
      "Validation score: -21.657410\n",
      "Iteration 778, loss = 1029.63516493\n",
      "Validation score: -21.630291\n",
      "Iteration 779, loss = 1028.36794326\n",
      "Validation score: -21.603192\n",
      "Iteration 780, loss = 1027.10486125\n",
      "Validation score: -21.576127\n",
      "Iteration 781, loss = 1025.83859438\n",
      "Validation score: -21.549181\n",
      "Iteration 782, loss = 1024.57595734\n",
      "Validation score: -21.522284\n",
      "Iteration 783, loss = 1023.31861010\n",
      "Validation score: -21.495362\n",
      "Iteration 784, loss = 1022.06167112\n",
      "Validation score: -21.468441\n",
      "Iteration 785, loss = 1020.80832259\n",
      "Validation score: -21.441538\n",
      "Iteration 786, loss = 1019.55023258\n",
      "Validation score: -21.414732\n",
      "Iteration 787, loss = 1018.29951093\n",
      "Validation score: -21.387951\n",
      "Iteration 788, loss = 1017.04630076\n",
      "Validation score: -21.361241\n",
      "Iteration 789, loss = 1015.79884494\n",
      "Validation score: -21.334548\n",
      "Iteration 790, loss = 1014.55174284\n",
      "Validation score: -21.307928\n",
      "Iteration 791, loss = 1013.30790121\n",
      "Validation score: -21.281378\n",
      "Iteration 792, loss = 1012.07025263\n",
      "Validation score: -21.254809\n",
      "Iteration 793, loss = 1010.82710447\n",
      "Validation score: -21.228336\n",
      "Iteration 794, loss = 1009.58954389\n",
      "Validation score: -21.201889\n",
      "Iteration 795, loss = 1008.35380348\n",
      "Validation score: -21.175440\n",
      "Iteration 796, loss = 1007.11980173\n",
      "Validation score: -21.148965\n",
      "Iteration 797, loss = 1005.88080015\n",
      "Validation score: -21.122559\n",
      "Iteration 798, loss = 1004.65020827\n",
      "Validation score: -21.096134\n",
      "Iteration 799, loss = 1003.41685399\n",
      "Validation score: -21.069766\n",
      "Iteration 800, loss = 1002.18229069\n",
      "Validation score: -21.043485\n",
      "Iteration 801, loss = 1000.95532593\n",
      "Validation score: -21.017191\n",
      "Iteration 802, loss = 999.72586380\n",
      "Validation score: -20.990923\n",
      "Iteration 803, loss = 998.49825796\n",
      "Validation score: -20.964708\n",
      "Iteration 804, loss = 997.27343754\n",
      "Validation score: -20.938528\n",
      "Iteration 805, loss = 996.05111574\n",
      "Validation score: -20.912372\n",
      "Iteration 806, loss = 994.83192435\n",
      "Validation score: -20.886190\n",
      "Iteration 807, loss = 993.60603174\n",
      "Validation score: -20.860082\n",
      "Iteration 808, loss = 992.38559979\n",
      "Validation score: -20.833984\n",
      "Iteration 809, loss = 991.17160203\n",
      "Validation score: -20.807873\n",
      "Iteration 810, loss = 989.94897356\n",
      "Validation score: -20.781862\n",
      "Iteration 811, loss = 988.73374105\n",
      "Validation score: -20.755819\n",
      "Iteration 812, loss = 987.51741876\n",
      "Validation score: -20.729820\n",
      "Iteration 813, loss = 986.30261781\n",
      "Validation score: -20.703850\n",
      "Iteration 814, loss = 985.08882997\n",
      "Validation score: -20.677910\n",
      "Iteration 815, loss = 983.87748027\n",
      "Validation score: -20.651996\n",
      "Iteration 816, loss = 982.66567632\n",
      "Validation score: -20.626086\n",
      "Iteration 817, loss = 981.46093517\n",
      "Validation score: -20.600165\n",
      "Iteration 818, loss = 980.25036787\n",
      "Validation score: -20.574346\n",
      "Iteration 819, loss = 979.04318229\n",
      "Validation score: -20.548558\n",
      "Iteration 820, loss = 977.83593262\n",
      "Validation score: -20.522827\n",
      "Iteration 821, loss = 976.63535780\n",
      "Validation score: -20.497046\n",
      "Iteration 822, loss = 975.43262821\n",
      "Validation score: -20.471287\n",
      "Iteration 823, loss = 974.23030244\n",
      "Validation score: -20.445550\n",
      "Iteration 824, loss = 973.02808607\n",
      "Validation score: -20.419890\n",
      "Iteration 825, loss = 971.82979867\n",
      "Validation score: -20.394256\n",
      "Iteration 826, loss = 970.63005167\n",
      "Validation score: -20.368664\n",
      "Iteration 827, loss = 969.43827166\n",
      "Validation score: -20.343019\n",
      "Iteration 828, loss = 968.24000531\n",
      "Validation score: -20.317434\n",
      "Iteration 829, loss = 967.04613267\n",
      "Validation score: -20.291899\n",
      "Iteration 830, loss = 965.85627744\n",
      "Validation score: -20.266392\n",
      "Iteration 831, loss = 964.66582949\n",
      "Validation score: -20.240896\n",
      "Iteration 832, loss = 963.47238592\n",
      "Validation score: -20.215463\n",
      "Iteration 833, loss = 962.28672503\n",
      "Validation score: -20.190012\n",
      "Iteration 834, loss = 961.09538304\n",
      "Validation score: -20.164585\n",
      "Iteration 835, loss = 959.90375374\n",
      "Validation score: -20.139178\n",
      "Iteration 836, loss = 958.72610343\n",
      "Validation score: -20.113703\n",
      "Iteration 837, loss = 957.53711986\n",
      "Validation score: -20.088341\n",
      "Iteration 838, loss = 956.35340074\n",
      "Validation score: -20.063011\n",
      "Iteration 839, loss = 955.16617461\n",
      "Validation score: -20.037745\n",
      "Iteration 840, loss = 953.98890596\n",
      "Validation score: -20.012436\n",
      "Iteration 841, loss = 952.80585091\n",
      "Validation score: -19.987198\n",
      "Iteration 842, loss = 951.62714107\n",
      "Validation score: -19.961944\n",
      "Iteration 843, loss = 950.45151945\n",
      "Validation score: -19.936684\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 844, loss = 949.27139074\n",
      "Validation score: -19.911480\n",
      "Iteration 845, loss = 948.09266561\n",
      "Validation score: -19.886333\n",
      "Iteration 846, loss = 946.92231482\n",
      "Validation score: -19.861179\n",
      "Iteration 847, loss = 945.74671435\n",
      "Validation score: -19.836102\n",
      "Iteration 848, loss = 944.57549420\n",
      "Validation score: -19.811041\n",
      "Iteration 849, loss = 943.40773178\n",
      "Validation score: -19.785940\n",
      "Iteration 850, loss = 942.23508061\n",
      "Validation score: -19.760877\n",
      "Iteration 851, loss = 941.06555360\n",
      "Validation score: -19.735773\n",
      "Iteration 852, loss = 939.89364688\n",
      "Validation score: -19.710705\n",
      "Iteration 853, loss = 938.72362256\n",
      "Validation score: -19.685649\n",
      "Iteration 854, loss = 937.55292028\n",
      "Validation score: -19.660670\n",
      "Iteration 855, loss = 936.38748569\n",
      "Validation score: -19.635710\n",
      "Iteration 856, loss = 935.22505240\n",
      "Validation score: -19.610744\n",
      "Iteration 857, loss = 934.05758083\n",
      "Validation score: -19.585838\n",
      "Iteration 858, loss = 932.89902653\n",
      "Validation score: -19.560922\n",
      "Iteration 859, loss = 931.73565732\n",
      "Validation score: -19.536089\n",
      "Iteration 860, loss = 930.57463830\n",
      "Validation score: -19.511332\n",
      "Iteration 861, loss = 929.42048966\n",
      "Validation score: -19.486517\n",
      "Iteration 862, loss = 928.26380317\n",
      "Validation score: -19.461713\n",
      "Iteration 863, loss = 927.10568488\n",
      "Validation score: -19.436931\n",
      "Iteration 864, loss = 925.95173176\n",
      "Validation score: -19.412134\n",
      "Iteration 865, loss = 924.79239908\n",
      "Validation score: -19.387395\n",
      "Iteration 866, loss = 923.64134988\n",
      "Validation score: -19.362622\n",
      "Iteration 867, loss = 922.48440037\n",
      "Validation score: -19.337922\n",
      "Iteration 868, loss = 921.33117165\n",
      "Validation score: -19.313286\n",
      "Iteration 869, loss = 920.18459765\n",
      "Validation score: -19.288630\n",
      "Iteration 870, loss = 919.03223917\n",
      "Validation score: -19.264055\n",
      "Iteration 871, loss = 917.88391416\n",
      "Validation score: -19.239505\n",
      "Iteration 872, loss = 916.73870734\n",
      "Validation score: -19.214914\n",
      "Iteration 873, loss = 915.59159893\n",
      "Validation score: -19.190360\n",
      "Iteration 874, loss = 914.44345658\n",
      "Validation score: -19.165842\n",
      "Iteration 875, loss = 913.30179009\n",
      "Validation score: -19.141248\n",
      "Iteration 876, loss = 912.15594566\n",
      "Validation score: -19.116692\n",
      "Iteration 877, loss = 911.00924634\n",
      "Validation score: -19.092160\n",
      "Iteration 878, loss = 909.86410792\n",
      "Validation score: -19.067653\n",
      "Iteration 879, loss = 908.72005152\n",
      "Validation score: -19.043202\n",
      "Iteration 880, loss = 907.58282232\n",
      "Validation score: -19.018743\n",
      "Iteration 881, loss = 906.44562654\n",
      "Validation score: -18.994304\n",
      "Iteration 882, loss = 905.30112021\n",
      "Validation score: -18.969993\n",
      "Iteration 883, loss = 904.16784546\n",
      "Validation score: -18.945637\n",
      "Iteration 884, loss = 903.03539296\n",
      "Validation score: -18.921306\n",
      "Iteration 885, loss = 901.90067366\n",
      "Validation score: -18.897016\n",
      "Iteration 886, loss = 900.76434548\n",
      "Validation score: -18.872798\n",
      "Iteration 887, loss = 899.63762072\n",
      "Validation score: -18.848559\n",
      "Iteration 888, loss = 898.50627280\n",
      "Validation score: -18.824387\n",
      "Iteration 889, loss = 897.37710340\n",
      "Validation score: -18.800227\n",
      "Iteration 890, loss = 896.25511970\n",
      "Validation score: -18.776042\n",
      "Iteration 891, loss = 895.12128818\n",
      "Validation score: -18.751993\n",
      "Iteration 892, loss = 894.00092642\n",
      "Validation score: -18.727829\n",
      "Iteration 893, loss = 892.87576196\n",
      "Validation score: -18.703648\n",
      "Iteration 894, loss = 891.74867449\n",
      "Validation score: -18.679509\n",
      "Iteration 895, loss = 890.62035915\n",
      "Validation score: -18.655456\n",
      "Iteration 896, loss = 889.50183654\n",
      "Validation score: -18.631345\n",
      "Iteration 897, loss = 888.37813482\n",
      "Validation score: -18.607264\n",
      "Iteration 898, loss = 887.25149515\n",
      "Validation score: -18.583265\n",
      "Iteration 899, loss = 886.13446227\n",
      "Validation score: -18.559242\n",
      "Iteration 900, loss = 885.01384559\n",
      "Validation score: -18.535260\n",
      "Iteration 901, loss = 883.89699834\n",
      "Validation score: -18.511283\n",
      "Iteration 902, loss = 882.77860378\n",
      "Validation score: -18.487332\n",
      "Iteration 903, loss = 881.66560880\n",
      "Validation score: -18.463366\n",
      "Iteration 904, loss = 880.54480032\n",
      "Validation score: -18.439491\n",
      "Iteration 905, loss = 879.42939490\n",
      "Validation score: -18.415628\n",
      "Iteration 906, loss = 878.32232986\n",
      "Validation score: -18.391699\n",
      "Iteration 907, loss = 877.20314745\n",
      "Validation score: -18.367865\n",
      "Iteration 908, loss = 876.09563107\n",
      "Validation score: -18.343980\n",
      "Iteration 909, loss = 874.98061259\n",
      "Validation score: -18.320155\n",
      "Iteration 910, loss = 873.86738493\n",
      "Validation score: -18.296360\n",
      "Iteration 911, loss = 872.76058379\n",
      "Validation score: -18.272520\n",
      "Iteration 912, loss = 871.65045519\n",
      "Validation score: -18.248751\n",
      "Iteration 913, loss = 870.54544755\n",
      "Validation score: -18.224984\n",
      "Iteration 914, loss = 869.43671573\n",
      "Validation score: -18.201280\n",
      "Iteration 915, loss = 868.32734727\n",
      "Validation score: -18.177604\n",
      "Iteration 916, loss = 867.22747985\n",
      "Validation score: -18.153889\n",
      "Iteration 917, loss = 866.12247855\n",
      "Validation score: -18.130228\n",
      "Iteration 918, loss = 865.01890255\n",
      "Validation score: -18.106616\n",
      "Iteration 919, loss = 863.91978419\n",
      "Validation score: -18.083012\n",
      "Iteration 920, loss = 862.81777966\n",
      "Validation score: -18.059455\n",
      "Iteration 921, loss = 861.72140564\n",
      "Validation score: -18.035862\n",
      "Iteration 922, loss = 860.62223074\n",
      "Validation score: -18.012348\n",
      "Iteration 923, loss = 859.52460465\n",
      "Validation score: -17.988886\n",
      "Iteration 924, loss = 858.43423683\n",
      "Validation score: -17.965359\n",
      "Iteration 925, loss = 857.33823909\n",
      "Validation score: -17.941862\n",
      "Iteration 926, loss = 856.23678547\n",
      "Validation score: -17.918444\n",
      "Iteration 927, loss = 855.14981740\n",
      "Validation score: -17.894916\n",
      "Iteration 928, loss = 854.05517525\n",
      "Validation score: -17.871435\n",
      "Iteration 929, loss = 852.96127659\n",
      "Validation score: -17.848024\n",
      "Iteration 930, loss = 851.86935135\n",
      "Validation score: -17.824656\n",
      "Iteration 931, loss = 850.78156461\n",
      "Validation score: -17.801293\n",
      "Iteration 932, loss = 849.69422531\n",
      "Validation score: -17.777942\n",
      "Iteration 933, loss = 848.60533692\n",
      "Validation score: -17.754614\n",
      "Iteration 934, loss = 847.51498963\n",
      "Validation score: -17.731317\n",
      "Iteration 935, loss = 846.42901627\n",
      "Validation score: -17.708002\n",
      "Iteration 936, loss = 845.34257931\n",
      "Validation score: -17.684677\n",
      "Iteration 937, loss = 844.25995711\n",
      "Validation score: -17.661318\n",
      "Iteration 938, loss = 843.17306211\n",
      "Validation score: -17.638027\n",
      "Iteration 939, loss = 842.08500099\n",
      "Validation score: -17.614819\n",
      "Iteration 940, loss = 841.00728238\n",
      "Validation score: -17.591569\n",
      "Iteration 941, loss = 839.92186582\n",
      "Validation score: -17.568380\n",
      "Iteration 942, loss = 838.84226481\n",
      "Validation score: -17.545218\n",
      "Iteration 943, loss = 837.76261543\n",
      "Validation score: -17.522089\n",
      "Iteration 944, loss = 836.68458694\n",
      "Validation score: -17.498954\n",
      "Iteration 945, loss = 835.60862671\n",
      "Validation score: -17.475783\n",
      "Iteration 946, loss = 834.52977075\n",
      "Validation score: -17.452656\n",
      "Iteration 947, loss = 833.45383323\n",
      "Validation score: -17.429556\n",
      "Iteration 948, loss = 832.37679672\n",
      "Validation score: -17.406493\n",
      "Iteration 949, loss = 831.30440538\n",
      "Validation score: -17.383408\n",
      "Iteration 950, loss = 830.22407433\n",
      "Validation score: -17.360397\n",
      "Iteration 951, loss = 829.15165093\n",
      "Validation score: -17.337362\n",
      "Iteration 952, loss = 828.07890732\n",
      "Validation score: -17.314293\n",
      "Iteration 953, loss = 827.00724299\n",
      "Validation score: -17.291201\n",
      "Iteration 954, loss = 825.93120351\n",
      "Validation score: -17.268189\n",
      "Iteration 955, loss = 824.85929532\n",
      "Validation score: -17.245204\n",
      "Iteration 956, loss = 823.79498414\n",
      "Validation score: -17.222183\n",
      "Iteration 957, loss = 822.72055653\n",
      "Validation score: -17.199287\n",
      "Iteration 958, loss = 821.65167171\n",
      "Validation score: -17.176432\n",
      "Iteration 959, loss = 820.59008329\n",
      "Validation score: -17.153533\n",
      "Iteration 960, loss = 819.52441161\n",
      "Validation score: -17.130674\n",
      "Iteration 961, loss = 818.46042371\n",
      "Validation score: -17.107845\n",
      "Iteration 962, loss = 817.39883245\n",
      "Validation score: -17.085017\n",
      "Iteration 963, loss = 816.33599225\n",
      "Validation score: -17.062233\n",
      "Iteration 964, loss = 815.27386693\n",
      "Validation score: -17.039427\n",
      "Iteration 965, loss = 814.21115003\n",
      "Validation score: -17.016672\n",
      "Iteration 966, loss = 813.15131109\n",
      "Validation score: -16.993925\n",
      "Iteration 967, loss = 812.09302905\n",
      "Validation score: -16.971183\n",
      "Iteration 968, loss = 811.03635937\n",
      "Validation score: -16.948445\n",
      "Iteration 969, loss = 809.97709437\n",
      "Validation score: -16.925774\n",
      "Iteration 970, loss = 808.92020764\n",
      "Validation score: -16.903093\n",
      "Iteration 971, loss = 807.86751410\n",
      "Validation score: -16.880390\n",
      "Iteration 972, loss = 806.81010864\n",
      "Validation score: -16.857802\n",
      "Iteration 973, loss = 805.75874987\n",
      "Validation score: -16.835222\n",
      "Iteration 974, loss = 804.70912711\n",
      "Validation score: -16.812591\n",
      "Iteration 975, loss = 803.65498496\n",
      "Validation score: -16.790007\n",
      "Iteration 976, loss = 802.60544947\n",
      "Validation score: -16.767449\n",
      "Iteration 977, loss = 801.55624019\n",
      "Validation score: -16.744929\n",
      "Iteration 978, loss = 800.50531852\n",
      "Validation score: -16.722441\n",
      "Iteration 979, loss = 799.46132128\n",
      "Validation score: -16.699930\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 980, loss = 798.41041116\n",
      "Validation score: -16.677467\n",
      "Iteration 981, loss = 797.36524233\n",
      "Validation score: -16.654964\n",
      "Iteration 982, loss = 796.31872588\n",
      "Validation score: -16.632483\n",
      "Iteration 983, loss = 795.27404720\n",
      "Validation score: -16.610029\n",
      "Iteration 984, loss = 794.22802592\n",
      "Validation score: -16.587616\n",
      "Iteration 985, loss = 793.18503352\n",
      "Validation score: -16.565229\n",
      "Iteration 986, loss = 792.14574644\n",
      "Validation score: -16.542829\n",
      "Iteration 987, loss = 791.10423200\n",
      "Validation score: -16.520439\n",
      "Iteration 988, loss = 790.05947174\n",
      "Validation score: -16.498095\n",
      "Iteration 989, loss = 789.02105555\n",
      "Validation score: -16.475754\n",
      "Iteration 990, loss = 787.98262772\n",
      "Validation score: -16.453413\n",
      "Iteration 991, loss = 786.94320842\n",
      "Validation score: -16.431095\n",
      "Iteration 992, loss = 785.90578271\n",
      "Validation score: -16.408797\n",
      "Iteration 993, loss = 784.86955743\n",
      "Validation score: -16.386557\n",
      "Iteration 994, loss = 783.83500446\n",
      "Validation score: -16.364300\n",
      "Iteration 995, loss = 782.79919272\n",
      "Validation score: -16.342058\n",
      "Iteration 996, loss = 781.76787926\n",
      "Validation score: -16.319797\n",
      "Iteration 997, loss = 780.72605817\n",
      "Validation score: -16.297685\n",
      "Iteration 998, loss = 779.69658609\n",
      "Validation score: -16.275538\n",
      "Iteration 999, loss = 778.66793090\n",
      "Validation score: -16.253360\n",
      "Iteration 1000, loss = 777.63590926\n",
      "Validation score: -16.231178\n",
      "Iteration 1001, loss = 776.60467828\n",
      "Validation score: -16.209037\n",
      "Iteration 1002, loss = 775.57612596\n",
      "Validation score: -16.186908\n",
      "Iteration 1003, loss = 774.54765518\n",
      "Validation score: -16.164800\n",
      "Iteration 1004, loss = 773.51913730\n",
      "Validation score: -16.142718\n",
      "Iteration 1005, loss = 772.49305585\n",
      "Validation score: -16.120663\n",
      "Iteration 1006, loss = 771.46654965\n",
      "Validation score: -16.098662\n",
      "Iteration 1007, loss = 770.44175692\n",
      "Validation score: -16.076674\n",
      "Iteration 1008, loss = 769.42219905\n",
      "Validation score: -16.054644\n",
      "Iteration 1009, loss = 768.39913661\n",
      "Validation score: -16.032689\n",
      "Iteration 1010, loss = 767.37697615\n",
      "Validation score: -16.010763\n",
      "Iteration 1011, loss = 766.35458593\n",
      "Validation score: -15.988890\n",
      "Iteration 1012, loss = 765.34065981\n",
      "Validation score: -15.966962\n",
      "Iteration 1013, loss = 764.31841509\n",
      "Validation score: -15.945094\n",
      "Iteration 1014, loss = 763.30190347\n",
      "Validation score: -15.923211\n",
      "Iteration 1015, loss = 762.28600109\n",
      "Validation score: -15.901304\n",
      "Iteration 1016, loss = 761.26733777\n",
      "Validation score: -15.879436\n",
      "Iteration 1017, loss = 760.25349845\n",
      "Validation score: -15.857567\n",
      "Iteration 1018, loss = 759.23484595\n",
      "Validation score: -15.835785\n",
      "Iteration 1019, loss = 758.22276119\n",
      "Validation score: -15.814021\n",
      "Iteration 1020, loss = 757.20958160\n",
      "Validation score: -15.792301\n",
      "Iteration 1021, loss = 756.20017224\n",
      "Validation score: -15.770582\n",
      "Iteration 1022, loss = 755.19214220\n",
      "Validation score: -15.748840\n",
      "Iteration 1023, loss = 754.18123638\n",
      "Validation score: -15.727113\n",
      "Iteration 1024, loss = 753.17054588\n",
      "Validation score: -15.705397\n",
      "Iteration 1025, loss = 752.16310837\n",
      "Validation score: -15.683643\n",
      "Iteration 1026, loss = 751.14819162\n",
      "Validation score: -15.661992\n",
      "Iteration 1027, loss = 750.14249189\n",
      "Validation score: -15.640289\n",
      "Iteration 1028, loss = 749.13512086\n",
      "Validation score: -15.618605\n",
      "Iteration 1029, loss = 748.12885549\n",
      "Validation score: -15.596980\n",
      "Iteration 1030, loss = 747.12430004\n",
      "Validation score: -15.575400\n",
      "Iteration 1031, loss = 746.11510226\n",
      "Validation score: -15.553876\n",
      "Iteration 1032, loss = 745.11747703\n",
      "Validation score: -15.532263\n",
      "Iteration 1033, loss = 744.11385376\n",
      "Validation score: -15.510662\n",
      "Iteration 1034, loss = 743.11034569\n",
      "Validation score: -15.489091\n",
      "Iteration 1035, loss = 742.11027157\n",
      "Validation score: -15.467502\n",
      "Iteration 1036, loss = 741.10588483\n",
      "Validation score: -15.445962\n",
      "Iteration 1037, loss = 740.10265951\n",
      "Validation score: -15.424472\n",
      "Iteration 1038, loss = 739.10448063\n",
      "Validation score: -15.402950\n",
      "Iteration 1039, loss = 738.10378197\n",
      "Validation score: -15.381447\n",
      "Iteration 1040, loss = 737.10509841\n",
      "Validation score: -15.359926\n",
      "Iteration 1041, loss = 736.10379391\n",
      "Validation score: -15.338426\n",
      "Iteration 1042, loss = 735.10584065\n",
      "Validation score: -15.316911\n",
      "Iteration 1043, loss = 734.10661856\n",
      "Validation score: -15.295415\n",
      "Iteration 1044, loss = 733.10918278\n",
      "Validation score: -15.273952\n",
      "Iteration 1045, loss = 732.11132200\n",
      "Validation score: -15.252521\n",
      "Iteration 1046, loss = 731.12009880\n",
      "Validation score: -15.231027\n",
      "Iteration 1047, loss = 730.11772546\n",
      "Validation score: -15.209619\n",
      "Iteration 1048, loss = 729.12374130\n",
      "Validation score: -15.188168\n",
      "Iteration 1049, loss = 728.12816146\n",
      "Validation score: -15.166730\n",
      "Iteration 1050, loss = 727.12880223\n",
      "Validation score: -15.145348\n",
      "Iteration 1051, loss = 726.13840582\n",
      "Validation score: -15.123858\n",
      "Iteration 1052, loss = 725.13591024\n",
      "Validation score: -15.102454\n",
      "Iteration 1053, loss = 724.14558115\n",
      "Validation score: -15.080946\n",
      "Iteration 1054, loss = 723.14342469\n",
      "Validation score: -15.059478\n",
      "Iteration 1055, loss = 722.14696054\n",
      "Validation score: -15.037910\n",
      "Iteration 1056, loss = 721.14230714\n",
      "Validation score: -15.016309\n",
      "Iteration 1057, loss = 720.14029971\n",
      "Validation score: -14.994606\n",
      "Iteration 1058, loss = 719.12952095\n",
      "Validation score: -14.972864\n",
      "Iteration 1059, loss = 718.11582408\n",
      "Validation score: -14.951106\n",
      "Iteration 1060, loss = 717.10587236\n",
      "Validation score: -14.929162\n",
      "Iteration 1061, loss = 716.08279482\n",
      "Validation score: -14.907159\n",
      "Iteration 1062, loss = 715.06200846\n",
      "Validation score: -14.885004\n",
      "Iteration 1063, loss = 714.02839686\n",
      "Validation score: -14.862749\n",
      "Iteration 1064, loss = 712.99638322\n",
      "Validation score: -14.840252\n",
      "Iteration 1065, loss = 711.94309747\n",
      "Validation score: -14.817674\n",
      "Iteration 1066, loss = 710.89799182\n",
      "Validation score: -14.794845\n",
      "Iteration 1067, loss = 709.82951304\n",
      "Validation score: -14.771894\n",
      "Iteration 1068, loss = 708.76067154\n",
      "Validation score: -14.748675\n",
      "Iteration 1069, loss = 707.68318698\n",
      "Validation score: -14.725193\n",
      "Iteration 1070, loss = 706.58529145\n",
      "Validation score: -14.701570\n",
      "Iteration 1071, loss = 705.48427533\n",
      "Validation score: -14.677710\n",
      "Iteration 1072, loss = 704.37359922\n",
      "Validation score: -14.653690\n",
      "Iteration 1073, loss = 703.25487472\n",
      "Validation score: -14.629525\n",
      "Iteration 1074, loss = 702.13118251\n",
      "Validation score: -14.605200\n",
      "Iteration 1075, loss = 700.99781706\n",
      "Validation score: -14.580886\n",
      "Iteration 1076, loss = 699.87269840\n",
      "Validation score: -14.556408\n",
      "Iteration 1077, loss = 698.73379759\n",
      "Validation score: -14.532005\n",
      "Iteration 1078, loss = 697.60039395\n",
      "Validation score: -14.507679\n",
      "Iteration 1079, loss = 696.46799866\n",
      "Validation score: -14.483406\n",
      "Iteration 1080, loss = 695.34613745\n",
      "Validation score: -14.459125\n",
      "Iteration 1081, loss = 694.21927361\n",
      "Validation score: -14.434961\n",
      "Iteration 1082, loss = 693.09963272\n",
      "Validation score: -14.410951\n",
      "Iteration 1083, loss = 691.98701965\n",
      "Validation score: -14.387087\n",
      "Iteration 1084, loss = 690.88349309\n",
      "Validation score: -14.363330\n",
      "Iteration 1085, loss = 689.78091399\n",
      "Validation score: -14.339744\n",
      "Iteration 1086, loss = 688.68698054\n",
      "Validation score: -14.316268\n",
      "Iteration 1087, loss = 687.60153629\n",
      "Validation score: -14.292877\n",
      "Iteration 1088, loss = 686.51903050\n",
      "Validation score: -14.269677\n",
      "Iteration 1089, loss = 685.44418656\n",
      "Validation score: -14.246637\n",
      "Iteration 1090, loss = 684.37405990\n",
      "Validation score: -14.223701\n",
      "Iteration 1091, loss = 683.31269292\n",
      "Validation score: -14.200852\n",
      "Iteration 1092, loss = 682.25359298\n",
      "Validation score: -14.178118\n",
      "Iteration 1093, loss = 681.19824600\n",
      "Validation score: -14.155444\n",
      "Iteration 1094, loss = 680.14911685\n",
      "Validation score: -14.132824\n",
      "Iteration 1095, loss = 679.10028957\n",
      "Validation score: -14.110358\n",
      "Iteration 1096, loss = 678.05670229\n",
      "Validation score: -14.087953\n",
      "Iteration 1097, loss = 677.02353607\n",
      "Validation score: -14.065577\n",
      "Iteration 1098, loss = 675.98278876\n",
      "Validation score: -14.043388\n",
      "Iteration 1099, loss = 674.95662310\n",
      "Validation score: -14.021243\n",
      "Iteration 1100, loss = 673.92945906\n",
      "Validation score: -13.999186\n",
      "Iteration 1101, loss = 672.91118295\n",
      "Validation score: -13.977134\n",
      "Iteration 1102, loss = 671.88695301\n",
      "Validation score: -13.955208\n",
      "Iteration 1103, loss = 670.87027362\n",
      "Validation score: -13.933332\n",
      "Iteration 1104, loss = 669.85655838\n",
      "Validation score: -13.911472\n",
      "Iteration 1105, loss = 668.84380509\n",
      "Validation score: -13.889661\n",
      "Iteration 1106, loss = 667.83177971\n",
      "Validation score: -13.867925\n",
      "Iteration 1107, loss = 666.82578827\n",
      "Validation score: -13.846264\n",
      "Iteration 1108, loss = 665.82076175\n",
      "Validation score: -13.824646\n",
      "Iteration 1109, loss = 664.82136674\n",
      "Validation score: -13.803046\n",
      "Iteration 1110, loss = 663.82365055\n",
      "Validation score: -13.781471\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1111, loss = 662.82044570\n",
      "Validation score: -13.760040\n",
      "Iteration 1112, loss = 661.82869781\n",
      "Validation score: -13.738653\n",
      "Iteration 1113, loss = 660.83787238\n",
      "Validation score: -13.717291\n",
      "Iteration 1114, loss = 659.84703292\n",
      "Validation score: -13.695970\n",
      "Iteration 1115, loss = 658.85940293\n",
      "Validation score: -13.674661\n",
      "Iteration 1116, loss = 657.87074839\n",
      "Validation score: -13.653432\n",
      "Iteration 1117, loss = 656.88744354\n",
      "Validation score: -13.632219\n",
      "Iteration 1118, loss = 655.90690690\n",
      "Validation score: -13.611058\n",
      "Iteration 1119, loss = 654.92772733\n",
      "Validation score: -13.589910\n",
      "Iteration 1120, loss = 653.94789821\n",
      "Validation score: -13.568834\n",
      "Iteration 1121, loss = 652.97089746\n",
      "Validation score: -13.547834\n",
      "Iteration 1122, loss = 651.99874725\n",
      "Validation score: -13.526835\n",
      "Iteration 1123, loss = 651.02426192\n",
      "Validation score: -13.505891\n",
      "Iteration 1124, loss = 650.05512363\n",
      "Validation score: -13.484950\n",
      "Iteration 1125, loss = 649.08359567\n",
      "Validation score: -13.464047\n",
      "Iteration 1126, loss = 648.11296722\n",
      "Validation score: -13.443163\n",
      "Iteration 1127, loss = 647.14769773\n",
      "Validation score: -13.422262\n",
      "Iteration 1128, loss = 646.18065750\n",
      "Validation score: -13.401413\n",
      "Iteration 1129, loss = 645.21712846\n",
      "Validation score: -13.380641\n",
      "Iteration 1130, loss = 644.25158387\n",
      "Validation score: -13.359948\n",
      "Iteration 1131, loss = 643.29156851\n",
      "Validation score: -13.339230\n",
      "Iteration 1132, loss = 642.33620733\n",
      "Validation score: -13.318491\n",
      "Iteration 1133, loss = 641.37896173\n",
      "Validation score: -13.297812\n",
      "Iteration 1134, loss = 640.41722615\n",
      "Validation score: -13.277280\n",
      "Iteration 1135, loss = 639.46760449\n",
      "Validation score: -13.256743\n",
      "Iteration 1136, loss = 638.51707139\n",
      "Validation score: -13.236184\n",
      "Iteration 1137, loss = 637.56216094\n",
      "Validation score: -13.215692\n",
      "Iteration 1138, loss = 636.61478709\n",
      "Validation score: -13.195171\n",
      "Iteration 1139, loss = 635.66350783\n",
      "Validation score: -13.174733\n",
      "Iteration 1140, loss = 634.71771554\n",
      "Validation score: -13.154292\n",
      "Iteration 1141, loss = 633.77325490\n",
      "Validation score: -13.133856\n",
      "Iteration 1142, loss = 632.82526623\n",
      "Validation score: -13.113510\n",
      "Iteration 1143, loss = 631.88531793\n",
      "Validation score: -13.093138\n",
      "Iteration 1144, loss = 630.94305382\n",
      "Validation score: -13.072820\n",
      "Iteration 1145, loss = 630.00094287\n",
      "Validation score: -13.052577\n",
      "Iteration 1146, loss = 629.06308915\n",
      "Validation score: -13.032316\n",
      "Iteration 1147, loss = 628.12338165\n",
      "Validation score: -13.012071\n",
      "Iteration 1148, loss = 627.18846097\n",
      "Validation score: -12.991807\n",
      "Iteration 1149, loss = 626.24874922\n",
      "Validation score: -12.971626\n",
      "Iteration 1150, loss = 625.31813561\n",
      "Validation score: -12.951436\n",
      "Iteration 1151, loss = 624.37999031\n",
      "Validation score: -12.931317\n",
      "Iteration 1152, loss = 623.45051931\n",
      "Validation score: -12.911156\n",
      "Iteration 1153, loss = 622.51552128\n",
      "Validation score: -12.891067\n",
      "Iteration 1154, loss = 621.58574291\n",
      "Validation score: -12.871003\n",
      "Iteration 1155, loss = 620.65672358\n",
      "Validation score: -12.850899\n",
      "Iteration 1156, loss = 619.73010669\n",
      "Validation score: -12.830777\n",
      "Iteration 1157, loss = 618.79860424\n",
      "Validation score: -12.810775\n",
      "Iteration 1158, loss = 617.86816005\n",
      "Validation score: -12.790854\n",
      "Iteration 1159, loss = 616.94937538\n",
      "Validation score: -12.770809\n",
      "Iteration 1160, loss = 616.01748338\n",
      "Validation score: -12.750871\n",
      "Iteration 1161, loss = 615.09841943\n",
      "Validation score: -12.730905\n",
      "Iteration 1162, loss = 614.17415304\n",
      "Validation score: -12.711000\n",
      "Iteration 1163, loss = 613.25051432\n",
      "Validation score: -12.691098\n",
      "Iteration 1164, loss = 612.33170955\n",
      "Validation score: -12.671154\n",
      "Iteration 1165, loss = 611.40605338\n",
      "Validation score: -12.651309\n",
      "Iteration 1166, loss = 610.49367579\n",
      "Validation score: -12.631407\n",
      "Iteration 1167, loss = 609.56901653\n",
      "Validation score: -12.611598\n",
      "Iteration 1168, loss = 608.65177828\n",
      "Validation score: -12.591794\n",
      "Iteration 1169, loss = 607.73714683\n",
      "Validation score: -12.571966\n",
      "Iteration 1170, loss = 606.82098972\n",
      "Validation score: -12.552187\n",
      "Iteration 1171, loss = 605.90257651\n",
      "Validation score: -12.532432\n",
      "Iteration 1172, loss = 604.99039761\n",
      "Validation score: -12.512647\n",
      "Iteration 1173, loss = 604.07322335\n",
      "Validation score: -12.492897\n",
      "Iteration 1174, loss = 603.15833655\n",
      "Validation score: -12.473116\n",
      "Iteration 1175, loss = 602.24405524\n",
      "Validation score: -12.453288\n",
      "Iteration 1176, loss = 601.32931023\n",
      "Validation score: -12.433521\n",
      "Iteration 1177, loss = 600.41297699\n",
      "Validation score: -12.413813\n",
      "Iteration 1178, loss = 599.49916499\n",
      "Validation score: -12.394088\n",
      "Iteration 1179, loss = 598.58965323\n",
      "Validation score: -12.374294\n",
      "Iteration 1180, loss = 597.67151644\n",
      "Validation score: -12.354550\n",
      "Iteration 1181, loss = 596.76185082\n",
      "Validation score: -12.334749\n",
      "Iteration 1182, loss = 595.84437641\n",
      "Validation score: -12.314974\n",
      "Iteration 1183, loss = 594.93047202\n",
      "Validation score: -12.295169\n",
      "Iteration 1184, loss = 594.01051526\n",
      "Validation score: -12.275400\n",
      "Iteration 1185, loss = 593.09648161\n",
      "Validation score: -12.255489\n",
      "Iteration 1186, loss = 592.17553411\n",
      "Validation score: -12.235579\n",
      "Iteration 1187, loss = 591.25547563\n",
      "Validation score: -12.215554\n",
      "Iteration 1188, loss = 590.32532996\n",
      "Validation score: -12.195450\n",
      "Iteration 1189, loss = 589.39195809\n",
      "Validation score: -12.175260\n",
      "Iteration 1190, loss = 588.46108820\n",
      "Validation score: -12.154880\n",
      "Iteration 1191, loss = 587.51494204\n",
      "Validation score: -12.134430\n",
      "Iteration 1192, loss = 586.56513607\n",
      "Validation score: -12.113792\n",
      "Iteration 1193, loss = 585.60763897\n",
      "Validation score: -12.092860\n",
      "Iteration 1194, loss = 584.63490456\n",
      "Validation score: -12.071702\n",
      "Iteration 1195, loss = 583.64890824\n",
      "Validation score: -12.050294\n",
      "Iteration 1196, loss = 582.65547421\n",
      "Validation score: -12.028561\n",
      "Iteration 1197, loss = 581.64211236\n",
      "Validation score: -12.006543\n",
      "Iteration 1198, loss = 580.62056999\n",
      "Validation score: -11.984168\n",
      "Iteration 1199, loss = 579.58324564\n",
      "Validation score: -11.961451\n",
      "Iteration 1200, loss = 578.52929451\n",
      "Validation score: -11.938452\n",
      "Iteration 1201, loss = 577.46148362\n",
      "Validation score: -11.915235\n",
      "Iteration 1202, loss = 576.38446421\n",
      "Validation score: -11.891868\n",
      "Iteration 1203, loss = 575.30105725\n",
      "Validation score: -11.868311\n",
      "Iteration 1204, loss = 574.20559904\n",
      "Validation score: -11.844611\n",
      "Iteration 1205, loss = 573.11554887\n",
      "Validation score: -11.820718\n",
      "Iteration 1206, loss = 572.00688552\n",
      "Validation score: -11.796860\n",
      "Iteration 1207, loss = 570.90427794\n",
      "Validation score: -11.772940\n",
      "Iteration 1208, loss = 569.80109202\n",
      "Validation score: -11.748980\n",
      "Iteration 1209, loss = 568.68967057\n",
      "Validation score: -11.725079\n",
      "Iteration 1210, loss = 567.58179278\n",
      "Validation score: -11.701098\n",
      "Iteration 1211, loss = 566.47442974\n",
      "Validation score: -11.677038\n",
      "Iteration 1212, loss = 565.36257159\n",
      "Validation score: -11.652930\n",
      "Iteration 1213, loss = 564.25040495\n",
      "Validation score: -11.628715\n",
      "Iteration 1214, loss = 563.12726487\n",
      "Validation score: -11.604453\n",
      "Iteration 1215, loss = 562.00157614\n",
      "Validation score: -11.580083\n",
      "Iteration 1216, loss = 560.87780978\n",
      "Validation score: -11.555579\n",
      "Iteration 1217, loss = 559.74649968\n",
      "Validation score: -11.530989\n",
      "Iteration 1218, loss = 558.60643434\n",
      "Validation score: -11.506379\n",
      "Iteration 1219, loss = 557.47548555\n",
      "Validation score: -11.481700\n",
      "Iteration 1220, loss = 556.33408945\n",
      "Validation score: -11.457120\n",
      "Iteration 1221, loss = 555.20069715\n",
      "Validation score: -11.432559\n",
      "Iteration 1222, loss = 554.06759106\n",
      "Validation score: -11.408065\n",
      "Iteration 1223, loss = 552.93778879\n",
      "Validation score: -11.383703\n",
      "Iteration 1224, loss = 551.81253536\n",
      "Validation score: -11.359432\n",
      "Iteration 1225, loss = 550.68956350\n",
      "Validation score: -11.335361\n",
      "Iteration 1226, loss = 549.58326924\n",
      "Validation score: -11.311406\n",
      "Iteration 1227, loss = 548.47907990\n",
      "Validation score: -11.287665\n",
      "Iteration 1228, loss = 547.38650443\n",
      "Validation score: -11.264080\n",
      "Iteration 1229, loss = 546.29960306\n",
      "Validation score: -11.240726\n",
      "Iteration 1230, loss = 545.22404557\n",
      "Validation score: -11.217607\n",
      "Iteration 1231, loss = 544.15733135\n",
      "Validation score: -11.194677\n",
      "Iteration 1232, loss = 543.10232137\n",
      "Validation score: -11.171897\n",
      "Iteration 1233, loss = 542.05273066\n",
      "Validation score: -11.149326\n",
      "Iteration 1234, loss = 541.01246136\n",
      "Validation score: -11.126971\n",
      "Iteration 1235, loss = 539.98198159\n",
      "Validation score: -11.104759\n",
      "Iteration 1236, loss = 538.95939368\n",
      "Validation score: -11.082657\n",
      "Iteration 1237, loss = 537.94297655\n",
      "Validation score: -11.060712\n",
      "Iteration 1238, loss = 536.92984716\n",
      "Validation score: -11.038964\n",
      "Iteration 1239, loss = 535.92701798\n",
      "Validation score: -11.017332\n",
      "Iteration 1240, loss = 534.93251213\n",
      "Validation score: -10.995757\n",
      "Iteration 1241, loss = 533.93740833\n",
      "Validation score: -10.974384\n",
      "Iteration 1242, loss = 532.95151104\n",
      "Validation score: -10.953122\n",
      "Iteration 1243, loss = 531.97435494\n",
      "Validation score: -10.931931\n",
      "Iteration 1244, loss = 531.00144517\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation score: -10.910811\n",
      "Iteration 1245, loss = 530.02759451\n",
      "Validation score: -10.889795\n",
      "Iteration 1246, loss = 529.05253346\n",
      "Validation score: -10.868898\n",
      "Iteration 1247, loss = 528.09470931\n",
      "Validation score: -10.847928\n",
      "Iteration 1248, loss = 527.12624472\n",
      "Validation score: -10.827087\n",
      "Iteration 1249, loss = 526.16751505\n",
      "Validation score: -10.806303\n",
      "Iteration 1250, loss = 525.20938545\n",
      "Validation score: -10.785512\n",
      "Iteration 1251, loss = 524.25127624\n",
      "Validation score: -10.764659\n",
      "Iteration 1252, loss = 523.28751525\n",
      "Validation score: -10.743863\n",
      "Iteration 1253, loss = 522.32958534\n",
      "Validation score: -10.723036\n",
      "Iteration 1254, loss = 521.36891680\n",
      "Validation score: -10.702164\n",
      "Iteration 1255, loss = 520.40823207\n",
      "Validation score: -10.681217\n",
      "Iteration 1256, loss = 519.44163147\n",
      "Validation score: -10.660178\n",
      "Iteration 1257, loss = 518.46764304\n",
      "Validation score: -10.639013\n",
      "Iteration 1258, loss = 517.48850937\n",
      "Validation score: -10.617653\n",
      "Iteration 1259, loss = 516.49876932\n",
      "Validation score: -10.596071\n",
      "Iteration 1260, loss = 515.50114446\n",
      "Validation score: -10.574211\n",
      "Iteration 1261, loss = 514.48798761\n",
      "Validation score: -10.552150\n",
      "Iteration 1262, loss = 513.47030473\n",
      "Validation score: -10.529761\n",
      "Iteration 1263, loss = 512.43595728\n",
      "Validation score: -10.507147\n",
      "Iteration 1264, loss = 511.39096732\n",
      "Validation score: -10.484370\n",
      "Iteration 1265, loss = 510.33779630\n",
      "Validation score: -10.461357\n",
      "Iteration 1266, loss = 509.27258030\n",
      "Validation score: -10.438257\n",
      "Iteration 1267, loss = 508.20967062\n",
      "Validation score: -10.414946\n",
      "Iteration 1268, loss = 507.13033095\n",
      "Validation score: -10.391636\n",
      "Iteration 1269, loss = 506.05846992\n",
      "Validation score: -10.368242\n",
      "Iteration 1270, loss = 504.97766694\n",
      "Validation score: -10.344977\n",
      "Iteration 1271, loss = 503.90679233\n",
      "Validation score: -10.321749\n",
      "Iteration 1272, loss = 502.83879607\n",
      "Validation score: -10.298634\n",
      "Iteration 1273, loss = 501.77855731\n",
      "Validation score: -10.275718\n",
      "Iteration 1274, loss = 500.72631121\n",
      "Validation score: -10.253013\n",
      "Iteration 1275, loss = 499.68140209\n",
      "Validation score: -10.230516\n",
      "Iteration 1276, loss = 498.64677608\n",
      "Validation score: -10.208206\n",
      "Iteration 1277, loss = 497.62154558\n",
      "Validation score: -10.186052\n",
      "Iteration 1278, loss = 496.60321101\n",
      "Validation score: -10.164127\n",
      "Iteration 1279, loss = 495.59466478\n",
      "Validation score: -10.142378\n",
      "Iteration 1280, loss = 494.59934419\n",
      "Validation score: -10.120802\n",
      "Iteration 1281, loss = 493.60421616\n",
      "Validation score: -10.099471\n",
      "Iteration 1282, loss = 492.62695172\n",
      "Validation score: -10.078220\n",
      "Iteration 1283, loss = 491.65129646\n",
      "Validation score: -10.057157\n",
      "Iteration 1284, loss = 490.68118353\n",
      "Validation score: -10.036370\n",
      "Iteration 1285, loss = 489.72944536\n",
      "Validation score: -10.015655\n",
      "Iteration 1286, loss = 488.77620165\n",
      "Validation score: -9.995131\n",
      "Iteration 1287, loss = 487.83196232\n",
      "Validation score: -9.974684\n",
      "Iteration 1288, loss = 486.89227291\n",
      "Validation score: -9.954294\n",
      "Iteration 1289, loss = 485.95835905\n",
      "Validation score: -9.934040\n",
      "Iteration 1290, loss = 485.02631545\n",
      "Validation score: -9.913933\n",
      "Iteration 1291, loss = 484.09983316\n",
      "Validation score: -9.893921\n",
      "Iteration 1292, loss = 483.17700476\n",
      "Validation score: -9.873982\n",
      "Iteration 1293, loss = 482.26266782\n",
      "Validation score: -9.854087\n",
      "Iteration 1294, loss = 481.34599161\n",
      "Validation score: -9.834342\n",
      "Iteration 1295, loss = 480.44248313\n",
      "Validation score: -9.814617\n",
      "Iteration 1296, loss = 479.53734173\n",
      "Validation score: -9.795014\n",
      "Iteration 1297, loss = 478.63536767\n",
      "Validation score: -9.775534\n",
      "Iteration 1298, loss = 477.74216166\n",
      "Validation score: -9.756095\n",
      "Iteration 1299, loss = 476.84713689\n",
      "Validation score: -9.736766\n",
      "Iteration 1300, loss = 475.96313013\n",
      "Validation score: -9.717453\n",
      "Iteration 1301, loss = 475.07109690\n",
      "Validation score: -9.698279\n",
      "Iteration 1302, loss = 474.19100250\n",
      "Validation score: -9.679122\n",
      "Iteration 1303, loss = 473.31374086\n",
      "Validation score: -9.660013\n",
      "Iteration 1304, loss = 472.43311594\n",
      "Validation score: -9.640982\n",
      "Iteration 1305, loss = 471.55848638\n",
      "Validation score: -9.622042\n",
      "Iteration 1306, loss = 470.69247103\n",
      "Validation score: -9.603055\n",
      "Iteration 1307, loss = 469.81527231\n",
      "Validation score: -9.584284\n",
      "Iteration 1308, loss = 468.95350435\n",
      "Validation score: -9.565479\n",
      "Iteration 1309, loss = 468.08834055\n",
      "Validation score: -9.546745\n",
      "Iteration 1310, loss = 467.22915210\n",
      "Validation score: -9.528041\n",
      "Iteration 1311, loss = 466.36848411\n",
      "Validation score: -9.509423\n",
      "Iteration 1312, loss = 465.51346477\n",
      "Validation score: -9.490836\n",
      "Iteration 1313, loss = 464.66294988\n",
      "Validation score: -9.472225\n",
      "Iteration 1314, loss = 463.80468665\n",
      "Validation score: -9.453736\n",
      "Iteration 1315, loss = 462.95592012\n",
      "Validation score: -9.435263\n",
      "Iteration 1316, loss = 462.10920700\n",
      "Validation score: -9.416791\n",
      "Iteration 1317, loss = 461.25937086\n",
      "Validation score: -9.398360\n",
      "Iteration 1318, loss = 460.41405590\n",
      "Validation score: -9.379960\n",
      "Iteration 1319, loss = 459.56821495\n",
      "Validation score: -9.361644\n",
      "Iteration 1320, loss = 458.72568511\n",
      "Validation score: -9.343391\n",
      "Iteration 1321, loss = 457.88654158\n",
      "Validation score: -9.325157\n",
      "Iteration 1322, loss = 457.05223752\n",
      "Validation score: -9.306949\n",
      "Iteration 1323, loss = 456.21545778\n",
      "Validation score: -9.288839\n",
      "Iteration 1324, loss = 455.38341579\n",
      "Validation score: -9.270750\n",
      "Iteration 1325, loss = 454.55236006\n",
      "Validation score: -9.252677\n",
      "Iteration 1326, loss = 453.72366574\n",
      "Validation score: -9.234632\n",
      "Iteration 1327, loss = 452.89677224\n",
      "Validation score: -9.216621\n",
      "Iteration 1328, loss = 452.07010004\n",
      "Validation score: -9.198666\n",
      "Iteration 1329, loss = 451.24289015\n",
      "Validation score: -9.180742\n",
      "Iteration 1330, loss = 450.41767611\n",
      "Validation score: -9.162860\n",
      "Iteration 1331, loss = 449.59562143\n",
      "Validation score: -9.144952\n",
      "Iteration 1332, loss = 448.77423885\n",
      "Validation score: -9.127037\n",
      "Iteration 1333, loss = 447.95462692\n",
      "Validation score: -9.109166\n",
      "Iteration 1334, loss = 447.13367761\n",
      "Validation score: -9.091389\n",
      "Iteration 1335, loss = 446.31898752\n",
      "Validation score: -9.073623\n",
      "Iteration 1336, loss = 445.50190136\n",
      "Validation score: -9.055926\n",
      "Iteration 1337, loss = 444.69057547\n",
      "Validation score: -9.038204\n",
      "Iteration 1338, loss = 443.87955046\n",
      "Validation score: -9.020534\n",
      "Iteration 1339, loss = 443.06945765\n",
      "Validation score: -9.002930\n",
      "Iteration 1340, loss = 442.25807002\n",
      "Validation score: -8.985398\n",
      "Iteration 1341, loss = 441.45382123\n",
      "Validation score: -8.967816\n",
      "Iteration 1342, loss = 440.64868348\n",
      "Validation score: -8.950221\n",
      "Iteration 1343, loss = 439.84288538\n",
      "Validation score: -8.932640\n",
      "Iteration 1344, loss = 439.03607751\n",
      "Validation score: -8.915163\n",
      "Iteration 1345, loss = 438.23428571\n",
      "Validation score: -8.897762\n",
      "Iteration 1346, loss = 437.43486933\n",
      "Validation score: -8.880373\n",
      "Iteration 1347, loss = 436.63700552\n",
      "Validation score: -8.863014\n",
      "Iteration 1348, loss = 435.84349671\n",
      "Validation score: -8.845640\n",
      "Iteration 1349, loss = 435.04506402\n",
      "Validation score: -8.828323\n",
      "Iteration 1350, loss = 434.24909229\n",
      "Validation score: -8.811093\n",
      "Iteration 1351, loss = 433.46104006\n",
      "Validation score: -8.793841\n",
      "Iteration 1352, loss = 432.66736539\n",
      "Validation score: -8.776632\n",
      "Iteration 1353, loss = 431.88249934\n",
      "Validation score: -8.759387\n",
      "Iteration 1354, loss = 431.08678726\n",
      "Validation score: -8.742271\n",
      "Iteration 1355, loss = 430.30423271\n",
      "Validation score: -8.725097\n",
      "Iteration 1356, loss = 429.51639937\n",
      "Validation score: -8.707996\n",
      "Iteration 1357, loss = 428.73447362\n",
      "Validation score: -8.690837\n",
      "Iteration 1358, loss = 427.94847582\n",
      "Validation score: -8.673774\n",
      "Iteration 1359, loss = 427.16739955\n",
      "Validation score: -8.656737\n",
      "Iteration 1360, loss = 426.38729331\n",
      "Validation score: -8.639758\n",
      "Iteration 1361, loss = 425.60403504\n",
      "Validation score: -8.622858\n",
      "Iteration 1362, loss = 424.83213884\n",
      "Validation score: -8.605866\n",
      "Iteration 1363, loss = 424.05419287\n",
      "Validation score: -8.588911\n",
      "Iteration 1364, loss = 423.27613514\n",
      "Validation score: -8.572003\n",
      "Iteration 1365, loss = 422.50149112\n",
      "Validation score: -8.555109\n",
      "Iteration 1366, loss = 421.72330084\n",
      "Validation score: -8.538303\n",
      "Iteration 1367, loss = 420.95458709\n",
      "Validation score: -8.521465\n",
      "Iteration 1368, loss = 420.18216569\n",
      "Validation score: -8.504635\n",
      "Iteration 1369, loss = 419.41615381\n",
      "Validation score: -8.487808\n",
      "Iteration 1370, loss = 418.64146485\n",
      "Validation score: -8.471113\n",
      "Iteration 1371, loss = 417.87683807\n",
      "Validation score: -8.454424\n",
      "Iteration 1372, loss = 417.11321596\n",
      "Validation score: -8.437735\n",
      "Iteration 1373, loss = 416.34895405\n",
      "Validation score: -8.421042\n",
      "Iteration 1374, loss = 415.58220208\n",
      "Validation score: -8.404393\n",
      "Iteration 1375, loss = 414.82326779\n",
      "Validation score: -8.387734\n",
      "Iteration 1376, loss = 414.06168289\n",
      "Validation score: -8.371125\n",
      "Iteration 1377, loss = 413.29482581\n",
      "Validation score: -8.354589\n",
      "Iteration 1378, loss = 412.53890126\n",
      "Validation score: -8.337973\n",
      "Iteration 1379, loss = 411.77812460\n",
      "Validation score: -8.321394\n",
      "Iteration 1380, loss = 411.01858979\n",
      "Validation score: -8.304857\n",
      "Iteration 1381, loss = 410.26010714\n",
      "Validation score: -8.288324\n",
      "Iteration 1382, loss = 409.50145414\n",
      "Validation score: -8.271833\n",
      "Iteration 1383, loss = 408.75020794\n",
      "Validation score: -8.255345\n",
      "Iteration 1384, loss = 407.99430357\n",
      "Validation score: -8.238953\n",
      "Iteration 1385, loss = 407.24176304\n",
      "Validation score: -8.222589\n",
      "Iteration 1386, loss = 406.48815733\n",
      "Validation score: -8.206255\n",
      "Iteration 1387, loss = 405.74520234\n",
      "Validation score: -8.189781\n",
      "Iteration 1388, loss = 404.99197378\n",
      "Validation score: -8.173426\n",
      "Iteration 1389, loss = 404.24157519\n",
      "Validation score: -8.157091\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1390, loss = 403.49337975\n",
      "Validation score: -8.140768\n",
      "Iteration 1391, loss = 402.74979963\n",
      "Validation score: -8.124476\n",
      "Iteration 1392, loss = 402.00616068\n",
      "Validation score: -8.108233\n",
      "Iteration 1393, loss = 401.26011408\n",
      "Validation score: -8.092075\n",
      "Iteration 1394, loss = 400.51609568\n",
      "Validation score: -8.075897\n",
      "Iteration 1395, loss = 399.78179177\n",
      "Validation score: -8.059623\n",
      "Iteration 1396, loss = 399.03769702\n",
      "Validation score: -8.043425\n",
      "Iteration 1397, loss = 398.29679708\n",
      "Validation score: -8.027303\n",
      "Iteration 1398, loss = 397.55786613\n",
      "Validation score: -8.011242\n",
      "Iteration 1399, loss = 396.81893620\n",
      "Validation score: -7.995226\n",
      "Iteration 1400, loss = 396.08904719\n",
      "Validation score: -7.979130\n",
      "Iteration 1401, loss = 395.35471295\n",
      "Validation score: -7.963063\n",
      "Iteration 1402, loss = 394.61994143\n",
      "Validation score: -7.947042\n",
      "Iteration 1403, loss = 393.88463359\n",
      "Validation score: -7.931068\n",
      "Iteration 1404, loss = 393.15360952\n",
      "Validation score: -7.915091\n",
      "Iteration 1405, loss = 392.41951780\n",
      "Validation score: -7.899138\n",
      "Iteration 1406, loss = 391.69474424\n",
      "Validation score: -7.883118\n",
      "Iteration 1407, loss = 390.96187743\n",
      "Validation score: -7.867161\n",
      "Iteration 1408, loss = 390.23033220\n",
      "Validation score: -7.851291\n",
      "Iteration 1409, loss = 389.50157435\n",
      "Validation score: -7.835456\n",
      "Iteration 1410, loss = 388.78588359\n",
      "Validation score: -7.819506\n",
      "Iteration 1411, loss = 388.05484028\n",
      "Validation score: -7.803700\n",
      "Iteration 1412, loss = 387.33157411\n",
      "Validation score: -7.787930\n",
      "Iteration 1413, loss = 386.61206123\n",
      "Validation score: -7.772138\n",
      "Iteration 1414, loss = 385.89032922\n",
      "Validation score: -7.756393\n",
      "Iteration 1415, loss = 385.17011175\n",
      "Validation score: -7.740677\n",
      "Iteration 1416, loss = 384.44736647\n",
      "Validation score: -7.725043\n",
      "Iteration 1417, loss = 383.73445727\n",
      "Validation score: -7.709359\n",
      "Iteration 1418, loss = 383.01773110\n",
      "Validation score: -7.693687\n",
      "Iteration 1419, loss = 382.30230992\n",
      "Validation score: -7.678034\n",
      "Iteration 1420, loss = 381.59029311\n",
      "Validation score: -7.662366\n",
      "Iteration 1421, loss = 380.87552604\n",
      "Validation score: -7.646748\n",
      "Iteration 1422, loss = 380.16037136\n",
      "Validation score: -7.631217\n",
      "Iteration 1423, loss = 379.44662085\n",
      "Validation score: -7.615752\n",
      "Iteration 1424, loss = 378.73940369\n",
      "Validation score: -7.600272\n",
      "Iteration 1425, loss = 378.03864327\n",
      "Validation score: -7.584687\n",
      "Iteration 1426, loss = 377.32229134\n",
      "Validation score: -7.569216\n",
      "Iteration 1427, loss = 376.62031930\n",
      "Validation score: -7.553695\n",
      "Iteration 1428, loss = 375.90550824\n",
      "Validation score: -7.538298\n",
      "Iteration 1429, loss = 375.20249902\n",
      "Validation score: -7.522886\n",
      "Iteration 1430, loss = 374.49666550\n",
      "Validation score: -7.507480\n",
      "Iteration 1431, loss = 373.79733214\n",
      "Validation score: -7.492022\n",
      "Iteration 1432, loss = 373.08749306\n",
      "Validation score: -7.476719\n",
      "Iteration 1433, loss = 372.39146500\n",
      "Validation score: -7.461331\n",
      "Iteration 1434, loss = 371.69112857\n",
      "Validation score: -7.445990\n",
      "Iteration 1435, loss = 370.98625487\n",
      "Validation score: -7.430738\n",
      "Iteration 1436, loss = 370.29217431\n",
      "Validation score: -7.415427\n",
      "Iteration 1437, loss = 369.59688955\n",
      "Validation score: -7.400107\n",
      "Iteration 1438, loss = 368.89520349\n",
      "Validation score: -7.384892\n",
      "Iteration 1439, loss = 368.20145158\n",
      "Validation score: -7.369705\n",
      "Iteration 1440, loss = 367.50728666\n",
      "Validation score: -7.354563\n",
      "Iteration 1441, loss = 366.81507718\n",
      "Validation score: -7.339422\n",
      "Iteration 1442, loss = 366.12246498\n",
      "Validation score: -7.324263\n",
      "Iteration 1443, loss = 365.43060609\n",
      "Validation score: -7.309101\n",
      "Iteration 1444, loss = 364.73662983\n",
      "Validation score: -7.293934\n",
      "Iteration 1445, loss = 364.04523263\n",
      "Validation score: -7.278784\n",
      "Iteration 1446, loss = 363.35202610\n",
      "Validation score: -7.263653\n",
      "Iteration 1447, loss = 362.66253036\n",
      "Validation score: -7.248510\n",
      "Iteration 1448, loss = 361.97371001\n",
      "Validation score: -7.233428\n",
      "Iteration 1449, loss = 361.28689314\n",
      "Validation score: -7.218393\n",
      "Iteration 1450, loss = 360.60342749\n",
      "Validation score: -7.203335\n",
      "Iteration 1451, loss = 359.91462663\n",
      "Validation score: -7.188348\n",
      "Iteration 1452, loss = 359.23005308\n",
      "Validation score: -7.173359\n",
      "Iteration 1453, loss = 358.54338099\n",
      "Validation score: -7.158424\n",
      "Iteration 1454, loss = 357.86375056\n",
      "Validation score: -7.143467\n",
      "Iteration 1455, loss = 357.18241574\n",
      "Validation score: -7.128530\n",
      "Iteration 1456, loss = 356.50189232\n",
      "Validation score: -7.113619\n",
      "Iteration 1457, loss = 355.82257669\n",
      "Validation score: -7.098740\n",
      "Iteration 1458, loss = 355.14414762\n",
      "Validation score: -7.083859\n",
      "Iteration 1459, loss = 354.46591130\n",
      "Validation score: -7.068994\n",
      "Iteration 1460, loss = 353.78740086\n",
      "Validation score: -7.054173\n",
      "Iteration 1461, loss = 353.11325794\n",
      "Validation score: -7.039317\n",
      "Iteration 1462, loss = 352.43654097\n",
      "Validation score: -7.024523\n",
      "Iteration 1463, loss = 351.76472465\n",
      "Validation score: -7.009757\n",
      "Iteration 1464, loss = 351.08926312\n",
      "Validation score: -6.995126\n",
      "Iteration 1465, loss = 350.42430895\n",
      "Validation score: -6.980409\n",
      "Iteration 1466, loss = 349.75442696\n",
      "Validation score: -6.965733\n",
      "Iteration 1467, loss = 349.08515789\n",
      "Validation score: -6.951101\n",
      "Iteration 1468, loss = 348.41814557\n",
      "Validation score: -6.936501\n",
      "Iteration 1469, loss = 347.75145476\n",
      "Validation score: -6.921954\n",
      "Iteration 1470, loss = 347.08825166\n",
      "Validation score: -6.907354\n",
      "Iteration 1471, loss = 346.42345275\n",
      "Validation score: -6.892805\n",
      "Iteration 1472, loss = 345.76075810\n",
      "Validation score: -6.878245\n",
      "Iteration 1473, loss = 345.09797033\n",
      "Validation score: -6.863700\n",
      "Iteration 1474, loss = 344.43340367\n",
      "Validation score: -6.849169\n",
      "Iteration 1475, loss = 343.77262067\n",
      "Validation score: -6.834623\n",
      "Iteration 1476, loss = 343.11083338\n",
      "Validation score: -6.820105\n",
      "Iteration 1477, loss = 342.44812679\n",
      "Validation score: -6.805646\n",
      "Iteration 1478, loss = 341.78772555\n",
      "Validation score: -6.791204\n",
      "Iteration 1479, loss = 341.13043027\n",
      "Validation score: -6.776706\n",
      "Iteration 1480, loss = 340.47368568\n",
      "Validation score: -6.762179\n",
      "Iteration 1481, loss = 339.81222880\n",
      "Validation score: -6.747766\n",
      "Iteration 1482, loss = 339.15602463\n",
      "Validation score: -6.733374\n",
      "Iteration 1483, loss = 338.49838638\n",
      "Validation score: -6.719003\n",
      "Iteration 1484, loss = 337.84301665\n",
      "Validation score: -6.704613\n",
      "Iteration 1485, loss = 337.18793637\n",
      "Validation score: -6.690231\n",
      "Iteration 1486, loss = 336.53660520\n",
      "Validation score: -6.675855\n",
      "Iteration 1487, loss = 335.88091778\n",
      "Validation score: -6.661554\n",
      "Iteration 1488, loss = 335.22975661\n",
      "Validation score: -6.647275\n",
      "Iteration 1489, loss = 334.58026786\n",
      "Validation score: -6.633042\n",
      "Iteration 1490, loss = 333.93579937\n",
      "Validation score: -6.618758\n",
      "Iteration 1491, loss = 333.28459513\n",
      "Validation score: -6.604519\n",
      "Iteration 1492, loss = 332.63291240\n",
      "Validation score: -6.590299\n",
      "Iteration 1493, loss = 331.98581980\n",
      "Validation score: -6.576042\n",
      "Iteration 1494, loss = 331.33756363\n",
      "Validation score: -6.561774\n",
      "Iteration 1495, loss = 330.69206907\n",
      "Validation score: -6.547508\n",
      "Iteration 1496, loss = 330.04118250\n",
      "Validation score: -6.533364\n",
      "Iteration 1497, loss = 329.40022728\n",
      "Validation score: -6.519170\n",
      "Iteration 1498, loss = 328.75258094\n",
      "Validation score: -6.505044\n",
      "Iteration 1499, loss = 328.10903653\n",
      "Validation score: -6.490907\n",
      "Iteration 1500, loss = 327.46548529\n",
      "Validation score: -6.476798\n",
      "Iteration 1501, loss = 326.82590972\n",
      "Validation score: -6.462685\n",
      "Iteration 1502, loss = 326.18125401\n",
      "Validation score: -6.448606\n",
      "Iteration 1503, loss = 325.54439560\n",
      "Validation score: -6.434468\n",
      "Iteration 1504, loss = 324.90119119\n",
      "Validation score: -6.420360\n",
      "Iteration 1505, loss = 324.25754141\n",
      "Validation score: -6.406258\n",
      "Iteration 1506, loss = 323.61468433\n",
      "Validation score: -6.392121\n",
      "Iteration 1507, loss = 322.97195034\n",
      "Validation score: -6.377882\n",
      "Iteration 1508, loss = 322.32719937\n",
      "Validation score: -6.363604\n",
      "Iteration 1509, loss = 321.67674246\n",
      "Validation score: -6.349344\n",
      "Iteration 1510, loss = 321.02433592\n",
      "Validation score: -6.335067\n",
      "Iteration 1511, loss = 320.37285964\n",
      "Validation score: -6.320674\n",
      "Iteration 1512, loss = 319.71857522\n",
      "Validation score: -6.306130\n",
      "Iteration 1513, loss = 319.05455711\n",
      "Validation score: -6.291497\n",
      "Iteration 1514, loss = 318.38859329\n",
      "Validation score: -6.276687\n",
      "Iteration 1515, loss = 317.71293041\n",
      "Validation score: -6.261701\n",
      "Iteration 1516, loss = 317.02843766\n",
      "Validation score: -6.246573\n",
      "Iteration 1517, loss = 316.33384597\n",
      "Validation score: -6.231179\n",
      "Iteration 1518, loss = 315.63199089\n",
      "Validation score: -6.215456\n",
      "Iteration 1519, loss = 314.91281196\n",
      "Validation score: -6.199516\n",
      "Iteration 1520, loss = 314.18688242\n",
      "Validation score: -6.183235\n",
      "Iteration 1521, loss = 313.43839549\n",
      "Validation score: -6.166796\n",
      "Iteration 1522, loss = 312.69100396\n",
      "Validation score: -6.150078\n",
      "Iteration 1523, loss = 311.93457614\n",
      "Validation score: -6.133220\n",
      "Iteration 1524, loss = 311.15822410\n",
      "Validation score: -6.116347\n",
      "Iteration 1525, loss = 310.39559582\n",
      "Validation score: -6.099311\n",
      "Iteration 1526, loss = 309.62053584\n",
      "Validation score: -6.082339\n",
      "Iteration 1527, loss = 308.85456328\n",
      "Validation score: -6.065365\n",
      "Iteration 1528, loss = 308.08401684\n",
      "Validation score: -6.048519\n",
      "Iteration 1529, loss = 307.32168820\n",
      "Validation score: -6.031809\n",
      "Iteration 1530, loss = 306.56605592\n",
      "Validation score: -6.015290\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1531, loss = 305.81807715\n",
      "Validation score: -5.998944\n",
      "Iteration 1532, loss = 305.07477885\n",
      "Validation score: -5.982747\n",
      "Iteration 1533, loss = 304.34529805\n",
      "Validation score: -5.966674\n",
      "Iteration 1534, loss = 303.61642890\n",
      "Validation score: -5.950788\n",
      "Iteration 1535, loss = 302.89851167\n",
      "Validation score: -5.935036\n",
      "Iteration 1536, loss = 302.18405323\n",
      "Validation score: -5.919440\n",
      "Iteration 1537, loss = 301.48143010\n",
      "Validation score: -5.904008\n",
      "Iteration 1538, loss = 300.78363302\n",
      "Validation score: -5.888732\n",
      "Iteration 1539, loss = 300.09069220\n",
      "Validation score: -5.873552\n",
      "Iteration 1540, loss = 299.39879107\n",
      "Validation score: -5.858539\n",
      "Iteration 1541, loss = 298.72269490\n",
      "Validation score: -5.843558\n",
      "Iteration 1542, loss = 298.04606887\n",
      "Validation score: -5.828665\n",
      "Iteration 1543, loss = 297.37255121\n",
      "Validation score: -5.813890\n",
      "Iteration 1544, loss = 296.70703412\n",
      "Validation score: -5.799156\n",
      "Iteration 1545, loss = 296.03765911\n",
      "Validation score: -5.784584\n",
      "Iteration 1546, loss = 295.37339777\n",
      "Validation score: -5.770142\n",
      "Iteration 1547, loss = 294.72337317\n",
      "Validation score: -5.755679\n",
      "Iteration 1548, loss = 294.06830735\n",
      "Validation score: -5.741340\n",
      "Iteration 1549, loss = 293.42237983\n",
      "Validation score: -5.727027\n",
      "Iteration 1550, loss = 292.76947954\n",
      "Validation score: -5.712834\n",
      "Iteration 1551, loss = 292.12856786\n",
      "Validation score: -5.698651\n",
      "Iteration 1552, loss = 291.49222947\n",
      "Validation score: -5.684472\n",
      "Iteration 1553, loss = 290.85258626\n",
      "Validation score: -5.670388\n",
      "Iteration 1554, loss = 290.21240817\n",
      "Validation score: -5.656415\n",
      "Iteration 1555, loss = 289.58033576\n",
      "Validation score: -5.642468\n",
      "Iteration 1556, loss = 288.94633586\n",
      "Validation score: -5.628547\n",
      "Iteration 1557, loss = 288.31514755\n",
      "Validation score: -5.614647\n",
      "Iteration 1558, loss = 287.68481133\n",
      "Validation score: -5.600761\n",
      "Iteration 1559, loss = 287.05998658\n",
      "Validation score: -5.586854\n",
      "Iteration 1560, loss = 286.43199448\n",
      "Validation score: -5.573033\n",
      "Iteration 1561, loss = 285.80626005\n",
      "Validation score: -5.559246\n",
      "Iteration 1562, loss = 285.18024061\n",
      "Validation score: -5.545450\n",
      "Iteration 1563, loss = 284.55906048\n",
      "Validation score: -5.531602\n",
      "Iteration 1564, loss = 283.92992913\n",
      "Validation score: -5.517806\n",
      "Iteration 1565, loss = 283.30744535\n",
      "Validation score: -5.503985\n",
      "Iteration 1566, loss = 282.68026474\n",
      "Validation score: -5.490138\n",
      "Iteration 1567, loss = 282.05343684\n",
      "Validation score: -5.476233\n",
      "Iteration 1568, loss = 281.42204028\n",
      "Validation score: -5.462249\n",
      "Iteration 1569, loss = 280.79058372\n",
      "Validation score: -5.448136\n",
      "Iteration 1570, loss = 280.14863592\n",
      "Validation score: -5.433942\n",
      "Iteration 1571, loss = 279.50514231\n",
      "Validation score: -5.419637\n",
      "Iteration 1572, loss = 278.85989279\n",
      "Validation score: -5.405158\n",
      "Iteration 1573, loss = 278.20230145\n",
      "Validation score: -5.390532\n",
      "Iteration 1574, loss = 277.53658299\n",
      "Validation score: -5.375744\n",
      "Iteration 1575, loss = 276.86526787\n",
      "Validation score: -5.360671\n",
      "Iteration 1576, loss = 276.18084762\n",
      "Validation score: -5.345342\n",
      "Iteration 1577, loss = 275.48253751\n",
      "Validation score: -5.329835\n",
      "Iteration 1578, loss = 274.78093346\n",
      "Validation score: -5.314128\n",
      "Iteration 1579, loss = 274.07030805\n",
      "Validation score: -5.298270\n",
      "Iteration 1580, loss = 273.35022065\n",
      "Validation score: -5.282297\n",
      "Iteration 1581, loss = 272.62484423\n",
      "Validation score: -5.266285\n",
      "Iteration 1582, loss = 271.90511438\n",
      "Validation score: -5.250203\n",
      "Iteration 1583, loss = 271.18153655\n",
      "Validation score: -5.234146\n",
      "Iteration 1584, loss = 270.45268878\n",
      "Validation score: -5.218230\n",
      "Iteration 1585, loss = 269.73634839\n",
      "Validation score: -5.202406\n",
      "Iteration 1586, loss = 269.02264381\n",
      "Validation score: -5.186741\n",
      "Iteration 1587, loss = 268.32103025\n",
      "Validation score: -5.171107\n",
      "Iteration 1588, loss = 267.61268739\n",
      "Validation score: -5.155748\n",
      "Iteration 1589, loss = 266.92283039\n",
      "Validation score: -5.140512\n",
      "Iteration 1590, loss = 266.23784235\n",
      "Validation score: -5.125380\n",
      "Iteration 1591, loss = 265.55270879\n",
      "Validation score: -5.110490\n",
      "Iteration 1592, loss = 264.88366406\n",
      "Validation score: -5.095695\n",
      "Iteration 1593, loss = 264.22079369\n",
      "Validation score: -5.081042\n",
      "Iteration 1594, loss = 263.55893127\n",
      "Validation score: -5.066529\n",
      "Iteration 1595, loss = 262.90593795\n",
      "Validation score: -5.052140\n",
      "Iteration 1596, loss = 262.25906447\n",
      "Validation score: -5.037894\n",
      "Iteration 1597, loss = 261.61893046\n",
      "Validation score: -5.023815\n",
      "Iteration 1598, loss = 260.98197647\n",
      "Validation score: -5.009877\n",
      "Iteration 1599, loss = 260.35288257\n",
      "Validation score: -4.995977\n",
      "Iteration 1600, loss = 259.72550550\n",
      "Validation score: -4.982188\n",
      "Iteration 1601, loss = 259.10587913\n",
      "Validation score: -4.968427\n",
      "Iteration 1602, loss = 258.48452507\n",
      "Validation score: -4.954754\n",
      "Iteration 1603, loss = 257.86827259\n",
      "Validation score: -4.941145\n",
      "Iteration 1604, loss = 257.25603408\n",
      "Validation score: -4.927579\n",
      "Iteration 1605, loss = 256.64669621\n",
      "Validation score: -4.914089\n",
      "Iteration 1606, loss = 256.04029958\n",
      "Validation score: -4.900717\n",
      "Iteration 1607, loss = 255.44202657\n",
      "Validation score: -4.887374\n",
      "Iteration 1608, loss = 254.83991836\n",
      "Validation score: -4.874155\n",
      "Iteration 1609, loss = 254.24274532\n",
      "Validation score: -4.861001\n",
      "Iteration 1610, loss = 253.65580718\n",
      "Validation score: -4.847840\n",
      "Iteration 1611, loss = 253.05894432\n",
      "Validation score: -4.834855\n",
      "Iteration 1612, loss = 252.47520793\n",
      "Validation score: -4.821884\n",
      "Iteration 1613, loss = 251.89241546\n",
      "Validation score: -4.808948\n",
      "Iteration 1614, loss = 251.31066775\n",
      "Validation score: -4.796038\n",
      "Iteration 1615, loss = 250.72837833\n",
      "Validation score: -4.783175\n",
      "Iteration 1616, loss = 250.15218687\n",
      "Validation score: -4.770331\n",
      "Iteration 1617, loss = 249.57569198\n",
      "Validation score: -4.757557\n",
      "Iteration 1618, loss = 249.00043782\n",
      "Validation score: -4.744875\n",
      "Iteration 1619, loss = 248.42978004\n",
      "Validation score: -4.732219\n",
      "Iteration 1620, loss = 247.86212947\n",
      "Validation score: -4.719608\n",
      "Iteration 1621, loss = 247.29498492\n",
      "Validation score: -4.707094\n",
      "Iteration 1622, loss = 246.73134500\n",
      "Validation score: -4.694612\n",
      "Iteration 1623, loss = 246.16714338\n",
      "Validation score: -4.682129\n",
      "Iteration 1624, loss = 245.60725585\n",
      "Validation score: -4.669612\n",
      "Iteration 1625, loss = 245.04478077\n",
      "Validation score: -4.657159\n",
      "Iteration 1626, loss = 244.48522002\n",
      "Validation score: -4.644700\n",
      "Iteration 1627, loss = 243.92354980\n",
      "Validation score: -4.632301\n",
      "Iteration 1628, loss = 243.36616700\n",
      "Validation score: -4.619916\n",
      "Iteration 1629, loss = 242.81204232\n",
      "Validation score: -4.607515\n",
      "Iteration 1630, loss = 242.25352022\n",
      "Validation score: -4.595172\n",
      "Iteration 1631, loss = 241.70207522\n",
      "Validation score: -4.582841\n",
      "Iteration 1632, loss = 241.14569264\n",
      "Validation score: -4.570566\n",
      "Iteration 1633, loss = 240.59242155\n",
      "Validation score: -4.558342\n",
      "Iteration 1634, loss = 240.04601534\n",
      "Validation score: -4.546092\n",
      "Iteration 1635, loss = 239.49374507\n",
      "Validation score: -4.533947\n",
      "Iteration 1636, loss = 238.94832144\n",
      "Validation score: -4.521781\n",
      "Iteration 1637, loss = 238.40447163\n",
      "Validation score: -4.509598\n",
      "Iteration 1638, loss = 237.85655799\n",
      "Validation score: -4.497527\n",
      "Iteration 1639, loss = 237.31503382\n",
      "Validation score: -4.485483\n",
      "Iteration 1640, loss = 236.77600267\n",
      "Validation score: -4.473454\n",
      "Iteration 1641, loss = 236.23314983\n",
      "Validation score: -4.461514\n",
      "Iteration 1642, loss = 235.69510034\n",
      "Validation score: -4.449606\n",
      "Iteration 1643, loss = 235.15814029\n",
      "Validation score: -4.437698\n",
      "Iteration 1644, loss = 234.62967022\n",
      "Validation score: -4.425703\n",
      "Iteration 1645, loss = 234.09269046\n",
      "Validation score: -4.413794\n",
      "Iteration 1646, loss = 233.55760701\n",
      "Validation score: -4.401943\n",
      "Iteration 1647, loss = 233.02528365\n",
      "Validation score: -4.390173\n",
      "Iteration 1648, loss = 232.50122679\n",
      "Validation score: -4.378406\n",
      "Iteration 1649, loss = 231.96975444\n",
      "Validation score: -4.366762\n",
      "Iteration 1650, loss = 231.44785650\n",
      "Validation score: -4.355033\n",
      "Iteration 1651, loss = 230.91985491\n",
      "Validation score: -4.343345\n",
      "Iteration 1652, loss = 230.39709401\n",
      "Validation score: -4.331649\n",
      "Iteration 1653, loss = 229.87151823\n",
      "Validation score: -4.320011\n",
      "Iteration 1654, loss = 229.35132163\n",
      "Validation score: -4.308320\n",
      "Iteration 1655, loss = 228.82652061\n",
      "Validation score: -4.296700\n",
      "Iteration 1656, loss = 228.30396737\n",
      "Validation score: -4.285103\n",
      "Iteration 1657, loss = 227.78722320\n",
      "Validation score: -4.273468\n",
      "Iteration 1658, loss = 227.26607002\n",
      "Validation score: -4.261850\n",
      "Iteration 1659, loss = 226.74456008\n",
      "Validation score: -4.250316\n",
      "Iteration 1660, loss = 226.22893102\n",
      "Validation score: -4.238824\n",
      "Iteration 1661, loss = 225.71338362\n",
      "Validation score: -4.227351\n",
      "Iteration 1662, loss = 225.19604951\n",
      "Validation score: -4.215940\n",
      "Iteration 1663, loss = 224.68818735\n",
      "Validation score: -4.204448\n",
      "Iteration 1664, loss = 224.17331337\n",
      "Validation score: -4.192994\n",
      "Iteration 1665, loss = 223.65877239\n",
      "Validation score: -4.181601\n",
      "Iteration 1666, loss = 223.15002336\n",
      "Validation score: -4.170236\n",
      "Iteration 1667, loss = 222.64216152\n",
      "Validation score: -4.158863\n",
      "Iteration 1668, loss = 222.13254092\n",
      "Validation score: -4.147558\n",
      "Iteration 1669, loss = 221.62914232\n",
      "Validation score: -4.136252\n",
      "Iteration 1670, loss = 221.12061342\n",
      "Validation score: -4.125018\n",
      "Iteration 1671, loss = 220.61714823\n",
      "Validation score: -4.113787\n",
      "Iteration 1672, loss = 220.11632142\n",
      "Validation score: -4.102542\n",
      "Iteration 1673, loss = 219.61361333\n",
      "Validation score: -4.091307\n",
      "Iteration 1674, loss = 219.10996261\n",
      "Validation score: -4.080126\n",
      "Iteration 1675, loss = 218.60824148\n",
      "Validation score: -4.068948\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1676, loss = 218.11113783\n",
      "Validation score: -4.057776\n",
      "Iteration 1677, loss = 217.61394992\n",
      "Validation score: -4.046648\n",
      "Iteration 1678, loss = 217.11412687\n",
      "Validation score: -4.035579\n",
      "Iteration 1679, loss = 216.61713142\n",
      "Validation score: -4.024528\n",
      "Iteration 1680, loss = 216.12601356\n",
      "Validation score: -4.013433\n",
      "Iteration 1681, loss = 215.62991361\n",
      "Validation score: -4.002424\n",
      "Iteration 1682, loss = 215.13435498\n",
      "Validation score: -3.991469\n",
      "Iteration 1683, loss = 214.64563897\n",
      "Validation score: -3.980470\n",
      "Iteration 1684, loss = 214.15547376\n",
      "Validation score: -3.969487\n",
      "Iteration 1685, loss = 213.66341757\n",
      "Validation score: -3.958550\n",
      "Iteration 1686, loss = 213.17163061\n",
      "Validation score: -3.947692\n",
      "Iteration 1687, loss = 212.68993445\n",
      "Validation score: -3.936768\n",
      "Iteration 1688, loss = 212.20155764\n",
      "Validation score: -3.925909\n",
      "Iteration 1689, loss = 211.71697408\n",
      "Validation score: -3.915042\n",
      "Iteration 1690, loss = 211.23038127\n",
      "Validation score: -3.904202\n",
      "Iteration 1691, loss = 210.74415320\n",
      "Validation score: -3.893426\n",
      "Iteration 1692, loss = 210.26763977\n",
      "Validation score: -3.882584\n",
      "Iteration 1693, loss = 209.78377710\n",
      "Validation score: -3.871824\n",
      "Iteration 1694, loss = 209.30171714\n",
      "Validation score: -3.861110\n",
      "Iteration 1695, loss = 208.82528026\n",
      "Validation score: -3.850373\n",
      "Iteration 1696, loss = 208.34537854\n",
      "Validation score: -3.839666\n",
      "Iteration 1697, loss = 207.86813795\n",
      "Validation score: -3.828949\n",
      "Iteration 1698, loss = 207.39012062\n",
      "Validation score: -3.818279\n",
      "Iteration 1699, loss = 206.91275436\n",
      "Validation score: -3.807631\n",
      "Iteration 1700, loss = 206.43943591\n",
      "Validation score: -3.796979\n",
      "Iteration 1701, loss = 205.96214276\n",
      "Validation score: -3.786384\n",
      "Iteration 1702, loss = 205.49189749\n",
      "Validation score: -3.775790\n",
      "Iteration 1703, loss = 205.01843562\n",
      "Validation score: -3.765247\n",
      "Iteration 1704, loss = 204.54929766\n",
      "Validation score: -3.754727\n",
      "Iteration 1705, loss = 204.07736658\n",
      "Validation score: -3.744279\n",
      "Iteration 1706, loss = 203.61390209\n",
      "Validation score: -3.733776\n",
      "Iteration 1707, loss = 203.14422169\n",
      "Validation score: -3.723348\n",
      "Iteration 1708, loss = 202.68058787\n",
      "Validation score: -3.712889\n",
      "Iteration 1709, loss = 202.21114953\n",
      "Validation score: -3.702499\n",
      "Iteration 1710, loss = 201.75133017\n",
      "Validation score: -3.692044\n",
      "Iteration 1711, loss = 201.28501347\n",
      "Validation score: -3.681668\n",
      "Iteration 1712, loss = 200.82395139\n",
      "Validation score: -3.671265\n",
      "Iteration 1713, loss = 200.35906562\n",
      "Validation score: -3.660925\n",
      "Iteration 1714, loss = 199.89729974\n",
      "Validation score: -3.650574\n",
      "Iteration 1715, loss = 199.43907344\n",
      "Validation score: -3.640199\n",
      "Iteration 1716, loss = 198.97402714\n",
      "Validation score: -3.629889\n",
      "Iteration 1717, loss = 198.51542849\n",
      "Validation score: -3.619571\n",
      "Iteration 1718, loss = 198.05496794\n",
      "Validation score: -3.609315\n",
      "Iteration 1719, loss = 197.60292817\n",
      "Validation score: -3.599025\n",
      "Iteration 1720, loss = 197.14398060\n",
      "Validation score: -3.588832\n",
      "Iteration 1721, loss = 196.68970750\n",
      "Validation score: -3.578653\n",
      "Iteration 1722, loss = 196.23986898\n",
      "Validation score: -3.568435\n",
      "Iteration 1723, loss = 195.78400791\n",
      "Validation score: -3.558312\n",
      "Iteration 1724, loss = 195.33119996\n",
      "Validation score: -3.548247\n",
      "Iteration 1725, loss = 194.88422630\n",
      "Validation score: -3.538148\n",
      "Iteration 1726, loss = 194.43637013\n",
      "Validation score: -3.528056\n",
      "Iteration 1727, loss = 193.99132018\n",
      "Validation score: -3.517990\n",
      "Iteration 1728, loss = 193.54072827\n",
      "Validation score: -3.508014\n",
      "Iteration 1729, loss = 193.09601003\n",
      "Validation score: -3.498036\n",
      "Iteration 1730, loss = 192.65065027\n",
      "Validation score: -3.488078\n",
      "Iteration 1731, loss = 192.21032241\n",
      "Validation score: -3.478065\n",
      "Iteration 1732, loss = 191.76415449\n",
      "Validation score: -3.468087\n",
      "Iteration 1733, loss = 191.32353496\n",
      "Validation score: -3.458109\n",
      "Iteration 1734, loss = 190.88352851\n",
      "Validation score: -3.448185\n",
      "Iteration 1735, loss = 190.44051827\n",
      "Validation score: -3.438329\n",
      "Iteration 1736, loss = 190.00040693\n",
      "Validation score: -3.428491\n",
      "Iteration 1737, loss = 189.56396484\n",
      "Validation score: -3.418624\n",
      "Iteration 1738, loss = 189.12285664\n",
      "Validation score: -3.408822\n",
      "Iteration 1739, loss = 188.69052330\n",
      "Validation score: -3.398935\n",
      "Iteration 1740, loss = 188.24811343\n",
      "Validation score: -3.389128\n",
      "Iteration 1741, loss = 187.81596369\n",
      "Validation score: -3.379310\n",
      "Iteration 1742, loss = 187.38083996\n",
      "Validation score: -3.369505\n",
      "Iteration 1743, loss = 186.94504718\n",
      "Validation score: -3.359748\n",
      "Iteration 1744, loss = 186.51004378\n",
      "Validation score: -3.350045\n",
      "Iteration 1745, loss = 186.07724266\n",
      "Validation score: -3.340317\n",
      "Iteration 1746, loss = 185.64447263\n",
      "Validation score: -3.330522\n",
      "Iteration 1747, loss = 185.21204881\n",
      "Validation score: -3.320727\n",
      "Iteration 1748, loss = 184.77863438\n",
      "Validation score: -3.311004\n",
      "Iteration 1749, loss = 184.34462697\n",
      "Validation score: -3.301352\n",
      "Iteration 1750, loss = 183.91739477\n",
      "Validation score: -3.291662\n",
      "Iteration 1751, loss = 183.49095601\n",
      "Validation score: -3.281986\n",
      "Iteration 1752, loss = 183.06128253\n",
      "Validation score: -3.272391\n",
      "Iteration 1753, loss = 182.63652443\n",
      "Validation score: -3.262799\n",
      "Iteration 1754, loss = 182.20899741\n",
      "Validation score: -3.253235\n",
      "Iteration 1755, loss = 181.78622690\n",
      "Validation score: -3.243617\n",
      "Iteration 1756, loss = 181.35942938\n",
      "Validation score: -3.234059\n",
      "Iteration 1757, loss = 180.93810208\n",
      "Validation score: -3.224542\n",
      "Iteration 1758, loss = 180.51822679\n",
      "Validation score: -3.215061\n",
      "Iteration 1759, loss = 180.09736063\n",
      "Validation score: -3.205637\n",
      "Iteration 1760, loss = 179.67998068\n",
      "Validation score: -3.196211\n",
      "Iteration 1761, loss = 179.26065199\n",
      "Validation score: -3.186840\n",
      "Iteration 1762, loss = 178.84606432\n",
      "Validation score: -3.177397\n",
      "Iteration 1763, loss = 178.42750410\n",
      "Validation score: -3.167974\n",
      "Iteration 1764, loss = 178.01320334\n",
      "Validation score: -3.158568\n",
      "Iteration 1765, loss = 177.59354421\n",
      "Validation score: -3.149261\n",
      "Iteration 1766, loss = 177.18513361\n",
      "Validation score: -3.139879\n",
      "Iteration 1767, loss = 176.77169872\n",
      "Validation score: -3.130574\n",
      "Iteration 1768, loss = 176.35957916\n",
      "Validation score: -3.121312\n",
      "Iteration 1769, loss = 175.94632565\n",
      "Validation score: -3.112070\n",
      "Iteration 1770, loss = 175.54013126\n",
      "Validation score: -3.102797\n",
      "Iteration 1771, loss = 175.12892839\n",
      "Validation score: -3.093546\n",
      "Iteration 1772, loss = 174.71950604\n",
      "Validation score: -3.084282\n",
      "Iteration 1773, loss = 174.30658247\n",
      "Validation score: -3.075072\n",
      "Iteration 1774, loss = 173.90066413\n",
      "Validation score: -3.065841\n",
      "Iteration 1775, loss = 173.49659650\n",
      "Validation score: -3.056573\n",
      "Iteration 1776, loss = 173.08431651\n",
      "Validation score: -3.047417\n",
      "Iteration 1777, loss = 172.67992275\n",
      "Validation score: -3.038254\n",
      "Iteration 1778, loss = 172.27537952\n",
      "Validation score: -3.029083\n",
      "Iteration 1779, loss = 171.87163693\n",
      "Validation score: -3.019928\n",
      "Iteration 1780, loss = 171.47127981\n",
      "Validation score: -3.010815\n",
      "Iteration 1781, loss = 171.06481777\n",
      "Validation score: -3.001828\n",
      "Iteration 1782, loss = 170.66841765\n",
      "Validation score: -2.992770\n",
      "Iteration 1783, loss = 170.26593073\n",
      "Validation score: -2.983721\n",
      "Iteration 1784, loss = 169.86676001\n",
      "Validation score: -2.974667\n",
      "Iteration 1785, loss = 169.46561214\n",
      "Validation score: -2.965627\n",
      "Iteration 1786, loss = 169.06778876\n",
      "Validation score: -2.956588\n",
      "Iteration 1787, loss = 168.66747783\n",
      "Validation score: -2.947598\n",
      "Iteration 1788, loss = 168.27303666\n",
      "Validation score: -2.938539\n",
      "Iteration 1789, loss = 167.87283867\n",
      "Validation score: -2.929539\n",
      "Iteration 1790, loss = 167.47840237\n",
      "Validation score: -2.920545\n",
      "Iteration 1791, loss = 167.08091256\n",
      "Validation score: -2.911628\n",
      "Iteration 1792, loss = 166.68969932\n",
      "Validation score: -2.902698\n",
      "Iteration 1793, loss = 166.29319410\n",
      "Validation score: -2.893818\n",
      "Iteration 1794, loss = 165.90459824\n",
      "Validation score: -2.884906\n",
      "Iteration 1795, loss = 165.50899785\n",
      "Validation score: -2.876082\n",
      "Iteration 1796, loss = 165.12015105\n",
      "Validation score: -2.867227\n",
      "Iteration 1797, loss = 164.73308528\n",
      "Validation score: -2.858286\n",
      "Iteration 1798, loss = 164.33496619\n",
      "Validation score: -2.849464\n",
      "Iteration 1799, loss = 163.94905525\n",
      "Validation score: -2.840612\n",
      "Iteration 1800, loss = 163.55732688\n",
      "Validation score: -2.831823\n",
      "Iteration 1801, loss = 163.17084030\n",
      "Validation score: -2.823013\n",
      "Iteration 1802, loss = 162.78286904\n",
      "Validation score: -2.814211\n",
      "Iteration 1803, loss = 162.39688828\n",
      "Validation score: -2.805396\n",
      "Iteration 1804, loss = 162.00889719\n",
      "Validation score: -2.796619\n",
      "Iteration 1805, loss = 161.62162057\n",
      "Validation score: -2.787887\n",
      "Iteration 1806, loss = 161.23996296\n",
      "Validation score: -2.779076\n",
      "Iteration 1807, loss = 160.84754060\n",
      "Validation score: -2.770316\n",
      "Iteration 1808, loss = 160.46301520\n",
      "Validation score: -2.761462\n",
      "Iteration 1809, loss = 160.06959913\n",
      "Validation score: -2.752591\n",
      "Iteration 1810, loss = 159.68208449\n",
      "Validation score: -2.743584\n",
      "Iteration 1811, loss = 159.28474958\n",
      "Validation score: -2.734547\n",
      "Iteration 1812, loss = 158.88510060\n",
      "Validation score: -2.725425\n",
      "Iteration 1813, loss = 158.48145617\n",
      "Validation score: -2.716231\n",
      "Iteration 1814, loss = 158.07737155\n",
      "Validation score: -2.706829\n",
      "Iteration 1815, loss = 157.65859114\n",
      "Validation score: -2.697309\n",
      "Iteration 1816, loss = 157.24088176\n",
      "Validation score: -2.687542\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1817, loss = 156.80651908\n",
      "Validation score: -2.677598\n",
      "Iteration 1818, loss = 156.36825153\n",
      "Validation score: -2.667416\n",
      "Iteration 1819, loss = 155.92137631\n",
      "Validation score: -2.657017\n",
      "Iteration 1820, loss = 155.45747018\n",
      "Validation score: -2.646498\n",
      "Iteration 1821, loss = 155.00167443\n",
      "Validation score: -2.635672\n",
      "Iteration 1822, loss = 154.52211545\n",
      "Validation score: -2.624877\n",
      "Iteration 1823, loss = 154.04620244\n",
      "Validation score: -2.614051\n",
      "Iteration 1824, loss = 153.57237322\n",
      "Validation score: -2.603188\n",
      "Iteration 1825, loss = 153.09514974\n",
      "Validation score: -2.592392\n",
      "Iteration 1826, loss = 152.62284116\n",
      "Validation score: -2.581669\n",
      "Iteration 1827, loss = 152.15468358\n",
      "Validation score: -2.571059\n",
      "Iteration 1828, loss = 151.68845095\n",
      "Validation score: -2.560593\n",
      "Iteration 1829, loss = 151.23110887\n",
      "Validation score: -2.550236\n",
      "Iteration 1830, loss = 150.78170374\n",
      "Validation score: -2.539990\n",
      "Iteration 1831, loss = 150.33385742\n",
      "Validation score: -2.529999\n",
      "Iteration 1832, loss = 149.89701303\n",
      "Validation score: -2.520156\n",
      "Iteration 1833, loss = 149.46551993\n",
      "Validation score: -2.510453\n",
      "Iteration 1834, loss = 149.04286224\n",
      "Validation score: -2.500856\n",
      "Iteration 1835, loss = 148.62366980\n",
      "Validation score: -2.491384\n",
      "Iteration 1836, loss = 148.20747631\n",
      "Validation score: -2.482010\n",
      "Iteration 1837, loss = 147.79684354\n",
      "Validation score: -2.472704\n",
      "Iteration 1838, loss = 147.39034278\n",
      "Validation score: -2.463446\n",
      "Iteration 1839, loss = 146.98479728\n",
      "Validation score: -2.454311\n",
      "Iteration 1840, loss = 146.58476088\n",
      "Validation score: -2.445244\n",
      "Iteration 1841, loss = 146.19382378\n",
      "Validation score: -2.436189\n",
      "Iteration 1842, loss = 145.79920791\n",
      "Validation score: -2.427254\n",
      "Iteration 1843, loss = 145.40557635\n",
      "Validation score: -2.418470\n",
      "Iteration 1844, loss = 145.02402475\n",
      "Validation score: -2.409644\n",
      "Iteration 1845, loss = 144.63702122\n",
      "Validation score: -2.400891\n",
      "Iteration 1846, loss = 144.25589956\n",
      "Validation score: -2.392177\n",
      "Iteration 1847, loss = 143.87835888\n",
      "Validation score: -2.383528\n",
      "Iteration 1848, loss = 143.49945456\n",
      "Validation score: -2.374992\n",
      "Iteration 1849, loss = 143.12731710\n",
      "Validation score: -2.366477\n",
      "Iteration 1850, loss = 142.75477483\n",
      "Validation score: -2.358039\n",
      "Iteration 1851, loss = 142.38624916\n",
      "Validation score: -2.349623\n",
      "Iteration 1852, loss = 142.01731056\n",
      "Validation score: -2.341258\n",
      "Iteration 1853, loss = 141.65569292\n",
      "Validation score: -2.332859\n",
      "Iteration 1854, loss = 141.29234249\n",
      "Validation score: -2.324537\n",
      "Iteration 1855, loss = 140.92764884\n",
      "Validation score: -2.316272\n",
      "Iteration 1856, loss = 140.57047257\n",
      "Validation score: -2.308014\n",
      "Iteration 1857, loss = 140.20960170\n",
      "Validation score: -2.299836\n",
      "Iteration 1858, loss = 139.85101139\n",
      "Validation score: -2.291681\n",
      "Iteration 1859, loss = 139.49617861\n",
      "Validation score: -2.283514\n",
      "Iteration 1860, loss = 139.14065583\n",
      "Validation score: -2.275355\n",
      "Iteration 1861, loss = 138.78420902\n",
      "Validation score: -2.267255\n",
      "Iteration 1862, loss = 138.43351383\n",
      "Validation score: -2.259173\n",
      "Iteration 1863, loss = 138.08267511\n",
      "Validation score: -2.251137\n",
      "Iteration 1864, loss = 137.73143996\n",
      "Validation score: -2.243157\n",
      "Iteration 1865, loss = 137.38557720\n",
      "Validation score: -2.235167\n",
      "Iteration 1866, loss = 137.03717210\n",
      "Validation score: -2.227222\n",
      "Iteration 1867, loss = 136.69392188\n",
      "Validation score: -2.219258\n",
      "Iteration 1868, loss = 136.34490137\n",
      "Validation score: -2.211395\n",
      "Iteration 1869, loss = 136.00593186\n",
      "Validation score: -2.203498\n",
      "Iteration 1870, loss = 135.65967667\n",
      "Validation score: -2.195678\n",
      "Iteration 1871, loss = 135.32330983\n",
      "Validation score: -2.187840\n",
      "Iteration 1872, loss = 134.98228578\n",
      "Validation score: -2.180041\n",
      "Iteration 1873, loss = 134.64226557\n",
      "Validation score: -2.172291\n",
      "Iteration 1874, loss = 134.30567300\n",
      "Validation score: -2.164564\n",
      "Iteration 1875, loss = 133.97069993\n",
      "Validation score: -2.156801\n",
      "Iteration 1876, loss = 133.63579849\n",
      "Validation score: -2.149037\n",
      "Iteration 1877, loss = 133.29961774\n",
      "Validation score: -2.141343\n",
      "Iteration 1878, loss = 132.96464906\n",
      "Validation score: -2.133734\n",
      "Iteration 1879, loss = 132.63558631\n",
      "Validation score: -2.126094\n",
      "Iteration 1880, loss = 132.30223650\n",
      "Validation score: -2.118513\n",
      "Iteration 1881, loss = 131.97192501\n",
      "Validation score: -2.110943\n",
      "Iteration 1882, loss = 131.64629988\n",
      "Validation score: -2.103335\n",
      "Iteration 1883, loss = 131.31874782\n",
      "Validation score: -2.095757\n",
      "Iteration 1884, loss = 130.99007728\n",
      "Validation score: -2.088234\n",
      "Iteration 1885, loss = 130.66268286\n",
      "Validation score: -2.080769\n",
      "Iteration 1886, loss = 130.34243555\n",
      "Validation score: -2.073264\n",
      "Iteration 1887, loss = 130.01387113\n",
      "Validation score: -2.065856\n",
      "Iteration 1888, loss = 129.69427151\n",
      "Validation score: -2.058400\n",
      "Iteration 1889, loss = 129.37226175\n",
      "Validation score: -2.050980\n",
      "Iteration 1890, loss = 129.05479202\n",
      "Validation score: -2.043599\n",
      "Iteration 1891, loss = 128.73405178\n",
      "Validation score: -2.036285\n",
      "Iteration 1892, loss = 128.41622321\n",
      "Validation score: -2.028965\n",
      "Iteration 1893, loss = 128.10058509\n",
      "Validation score: -2.021632\n",
      "Iteration 1894, loss = 127.78210432\n",
      "Validation score: -2.014332\n",
      "Iteration 1895, loss = 127.46649632\n",
      "Validation score: -2.007050\n",
      "Iteration 1896, loss = 127.15005226\n",
      "Validation score: -1.999860\n",
      "Iteration 1897, loss = 126.83862418\n",
      "Validation score: -1.992611\n",
      "Iteration 1898, loss = 126.52555138\n",
      "Validation score: -1.985347\n",
      "Iteration 1899, loss = 126.21381673\n",
      "Validation score: -1.978111\n",
      "Iteration 1900, loss = 125.90426016\n",
      "Validation score: -1.970926\n",
      "Iteration 1901, loss = 125.59120086\n",
      "Validation score: -1.963821\n",
      "Iteration 1902, loss = 125.28812936\n",
      "Validation score: -1.956695\n",
      "Iteration 1903, loss = 124.97706821\n",
      "Validation score: -1.949664\n",
      "Iteration 1904, loss = 124.67190861\n",
      "Validation score: -1.942620\n",
      "Iteration 1905, loss = 124.37126212\n",
      "Validation score: -1.935501\n",
      "Iteration 1906, loss = 124.06409491\n",
      "Validation score: -1.928461\n",
      "Iteration 1907, loss = 123.76143506\n",
      "Validation score: -1.921420\n",
      "Iteration 1908, loss = 123.45292471\n",
      "Validation score: -1.914437\n",
      "Iteration 1909, loss = 123.15128304\n",
      "Validation score: -1.907394\n",
      "Iteration 1910, loss = 122.84911579\n",
      "Validation score: -1.900333\n",
      "Iteration 1911, loss = 122.54808315\n",
      "Validation score: -1.893316\n",
      "Iteration 1912, loss = 122.24277103\n",
      "Validation score: -1.886369\n",
      "Iteration 1913, loss = 121.94575787\n",
      "Validation score: -1.879399\n",
      "Iteration 1914, loss = 121.64377631\n",
      "Validation score: -1.872486\n",
      "Iteration 1915, loss = 121.34573769\n",
      "Validation score: -1.865527\n",
      "Iteration 1916, loss = 121.04802990\n",
      "Validation score: -1.858605\n",
      "Iteration 1917, loss = 120.75093203\n",
      "Validation score: -1.851736\n",
      "Iteration 1918, loss = 120.45598223\n",
      "Validation score: -1.844898\n",
      "Iteration 1919, loss = 120.16022322\n",
      "Validation score: -1.838124\n",
      "Iteration 1920, loss = 119.86922230\n",
      "Validation score: -1.831332\n",
      "Iteration 1921, loss = 119.57624845\n",
      "Validation score: -1.824575\n",
      "Iteration 1922, loss = 119.28583680\n",
      "Validation score: -1.817831\n",
      "Iteration 1923, loss = 118.99474452\n",
      "Validation score: -1.811074\n",
      "Iteration 1924, loss = 118.70668211\n",
      "Validation score: -1.804304\n",
      "Iteration 1925, loss = 118.41663567\n",
      "Validation score: -1.797570\n",
      "Iteration 1926, loss = 118.12619453\n",
      "Validation score: -1.790882\n",
      "Iteration 1927, loss = 117.83889498\n",
      "Validation score: -1.784192\n",
      "Iteration 1928, loss = 117.55200936\n",
      "Validation score: -1.777505\n",
      "Iteration 1929, loss = 117.26455279\n",
      "Validation score: -1.770860\n",
      "Iteration 1930, loss = 116.97984924\n",
      "Validation score: -1.764228\n",
      "Iteration 1931, loss = 116.69346605\n",
      "Validation score: -1.757625\n",
      "Iteration 1932, loss = 116.41525345\n",
      "Validation score: -1.750997\n",
      "Iteration 1933, loss = 116.12981148\n",
      "Validation score: -1.744457\n",
      "Iteration 1934, loss = 115.85105130\n",
      "Validation score: -1.737899\n",
      "Iteration 1935, loss = 115.56671533\n",
      "Validation score: -1.731415\n",
      "Iteration 1936, loss = 115.28850240\n",
      "Validation score: -1.724930\n",
      "Iteration 1937, loss = 115.01218530\n",
      "Validation score: -1.718400\n",
      "Iteration 1938, loss = 114.73270066\n",
      "Validation score: -1.711913\n",
      "Iteration 1939, loss = 114.45385638\n",
      "Validation score: -1.705435\n",
      "Iteration 1940, loss = 114.17749502\n",
      "Validation score: -1.698951\n",
      "Iteration 1941, loss = 113.89865546\n",
      "Validation score: -1.692491\n",
      "Iteration 1942, loss = 113.62279937\n",
      "Validation score: -1.686025\n",
      "Iteration 1943, loss = 113.34891680\n",
      "Validation score: -1.679553\n",
      "Iteration 1944, loss = 113.07168727\n",
      "Validation score: -1.673191\n",
      "Iteration 1945, loss = 112.79789343\n",
      "Validation score: -1.666848\n",
      "Iteration 1946, loss = 112.52910257\n",
      "Validation score: -1.660475\n",
      "Iteration 1947, loss = 112.25417391\n",
      "Validation score: -1.654152\n",
      "Iteration 1948, loss = 111.98626473\n",
      "Validation score: -1.647813\n",
      "Iteration 1949, loss = 111.71415038\n",
      "Validation score: -1.641517\n",
      "Iteration 1950, loss = 111.44518094\n",
      "Validation score: -1.635231\n",
      "Iteration 1951, loss = 111.17725079\n",
      "Validation score: -1.628932\n",
      "Iteration 1952, loss = 110.90887263\n",
      "Validation score: -1.622625\n",
      "Iteration 1953, loss = 110.64212578\n",
      "Validation score: -1.616362\n",
      "Iteration 1954, loss = 110.37174386\n",
      "Validation score: -1.610193\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1955, loss = 110.10982437\n",
      "Validation score: -1.604017\n",
      "Iteration 1956, loss = 109.84632155\n",
      "Validation score: -1.597840\n",
      "Iteration 1957, loss = 109.58223846\n",
      "Validation score: -1.591710\n",
      "Iteration 1958, loss = 109.32159626\n",
      "Validation score: -1.585576\n",
      "Iteration 1959, loss = 109.05950527\n",
      "Validation score: -1.579473\n",
      "Iteration 1960, loss = 108.80137251\n",
      "Validation score: -1.573331\n",
      "Iteration 1961, loss = 108.53806936\n",
      "Validation score: -1.567245\n",
      "Iteration 1962, loss = 108.27780639\n",
      "Validation score: -1.561189\n",
      "Iteration 1963, loss = 108.02109177\n",
      "Validation score: -1.555074\n",
      "Iteration 1964, loss = 107.76299231\n",
      "Validation score: -1.549009\n",
      "Iteration 1965, loss = 107.50370475\n",
      "Validation score: -1.542973\n",
      "Iteration 1966, loss = 107.24615834\n",
      "Validation score: -1.536959\n",
      "Iteration 1967, loss = 106.99299996\n",
      "Validation score: -1.530961\n",
      "Iteration 1968, loss = 106.73543136\n",
      "Validation score: -1.525010\n",
      "Iteration 1969, loss = 106.48160405\n",
      "Validation score: -1.519051\n",
      "Iteration 1970, loss = 106.22942713\n",
      "Validation score: -1.513067\n",
      "Iteration 1971, loss = 105.97864357\n",
      "Validation score: -1.507077\n",
      "Iteration 1972, loss = 105.72065519\n",
      "Validation score: -1.501178\n",
      "Iteration 1973, loss = 105.47201619\n",
      "Validation score: -1.495215\n",
      "Iteration 1974, loss = 105.21659253\n",
      "Validation score: -1.489316\n",
      "Iteration 1975, loss = 104.96681047\n",
      "Validation score: -1.483388\n",
      "Iteration 1976, loss = 104.71739488\n",
      "Validation score: -1.477477\n",
      "Iteration 1977, loss = 104.46607777\n",
      "Validation score: -1.471585\n",
      "Iteration 1978, loss = 104.21672894\n",
      "Validation score: -1.465723\n",
      "Iteration 1979, loss = 103.96723049\n",
      "Validation score: -1.459900\n",
      "Iteration 1980, loss = 103.72147785\n",
      "Validation score: -1.454028\n",
      "Iteration 1981, loss = 103.47554896\n",
      "Validation score: -1.448207\n",
      "Iteration 1982, loss = 103.22799469\n",
      "Validation score: -1.442475\n",
      "Iteration 1983, loss = 102.98737606\n",
      "Validation score: -1.436713\n",
      "Iteration 1984, loss = 102.74088817\n",
      "Validation score: -1.431037\n",
      "Iteration 1985, loss = 102.50514439\n",
      "Validation score: -1.425300\n",
      "Iteration 1986, loss = 102.25865538\n",
      "Validation score: -1.419616\n",
      "Iteration 1987, loss = 102.01754182\n",
      "Validation score: -1.413896\n",
      "Iteration 1988, loss = 101.77473808\n",
      "Validation score: -1.408180\n",
      "Iteration 1989, loss = 101.53416893\n",
      "Validation score: -1.402385\n",
      "Iteration 1990, loss = 101.28909301\n",
      "Validation score: -1.396593\n",
      "Iteration 1991, loss = 101.04194699\n",
      "Validation score: -1.390845\n",
      "Iteration 1992, loss = 100.79894081\n",
      "Validation score: -1.385068\n",
      "Iteration 1993, loss = 100.55437398\n",
      "Validation score: -1.379270\n",
      "Iteration 1994, loss = 100.30686467\n",
      "Validation score: -1.373412\n",
      "Iteration 1995, loss = 100.05773978\n",
      "Validation score: -1.367430\n",
      "Iteration 1996, loss = 99.80851039\n",
      "Validation score: -1.361301\n",
      "Iteration 1997, loss = 99.54974341\n",
      "Validation score: -1.355138\n",
      "Iteration 1998, loss = 99.28496503\n",
      "Validation score: -1.348949\n",
      "Iteration 1999, loss = 99.02186729\n",
      "Validation score: -1.342553\n",
      "Iteration 2000, loss = 98.75138120\n",
      "Validation score: -1.335992\n",
      "Iteration 2001, loss = 98.47272807\n",
      "Validation score: -1.329266\n",
      "Iteration 2002, loss = 98.18855901\n",
      "Validation score: -1.322381\n",
      "Iteration 2003, loss = 97.89276019\n",
      "Validation score: -1.315350\n",
      "Iteration 2004, loss = 97.59680769\n",
      "Validation score: -1.308155\n",
      "Iteration 2005, loss = 97.29290177\n",
      "Validation score: -1.300832\n",
      "Iteration 2006, loss = 96.98096289\n",
      "Validation score: -1.293481\n",
      "Iteration 2007, loss = 96.67363934\n",
      "Validation score: -1.286077\n",
      "Iteration 2008, loss = 96.36319708\n",
      "Validation score: -1.278690\n",
      "Iteration 2009, loss = 96.05401335\n",
      "Validation score: -1.271384\n",
      "Iteration 2010, loss = 95.75072079\n",
      "Validation score: -1.264176\n",
      "Iteration 2011, loss = 95.45009504\n",
      "Validation score: -1.257129\n",
      "Iteration 2012, loss = 95.15311686\n",
      "Validation score: -1.250263\n",
      "Iteration 2013, loss = 94.86609094\n",
      "Validation score: -1.243509\n",
      "Iteration 2014, loss = 94.58552020\n",
      "Validation score: -1.236859\n",
      "Iteration 2015, loss = 94.30749790\n",
      "Validation score: -1.230354\n",
      "Iteration 2016, loss = 94.03558112\n",
      "Validation score: -1.223974\n",
      "Iteration 2017, loss = 93.76756478\n",
      "Validation score: -1.217662\n",
      "Iteration 2018, loss = 93.50596001\n",
      "Validation score: -1.211436\n",
      "Iteration 2019, loss = 93.24583911\n",
      "Validation score: -1.205322\n",
      "Iteration 2020, loss = 92.99086723\n",
      "Validation score: -1.199294\n",
      "Iteration 2021, loss = 92.73995636\n",
      "Validation score: -1.193349\n",
      "Iteration 2022, loss = 92.48996530\n",
      "Validation score: -1.187517\n",
      "Iteration 2023, loss = 92.24827576\n",
      "Validation score: -1.181718\n",
      "Iteration 2024, loss = 92.00816554\n",
      "Validation score: -1.175941\n",
      "Iteration 2025, loss = 91.76729403\n",
      "Validation score: -1.170244\n",
      "Iteration 2026, loss = 91.52890014\n",
      "Validation score: -1.164598\n",
      "Iteration 2027, loss = 91.29214316\n",
      "Validation score: -1.159039\n",
      "Iteration 2028, loss = 91.06322499\n",
      "Validation score: -1.153482\n",
      "Iteration 2029, loss = 90.83335808\n",
      "Validation score: -1.147967\n",
      "Iteration 2030, loss = 90.60293094\n",
      "Validation score: -1.142535\n",
      "Iteration 2031, loss = 90.37544953\n",
      "Validation score: -1.137137\n",
      "Iteration 2032, loss = 90.15257632\n",
      "Validation score: -1.131727\n",
      "Iteration 2033, loss = 89.93037833\n",
      "Validation score: -1.126370\n",
      "Iteration 2034, loss = 89.70706399\n",
      "Validation score: -1.121106\n",
      "Iteration 2035, loss = 89.48855191\n",
      "Validation score: -1.115848\n",
      "Iteration 2036, loss = 89.27169168\n",
      "Validation score: -1.110630\n",
      "Iteration 2037, loss = 89.05268425\n",
      "Validation score: -1.105453\n",
      "Iteration 2038, loss = 88.83697452\n",
      "Validation score: -1.100265\n",
      "Iteration 2039, loss = 88.62078379\n",
      "Validation score: -1.095094\n",
      "Iteration 2040, loss = 88.40521162\n",
      "Validation score: -1.089943\n",
      "Iteration 2041, loss = 88.19653909\n",
      "Validation score: -1.084775\n",
      "Iteration 2042, loss = 87.98090346\n",
      "Validation score: -1.079743\n",
      "Iteration 2043, loss = 87.77312974\n",
      "Validation score: -1.074682\n",
      "Iteration 2044, loss = 87.56110380\n",
      "Validation score: -1.069689\n",
      "Iteration 2045, loss = 87.35715976\n",
      "Validation score: -1.064622\n",
      "Iteration 2046, loss = 87.14780434\n",
      "Validation score: -1.059610\n",
      "Iteration 2047, loss = 86.94086774\n",
      "Validation score: -1.054682\n",
      "Iteration 2048, loss = 86.73587007\n",
      "Validation score: -1.049760\n",
      "Iteration 2049, loss = 86.53340844\n",
      "Validation score: -1.044798\n",
      "Iteration 2050, loss = 86.32598333\n",
      "Validation score: -1.039835\n",
      "Iteration 2051, loss = 86.12342087\n",
      "Validation score: -1.034815\n",
      "Iteration 2052, loss = 85.91696937\n",
      "Validation score: -1.029855\n",
      "Iteration 2053, loss = 85.70879093\n",
      "Validation score: -1.024939\n",
      "Iteration 2054, loss = 85.50621035\n",
      "Validation score: -1.019976\n",
      "Iteration 2055, loss = 85.30398131\n",
      "Validation score: -1.014945\n",
      "Iteration 2056, loss = 85.09744239\n",
      "Validation score: -1.009925\n",
      "Iteration 2057, loss = 84.88850333\n",
      "Validation score: -1.004880\n",
      "Iteration 2058, loss = 84.67807364\n",
      "Validation score: -0.999784\n",
      "Iteration 2059, loss = 84.46883171\n",
      "Validation score: -0.994599\n",
      "Iteration 2060, loss = 84.25416928\n",
      "Validation score: -0.989330\n",
      "Iteration 2061, loss = 84.03595219\n",
      "Validation score: -0.983952\n",
      "Iteration 2062, loss = 83.81360239\n",
      "Validation score: -0.978467\n",
      "Iteration 2063, loss = 83.58538357\n",
      "Validation score: -0.972860\n",
      "Iteration 2064, loss = 83.35658048\n",
      "Validation score: -0.967090\n",
      "Iteration 2065, loss = 83.11821577\n",
      "Validation score: -0.961219\n",
      "Iteration 2066, loss = 82.87433097\n",
      "Validation score: -0.955263\n",
      "Iteration 2067, loss = 82.62761179\n",
      "Validation score: -0.949175\n",
      "Iteration 2068, loss = 82.37929651\n",
      "Validation score: -0.942971\n",
      "Iteration 2069, loss = 82.12084970\n",
      "Validation score: -0.936822\n",
      "Iteration 2070, loss = 81.87118709\n",
      "Validation score: -0.930642\n",
      "Iteration 2071, loss = 81.61483850\n",
      "Validation score: -0.924546\n",
      "Iteration 2072, loss = 81.36365840\n",
      "Validation score: -0.918512\n",
      "Iteration 2073, loss = 81.11949945\n",
      "Validation score: -0.912556\n",
      "Iteration 2074, loss = 80.88097034\n",
      "Validation score: -0.906647\n",
      "Iteration 2075, loss = 80.64085266\n",
      "Validation score: -0.900917\n",
      "Iteration 2076, loss = 80.40778058\n",
      "Validation score: -0.895333\n",
      "Iteration 2077, loss = 80.17927880\n",
      "Validation score: -0.889866\n",
      "Iteration 2078, loss = 79.95850580\n",
      "Validation score: -0.884478\n",
      "Iteration 2079, loss = 79.73848481\n",
      "Validation score: -0.879237\n",
      "Iteration 2080, loss = 79.52489990\n",
      "Validation score: -0.874124\n",
      "Iteration 2081, loss = 79.31848789\n",
      "Validation score: -0.869104\n",
      "Iteration 2082, loss = 79.11143324\n",
      "Validation score: -0.864152\n",
      "Iteration 2083, loss = 78.91010570\n",
      "Validation score: -0.859236\n",
      "Iteration 2084, loss = 78.70730211\n",
      "Validation score: -0.854410\n",
      "Iteration 2085, loss = 78.51378991\n",
      "Validation score: -0.849556\n",
      "Iteration 2086, loss = 78.31642336\n",
      "Validation score: -0.844768\n",
      "Iteration 2087, loss = 78.12374896\n",
      "Validation score: -0.840029\n",
      "Iteration 2088, loss = 77.92744788\n",
      "Validation score: -0.835408\n",
      "Iteration 2089, loss = 77.74372396\n",
      "Validation score: -0.830692\n",
      "Iteration 2090, loss = 77.55297180\n",
      "Validation score: -0.826108\n",
      "Iteration 2091, loss = 77.36758752\n",
      "Validation score: -0.821573\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 2092, loss = 77.18379257\n",
      "Validation score: -0.817075\n",
      "Iteration 2093, loss = 77.00087402\n",
      "Validation score: -0.812649\n",
      "Iteration 2094, loss = 76.81956293\n",
      "Validation score: -0.808246\n",
      "Iteration 2095, loss = 76.64009071\n",
      "Validation score: -0.803841\n",
      "Iteration 2096, loss = 76.46362314\n",
      "Validation score: -0.799437\n",
      "Iteration 2097, loss = 76.28743978\n",
      "Validation score: -0.795063\n",
      "Iteration 2098, loss = 76.11050075\n",
      "Validation score: -0.790743\n",
      "Iteration 2099, loss = 75.93377153\n",
      "Validation score: -0.786433\n",
      "Iteration 2100, loss = 75.76298416\n",
      "Validation score: -0.782160\n",
      "Iteration 2101, loss = 75.59012710\n",
      "Validation score: -0.777942\n",
      "Iteration 2102, loss = 75.41967291\n",
      "Validation score: -0.773703\n",
      "Iteration 2103, loss = 75.24991809\n",
      "Validation score: -0.769545\n",
      "Iteration 2104, loss = 75.08078994\n",
      "Validation score: -0.765445\n",
      "Iteration 2105, loss = 74.91261235\n",
      "Validation score: -0.761285\n",
      "Iteration 2106, loss = 74.74517919\n",
      "Validation score: -0.757114\n",
      "Iteration 2107, loss = 74.58128384\n",
      "Validation score: -0.752952\n",
      "Iteration 2108, loss = 74.41291662\n",
      "Validation score: -0.748805\n",
      "Iteration 2109, loss = 74.24474675\n",
      "Validation score: -0.744643\n",
      "Iteration 2110, loss = 74.07928271\n",
      "Validation score: -0.740483\n",
      "Iteration 2111, loss = 73.91118121\n",
      "Validation score: -0.736351\n",
      "Iteration 2112, loss = 73.74530679\n",
      "Validation score: -0.732242\n",
      "Iteration 2113, loss = 73.57767599\n",
      "Validation score: -0.728138\n",
      "Iteration 2114, loss = 73.41146932\n",
      "Validation score: -0.724042\n",
      "Iteration 2115, loss = 73.24791977\n",
      "Validation score: -0.719908\n",
      "Iteration 2116, loss = 73.08134007\n",
      "Validation score: -0.715878\n",
      "Iteration 2117, loss = 72.91756983\n",
      "Validation score: -0.711807\n",
      "Iteration 2118, loss = 72.74958767\n",
      "Validation score: -0.707824\n",
      "Iteration 2119, loss = 72.58563349\n",
      "Validation score: -0.703827\n",
      "Iteration 2120, loss = 72.42136149\n",
      "Validation score: -0.699808\n",
      "Iteration 2121, loss = 72.25527170\n",
      "Validation score: -0.695677\n",
      "Iteration 2122, loss = 72.08813147\n",
      "Validation score: -0.691442\n",
      "Iteration 2123, loss = 71.92114619\n",
      "Validation score: -0.687333\n",
      "Iteration 2124, loss = 71.74926743\n",
      "Validation score: -0.683304\n",
      "Iteration 2125, loss = 71.58578103\n",
      "Validation score: -0.679324\n",
      "Iteration 2126, loss = 71.42070218\n",
      "Validation score: -0.675497\n",
      "Iteration 2127, loss = 71.25437894\n",
      "Validation score: -0.671647\n",
      "Iteration 2128, loss = 71.08480871\n",
      "Validation score: -0.667844\n",
      "Iteration 2129, loss = 70.92290322\n",
      "Validation score: -0.663892\n",
      "Iteration 2130, loss = 70.75729929\n",
      "Validation score: -0.660109\n",
      "Iteration 2131, loss = 70.59530350\n",
      "Validation score: -0.656186\n",
      "Iteration 2132, loss = 70.42948402\n",
      "Validation score: -0.652377\n",
      "Iteration 2133, loss = 70.26765949\n",
      "Validation score: -0.648443\n",
      "Iteration 2134, loss = 70.10516299\n",
      "Validation score: -0.644870\n",
      "Iteration 2135, loss = 69.93968339\n",
      "Validation score: -0.641066\n",
      "Iteration 2136, loss = 69.77732016\n",
      "Validation score: -0.637249\n",
      "Iteration 2137, loss = 69.61589472\n",
      "Validation score: -0.633604\n",
      "Iteration 2138, loss = 69.45139976\n",
      "Validation score: -0.629667\n",
      "Iteration 2139, loss = 69.29033063\n",
      "Validation score: -0.626037\n",
      "Iteration 2140, loss = 69.12803454\n",
      "Validation score: -0.622128\n",
      "Iteration 2141, loss = 68.96109478\n",
      "Validation score: -0.618544\n",
      "Iteration 2142, loss = 68.80421824\n",
      "Validation score: -0.614964\n",
      "Iteration 2143, loss = 68.64391350\n",
      "Validation score: -0.611307\n",
      "Iteration 2144, loss = 68.47887690\n",
      "Validation score: -0.607668\n",
      "Iteration 2145, loss = 68.32292895\n",
      "Validation score: -0.604385\n",
      "Iteration 2146, loss = 68.16328650\n",
      "Validation score: -0.601041\n",
      "Iteration 2147, loss = 68.00362545\n",
      "Validation score: -0.597214\n",
      "Iteration 2148, loss = 67.84517922\n",
      "Validation score: -0.593546\n",
      "Iteration 2149, loss = 67.68569125\n",
      "Validation score: -0.590110\n",
      "Iteration 2150, loss = 67.52558850\n",
      "Validation score: -0.586631\n",
      "Iteration 2151, loss = 67.36897259\n",
      "Validation score: -0.582993\n",
      "Iteration 2152, loss = 67.20971607\n",
      "Validation score: -0.579027\n",
      "Iteration 2153, loss = 67.05109452\n",
      "Validation score: -0.575507\n",
      "Iteration 2154, loss = 66.89046275\n",
      "Validation score: -0.572182\n",
      "Iteration 2155, loss = 66.73560541\n",
      "Validation score: -0.568751\n",
      "Iteration 2156, loss = 66.57711528\n",
      "Validation score: -0.565184\n",
      "Iteration 2157, loss = 66.41831872\n",
      "Validation score: -0.561754\n",
      "Iteration 2158, loss = 66.26298103\n",
      "Validation score: -0.558450\n",
      "Iteration 2159, loss = 66.11060381\n",
      "Validation score: -0.554979\n",
      "Iteration 2160, loss = 65.95285481\n",
      "Validation score: -0.551283\n",
      "Iteration 2161, loss = 65.79817190\n",
      "Validation score: -0.547891\n",
      "Iteration 2162, loss = 65.64773115\n",
      "Validation score: -0.544560\n",
      "Iteration 2163, loss = 65.49178787\n",
      "Validation score: -0.540780\n",
      "Iteration 2164, loss = 65.33755120\n",
      "Validation score: -0.537609\n",
      "Iteration 2165, loss = 65.18416632\n",
      "Validation score: -0.533967\n",
      "Iteration 2166, loss = 65.03206986\n",
      "Validation score: -0.530865\n",
      "Iteration 2167, loss = 64.87796318\n",
      "Validation score: -0.527819\n",
      "Iteration 2168, loss = 64.72320190\n",
      "Validation score: -0.524458\n",
      "Iteration 2169, loss = 64.56857340\n",
      "Validation score: -0.521347\n",
      "Iteration 2170, loss = 64.41830546\n",
      "Validation score: -0.518100\n",
      "Iteration 2171, loss = 64.26620086\n",
      "Validation score: -0.514254\n",
      "Iteration 2172, loss = 64.11473590\n",
      "Validation score: -0.510497\n",
      "Iteration 2173, loss = 63.96335538\n",
      "Validation score: -0.507067\n",
      "Iteration 2174, loss = 63.81000127\n",
      "Validation score: -0.503978\n",
      "Iteration 2175, loss = 63.66115017\n",
      "Validation score: -0.500875\n",
      "Iteration 2176, loss = 63.51190224\n",
      "Validation score: -0.497722\n",
      "Iteration 2177, loss = 63.35649510\n",
      "Validation score: -0.494319\n",
      "Iteration 2178, loss = 63.21105813\n",
      "Validation score: -0.490849\n",
      "Iteration 2179, loss = 63.06317199\n",
      "Validation score: -0.488006\n",
      "Iteration 2180, loss = 62.91198856\n",
      "Validation score: -0.484716\n",
      "Iteration 2181, loss = 62.76089648\n",
      "Validation score: -0.481124\n",
      "Iteration 2182, loss = 62.61493481\n",
      "Validation score: -0.477937\n",
      "Iteration 2183, loss = 62.46725047\n",
      "Validation score: -0.474568\n",
      "Iteration 2184, loss = 62.31826215\n",
      "Validation score: -0.471151\n",
      "Iteration 2185, loss = 62.17419916\n",
      "Validation score: -0.468258\n",
      "Iteration 2186, loss = 62.02486337\n",
      "Validation score: -0.464787\n",
      "Iteration 2187, loss = 61.87854388\n",
      "Validation score: -0.461768\n",
      "Iteration 2188, loss = 61.73512412\n",
      "Validation score: -0.459161\n",
      "Iteration 2189, loss = 61.59057383\n",
      "Validation score: -0.455710\n",
      "Iteration 2190, loss = 61.44692757\n",
      "Validation score: -0.452245\n",
      "Iteration 2191, loss = 61.30082673\n",
      "Validation score: -0.448439\n",
      "Iteration 2192, loss = 61.15452893\n",
      "Validation score: -0.445419\n",
      "Iteration 2193, loss = 61.01155058\n",
      "Validation score: -0.442114\n",
      "Iteration 2194, loss = 60.87018661\n",
      "Validation score: -0.438656\n",
      "Iteration 2195, loss = 60.73134923\n",
      "Validation score: -0.435534\n",
      "Iteration 2196, loss = 60.58799617\n",
      "Validation score: -0.432295\n",
      "Iteration 2197, loss = 60.44711112\n",
      "Validation score: -0.429147\n",
      "Iteration 2198, loss = 60.30180179\n",
      "Validation score: -0.426133\n",
      "Iteration 2199, loss = 60.16398418\n",
      "Validation score: -0.423006\n",
      "Iteration 2200, loss = 60.02310244\n",
      "Validation score: -0.420256\n",
      "Iteration 2201, loss = 59.88503426\n",
      "Validation score: -0.417633\n",
      "Iteration 2202, loss = 59.74455471\n",
      "Validation score: -0.414053\n",
      "Iteration 2203, loss = 59.60393254\n",
      "Validation score: -0.410885\n",
      "Iteration 2204, loss = 59.46409542\n",
      "Validation score: -0.407601\n",
      "Iteration 2205, loss = 59.32384862\n",
      "Validation score: -0.404259\n",
      "Iteration 2206, loss = 59.18642305\n",
      "Validation score: -0.401262\n",
      "Iteration 2207, loss = 59.04871289\n",
      "Validation score: -0.398032\n",
      "Iteration 2208, loss = 58.90520776\n",
      "Validation score: -0.394608\n",
      "Iteration 2209, loss = 58.76569680\n",
      "Validation score: -0.390985\n",
      "Iteration 2210, loss = 58.62855321\n",
      "Validation score: -0.387142\n",
      "Iteration 2211, loss = 58.48403413\n",
      "Validation score: -0.383689\n",
      "Iteration 2212, loss = 58.34429215\n",
      "Validation score: -0.380284\n",
      "Iteration 2213, loss = 58.20083485\n",
      "Validation score: -0.376892\n",
      "Iteration 2214, loss = 58.05664040\n",
      "Validation score: -0.373703\n",
      "Iteration 2215, loss = 57.91349298\n",
      "Validation score: -0.370739\n",
      "Iteration 2216, loss = 57.76138408\n",
      "Validation score: -0.367228\n",
      "Iteration 2217, loss = 57.61002478\n",
      "Validation score: -0.363508\n",
      "Iteration 2218, loss = 57.45448454\n",
      "Validation score: -0.359989\n",
      "Iteration 2219, loss = 57.30057371\n",
      "Validation score: -0.356248\n",
      "Iteration 2220, loss = 57.13600247\n",
      "Validation score: -0.352033\n",
      "Iteration 2221, loss = 56.96853901\n",
      "Validation score: -0.347719\n",
      "Iteration 2222, loss = 56.79504834\n",
      "Validation score: -0.343531\n",
      "Iteration 2223, loss = 56.62208900\n",
      "Validation score: -0.339434\n",
      "Iteration 2224, loss = 56.44378896\n",
      "Validation score: -0.335213\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 2225, loss = 56.26408137\n",
      "Validation score: -0.331041\n",
      "Iteration 2226, loss = 56.09124101\n",
      "Validation score: -0.326908\n",
      "Iteration 2227, loss = 55.91691213\n",
      "Validation score: -0.322156\n",
      "Iteration 2228, loss = 55.74430280\n",
      "Validation score: -0.318119\n",
      "Iteration 2229, loss = 55.57440572\n",
      "Validation score: -0.313764\n",
      "Iteration 2230, loss = 55.41220684\n",
      "Validation score: -0.309916\n",
      "Iteration 2231, loss = 55.24873670\n",
      "Validation score: -0.306201\n",
      "Iteration 2232, loss = 55.09378859\n",
      "Validation score: -0.302362\n",
      "Iteration 2233, loss = 54.93799541\n",
      "Validation score: -0.298893\n",
      "Iteration 2234, loss = 54.78957583\n",
      "Validation score: -0.295681\n",
      "Iteration 2235, loss = 54.64044826\n",
      "Validation score: -0.292051\n",
      "Iteration 2236, loss = 54.49049814\n",
      "Validation score: -0.288740\n",
      "Iteration 2237, loss = 54.34906880\n",
      "Validation score: -0.285030\n",
      "Iteration 2238, loss = 54.21180351\n",
      "Validation score: -0.281173\n",
      "Iteration 2239, loss = 54.06358759\n",
      "Validation score: -0.278253\n",
      "Iteration 2240, loss = 53.93038452\n",
      "Validation score: -0.275086\n",
      "Iteration 2241, loss = 53.78994459\n",
      "Validation score: -0.272012\n",
      "Iteration 2242, loss = 53.65053237\n",
      "Validation score: -0.268530\n",
      "Iteration 2243, loss = 53.51753787\n",
      "Validation score: -0.265540\n",
      "Iteration 2244, loss = 53.38510210\n",
      "Validation score: -0.262481\n",
      "Iteration 2245, loss = 53.24770118\n",
      "Validation score: -0.259163\n",
      "Iteration 2246, loss = 53.11815348\n",
      "Validation score: -0.255930\n",
      "Iteration 2247, loss = 52.98884060\n",
      "Validation score: -0.252636\n",
      "Iteration 2248, loss = 52.86015989\n",
      "Validation score: -0.249535\n",
      "Iteration 2249, loss = 52.73075673\n",
      "Validation score: -0.246238\n",
      "Iteration 2250, loss = 52.60255086\n",
      "Validation score: -0.243265\n",
      "Iteration 2251, loss = 52.48024804\n",
      "Validation score: -0.240343\n",
      "Iteration 2252, loss = 52.35181588\n",
      "Validation score: -0.236938\n",
      "Iteration 2253, loss = 52.22638224\n",
      "Validation score: -0.233562\n",
      "Iteration 2254, loss = 52.10399924\n",
      "Validation score: -0.230530\n",
      "Iteration 2255, loss = 51.97932498\n",
      "Validation score: -0.227735\n",
      "Iteration 2256, loss = 51.85657375\n",
      "Validation score: -0.224724\n",
      "Iteration 2257, loss = 51.73507153\n",
      "Validation score: -0.221755\n",
      "Iteration 2258, loss = 51.61288052\n",
      "Validation score: -0.218856\n",
      "Iteration 2259, loss = 51.49725149\n",
      "Validation score: -0.216153\n",
      "Iteration 2260, loss = 51.37217853\n",
      "Validation score: -0.212968\n",
      "Iteration 2261, loss = 51.25362942\n",
      "Validation score: -0.209603\n",
      "Iteration 2262, loss = 51.13940208\n",
      "Validation score: -0.206154\n",
      "Iteration 2263, loss = 51.01821423\n",
      "Validation score: -0.203249\n",
      "Iteration 2264, loss = 50.90181764\n",
      "Validation score: -0.200381\n",
      "Iteration 2265, loss = 50.78300246\n",
      "Validation score: -0.197741\n",
      "Iteration 2266, loss = 50.66552067\n",
      "Validation score: -0.195027\n",
      "Iteration 2267, loss = 50.54716726\n",
      "Validation score: -0.192172\n",
      "Iteration 2268, loss = 50.43518127\n",
      "Validation score: -0.189265\n",
      "Iteration 2269, loss = 50.32173733\n",
      "Validation score: -0.186808\n",
      "Iteration 2270, loss = 50.20284087\n",
      "Validation score: -0.183970\n",
      "Iteration 2271, loss = 50.09174155\n",
      "Validation score: -0.181222\n",
      "Iteration 2272, loss = 49.97900529\n",
      "Validation score: -0.178601\n",
      "Iteration 2273, loss = 49.86844184\n",
      "Validation score: -0.175587\n",
      "Iteration 2274, loss = 49.75490612\n",
      "Validation score: -0.172777\n",
      "Iteration 2275, loss = 49.64614801\n",
      "Validation score: -0.169833\n",
      "Iteration 2276, loss = 49.53254878\n",
      "Validation score: -0.167170\n",
      "Iteration 2277, loss = 49.42286680\n",
      "Validation score: -0.164417\n",
      "Iteration 2278, loss = 49.31318788\n",
      "Validation score: -0.161895\n",
      "Iteration 2279, loss = 49.20619763\n",
      "Validation score: -0.159210\n",
      "Iteration 2280, loss = 49.09582062\n",
      "Validation score: -0.156572\n",
      "Iteration 2281, loss = 48.99324538\n",
      "Validation score: -0.153705\n",
      "Iteration 2282, loss = 48.88024882\n",
      "Validation score: -0.151234\n",
      "Iteration 2283, loss = 48.77568265\n",
      "Validation score: -0.148720\n",
      "Iteration 2284, loss = 48.66665389\n",
      "Validation score: -0.146031\n",
      "Iteration 2285, loss = 48.56018290\n",
      "Validation score: -0.143215\n",
      "Iteration 2286, loss = 48.45564161\n",
      "Validation score: -0.140542\n",
      "Iteration 2287, loss = 48.34852913\n",
      "Validation score: -0.137851\n",
      "Iteration 2288, loss = 48.24226324\n",
      "Validation score: -0.134961\n",
      "Iteration 2289, loss = 48.13747328\n",
      "Validation score: -0.132306\n",
      "Iteration 2290, loss = 48.03305813\n",
      "Validation score: -0.129617\n",
      "Iteration 2291, loss = 47.93096988\n",
      "Validation score: -0.126905\n",
      "Iteration 2292, loss = 47.82371173\n",
      "Validation score: -0.124409\n",
      "Iteration 2293, loss = 47.72286713\n",
      "Validation score: -0.121752\n",
      "Iteration 2294, loss = 47.62107395\n",
      "Validation score: -0.119204\n",
      "Iteration 2295, loss = 47.51763952\n",
      "Validation score: -0.116607\n",
      "Iteration 2296, loss = 47.41713371\n",
      "Validation score: -0.113864\n",
      "Iteration 2297, loss = 47.31226444\n",
      "Validation score: -0.111452\n",
      "Iteration 2298, loss = 47.21121339\n",
      "Validation score: -0.108855\n",
      "Iteration 2299, loss = 47.11464898\n",
      "Validation score: -0.106410\n",
      "Iteration 2300, loss = 47.01124909\n",
      "Validation score: -0.103848\n",
      "Iteration 2301, loss = 46.91183798\n",
      "Validation score: -0.101395\n",
      "Iteration 2302, loss = 46.81675266\n",
      "Validation score: -0.099108\n",
      "Iteration 2303, loss = 46.71549581\n",
      "Validation score: -0.096515\n",
      "Iteration 2304, loss = 46.61736463\n",
      "Validation score: -0.094054\n",
      "Iteration 2305, loss = 46.52332474\n",
      "Validation score: -0.091520\n",
      "Iteration 2306, loss = 46.42263899\n",
      "Validation score: -0.089066\n",
      "Iteration 2307, loss = 46.32941094\n",
      "Validation score: -0.086472\n",
      "Iteration 2308, loss = 46.22873929\n",
      "Validation score: -0.083507\n",
      "Iteration 2309, loss = 46.13228569\n",
      "Validation score: -0.080790\n",
      "Iteration 2310, loss = 46.03494906\n",
      "Validation score: -0.078300\n",
      "Iteration 2311, loss = 45.93765634\n",
      "Validation score: -0.075990\n",
      "Iteration 2312, loss = 45.84240302\n",
      "Validation score: -0.073759\n",
      "Iteration 2313, loss = 45.74551083\n",
      "Validation score: -0.071389\n",
      "Iteration 2314, loss = 45.64804101\n",
      "Validation score: -0.068902\n",
      "Iteration 2315, loss = 45.55302025\n",
      "Validation score: -0.066482\n",
      "Iteration 2316, loss = 45.46111978\n",
      "Validation score: -0.064023\n",
      "Iteration 2317, loss = 45.36450144\n",
      "Validation score: -0.061346\n",
      "Iteration 2318, loss = 45.27132935\n",
      "Validation score: -0.058704\n",
      "Iteration 2319, loss = 45.17941357\n",
      "Validation score: -0.056194\n",
      "Iteration 2320, loss = 45.08942263\n",
      "Validation score: -0.053805\n",
      "Iteration 2321, loss = 44.99862465\n",
      "Validation score: -0.051345\n",
      "Iteration 2322, loss = 44.90958627\n",
      "Validation score: -0.048895\n",
      "Iteration 2323, loss = 44.81587410\n",
      "Validation score: -0.046740\n",
      "Iteration 2324, loss = 44.72513983\n",
      "Validation score: -0.044523\n",
      "Iteration 2325, loss = 44.63584560\n",
      "Validation score: -0.042216\n",
      "Iteration 2326, loss = 44.54714885\n",
      "Validation score: -0.040072\n",
      "Iteration 2327, loss = 44.45702156\n",
      "Validation score: -0.037783\n",
      "Iteration 2328, loss = 44.36943407\n",
      "Validation score: -0.035408\n",
      "Iteration 2329, loss = 44.28040576\n",
      "Validation score: -0.033021\n",
      "Iteration 2330, loss = 44.19237400\n",
      "Validation score: -0.030555\n",
      "Iteration 2331, loss = 44.10305682\n",
      "Validation score: -0.028341\n",
      "Iteration 2332, loss = 44.01395901\n",
      "Validation score: -0.025999\n",
      "Iteration 2333, loss = 43.92647261\n",
      "Validation score: -0.023647\n",
      "Iteration 2334, loss = 43.84200878\n",
      "Validation score: -0.021313\n",
      "Iteration 2335, loss = 43.75370481\n",
      "Validation score: -0.019115\n",
      "Iteration 2336, loss = 43.66922844\n",
      "Validation score: -0.016702\n",
      "Iteration 2337, loss = 43.58268118\n",
      "Validation score: -0.014418\n",
      "Iteration 2338, loss = 43.49891338\n",
      "Validation score: -0.012228\n",
      "Iteration 2339, loss = 43.41678467\n",
      "Validation score: -0.010209\n",
      "Iteration 2340, loss = 43.33310391\n",
      "Validation score: -0.007880\n",
      "Iteration 2341, loss = 43.24918461\n",
      "Validation score: -0.005716\n",
      "Iteration 2342, loss = 43.16896982\n",
      "Validation score: -0.003624\n",
      "Iteration 2343, loss = 43.08314375\n",
      "Validation score: -0.001440\n",
      "Iteration 2344, loss = 43.00131272\n",
      "Validation score: 0.000711\n",
      "Iteration 2345, loss = 42.91805220\n",
      "Validation score: 0.002937\n",
      "Iteration 2346, loss = 42.83781135\n",
      "Validation score: 0.005425\n",
      "Iteration 2347, loss = 42.75662860\n",
      "Validation score: 0.007764\n",
      "Iteration 2348, loss = 42.67413369\n",
      "Validation score: 0.009993\n",
      "Iteration 2349, loss = 42.59436575\n",
      "Validation score: 0.012053\n",
      "Iteration 2350, loss = 42.51203721\n",
      "Validation score: 0.014301\n",
      "Iteration 2351, loss = 42.43169500\n",
      "Validation score: 0.016432\n",
      "Iteration 2352, loss = 42.35268791\n",
      "Validation score: 0.018421\n",
      "Iteration 2353, loss = 42.27243441\n",
      "Validation score: 0.020428\n",
      "Iteration 2354, loss = 42.19453068\n",
      "Validation score: 0.022685\n",
      "Iteration 2355, loss = 42.11596549\n",
      "Validation score: 0.024753\n",
      "Iteration 2356, loss = 42.03806236\n",
      "Validation score: 0.026994\n",
      "Iteration 2357, loss = 41.95673958\n",
      "Validation score: 0.029057\n",
      "Iteration 2358, loss = 41.87942293\n",
      "Validation score: 0.030992\n",
      "Iteration 2359, loss = 41.80343452\n",
      "Validation score: 0.033070\n",
      "Iteration 2360, loss = 41.72345959\n",
      "Validation score: 0.035195\n",
      "Iteration 2361, loss = 41.64857904\n",
      "Validation score: 0.037456\n",
      "Iteration 2362, loss = 41.56950519\n",
      "Validation score: 0.039597\n",
      "Iteration 2363, loss = 41.49234169\n",
      "Validation score: 0.041668\n",
      "Iteration 2364, loss = 41.41805283\n",
      "Validation score: 0.043835\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 2365, loss = 41.34180293\n",
      "Validation score: 0.045940\n",
      "Iteration 2366, loss = 41.26930201\n",
      "Validation score: 0.047956\n",
      "Iteration 2367, loss = 41.19254967\n",
      "Validation score: 0.049820\n",
      "Iteration 2368, loss = 41.11758184\n",
      "Validation score: 0.051778\n",
      "Iteration 2369, loss = 41.04647652\n",
      "Validation score: 0.053906\n",
      "Iteration 2370, loss = 40.97102484\n",
      "Validation score: 0.055994\n",
      "Iteration 2371, loss = 40.89742895\n",
      "Validation score: 0.057970\n",
      "Iteration 2372, loss = 40.82457228\n",
      "Validation score: 0.059932\n",
      "Iteration 2373, loss = 40.75015089\n",
      "Validation score: 0.061790\n",
      "Iteration 2374, loss = 40.67946932\n",
      "Validation score: 0.063598\n",
      "Iteration 2375, loss = 40.60910589\n",
      "Validation score: 0.065564\n",
      "Iteration 2376, loss = 40.53483207\n",
      "Validation score: 0.067564\n",
      "Iteration 2377, loss = 40.46200098\n",
      "Validation score: 0.069569\n",
      "Iteration 2378, loss = 40.39272388\n",
      "Validation score: 0.071568\n",
      "Iteration 2379, loss = 40.31836656\n",
      "Validation score: 0.073635\n",
      "Iteration 2380, loss = 40.25052392\n",
      "Validation score: 0.075705\n",
      "Iteration 2381, loss = 40.17974509\n",
      "Validation score: 0.077752\n",
      "Iteration 2382, loss = 40.10858746\n",
      "Validation score: 0.079650\n",
      "Iteration 2383, loss = 40.03714737\n",
      "Validation score: 0.081554\n",
      "Iteration 2384, loss = 39.96768650\n",
      "Validation score: 0.083546\n",
      "Iteration 2385, loss = 39.89800112\n",
      "Validation score: 0.085472\n",
      "Iteration 2386, loss = 39.82842485\n",
      "Validation score: 0.087408\n",
      "Iteration 2387, loss = 39.75946498\n",
      "Validation score: 0.089304\n",
      "Iteration 2388, loss = 39.69079885\n",
      "Validation score: 0.091259\n",
      "Iteration 2389, loss = 39.62564071\n",
      "Validation score: 0.093091\n",
      "Iteration 2390, loss = 39.55611886\n",
      "Validation score: 0.094955\n",
      "Iteration 2391, loss = 39.48901597\n",
      "Validation score: 0.096883\n",
      "Iteration 2392, loss = 39.42201259\n",
      "Validation score: 0.098864\n",
      "Iteration 2393, loss = 39.35472264\n",
      "Validation score: 0.100847\n",
      "Iteration 2394, loss = 39.28667314\n",
      "Validation score: 0.102726\n",
      "Iteration 2395, loss = 39.22002108\n",
      "Validation score: 0.104598\n",
      "Iteration 2396, loss = 39.15678308\n",
      "Validation score: 0.106395\n",
      "Iteration 2397, loss = 39.08653007\n",
      "Validation score: 0.108330\n",
      "Iteration 2398, loss = 39.02435437\n",
      "Validation score: 0.110344\n",
      "Iteration 2399, loss = 38.95908057\n",
      "Validation score: 0.112208\n",
      "Iteration 2400, loss = 38.89131385\n",
      "Validation score: 0.113984\n",
      "Iteration 2401, loss = 38.82802070\n",
      "Validation score: 0.115779\n",
      "Iteration 2402, loss = 38.76361572\n",
      "Validation score: 0.117536\n",
      "Iteration 2403, loss = 38.70003324\n",
      "Validation score: 0.119380\n",
      "Iteration 2404, loss = 38.63554750\n",
      "Validation score: 0.121127\n",
      "Iteration 2405, loss = 38.57350023\n",
      "Validation score: 0.122882\n",
      "Iteration 2406, loss = 38.50860132\n",
      "Validation score: 0.124755\n",
      "Iteration 2407, loss = 38.44481086\n",
      "Validation score: 0.126557\n",
      "Iteration 2408, loss = 38.38107602\n",
      "Validation score: 0.128280\n",
      "Iteration 2409, loss = 38.31894254\n",
      "Validation score: 0.130111\n",
      "Iteration 2410, loss = 38.25587902\n",
      "Validation score: 0.131937\n",
      "Iteration 2411, loss = 38.19315952\n",
      "Validation score: 0.133723\n",
      "Iteration 2412, loss = 38.13047252\n",
      "Validation score: 0.135481\n",
      "Iteration 2413, loss = 38.07013228\n",
      "Validation score: 0.137229\n",
      "Iteration 2414, loss = 38.00959721\n",
      "Validation score: 0.139018\n",
      "Iteration 2415, loss = 37.94691416\n",
      "Validation score: 0.140742\n",
      "Iteration 2416, loss = 37.88445410\n",
      "Validation score: 0.142288\n",
      "Iteration 2417, loss = 37.82702156\n",
      "Validation score: 0.143974\n",
      "Iteration 2418, loss = 37.76290066\n",
      "Validation score: 0.145737\n",
      "Iteration 2419, loss = 37.70496855\n",
      "Validation score: 0.147460\n",
      "Iteration 2420, loss = 37.64704116\n",
      "Validation score: 0.149142\n",
      "Iteration 2421, loss = 37.58503529\n",
      "Validation score: 0.150897\n",
      "Iteration 2422, loss = 37.52715760\n",
      "Validation score: 0.152652\n",
      "Iteration 2423, loss = 37.46664540\n",
      "Validation score: 0.154338\n",
      "Iteration 2424, loss = 37.41009377\n",
      "Validation score: 0.156023\n",
      "Iteration 2425, loss = 37.34854197\n",
      "Validation score: 0.157724\n",
      "Iteration 2426, loss = 37.29109747\n",
      "Validation score: 0.159387\n",
      "Iteration 2427, loss = 37.23248365\n",
      "Validation score: 0.161069\n",
      "Iteration 2428, loss = 37.17489581\n",
      "Validation score: 0.162875\n",
      "Iteration 2429, loss = 37.11787375\n",
      "Validation score: 0.164667\n",
      "Iteration 2430, loss = 37.05856441\n",
      "Validation score: 0.166446\n",
      "Iteration 2431, loss = 37.00712967\n",
      "Validation score: 0.168181\n",
      "Iteration 2432, loss = 36.94726703\n",
      "Validation score: 0.169764\n",
      "Iteration 2433, loss = 36.89225278\n",
      "Validation score: 0.171276\n",
      "Iteration 2434, loss = 36.83704553\n",
      "Validation score: 0.172921\n",
      "Iteration 2435, loss = 36.78066182\n",
      "Validation score: 0.174601\n",
      "Iteration 2436, loss = 36.72301240\n",
      "Validation score: 0.176070\n",
      "Iteration 2437, loss = 36.67020429\n",
      "Validation score: 0.177690\n",
      "Iteration 2438, loss = 36.61425060\n",
      "Validation score: 0.179263\n",
      "Iteration 2439, loss = 36.56107574\n",
      "Validation score: 0.180831\n",
      "Iteration 2440, loss = 36.50460134\n",
      "Validation score: 0.182514\n",
      "Iteration 2441, loss = 36.45036849\n",
      "Validation score: 0.184187\n",
      "Iteration 2442, loss = 36.39655513\n",
      "Validation score: 0.185779\n",
      "Iteration 2443, loss = 36.34216628\n",
      "Validation score: 0.187332\n",
      "Iteration 2444, loss = 36.28736008\n",
      "Validation score: 0.188847\n",
      "Iteration 2445, loss = 36.23774230\n",
      "Validation score: 0.190456\n",
      "Iteration 2446, loss = 36.18392136\n",
      "Validation score: 0.192102\n",
      "Iteration 2447, loss = 36.13146513\n",
      "Validation score: 0.193704\n",
      "Iteration 2448, loss = 36.08092097\n",
      "Validation score: 0.195209\n",
      "Iteration 2449, loss = 36.03027216\n",
      "Validation score: 0.196724\n",
      "Iteration 2450, loss = 35.97764501\n",
      "Validation score: 0.198210\n",
      "Iteration 2451, loss = 35.92632433\n",
      "Validation score: 0.199728\n",
      "Iteration 2452, loss = 35.87458581\n",
      "Validation score: 0.201166\n",
      "Iteration 2453, loss = 35.82396906\n",
      "Validation score: 0.202678\n",
      "Iteration 2454, loss = 35.77148958\n",
      "Validation score: 0.204231\n",
      "Iteration 2455, loss = 35.72081264\n",
      "Validation score: 0.205819\n",
      "Iteration 2456, loss = 35.67067960\n",
      "Validation score: 0.207322\n",
      "Iteration 2457, loss = 35.61798123\n",
      "Validation score: 0.208835\n",
      "Iteration 2458, loss = 35.56909880\n",
      "Validation score: 0.210389\n",
      "Iteration 2459, loss = 35.52094930\n",
      "Validation score: 0.211920\n",
      "Iteration 2460, loss = 35.46805473\n",
      "Validation score: 0.213419\n",
      "Iteration 2461, loss = 35.41824374\n",
      "Validation score: 0.214955\n",
      "Iteration 2462, loss = 35.36979896\n",
      "Validation score: 0.216468\n",
      "Iteration 2463, loss = 35.32249209\n",
      "Validation score: 0.217950\n",
      "Iteration 2464, loss = 35.27061105\n",
      "Validation score: 0.219474\n",
      "Iteration 2465, loss = 35.22077251\n",
      "Validation score: 0.220908\n",
      "Iteration 2466, loss = 35.17362351\n",
      "Validation score: 0.222354\n",
      "Iteration 2467, loss = 35.12769596\n",
      "Validation score: 0.223764\n",
      "Iteration 2468, loss = 35.08013545\n",
      "Validation score: 0.225318\n",
      "Iteration 2469, loss = 35.03106287\n",
      "Validation score: 0.226775\n",
      "Iteration 2470, loss = 34.98616607\n",
      "Validation score: 0.228260\n",
      "Iteration 2471, loss = 34.93731812\n",
      "Validation score: 0.229683\n",
      "Iteration 2472, loss = 34.89158258\n",
      "Validation score: 0.231082\n",
      "Iteration 2473, loss = 34.84438958\n",
      "Validation score: 0.232462\n",
      "Iteration 2474, loss = 34.79828932\n",
      "Validation score: 0.233866\n",
      "Iteration 2475, loss = 34.75581382\n",
      "Validation score: 0.235323\n",
      "Iteration 2476, loss = 34.70497502\n",
      "Validation score: 0.236631\n",
      "Iteration 2477, loss = 34.66373862\n",
      "Validation score: 0.237979\n",
      "Iteration 2478, loss = 34.61595477\n",
      "Validation score: 0.239399\n",
      "Iteration 2479, loss = 34.57019512\n",
      "Validation score: 0.240796\n",
      "Iteration 2480, loss = 34.52523582\n",
      "Validation score: 0.242142\n",
      "Iteration 2481, loss = 34.47992288\n",
      "Validation score: 0.243417\n",
      "Iteration 2482, loss = 34.43759472\n",
      "Validation score: 0.244719\n",
      "Iteration 2483, loss = 34.39620323\n",
      "Validation score: 0.246029\n",
      "Iteration 2484, loss = 34.34997019\n",
      "Validation score: 0.247468\n",
      "Iteration 2485, loss = 34.30577268\n",
      "Validation score: 0.248867\n",
      "Iteration 2486, loss = 34.26162719\n",
      "Validation score: 0.250221\n",
      "Iteration 2487, loss = 34.21595503\n",
      "Validation score: 0.251545\n",
      "Iteration 2488, loss = 34.17765085\n",
      "Validation score: 0.252899\n",
      "Iteration 2489, loss = 34.12955564\n",
      "Validation score: 0.254227\n",
      "Iteration 2490, loss = 34.08555137\n",
      "Validation score: 0.255546\n",
      "Iteration 2491, loss = 34.04378174\n",
      "Validation score: 0.256875\n",
      "Iteration 2492, loss = 34.00832549\n",
      "Validation score: 0.258269\n",
      "Iteration 2493, loss = 33.95841938\n",
      "Validation score: 0.259451\n",
      "Iteration 2494, loss = 33.91534165\n",
      "Validation score: 0.260704\n",
      "Iteration 2495, loss = 33.87417594\n",
      "Validation score: 0.261948\n",
      "Iteration 2496, loss = 33.83263746\n",
      "Validation score: 0.263201\n",
      "Iteration 2497, loss = 33.79454917\n",
      "Validation score: 0.264466\n",
      "Iteration 2498, loss = 33.74871564\n",
      "Validation score: 0.265780\n",
      "Iteration 2499, loss = 33.71187743\n",
      "Validation score: 0.267154\n",
      "Iteration 2500, loss = 33.66650171\n",
      "Validation score: 0.268466\n",
      "Iteration 2501, loss = 33.62750110\n",
      "Validation score: 0.269733\n",
      "Iteration 2502, loss = 33.58469296\n",
      "Validation score: 0.271037\n",
      "Iteration 2503, loss = 33.54289459\n",
      "Validation score: 0.272314\n",
      "Iteration 2504, loss = 33.50323157\n",
      "Validation score: 0.273605\n",
      "Iteration 2505, loss = 33.46542110\n",
      "Validation score: 0.274851\n",
      "Iteration 2506, loss = 33.42178146\n",
      "Validation score: 0.276118\n",
      "Iteration 2507, loss = 33.38331523\n",
      "Validation score: 0.277370\n",
      "Iteration 2508, loss = 33.34212601\n",
      "Validation score: 0.278643\n",
      "Iteration 2509, loss = 33.30606201\n",
      "Validation score: 0.279914\n",
      "Iteration 2510, loss = 33.26512051\n",
      "Validation score: 0.281193\n",
      "Iteration 2511, loss = 33.22736060\n",
      "Validation score: 0.282422\n",
      "Iteration 2512, loss = 33.19043196\n",
      "Validation score: 0.283621\n",
      "Iteration 2513, loss = 33.15511851\n",
      "Validation score: 0.284894\n",
      "Iteration 2514, loss = 33.10907782\n",
      "Validation score: 0.286104\n",
      "Iteration 2515, loss = 33.07100898\n",
      "Validation score: 0.287258\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 2516, loss = 33.03488443\n",
      "Validation score: 0.288472\n",
      "Iteration 2517, loss = 32.99579683\n",
      "Validation score: 0.289654\n",
      "Iteration 2518, loss = 32.95721156\n",
      "Validation score: 0.290884\n",
      "Iteration 2519, loss = 32.91993149\n",
      "Validation score: 0.292125\n",
      "Iteration 2520, loss = 32.88282036\n",
      "Validation score: 0.293364\n",
      "Iteration 2521, loss = 32.84363782\n",
      "Validation score: 0.294551\n",
      "Iteration 2522, loss = 32.80703489\n",
      "Validation score: 0.295673\n",
      "Iteration 2523, loss = 32.76765573\n",
      "Validation score: 0.296842\n",
      "Iteration 2524, loss = 32.73539840\n",
      "Validation score: 0.298042\n",
      "Iteration 2525, loss = 32.69662739\n",
      "Validation score: 0.299242\n",
      "Iteration 2526, loss = 32.66174759\n",
      "Validation score: 0.300420\n",
      "Iteration 2527, loss = 32.62227064\n",
      "Validation score: 0.301564\n",
      "Iteration 2528, loss = 32.58573146\n",
      "Validation score: 0.302774\n",
      "Iteration 2529, loss = 32.55015584\n",
      "Validation score: 0.303983\n",
      "Iteration 2530, loss = 32.51365950\n",
      "Validation score: 0.305195\n",
      "Iteration 2531, loss = 32.47786095\n",
      "Validation score: 0.306369\n",
      "Iteration 2532, loss = 32.44392795\n",
      "Validation score: 0.307501\n",
      "Iteration 2533, loss = 32.41140685\n",
      "Validation score: 0.308565\n",
      "Iteration 2534, loss = 32.37165284\n",
      "Validation score: 0.309629\n",
      "Iteration 2535, loss = 32.33768180\n",
      "Validation score: 0.310758\n",
      "Iteration 2536, loss = 32.30414376\n",
      "Validation score: 0.311879\n",
      "Iteration 2537, loss = 32.26853074\n",
      "Validation score: 0.312963\n",
      "Iteration 2538, loss = 32.23395913\n",
      "Validation score: 0.314070\n",
      "Iteration 2539, loss = 32.20002519\n",
      "Validation score: 0.315179\n",
      "Iteration 2540, loss = 32.16463894\n",
      "Validation score: 0.316270\n",
      "Iteration 2541, loss = 32.13174695\n",
      "Validation score: 0.317380\n",
      "Iteration 2542, loss = 32.09980439\n",
      "Validation score: 0.318537\n",
      "Iteration 2543, loss = 32.06325671\n",
      "Validation score: 0.319627\n",
      "Iteration 2544, loss = 32.03035836\n",
      "Validation score: 0.320713\n",
      "Iteration 2545, loss = 31.99619235\n",
      "Validation score: 0.321786\n",
      "Iteration 2546, loss = 31.96283028\n",
      "Validation score: 0.322924\n",
      "Iteration 2547, loss = 31.92865135\n",
      "Validation score: 0.323996\n",
      "Iteration 2548, loss = 31.89802363\n",
      "Validation score: 0.325101\n",
      "Iteration 2549, loss = 31.86395746\n",
      "Validation score: 0.326172\n",
      "Iteration 2550, loss = 31.82998056\n",
      "Validation score: 0.327224\n",
      "Iteration 2551, loss = 31.79825968\n",
      "Validation score: 0.328245\n",
      "Iteration 2552, loss = 31.76325022\n",
      "Validation score: 0.329288\n",
      "Iteration 2553, loss = 31.73162771\n",
      "Validation score: 0.330347\n",
      "Iteration 2554, loss = 31.69880299\n",
      "Validation score: 0.331395\n",
      "Iteration 2555, loss = 31.66890029\n",
      "Validation score: 0.332444\n",
      "Iteration 2556, loss = 31.63556522\n",
      "Validation score: 0.333540\n",
      "Iteration 2557, loss = 31.60444916\n",
      "Validation score: 0.334680\n",
      "Iteration 2558, loss = 31.57034371\n",
      "Validation score: 0.335756\n",
      "Iteration 2559, loss = 31.54116684\n",
      "Validation score: 0.336825\n",
      "Iteration 2560, loss = 31.50833138\n",
      "Validation score: 0.337831\n",
      "Iteration 2561, loss = 31.47700701\n",
      "Validation score: 0.338862\n",
      "Iteration 2562, loss = 31.44486306\n",
      "Validation score: 0.339951\n",
      "Iteration 2563, loss = 31.41226620\n",
      "Validation score: 0.340989\n",
      "Iteration 2564, loss = 31.38328761\n",
      "Validation score: 0.342024\n",
      "Iteration 2565, loss = 31.35052197\n",
      "Validation score: 0.343062\n",
      "Iteration 2566, loss = 31.31940728\n",
      "Validation score: 0.344120\n",
      "Iteration 2567, loss = 31.28917226\n",
      "Validation score: 0.345148\n",
      "Iteration 2568, loss = 31.25799453\n",
      "Validation score: 0.346147\n",
      "Iteration 2569, loss = 31.22815954\n",
      "Validation score: 0.347152\n",
      "Iteration 2570, loss = 31.19882829\n",
      "Validation score: 0.348169\n",
      "Iteration 2571, loss = 31.17032454\n",
      "Validation score: 0.349210\n",
      "Iteration 2572, loss = 31.13706150\n",
      "Validation score: 0.350167\n",
      "Iteration 2573, loss = 31.11113071\n",
      "Validation score: 0.351118\n",
      "Iteration 2574, loss = 31.07937613\n",
      "Validation score: 0.352131\n",
      "Iteration 2575, loss = 31.04901958\n",
      "Validation score: 0.353118\n",
      "Iteration 2576, loss = 31.01943044\n",
      "Validation score: 0.354070\n",
      "Iteration 2577, loss = 30.99076312\n",
      "Validation score: 0.355071\n",
      "Iteration 2578, loss = 30.96410228\n",
      "Validation score: 0.356004\n",
      "Iteration 2579, loss = 30.93158710\n",
      "Validation score: 0.356960\n",
      "Iteration 2580, loss = 30.90512501\n",
      "Validation score: 0.357945\n",
      "Iteration 2581, loss = 30.87828340\n",
      "Validation score: 0.358903\n",
      "Iteration 2582, loss = 30.85080803\n",
      "Validation score: 0.359851\n",
      "Iteration 2583, loss = 30.82312836\n",
      "Validation score: 0.360808\n",
      "Iteration 2584, loss = 30.79511165\n",
      "Validation score: 0.361714\n",
      "Iteration 2585, loss = 30.77060114\n",
      "Validation score: 0.362619\n",
      "Iteration 2586, loss = 30.73824643\n",
      "Validation score: 0.363561\n",
      "Iteration 2587, loss = 30.71060129\n",
      "Validation score: 0.364495\n",
      "Iteration 2588, loss = 30.68154508\n",
      "Validation score: 0.365384\n",
      "Iteration 2589, loss = 30.65389347\n",
      "Validation score: 0.366237\n",
      "Iteration 2590, loss = 30.62709515\n",
      "Validation score: 0.367178\n",
      "Iteration 2591, loss = 30.59856778\n",
      "Validation score: 0.368069\n",
      "Iteration 2592, loss = 30.57133884\n",
      "Validation score: 0.368965\n",
      "Iteration 2593, loss = 30.54607428\n",
      "Validation score: 0.369853\n",
      "Iteration 2594, loss = 30.51870306\n",
      "Validation score: 0.370773\n",
      "Iteration 2595, loss = 30.49273893\n",
      "Validation score: 0.371690\n",
      "Iteration 2596, loss = 30.46435027\n",
      "Validation score: 0.372593\n",
      "Iteration 2597, loss = 30.44250237\n",
      "Validation score: 0.373421\n",
      "Iteration 2598, loss = 30.41164901\n",
      "Validation score: 0.374300\n",
      "Iteration 2599, loss = 30.38355090\n",
      "Validation score: 0.375180\n",
      "Iteration 2600, loss = 30.36127688\n",
      "Validation score: 0.376131\n",
      "Iteration 2601, loss = 30.33488892\n",
      "Validation score: 0.377012\n",
      "Iteration 2602, loss = 30.30875944\n",
      "Validation score: 0.377876\n",
      "Iteration 2603, loss = 30.28083650\n",
      "Validation score: 0.378768\n",
      "Iteration 2604, loss = 30.25379215\n",
      "Validation score: 0.379638\n",
      "Iteration 2605, loss = 30.23036234\n",
      "Validation score: 0.380526\n",
      "Iteration 2606, loss = 30.20241012\n",
      "Validation score: 0.381422\n",
      "Iteration 2607, loss = 30.17611473\n",
      "Validation score: 0.382299\n",
      "Iteration 2608, loss = 30.15150063\n",
      "Validation score: 0.383130\n",
      "Iteration 2609, loss = 30.12692773\n",
      "Validation score: 0.383963\n",
      "Iteration 2610, loss = 30.10122894\n",
      "Validation score: 0.384805\n",
      "Iteration 2611, loss = 30.07691598\n",
      "Validation score: 0.385629\n",
      "Iteration 2612, loss = 30.05265316\n",
      "Validation score: 0.386456\n",
      "Iteration 2613, loss = 30.02691346\n",
      "Validation score: 0.387272\n",
      "Iteration 2614, loss = 30.00350326\n",
      "Validation score: 0.388099\n",
      "Iteration 2615, loss = 29.97890083\n",
      "Validation score: 0.388940\n",
      "Iteration 2616, loss = 29.95376601\n",
      "Validation score: 0.389768\n",
      "Iteration 2617, loss = 29.92959788\n",
      "Validation score: 0.390543\n",
      "Iteration 2618, loss = 29.90561419\n",
      "Validation score: 0.391338\n",
      "Iteration 2619, loss = 29.88562776\n",
      "Validation score: 0.392239\n",
      "Iteration 2620, loss = 29.85505660\n",
      "Validation score: 0.393116\n",
      "Iteration 2621, loss = 29.82902616\n",
      "Validation score: 0.393955\n",
      "Iteration 2622, loss = 29.80437844\n",
      "Validation score: 0.394797\n",
      "Iteration 2623, loss = 29.78364226\n",
      "Validation score: 0.395658\n",
      "Iteration 2624, loss = 29.75770599\n",
      "Validation score: 0.396484\n",
      "Iteration 2625, loss = 29.73331235\n",
      "Validation score: 0.397300\n",
      "Iteration 2626, loss = 29.71218376\n",
      "Validation score: 0.398136\n",
      "Iteration 2627, loss = 29.68761519\n",
      "Validation score: 0.398964\n",
      "Iteration 2628, loss = 29.66153561\n",
      "Validation score: 0.399775\n",
      "Iteration 2629, loss = 29.63978526\n",
      "Validation score: 0.400614\n",
      "Iteration 2630, loss = 29.61514844\n",
      "Validation score: 0.401413\n",
      "Iteration 2631, loss = 29.59323426\n",
      "Validation score: 0.402198\n",
      "Iteration 2632, loss = 29.57478127\n",
      "Validation score: 0.402973\n",
      "Iteration 2633, loss = 29.54609491\n",
      "Validation score: 0.403783\n",
      "Iteration 2634, loss = 29.52196376\n",
      "Validation score: 0.404596\n",
      "Iteration 2635, loss = 29.50037883\n",
      "Validation score: 0.405415\n",
      "Iteration 2636, loss = 29.47745816\n",
      "Validation score: 0.406155\n",
      "Iteration 2637, loss = 29.45770084\n",
      "Validation score: 0.406990\n",
      "Iteration 2638, loss = 29.43654999\n",
      "Validation score: 0.407773\n",
      "Iteration 2639, loss = 29.40846627\n",
      "Validation score: 0.408515\n",
      "Iteration 2640, loss = 29.38756455\n",
      "Validation score: 0.409256\n",
      "Iteration 2641, loss = 29.36483725\n",
      "Validation score: 0.410008\n",
      "Iteration 2642, loss = 29.34480429\n",
      "Validation score: 0.410787\n",
      "Iteration 2643, loss = 29.31982027\n",
      "Validation score: 0.411557\n",
      "Iteration 2644, loss = 29.29789067\n",
      "Validation score: 0.412301\n",
      "Iteration 2645, loss = 29.27848025\n",
      "Validation score: 0.413048\n",
      "Iteration 2646, loss = 29.25401558\n",
      "Validation score: 0.413776\n",
      "Iteration 2647, loss = 29.23343912\n",
      "Validation score: 0.414511\n",
      "Iteration 2648, loss = 29.21171637\n",
      "Validation score: 0.415287\n",
      "Iteration 2649, loss = 29.18901835\n",
      "Validation score: 0.416026\n",
      "Iteration 2650, loss = 29.16745564\n",
      "Validation score: 0.416752\n",
      "Iteration 2651, loss = 29.14599996\n",
      "Validation score: 0.417489\n",
      "Iteration 2652, loss = 29.12490097\n",
      "Validation score: 0.418188\n",
      "Iteration 2653, loss = 29.10382676\n",
      "Validation score: 0.418895\n",
      "Iteration 2654, loss = 29.08264494\n",
      "Validation score: 0.419588\n",
      "Iteration 2655, loss = 29.06113376\n",
      "Validation score: 0.420326\n",
      "Iteration 2656, loss = 29.04094609\n",
      "Validation score: 0.421040\n",
      "Iteration 2657, loss = 29.02007143\n",
      "Validation score: 0.421721\n",
      "Iteration 2658, loss = 28.99814715\n",
      "Validation score: 0.422404\n",
      "Iteration 2659, loss = 28.97826865\n",
      "Validation score: 0.423154\n",
      "Iteration 2660, loss = 28.95956158\n",
      "Validation score: 0.423906\n",
      "Iteration 2661, loss = 28.93762474\n",
      "Validation score: 0.424625\n",
      "Iteration 2662, loss = 28.91575488\n",
      "Validation score: 0.425374\n",
      "Iteration 2663, loss = 28.89520907\n",
      "Validation score: 0.426062\n",
      "Iteration 2664, loss = 28.87436132\n",
      "Validation score: 0.426801\n",
      "Iteration 2665, loss = 28.85589765\n",
      "Validation score: 0.427524\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 2666, loss = 28.83462405\n",
      "Validation score: 0.428206\n",
      "Iteration 2667, loss = 28.81382529\n",
      "Validation score: 0.428910\n",
      "Iteration 2668, loss = 28.79595821\n",
      "Validation score: 0.429614\n",
      "Iteration 2669, loss = 28.77845079\n",
      "Validation score: 0.430293\n",
      "Iteration 2670, loss = 28.75634362\n",
      "Validation score: 0.430948\n",
      "Iteration 2671, loss = 28.73622447\n",
      "Validation score: 0.431614\n",
      "Iteration 2672, loss = 28.71615778\n",
      "Validation score: 0.432301\n",
      "Iteration 2673, loss = 28.69686813\n",
      "Validation score: 0.432991\n",
      "Iteration 2674, loss = 28.67729542\n",
      "Validation score: 0.433676\n",
      "Iteration 2675, loss = 28.65830665\n",
      "Validation score: 0.434331\n",
      "Iteration 2676, loss = 28.64190673\n",
      "Validation score: 0.435033\n",
      "Iteration 2677, loss = 28.62413627\n",
      "Validation score: 0.435760\n",
      "Iteration 2678, loss = 28.60111019\n",
      "Validation score: 0.436400\n",
      "Iteration 2679, loss = 28.57874076\n",
      "Validation score: 0.437061\n",
      "Iteration 2680, loss = 28.55944244\n",
      "Validation score: 0.437715\n",
      "Iteration 2681, loss = 28.53998606\n",
      "Validation score: 0.438380\n",
      "Iteration 2682, loss = 28.52137994\n",
      "Validation score: 0.439036\n",
      "Iteration 2683, loss = 28.50062299\n",
      "Validation score: 0.439670\n",
      "Iteration 2684, loss = 28.48342073\n",
      "Validation score: 0.440298\n",
      "Iteration 2685, loss = 28.46401783\n",
      "Validation score: 0.440941\n",
      "Iteration 2686, loss = 28.45154568\n",
      "Validation score: 0.441642\n",
      "Iteration 2687, loss = 28.42649315\n",
      "Validation score: 0.442333\n",
      "Iteration 2688, loss = 28.40711302\n",
      "Validation score: 0.442950\n",
      "Iteration 2689, loss = 28.38823993\n",
      "Validation score: 0.443570\n",
      "Iteration 2690, loss = 28.36926895\n",
      "Validation score: 0.444190\n",
      "Iteration 2691, loss = 28.35292798\n",
      "Validation score: 0.444828\n",
      "Iteration 2692, loss = 28.33457863\n",
      "Validation score: 0.445408\n",
      "Iteration 2693, loss = 28.31494258\n",
      "Validation score: 0.446051\n",
      "Iteration 2694, loss = 28.29831549\n",
      "Validation score: 0.446657\n",
      "Iteration 2695, loss = 28.27831556\n",
      "Validation score: 0.447289\n",
      "Iteration 2696, loss = 28.26196741\n",
      "Validation score: 0.447929\n",
      "Iteration 2697, loss = 28.24435001\n",
      "Validation score: 0.448551\n",
      "Iteration 2698, loss = 28.22679940\n",
      "Validation score: 0.449156\n",
      "Iteration 2699, loss = 28.21121954\n",
      "Validation score: 0.449750\n",
      "Iteration 2700, loss = 28.19132775\n",
      "Validation score: 0.450355\n",
      "Iteration 2701, loss = 28.17150260\n",
      "Validation score: 0.450965\n",
      "Iteration 2702, loss = 28.15357119\n",
      "Validation score: 0.451513\n",
      "Iteration 2703, loss = 28.13741356\n",
      "Validation score: 0.452134\n",
      "Iteration 2704, loss = 28.11702777\n",
      "Validation score: 0.452755\n",
      "Iteration 2705, loss = 28.09930726\n",
      "Validation score: 0.453371\n",
      "Iteration 2706, loss = 28.08025559\n",
      "Validation score: 0.453958\n",
      "Iteration 2707, loss = 28.06387326\n",
      "Validation score: 0.454519\n",
      "Iteration 2708, loss = 28.05028242\n",
      "Validation score: 0.455027\n",
      "Iteration 2709, loss = 28.03318178\n",
      "Validation score: 0.455537\n",
      "Iteration 2710, loss = 28.01315051\n",
      "Validation score: 0.456215\n",
      "Iteration 2711, loss = 27.99643535\n",
      "Validation score: 0.456828\n",
      "Iteration 2712, loss = 27.97669579\n",
      "Validation score: 0.457436\n",
      "Iteration 2713, loss = 27.96019481\n",
      "Validation score: 0.458069\n",
      "Iteration 2714, loss = 27.94278530\n",
      "Validation score: 0.458693\n",
      "Iteration 2715, loss = 27.92650835\n",
      "Validation score: 0.459265\n",
      "Iteration 2716, loss = 27.90763833\n",
      "Validation score: 0.459875\n",
      "Iteration 2717, loss = 27.89567302\n",
      "Validation score: 0.460494\n",
      "Iteration 2718, loss = 27.87571099\n",
      "Validation score: 0.461058\n",
      "Iteration 2719, loss = 27.86266757\n",
      "Validation score: 0.461657\n",
      "Iteration 2720, loss = 27.84031901\n",
      "Validation score: 0.462226\n",
      "Iteration 2721, loss = 27.82482545\n",
      "Validation score: 0.462824\n",
      "Iteration 2722, loss = 27.80819043\n",
      "Validation score: 0.463423\n",
      "Iteration 2723, loss = 27.79139011\n",
      "Validation score: 0.464027\n",
      "Iteration 2724, loss = 27.77421383\n",
      "Validation score: 0.464568\n",
      "Iteration 2725, loss = 27.75818523\n",
      "Validation score: 0.465188\n",
      "Iteration 2726, loss = 27.74249607\n",
      "Validation score: 0.465795\n",
      "Iteration 2727, loss = 27.72755631\n",
      "Validation score: 0.466351\n",
      "Iteration 2728, loss = 27.70817765\n",
      "Validation score: 0.466938\n",
      "Iteration 2729, loss = 27.69478126\n",
      "Validation score: 0.467514\n",
      "Iteration 2730, loss = 27.67799426\n",
      "Validation score: 0.468053\n",
      "Iteration 2731, loss = 27.66157612\n",
      "Validation score: 0.468667\n",
      "Iteration 2732, loss = 27.64300792\n",
      "Validation score: 0.469158\n",
      "Iteration 2733, loss = 27.62969595\n",
      "Validation score: 0.469676\n",
      "Iteration 2734, loss = 27.61768759\n",
      "Validation score: 0.470302\n",
      "Iteration 2735, loss = 27.59762972\n",
      "Validation score: 0.470873\n",
      "Iteration 2736, loss = 27.58177439\n",
      "Validation score: 0.471401\n",
      "Iteration 2737, loss = 27.56610537\n",
      "Validation score: 0.471901\n",
      "Iteration 2738, loss = 27.54984730\n",
      "Validation score: 0.472432\n",
      "Iteration 2739, loss = 27.53461608\n",
      "Validation score: 0.473011\n",
      "Iteration 2740, loss = 27.51865403\n",
      "Validation score: 0.473598\n",
      "Iteration 2741, loss = 27.50323479\n",
      "Validation score: 0.474156\n",
      "Iteration 2742, loss = 27.48708034\n",
      "Validation score: 0.474630\n",
      "Iteration 2743, loss = 27.47235546\n",
      "Validation score: 0.475174\n",
      "Iteration 2744, loss = 27.45766020\n",
      "Validation score: 0.475707\n",
      "Iteration 2745, loss = 27.44351424\n",
      "Validation score: 0.476235\n",
      "Iteration 2746, loss = 27.42603930\n",
      "Validation score: 0.476753\n",
      "Iteration 2747, loss = 27.41074564\n",
      "Validation score: 0.477314\n",
      "Iteration 2748, loss = 27.39823765\n",
      "Validation score: 0.477894\n",
      "Iteration 2749, loss = 27.38364288\n",
      "Validation score: 0.478360\n",
      "Iteration 2750, loss = 27.36466739\n",
      "Validation score: 0.478873\n",
      "Iteration 2751, loss = 27.34967928\n",
      "Validation score: 0.479410\n",
      "Iteration 2752, loss = 27.33478414\n",
      "Validation score: 0.479928\n",
      "Iteration 2753, loss = 27.32012482\n",
      "Validation score: 0.480412\n",
      "Iteration 2754, loss = 27.30611220\n",
      "Validation score: 0.480889\n",
      "Iteration 2755, loss = 27.29082812\n",
      "Validation score: 0.481485\n",
      "Iteration 2756, loss = 27.27377065\n",
      "Validation score: 0.482020\n",
      "Iteration 2757, loss = 27.26016454\n",
      "Validation score: 0.482508\n",
      "Iteration 2758, loss = 27.24332335\n",
      "Validation score: 0.483107\n",
      "Iteration 2759, loss = 27.22781270\n",
      "Validation score: 0.483648\n",
      "Iteration 2760, loss = 27.21368958\n",
      "Validation score: 0.484161\n",
      "Iteration 2761, loss = 27.20337428\n",
      "Validation score: 0.484714\n",
      "Iteration 2762, loss = 27.18626371\n",
      "Validation score: 0.485191\n",
      "Iteration 2763, loss = 27.17041148\n",
      "Validation score: 0.485668\n",
      "Iteration 2764, loss = 27.15681323\n",
      "Validation score: 0.486154\n",
      "Iteration 2765, loss = 27.14401918\n",
      "Validation score: 0.486641\n",
      "Iteration 2766, loss = 27.12862162\n",
      "Validation score: 0.487140\n",
      "Iteration 2767, loss = 27.11479082\n",
      "Validation score: 0.487656\n",
      "Iteration 2768, loss = 27.09828364\n",
      "Validation score: 0.488104\n",
      "Iteration 2769, loss = 27.08400123\n",
      "Validation score: 0.488602\n",
      "Iteration 2770, loss = 27.07001119\n",
      "Validation score: 0.489092\n",
      "Iteration 2771, loss = 27.05604113\n",
      "Validation score: 0.489562\n",
      "Iteration 2772, loss = 27.04121046\n",
      "Validation score: 0.490095\n",
      "Iteration 2773, loss = 27.02780613\n",
      "Validation score: 0.490621\n",
      "Iteration 2774, loss = 27.01333774\n",
      "Validation score: 0.491131\n",
      "Iteration 2775, loss = 26.99960585\n",
      "Validation score: 0.491588\n",
      "Iteration 2776, loss = 26.98429006\n",
      "Validation score: 0.492108\n",
      "Iteration 2777, loss = 26.97209590\n",
      "Validation score: 0.492621\n",
      "Iteration 2778, loss = 26.95910666\n",
      "Validation score: 0.493097\n",
      "Iteration 2779, loss = 26.94274088\n",
      "Validation score: 0.493591\n",
      "Iteration 2780, loss = 26.92954934\n",
      "Validation score: 0.494095\n",
      "Iteration 2781, loss = 26.91529506\n",
      "Validation score: 0.494538\n",
      "Iteration 2782, loss = 26.90107785\n",
      "Validation score: 0.495017\n",
      "Iteration 2783, loss = 26.88760989\n",
      "Validation score: 0.495470\n",
      "Iteration 2784, loss = 26.87329476\n",
      "Validation score: 0.495995\n",
      "Iteration 2785, loss = 26.86050440\n",
      "Validation score: 0.496521\n",
      "Iteration 2786, loss = 26.84704452\n",
      "Validation score: 0.496952\n",
      "Iteration 2787, loss = 26.83262007\n",
      "Validation score: 0.497464\n",
      "Iteration 2788, loss = 26.81769871\n",
      "Validation score: 0.497924\n",
      "Iteration 2789, loss = 26.80510861\n",
      "Validation score: 0.498413\n",
      "Iteration 2790, loss = 26.79200298\n",
      "Validation score: 0.498929\n",
      "Iteration 2791, loss = 26.77769791\n",
      "Validation score: 0.499387\n",
      "Iteration 2792, loss = 26.76494445\n",
      "Validation score: 0.499837\n",
      "Iteration 2793, loss = 26.75181245\n",
      "Validation score: 0.500246\n",
      "Iteration 2794, loss = 26.73834239\n",
      "Validation score: 0.500601\n",
      "Iteration 2795, loss = 26.72455822\n",
      "Validation score: 0.500990\n",
      "Iteration 2796, loss = 26.71072727\n",
      "Validation score: 0.501467\n",
      "Iteration 2797, loss = 26.69669297\n",
      "Validation score: 0.501897\n",
      "Iteration 2798, loss = 26.68433295\n",
      "Validation score: 0.502285\n",
      "Iteration 2799, loss = 26.67034538\n",
      "Validation score: 0.502752\n",
      "Iteration 2800, loss = 26.65779146\n",
      "Validation score: 0.503256\n",
      "Iteration 2801, loss = 26.64583009\n",
      "Validation score: 0.503712\n",
      "Iteration 2802, loss = 26.63166399\n",
      "Validation score: 0.504149\n",
      "Iteration 2803, loss = 26.62020676\n",
      "Validation score: 0.504537\n",
      "Iteration 2804, loss = 26.60597547\n",
      "Validation score: 0.504981\n",
      "Iteration 2805, loss = 26.59437310\n",
      "Validation score: 0.505496\n",
      "Iteration 2806, loss = 26.58027394\n",
      "Validation score: 0.505944\n",
      "Iteration 2807, loss = 26.56833113\n",
      "Validation score: 0.506337\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 2808, loss = 26.55609665\n",
      "Validation score: 0.506735\n",
      "Iteration 2809, loss = 26.54435642\n",
      "Validation score: 0.507080\n",
      "Iteration 2810, loss = 26.52924154\n",
      "Validation score: 0.507628\n",
      "Iteration 2811, loss = 26.51505841\n",
      "Validation score: 0.508083\n",
      "Iteration 2812, loss = 26.50417531\n",
      "Validation score: 0.508552\n",
      "Iteration 2813, loss = 26.49136452\n",
      "Validation score: 0.508969\n",
      "Iteration 2814, loss = 26.48040680\n",
      "Validation score: 0.509377\n",
      "Iteration 2815, loss = 26.46901220\n",
      "Validation score: 0.509730\n",
      "Iteration 2816, loss = 26.45317365\n",
      "Validation score: 0.510182\n",
      "Iteration 2817, loss = 26.43994852\n",
      "Validation score: 0.510579\n",
      "Iteration 2818, loss = 26.42861133\n",
      "Validation score: 0.510999\n",
      "Iteration 2819, loss = 26.41511132\n",
      "Validation score: 0.511314\n",
      "Iteration 2820, loss = 26.40392143\n",
      "Validation score: 0.511694\n",
      "Iteration 2821, loss = 26.39179519\n",
      "Validation score: 0.512034\n",
      "Iteration 2822, loss = 26.38056091\n",
      "Validation score: 0.512410\n",
      "Iteration 2823, loss = 26.36872815\n",
      "Validation score: 0.512785\n",
      "Iteration 2824, loss = 26.35591118\n",
      "Validation score: 0.513140\n",
      "Iteration 2825, loss = 26.34278988\n",
      "Validation score: 0.513484\n",
      "Iteration 2826, loss = 26.33238570\n",
      "Validation score: 0.513827\n",
      "Iteration 2827, loss = 26.32111114\n",
      "Validation score: 0.514309\n",
      "Iteration 2828, loss = 26.30912479\n",
      "Validation score: 0.514653\n",
      "Iteration 2829, loss = 26.29540879\n",
      "Validation score: 0.515040\n",
      "Iteration 2830, loss = 26.28310093\n",
      "Validation score: 0.515474\n",
      "Iteration 2831, loss = 26.26971031\n",
      "Validation score: 0.515912\n",
      "Iteration 2832, loss = 26.25733280\n",
      "Validation score: 0.516403\n",
      "Iteration 2833, loss = 26.24409653\n",
      "Validation score: 0.516814\n",
      "Iteration 2834, loss = 26.23155123\n",
      "Validation score: 0.517295\n",
      "Iteration 2835, loss = 26.21834703\n",
      "Validation score: 0.517777\n",
      "Iteration 2836, loss = 26.20679196\n",
      "Validation score: 0.518238\n",
      "Iteration 2837, loss = 26.19692621\n",
      "Validation score: 0.518687\n",
      "Iteration 2838, loss = 26.18325098\n",
      "Validation score: 0.519017\n",
      "Iteration 2839, loss = 26.17105477\n",
      "Validation score: 0.519368\n",
      "Iteration 2840, loss = 26.15956041\n",
      "Validation score: 0.519748\n",
      "Iteration 2841, loss = 26.14479805\n",
      "Validation score: 0.520268\n",
      "Iteration 2842, loss = 26.13380261\n",
      "Validation score: 0.520697\n",
      "Iteration 2843, loss = 26.12560163\n",
      "Validation score: 0.521154\n",
      "Iteration 2844, loss = 26.11342714\n",
      "Validation score: 0.521630\n",
      "Iteration 2845, loss = 26.10153148\n",
      "Validation score: 0.522051\n",
      "Iteration 2846, loss = 26.09274374\n",
      "Validation score: 0.522430\n",
      "Iteration 2847, loss = 26.07647963\n",
      "Validation score: 0.522816\n",
      "Iteration 2848, loss = 26.06431380\n",
      "Validation score: 0.523195\n",
      "Iteration 2849, loss = 26.05363677\n",
      "Validation score: 0.523586\n",
      "Iteration 2850, loss = 26.04391520\n",
      "Validation score: 0.523935\n",
      "Iteration 2851, loss = 26.03112159\n",
      "Validation score: 0.524380\n",
      "Iteration 2852, loss = 26.01825592\n",
      "Validation score: 0.524779\n",
      "Iteration 2853, loss = 26.00791706\n",
      "Validation score: 0.525168\n",
      "Iteration 2854, loss = 25.99785931\n",
      "Validation score: 0.525586\n",
      "Iteration 2855, loss = 25.98286976\n",
      "Validation score: 0.526057\n",
      "Iteration 2856, loss = 25.97322495\n",
      "Validation score: 0.526496\n",
      "Iteration 2857, loss = 25.96219418\n",
      "Validation score: 0.526925\n",
      "Iteration 2858, loss = 25.95097643\n",
      "Validation score: 0.527359\n",
      "Iteration 2859, loss = 25.94381988\n",
      "Validation score: 0.527776\n",
      "Iteration 2860, loss = 25.92921262\n",
      "Validation score: 0.528214\n",
      "Iteration 2861, loss = 25.91810379\n",
      "Validation score: 0.528637\n",
      "Iteration 2862, loss = 25.90588225\n",
      "Validation score: 0.529015\n",
      "Iteration 2863, loss = 25.89431983\n",
      "Validation score: 0.529327\n",
      "Iteration 2864, loss = 25.88866723\n",
      "Validation score: 0.529587\n",
      "Iteration 2865, loss = 25.87728740\n",
      "Validation score: 0.530107\n",
      "Iteration 2866, loss = 25.86224448\n",
      "Validation score: 0.530430\n",
      "Iteration 2867, loss = 25.85094312\n",
      "Validation score: 0.530815\n",
      "Iteration 2868, loss = 25.83981032\n",
      "Validation score: 0.531228\n",
      "Iteration 2869, loss = 25.82955685\n",
      "Validation score: 0.531644\n",
      "Iteration 2870, loss = 25.81849373\n",
      "Validation score: 0.531988\n",
      "Iteration 2871, loss = 25.80913652\n",
      "Validation score: 0.532405\n",
      "Iteration 2872, loss = 25.79897764\n",
      "Validation score: 0.532768\n",
      "Iteration 2873, loss = 25.78892797\n",
      "Validation score: 0.533039\n",
      "Iteration 2874, loss = 25.77586182\n",
      "Validation score: 0.533335\n",
      "Iteration 2875, loss = 25.76575613\n",
      "Validation score: 0.533666\n",
      "Iteration 2876, loss = 25.75758935\n",
      "Validation score: 0.533935\n",
      "Iteration 2877, loss = 25.74343123\n",
      "Validation score: 0.534305\n",
      "Iteration 2878, loss = 25.73421273\n",
      "Validation score: 0.534556\n",
      "Iteration 2879, loss = 25.72204278\n",
      "Validation score: 0.534950\n",
      "Iteration 2880, loss = 25.71281323\n",
      "Validation score: 0.535350\n",
      "Iteration 2881, loss = 25.70266034\n",
      "Validation score: 0.535708\n",
      "Iteration 2882, loss = 25.69157911\n",
      "Validation score: 0.535962\n",
      "Iteration 2883, loss = 25.67983019\n",
      "Validation score: 0.536268\n",
      "Iteration 2884, loss = 25.67162770\n",
      "Validation score: 0.536593\n",
      "Iteration 2885, loss = 25.66093274\n",
      "Validation score: 0.536997\n",
      "Iteration 2886, loss = 25.65135980\n",
      "Validation score: 0.537295\n",
      "Iteration 2887, loss = 25.64181042\n",
      "Validation score: 0.537770\n",
      "Iteration 2888, loss = 25.63105496\n",
      "Validation score: 0.538138\n",
      "Iteration 2889, loss = 25.62030374\n",
      "Validation score: 0.538415\n",
      "Iteration 2890, loss = 25.61134458\n",
      "Validation score: 0.538690\n",
      "Iteration 2891, loss = 25.60139273\n",
      "Validation score: 0.539049\n",
      "Iteration 2892, loss = 25.59156155\n",
      "Validation score: 0.539293\n",
      "Iteration 2893, loss = 25.58144605\n",
      "Validation score: 0.539710\n",
      "Iteration 2894, loss = 25.57019123\n",
      "Validation score: 0.540038\n",
      "Iteration 2895, loss = 25.56199853\n",
      "Validation score: 0.540314\n",
      "Iteration 2896, loss = 25.55011289\n",
      "Validation score: 0.540640\n",
      "Iteration 2897, loss = 25.54018743\n",
      "Validation score: 0.541019\n",
      "Iteration 2898, loss = 25.53120708\n",
      "Validation score: 0.541345\n",
      "Iteration 2899, loss = 25.52038203\n",
      "Validation score: 0.541801\n",
      "Iteration 2900, loss = 25.50971712\n",
      "Validation score: 0.542168\n",
      "Iteration 2901, loss = 25.50194315\n",
      "Validation score: 0.542550\n",
      "Iteration 2902, loss = 25.49163203\n",
      "Validation score: 0.542878\n",
      "Iteration 2903, loss = 25.48044187\n",
      "Validation score: 0.543303\n",
      "Iteration 2904, loss = 25.47180597\n",
      "Validation score: 0.543666\n",
      "Iteration 2905, loss = 25.46130082\n",
      "Validation score: 0.543943\n",
      "Iteration 2906, loss = 25.45091818\n",
      "Validation score: 0.544204\n",
      "Iteration 2907, loss = 25.44459778\n",
      "Validation score: 0.544582\n",
      "Iteration 2908, loss = 25.43228866\n",
      "Validation score: 0.544743\n",
      "Iteration 2909, loss = 25.42415761\n",
      "Validation score: 0.544733\n",
      "Iteration 2910, loss = 25.41934426\n",
      "Validation score: 0.544827\n",
      "Iteration 2911, loss = 25.41132672\n",
      "Validation score: 0.545254\n",
      "Iteration 2912, loss = 25.39421920\n",
      "Validation score: 0.545641\n",
      "Iteration 2913, loss = 25.38343328\n",
      "Validation score: 0.546100\n",
      "Iteration 2914, loss = 25.37470472\n",
      "Validation score: 0.546509\n",
      "Iteration 2915, loss = 25.36794360\n",
      "Validation score: 0.546813\n",
      "Iteration 2916, loss = 25.35579463\n",
      "Validation score: 0.547071\n",
      "Iteration 2917, loss = 25.34588416\n",
      "Validation score: 0.547345\n",
      "Iteration 2918, loss = 25.33674906\n",
      "Validation score: 0.547591\n",
      "Iteration 2919, loss = 25.32757418\n",
      "Validation score: 0.547923\n",
      "Iteration 2920, loss = 25.31778558\n",
      "Validation score: 0.548285\n",
      "Iteration 2921, loss = 25.31885968\n",
      "Validation score: 0.548695\n",
      "Iteration 2922, loss = 25.29922195\n",
      "Validation score: 0.548899\n",
      "Iteration 2923, loss = 25.29376958\n",
      "Validation score: 0.549090\n",
      "Iteration 2924, loss = 25.28077420\n",
      "Validation score: 0.549418\n",
      "Iteration 2925, loss = 25.27567255\n",
      "Validation score: 0.549824\n",
      "Iteration 2926, loss = 25.26392338\n",
      "Validation score: 0.550001\n",
      "Iteration 2927, loss = 25.25293545\n",
      "Validation score: 0.550300\n",
      "Iteration 2928, loss = 25.24372603\n",
      "Validation score: 0.550576\n",
      "Iteration 2929, loss = 25.23507829\n",
      "Validation score: 0.550962\n",
      "Iteration 2930, loss = 25.22725484\n",
      "Validation score: 0.551213\n",
      "Iteration 2931, loss = 25.21643312\n",
      "Validation score: 0.551512\n",
      "Iteration 2932, loss = 25.20678807\n",
      "Validation score: 0.551864\n",
      "Iteration 2933, loss = 25.19987458\n",
      "Validation score: 0.552240\n",
      "Iteration 2934, loss = 25.18902343\n",
      "Validation score: 0.552508\n",
      "Iteration 2935, loss = 25.18233222\n",
      "Validation score: 0.552837\n",
      "Iteration 2936, loss = 25.17348845\n",
      "Validation score: 0.553013\n",
      "Iteration 2937, loss = 25.16404846\n",
      "Validation score: 0.553280\n",
      "Iteration 2938, loss = 25.15485185\n",
      "Validation score: 0.553588\n",
      "Iteration 2939, loss = 25.14548807\n",
      "Validation score: 0.553766\n",
      "Iteration 2940, loss = 25.13715377\n",
      "Validation score: 0.553997\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 2941, loss = 25.12778362\n",
      "Validation score: 0.554298\n",
      "Iteration 2942, loss = 25.11853583\n",
      "Validation score: 0.554592\n",
      "Iteration 2943, loss = 25.10975460\n",
      "Validation score: 0.554881\n",
      "Iteration 2944, loss = 25.10099801\n",
      "Validation score: 0.555159\n",
      "Iteration 2945, loss = 25.09131071\n",
      "Validation score: 0.555397\n",
      "Iteration 2946, loss = 25.08412694\n",
      "Validation score: 0.555655\n",
      "Iteration 2947, loss = 25.07617902\n",
      "Validation score: 0.555850\n",
      "Iteration 2948, loss = 25.06859161\n",
      "Validation score: 0.556282\n",
      "Iteration 2949, loss = 25.06420399\n",
      "Validation score: 0.556580\n",
      "Iteration 2950, loss = 25.05278125\n",
      "Validation score: 0.556780\n",
      "Iteration 2951, loss = 25.04225689\n",
      "Validation score: 0.557166\n",
      "Iteration 2952, loss = 25.03217335\n",
      "Validation score: 0.557310\n",
      "Iteration 2953, loss = 25.02387368\n",
      "Validation score: 0.557468\n",
      "Iteration 2954, loss = 25.01391931\n",
      "Validation score: 0.557670\n",
      "Iteration 2955, loss = 25.00700216\n",
      "Validation score: 0.557865\n",
      "Iteration 2956, loss = 24.99921851\n",
      "Validation score: 0.558216\n",
      "Iteration 2957, loss = 24.99100413\n",
      "Validation score: 0.558574\n",
      "Iteration 2958, loss = 24.98174954\n",
      "Validation score: 0.558935\n",
      "Iteration 2959, loss = 24.97279621\n",
      "Validation score: 0.559194\n",
      "Iteration 2960, loss = 24.96535388\n",
      "Validation score: 0.559497\n",
      "Iteration 2961, loss = 24.95535580\n",
      "Validation score: 0.559756\n",
      "Iteration 2962, loss = 24.95098100\n",
      "Validation score: 0.559990\n",
      "Iteration 2963, loss = 24.93959147\n",
      "Validation score: 0.560225\n",
      "Iteration 2964, loss = 24.93110017\n",
      "Validation score: 0.560469\n",
      "Iteration 2965, loss = 24.92227697\n",
      "Validation score: 0.560694\n",
      "Iteration 2966, loss = 24.91531616\n",
      "Validation score: 0.560936\n",
      "Iteration 2967, loss = 24.90638250\n",
      "Validation score: 0.561219\n",
      "Iteration 2968, loss = 24.89906599\n",
      "Validation score: 0.561436\n",
      "Iteration 2969, loss = 24.89030854\n",
      "Validation score: 0.561674\n",
      "Iteration 2970, loss = 24.88852442\n",
      "Validation score: 0.561967\n",
      "Iteration 2971, loss = 24.87279677\n",
      "Validation score: 0.562180\n",
      "Iteration 2972, loss = 24.86986954\n",
      "Validation score: 0.562378\n",
      "Iteration 2973, loss = 24.86147547\n",
      "Validation score: 0.562585\n",
      "Iteration 2974, loss = 24.85268813\n",
      "Validation score: 0.562785\n",
      "Iteration 2975, loss = 24.84362230\n",
      "Validation score: 0.563132\n",
      "Iteration 2976, loss = 24.83432382\n",
      "Validation score: 0.563375\n",
      "Iteration 2977, loss = 24.82982049\n",
      "Validation score: 0.563632\n",
      "Iteration 2978, loss = 24.82141079\n",
      "Validation score: 0.563790\n",
      "Iteration 2979, loss = 24.81198208\n",
      "Validation score: 0.564246\n",
      "Iteration 2980, loss = 24.80302694\n",
      "Validation score: 0.564646\n",
      "Iteration 2981, loss = 24.79593200\n",
      "Validation score: 0.564996\n",
      "Iteration 2982, loss = 24.78727279\n",
      "Validation score: 0.565334\n",
      "Iteration 2983, loss = 24.77868092\n",
      "Validation score: 0.565574\n",
      "Iteration 2984, loss = 24.77223726\n",
      "Validation score: 0.565865\n",
      "Iteration 2985, loss = 24.76478337\n",
      "Validation score: 0.566091\n",
      "Iteration 2986, loss = 24.75454759\n",
      "Validation score: 0.566283\n",
      "Iteration 2987, loss = 24.74694241\n",
      "Validation score: 0.566481\n",
      "Iteration 2988, loss = 24.73854061\n",
      "Validation score: 0.566735\n",
      "Iteration 2989, loss = 24.73115672\n",
      "Validation score: 0.567096\n",
      "Iteration 2990, loss = 24.72309630\n",
      "Validation score: 0.567517\n",
      "Iteration 2991, loss = 24.71516022\n",
      "Validation score: 0.567813\n",
      "Iteration 2992, loss = 24.70819160\n",
      "Validation score: 0.568104\n",
      "Iteration 2993, loss = 24.70059463\n",
      "Validation score: 0.568443\n",
      "Iteration 2994, loss = 24.69249388\n",
      "Validation score: 0.568683\n",
      "Iteration 2995, loss = 24.68436916\n",
      "Validation score: 0.568884\n",
      "Iteration 2996, loss = 24.67811138\n",
      "Validation score: 0.568948\n",
      "Iteration 2997, loss = 24.66956265\n",
      "Validation score: 0.569244\n",
      "Iteration 2998, loss = 24.66343425\n",
      "Validation score: 0.569628\n",
      "Iteration 2999, loss = 24.65586146\n",
      "Validation score: 0.569882\n",
      "Iteration 3000, loss = 24.64606607\n",
      "Validation score: 0.570078\n",
      "Iteration 3001, loss = 24.63973121\n",
      "Validation score: 0.570202\n",
      "Iteration 3002, loss = 24.63281647\n",
      "Validation score: 0.570365\n",
      "Iteration 3003, loss = 24.62609807\n",
      "Validation score: 0.570624\n",
      "Iteration 3004, loss = 24.61841015\n",
      "Validation score: 0.570878\n",
      "Iteration 3005, loss = 24.60951132\n",
      "Validation score: 0.571014\n",
      "Iteration 3006, loss = 24.60395727\n",
      "Validation score: 0.571156\n",
      "Iteration 3007, loss = 24.59697190\n",
      "Validation score: 0.571320\n",
      "Iteration 3008, loss = 24.58932978\n",
      "Validation score: 0.571537\n",
      "Iteration 3009, loss = 24.58213951\n",
      "Validation score: 0.571790\n",
      "Iteration 3010, loss = 24.57553297\n",
      "Validation score: 0.572024\n",
      "Iteration 3011, loss = 24.56785634\n",
      "Validation score: 0.572146\n",
      "Iteration 3012, loss = 24.56004149\n",
      "Validation score: 0.572388\n",
      "Iteration 3013, loss = 24.55664028\n",
      "Validation score: 0.572671\n",
      "Iteration 3014, loss = 24.54494468\n",
      "Validation score: 0.572855\n",
      "Iteration 3015, loss = 24.53748017\n",
      "Validation score: 0.573234\n",
      "Iteration 3016, loss = 24.53286721\n",
      "Validation score: 0.573511\n",
      "Iteration 3017, loss = 24.52223544\n",
      "Validation score: 0.573648\n",
      "Iteration 3018, loss = 24.51605787\n",
      "Validation score: 0.573878\n",
      "Iteration 3019, loss = 24.50927881\n",
      "Validation score: 0.574073\n",
      "Iteration 3020, loss = 24.50479819\n",
      "Validation score: 0.574069\n",
      "Iteration 3021, loss = 24.49626047\n",
      "Validation score: 0.574350\n",
      "Iteration 3022, loss = 24.48882826\n",
      "Validation score: 0.574528\n",
      "Iteration 3023, loss = 24.48101732\n",
      "Validation score: 0.574710\n",
      "Iteration 3024, loss = 24.47556111\n",
      "Validation score: 0.575056\n",
      "Iteration 3025, loss = 24.46480361\n",
      "Validation score: 0.575351\n",
      "Iteration 3026, loss = 24.45948171\n",
      "Validation score: 0.575680\n",
      "Iteration 3027, loss = 24.45380394\n",
      "Validation score: 0.575791\n",
      "Iteration 3028, loss = 24.44667233\n",
      "Validation score: 0.575995\n",
      "Iteration 3029, loss = 24.43839541\n",
      "Validation score: 0.576027\n",
      "Iteration 3030, loss = 24.43207068\n",
      "Validation score: 0.576249\n",
      "Iteration 3031, loss = 24.42844681\n",
      "Validation score: 0.576257\n",
      "Iteration 3032, loss = 24.41935101\n",
      "Validation score: 0.576405\n",
      "Iteration 3033, loss = 24.41420358\n",
      "Validation score: 0.576850\n",
      "Iteration 3034, loss = 24.40797025\n",
      "Validation score: 0.576994\n",
      "Iteration 3035, loss = 24.39638816\n",
      "Validation score: 0.577351\n",
      "Iteration 3036, loss = 24.39661511\n",
      "Validation score: 0.577668\n",
      "Iteration 3037, loss = 24.38625508\n",
      "Validation score: 0.577904\n",
      "Iteration 3038, loss = 24.38117777\n",
      "Validation score: 0.578131\n",
      "Iteration 3039, loss = 24.37508982\n",
      "Validation score: 0.578469\n",
      "Iteration 3040, loss = 24.36556459\n",
      "Validation score: 0.578563\n",
      "Iteration 3041, loss = 24.36247479\n",
      "Validation score: 0.578514\n",
      "Iteration 3042, loss = 24.35200158\n",
      "Validation score: 0.578533\n",
      "Iteration 3043, loss = 24.34485893\n",
      "Validation score: 0.578770\n",
      "Iteration 3044, loss = 24.34382650\n",
      "Validation score: 0.578981\n",
      "Iteration 3045, loss = 24.33102072\n",
      "Validation score: 0.578998\n",
      "Iteration 3046, loss = 24.32557195\n",
      "Validation score: 0.579229\n",
      "Iteration 3047, loss = 24.32178530\n",
      "Validation score: 0.579520\n",
      "Iteration 3048, loss = 24.30974902\n",
      "Validation score: 0.579689\n",
      "Iteration 3049, loss = 24.31053265\n",
      "Validation score: 0.579665\n",
      "Iteration 3050, loss = 24.30388271\n",
      "Validation score: 0.579811\n",
      "Iteration 3051, loss = 24.29603975\n",
      "Validation score: 0.580063\n",
      "Iteration 3052, loss = 24.28841729\n",
      "Validation score: 0.580283\n",
      "Iteration 3053, loss = 24.28149264\n",
      "Validation score: 0.580646\n",
      "Iteration 3054, loss = 24.27670497\n",
      "Validation score: 0.581093\n",
      "Iteration 3055, loss = 24.26842961\n",
      "Validation score: 0.581504\n",
      "Iteration 3056, loss = 24.26061960\n",
      "Validation score: 0.581638\n",
      "Iteration 3057, loss = 24.25649524\n",
      "Validation score: 0.581628\n",
      "Iteration 3058, loss = 24.25034272\n",
      "Validation score: 0.581908\n",
      "Iteration 3059, loss = 24.24134473\n",
      "Validation score: 0.582009\n",
      "Iteration 3060, loss = 24.23738495\n",
      "Validation score: 0.582199\n",
      "Iteration 3061, loss = 24.22934844\n",
      "Validation score: 0.582378\n",
      "Iteration 3062, loss = 24.22335332\n",
      "Validation score: 0.582768\n",
      "Iteration 3063, loss = 24.21783375\n",
      "Validation score: 0.582911\n",
      "Iteration 3064, loss = 24.21045269\n",
      "Validation score: 0.583096\n",
      "Iteration 3065, loss = 24.20464123\n",
      "Validation score: 0.583339\n",
      "Iteration 3066, loss = 24.20003041\n",
      "Validation score: 0.583572\n",
      "Iteration 3067, loss = 24.19409230\n",
      "Validation score: 0.583695\n",
      "Iteration 3068, loss = 24.18799281\n",
      "Validation score: 0.584027\n",
      "Iteration 3069, loss = 24.17883515\n",
      "Validation score: 0.584251\n",
      "Iteration 3070, loss = 24.17526517\n",
      "Validation score: 0.584472\n",
      "Iteration 3071, loss = 24.17135314\n",
      "Validation score: 0.584517\n",
      "Iteration 3072, loss = 24.16212959\n",
      "Validation score: 0.584710\n",
      "Iteration 3073, loss = 24.15964370\n",
      "Validation score: 0.584868\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 3074, loss = 24.14980118\n",
      "Validation score: 0.584958\n",
      "Iteration 3075, loss = 24.14464529\n",
      "Validation score: 0.585099\n",
      "Iteration 3076, loss = 24.13828506\n",
      "Validation score: 0.585320\n",
      "Iteration 3077, loss = 24.13687808\n",
      "Validation score: 0.585597\n",
      "Iteration 3078, loss = 24.12846599\n",
      "Validation score: 0.585586\n",
      "Iteration 3079, loss = 24.12081792\n",
      "Validation score: 0.585547\n",
      "Iteration 3080, loss = 24.11578282\n",
      "Validation score: 0.585687\n",
      "Iteration 3081, loss = 24.11262688\n",
      "Validation score: 0.585711\n",
      "Iteration 3082, loss = 24.10614658\n",
      "Validation score: 0.586149\n",
      "Iteration 3083, loss = 24.10271228\n",
      "Validation score: 0.586645\n",
      "Iteration 3084, loss = 24.09274766\n",
      "Validation score: 0.586886\n",
      "Iteration 3085, loss = 24.08787013\n",
      "Validation score: 0.586990\n",
      "Iteration 3086, loss = 24.08470320\n",
      "Validation score: 0.587242\n",
      "Iteration 3087, loss = 24.07620348\n",
      "Validation score: 0.587297\n",
      "Iteration 3088, loss = 24.07270917\n",
      "Validation score: 0.587384\n",
      "Iteration 3089, loss = 24.06184245\n",
      "Validation score: 0.587632\n",
      "Iteration 3090, loss = 24.05941012\n",
      "Validation score: 0.587974\n",
      "Iteration 3091, loss = 24.05570451\n",
      "Validation score: 0.588164\n",
      "Iteration 3092, loss = 24.05052311\n",
      "Validation score: 0.588293\n",
      "Iteration 3093, loss = 24.04764365\n",
      "Validation score: 0.588275\n",
      "Iteration 3094, loss = 24.03713673\n",
      "Validation score: 0.588504\n",
      "Iteration 3095, loss = 24.02995409\n",
      "Validation score: 0.588615\n",
      "Iteration 3096, loss = 24.02588987\n",
      "Validation score: 0.588629\n",
      "Iteration 3097, loss = 24.01883416\n",
      "Validation score: 0.588728\n",
      "Iteration 3098, loss = 24.01588479\n",
      "Validation score: 0.588735\n",
      "Iteration 3099, loss = 24.01006822\n",
      "Validation score: 0.588966\n",
      "Iteration 3100, loss = 24.00497190\n",
      "Validation score: 0.589249\n",
      "Iteration 3101, loss = 23.99775236\n",
      "Validation score: 0.589480\n",
      "Iteration 3102, loss = 23.99474719\n",
      "Validation score: 0.589744\n",
      "Iteration 3103, loss = 23.99059858\n",
      "Validation score: 0.589936\n",
      "Iteration 3104, loss = 23.98521624\n",
      "Validation score: 0.589962\n",
      "Iteration 3105, loss = 23.97832010\n",
      "Validation score: 0.590120\n",
      "Iteration 3106, loss = 23.97251983\n",
      "Validation score: 0.590217\n",
      "Iteration 3107, loss = 23.96994622\n",
      "Validation score: 0.590077\n",
      "Iteration 3108, loss = 23.96195904\n",
      "Validation score: 0.590406\n",
      "Iteration 3109, loss = 23.95713053\n",
      "Validation score: 0.590669\n",
      "Iteration 3110, loss = 23.95088319\n",
      "Validation score: 0.590999\n",
      "Iteration 3111, loss = 23.94497649\n",
      "Validation score: 0.591264\n",
      "Iteration 3112, loss = 23.94091580\n",
      "Validation score: 0.591430\n",
      "Iteration 3113, loss = 23.93693664\n",
      "Validation score: 0.591556\n",
      "Iteration 3114, loss = 23.92907273\n",
      "Validation score: 0.591833\n",
      "Iteration 3115, loss = 23.92519332\n",
      "Validation score: 0.592089\n",
      "Iteration 3116, loss = 23.92418042\n",
      "Validation score: 0.592475\n",
      "Iteration 3117, loss = 23.91656427\n",
      "Validation score: 0.592545\n",
      "Iteration 3118, loss = 23.91191189\n",
      "Validation score: 0.592617\n",
      "Iteration 3119, loss = 23.90672061\n",
      "Validation score: 0.592565\n",
      "Iteration 3120, loss = 23.90038042\n",
      "Validation score: 0.592592\n",
      "Iteration 3121, loss = 23.89721293\n",
      "Validation score: 0.592664\n",
      "Iteration 3122, loss = 23.89208549\n",
      "Validation score: 0.592927\n",
      "Iteration 3123, loss = 23.88579175\n",
      "Validation score: 0.593079\n",
      "Iteration 3124, loss = 23.88329539\n",
      "Validation score: 0.593186\n",
      "Iteration 3125, loss = 23.87886384\n",
      "Validation score: 0.593204\n",
      "Iteration 3126, loss = 23.87282639\n",
      "Validation score: 0.593489\n",
      "Iteration 3127, loss = 23.86648762\n",
      "Validation score: 0.593894\n",
      "Iteration 3128, loss = 23.86379328\n",
      "Validation score: 0.594302\n",
      "Iteration 3129, loss = 23.85968752\n",
      "Validation score: 0.594411\n",
      "Iteration 3130, loss = 23.85223839\n",
      "Validation score: 0.594479\n",
      "Iteration 3131, loss = 23.84729040\n",
      "Validation score: 0.594461\n",
      "Iteration 3132, loss = 23.84571832\n",
      "Validation score: 0.594432\n",
      "Iteration 3133, loss = 23.83981360\n",
      "Validation score: 0.594465\n",
      "Validation score did not improve more than tol=0.000000 for two consecutive epochs. Stopping.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPRegressor(activation='logistic', alpha=0.1, batch_size='auto', beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=True, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(80, 60), learning_rate='constant',\n",
       "       learning_rate_init=0.0001, max_iter=15000, momentum=0.9,\n",
       "       nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
       "       shuffle=True, solver='adam', tol=1e-11, validation_fraction=0.1,\n",
       "       verbose=True, warm_start=False)"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model = MLPRegressor(batch_size = 200,validation_fraction=0.05, verbose=True, tol = 0.00000001,learning_rate_init=0.0001)\n",
    "\n",
    "model = MLPRegressor(learning_rate='constant', \n",
    "                        hidden_layer_sizes=(80, 60),\n",
    "                         activation='logistic', \n",
    "                         learning_rate_init=0.0001, \n",
    "                         max_iter=15000, \n",
    "                         early_stopping =True,\n",
    "                         validation_fraction=0.1,\n",
    "                         tol=0.00000000001,\n",
    "                         alpha=0.1,\n",
    "                         #n_iter_no_change=100,\n",
    "                         verbose=True)\n",
    "model.fit(X_train_subset,Y_train)\n",
    "\n",
    "#score = cross_val_score((model), X_train_subset, Y_train, scoring='r2', cv=4)\n",
    "#print(score.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[76.1767633  73.39308756 74.93653561 63.81670775 76.73501598 62.60946238\n",
      " 76.09858195 63.73686651 75.39391995 64.53426641 76.04004167 62.52858405\n",
      " 67.64166433 75.60402451 76.19547065 74.95740401 58.62515722 74.80758093\n",
      " 73.67729917 65.66263985 63.43481488 61.86282955 75.85192151 66.2839293\n",
      " 74.72734196 59.45358346 59.8540276  76.03032376 76.97345097 70.29011933\n",
      " 51.99800502 74.90087254 61.11722633 64.17485272 66.60400729 72.4346097\n",
      " 76.20262844 56.62398202 63.95722809 73.10761078 75.6585673  76.65803011\n",
      " 59.54306506 65.92281151 64.3467478  61.21498737 76.69456472 76.82114315\n",
      " 76.48790972 76.86336929 60.43625882 62.77174748 60.21029267 63.12236221\n",
      " 59.19719219 66.18583016 76.58265732 56.72534251 56.33771127 74.62955105\n",
      " 76.25782728 75.71506143 76.86083334 64.58571712 63.85985911 64.53067488\n",
      " 76.51532691 75.36257374 56.64017072 60.02734926 76.40006017 64.68573108\n",
      " 76.05491606 75.89261056 62.41619687 64.89848947 67.32317536 71.01258602\n",
      " 77.09848743 59.54493655 65.67646093 68.30259602 75.5845355  64.32778626\n",
      " 73.36681257 76.65809384 74.67559749 76.33364044 74.24216333 68.85301812\n",
      " 76.64898335 71.75144344 76.79146432 68.67233061 76.7611052  63.04437349\n",
      " 75.24444378 76.27834529 63.0790897  60.70632136 72.75491787 76.93075982\n",
      " 76.73949298 75.33628178 76.29878884 69.28774109 76.82869962 76.82565325\n",
      " 77.16235768 76.45727595 64.91285782 75.14556165 57.58072109 75.26206283\n",
      " 65.64292944 67.71306061 76.67440429 62.96088505 60.45408458 76.03383042\n",
      " 70.92319455 63.47931917 72.16842716 76.20044545 58.92924782 63.4979845\n",
      " 56.7394496  75.06501546 67.4638454  77.15371876 76.69119783 72.80023551\n",
      " 68.53810917 66.09514421 68.94562274 71.09072259 73.87074991 60.9807643\n",
      " 54.2912186  74.07172302 62.90006673 67.09506842 68.83045454 76.77116815\n",
      " 75.91958981 73.73410763 75.12634165 74.45651423 69.05996627 72.08945612\n",
      " 72.31980919 67.75872448 60.39661032 70.79074572 74.43676369 75.37075549\n",
      " 75.32460537 76.54428554 67.01154386 74.09584108 62.39011977 65.0234694\n",
      " 76.30173815 60.98563162 66.19460062 62.83793762 75.86305948 65.4345969\n",
      " 76.18427713 75.08370897 76.23465984 75.51267409 65.18688684 61.1789429\n",
      " 74.0096758  60.94085351 75.54296301 73.09736257 63.30640112 70.38727143\n",
      " 75.24431758 76.89923896 76.06723769 76.0564742  76.04848312 74.5391982\n",
      " 64.71096061 61.84061507 66.2232146  56.85985397 72.61589832 75.7642655\n",
      " 76.62437293 58.8466957  68.95635133 76.86761684 74.36099547 75.20879606\n",
      " 76.8529756  75.66278426 59.48613893 71.86532245 74.3953267  75.10351287\n",
      " 71.28240851 76.55467626 76.71983773 59.93073229 58.53034024 63.29130206\n",
      " 74.1286955  74.12396543 66.56670191 76.31448042 63.69574085 58.74217878\n",
      " 68.80196326 73.68055163 58.19210468 76.19147715 75.31526537 76.90602018\n",
      " 63.95444646 57.15845919 73.62400188 76.99132855 74.73109727 75.94162324\n",
      " 72.57150022 75.30780446 69.06855372 73.82089329 53.37362524 76.77574559\n",
      " 50.77438978 75.73516823 73.68152189 63.12599858 73.80053563 72.2637992\n",
      " 74.61468363 61.719979   66.74620444 76.72300861 68.66621857 60.00555843\n",
      " 71.77611274 76.95550015 75.34497513 67.95215033 64.17181555 71.56342344\n",
      " 75.63297362 62.30635895 61.09885379 75.82577327 76.865866   75.43306515\n",
      " 64.05064896 74.47842507 72.40692097 77.13314322 60.50579941 62.65342175\n",
      " 74.63635759 64.57674922 76.29040214 75.89647691 74.08510706 76.76540634\n",
      " 76.11496226 63.24054474 62.08162601 57.73040115 66.77331596 68.17523388\n",
      " 75.26265197 75.97648829 76.00978237 75.65807204 75.01938916 76.99352449\n",
      " 68.79441139 72.09618549 68.9619058  76.93746939 76.66606369 75.33374643\n",
      " 76.45373572 61.14628967 65.5823483  70.60907477 73.30755311 77.01925307\n",
      " 67.69301353 67.34653728 57.57592469 57.77826598 68.66932953 65.19576529\n",
      " 73.08046374 64.73182947 75.50248799 75.9404578  75.30251021 63.86895163\n",
      " 75.36167137 57.85623979 66.93532165 75.92238032 60.44947754 75.96225138\n",
      " 76.75796646 75.1526616  75.21090879 61.82647048 56.80588949 76.38439854\n",
      " 61.44471938 71.63033335 64.03768322 74.49201108 66.16526605 75.21009776\n",
      " 75.57120595 70.22645193 76.5258435  76.69655535 61.77225395 64.21568576\n",
      " 76.52529288 65.14339696 75.70825938 76.14031001 76.81935976 60.58581786\n",
      " 62.66920745 69.39204622 67.9739269  74.13582982 70.19739559 74.9384634\n",
      " 67.27675464 71.17846171 71.87906887 64.20842701 76.30525515 65.44836246\n",
      " 60.30678188 71.68780418 68.16507154 72.85535253 76.76242501 76.37833827\n",
      " 66.71281137 75.55793801 75.17209928 62.96770318 76.06720155 76.778608\n",
      " 68.82527542 62.04979299 67.26334275 66.14555374 76.4390548  52.51818409\n",
      " 69.29052878 51.79139989 60.08169636 76.00823632 62.9005562  69.31818046\n",
      " 76.76793453 75.17287909 75.77231574 58.64920334 76.40195574 75.72212332\n",
      " 76.78184625 72.26136682 70.56356983 76.47506037 76.90724299 70.53871743\n",
      " 71.71602985 76.99479103 65.91988606 72.64418666 60.61187915 76.34586472\n",
      " 74.43193867 57.17027973 75.79236685 61.95962218 75.83590762 67.8054256\n",
      " 64.58487962 76.21184074 56.19230127 77.14324638 74.58834993 59.13992161\n",
      " 74.72437731 74.98099212 76.19049336 68.66030015 61.32262821 76.55491837\n",
      " 66.9010167  75.78052869 74.7391524  65.67426698 65.31465521 76.53892362\n",
      " 57.93428261 68.42676218 76.10922858 76.58598906 71.63876222 59.0001331\n",
      " 76.07768489 64.98600298 68.04397186 69.53372037 74.87012694 76.41687566\n",
      " 59.67155527 76.61800156 76.36295552 76.86415304 58.31712374 62.95158586\n",
      " 76.95875684 65.1885311  63.3208631  68.15251091 76.84057118 61.43845236\n",
      " 75.71578083 73.67830632 62.61131091 60.14499584 57.85936484 66.39574022\n",
      " 59.98508313 75.0583683  74.35859527 75.96142927 76.76245601 61.11243021\n",
      " 68.45874752 64.70921701 71.14746707 67.45791172 70.24143229 56.81072752\n",
      " 56.7385257  75.24093089 76.70438598 75.28985646 76.9297211  65.38361122\n",
      " 66.99193673 77.10822389 71.56351944 76.07465825 75.05982424 61.54029312\n",
      " 62.5828837  75.62283259 73.64696152 61.45345911 75.72769618 73.04898986\n",
      " 76.4145793  64.91812078 75.76323183 64.74235867 75.97529874 70.26688769\n",
      " 62.70711767 66.66336551 72.61213584 58.53106983 69.13076464 73.18936921\n",
      " 69.23961596 73.24748366 62.81636421 75.30877006 75.77219216 76.40723546\n",
      " 76.79946841 58.7421292  76.91012267 63.21214943 61.17694599 67.05525599\n",
      " 73.16995252 66.55475894 69.81177256 73.07605566 76.65650161 75.83103005\n",
      " 74.5928129  75.44019696 76.66928378 75.45069878 75.97805955 68.66721491\n",
      " 69.8343988  67.44249595 60.28907588 64.09985389 75.76289123 73.62858301\n",
      " 69.12876394 76.86493998 66.93324993 63.0113016  76.59176108 61.33257487\n",
      " 68.2223112  70.01653258 58.81586788 74.68978422 62.43826821 73.74012081\n",
      " 66.62772015 62.43151551 75.68592137 67.60857312 59.52846329 75.66280273\n",
      " 65.58106297 59.71738458 75.63204832 75.11990882 74.33240897 65.45295743\n",
      " 55.3502829  76.18919048 64.46051712 72.60589231 67.86636423 61.62000627\n",
      " 76.65128435 74.63193171 69.75291275 68.30225477 77.00542234 61.17885141\n",
      " 60.99733697 60.72524851 74.81860474 74.95640067 70.83517579 64.96345149\n",
      " 59.19558685 76.75975927 75.22414503 75.93829564 67.49633416 58.92459169\n",
      " 75.79721085 76.09209648 76.5973863  56.98103519 69.22147245 70.73619963\n",
      " 74.12989698 64.59677254 75.1194738  70.95996095 61.40183288 72.5029502\n",
      " 64.55095079 74.58543388 76.46683957 62.28550402 76.79253165 59.06492843\n",
      " 73.81844686 75.77235844 76.87455631 76.1221913  63.15082347 75.88467894\n",
      " 68.95990383 74.28137899 71.19793294 75.14355501 76.78576743 76.73961798\n",
      " 63.32841176 64.26863168 69.04641249 76.82829153 75.80549468 76.50697296\n",
      " 60.66764932 76.81224785 53.48351655 62.50712698 57.16480416 63.72286243\n",
      " 74.11065577 76.43872018 77.05880563 58.20448262 57.54709352 75.85928963\n",
      " 75.80787229 63.2437891  76.22578644 64.06896401 56.57188611 61.07703248\n",
      " 56.70902824 63.86394391 76.01104838 59.79245994 76.11670653 73.82490955\n",
      " 66.2617726  64.42004173 73.01683504 74.34989237 75.81127046 73.3347892\n",
      " 75.18902431 69.62474726 72.50572172 63.49967951 76.15180463 76.96062438\n",
      " 60.76433902 75.11836059 74.73171    57.43783356 76.00765997 74.56098014\n",
      " 62.96178962 63.54116843 59.54604087 76.73466442 76.36053812 64.01992134\n",
      " 71.66837891 60.33245777 75.87813793 75.28180794 76.49747117 65.03110138\n",
      " 56.83971498 65.09391015 67.756336   65.68760414 76.16646594 75.53748097\n",
      " 61.86825052 67.64222767 49.66735378 76.89345637 62.94118181 73.64951155\n",
      " 69.65297535 77.02294488 76.99361981 68.58357631 58.64655109 76.5766612\n",
      " 58.09703682 52.16254635 74.29297481 58.14386806 75.2819556  60.20571921\n",
      " 65.26728003 67.47581185 62.59238143 57.83276006 76.79201419 74.96893579\n",
      " 61.6327415  65.9134857  76.85596042 54.99952791 64.08938337 76.67054781\n",
      " 63.09423347 73.20359882 59.49653187 75.59181279 75.20080073 59.25342391\n",
      " 77.15953401 63.13811226 77.05349498 76.48067349 75.52334876 77.06661132\n",
      " 59.668073   61.05928499 74.96974743 76.42773989 63.62367742 60.93197499\n",
      " 64.04948174 65.85717973 75.95244669 76.53756778 54.37604427 71.60564509\n",
      " 69.5236618  73.68935554 63.97302892 71.44564134 70.63803739 75.56313711\n",
      " 66.06293367 76.02127315 63.43567853 75.41807773 72.99626644 74.66536739\n",
      " 61.33371961 55.68353349 65.11121942 62.6848986  74.61151638 64.931347\n",
      " 76.79626082 71.54472791 76.86180507 66.33439746 65.98584142 71.31754045\n",
      " 75.16969033 77.09764294 60.35008187 58.8136689  76.60940452 57.50800152\n",
      " 72.49789192 64.27167064 63.27097091 71.7375522  76.78937415 75.9521964\n",
      " 76.94162958 66.58560596 61.37724993 70.88806967 62.38521934 76.80218422\n",
      " 70.575704   76.77668489 57.36493315 61.13901002 75.56565711 73.85764807\n",
      " 65.41520535 61.15337522 76.65440942 69.25163798 75.08418997 76.30510479\n",
      " 71.73179795 65.16780271 76.60562481 69.26750697 63.658702   76.83409957\n",
      " 62.2801684  67.69748865]\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test_subset)\n",
    "test_set[\"y\"] = y_pred\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create submission\n",
    "test_set[[\"id\", \"y\"]].to_csv(\"submissions/fifth_mlp.csv\", index= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
