{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload \n",
    "%autoreload 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.preprocessing import RobustScaler, StandardScaler\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from fancyimpute import KNN, NuclearNormMinimization, SoftImpute, IterativeImputer, BiScaler, MatrixFactorization\n",
    "\n",
    "%aimport util.data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data: \n",
      "  Amount of features: 888\n",
      "  Amount of observations: 1212\n",
      "  Min age: 42.0 Max age: 96.0\n",
      "\n",
      "Test Data: \n",
      "  Amount of observations: 776\n"
     ]
    }
   ],
   "source": [
    "train_data, test_data = util.data.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fill Missing Values (Remove NaNs)\n",
    "\n",
    "use one of the methods to fill the missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_incomplete = train_data.drop([\"id\", \"y\"], axis=1).values\n",
    "y = train_data[\"y\"].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### k-nearest neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imputing row 1/1212 with 66 missing, elapsed time: 10.716\n",
      "Imputing row 101/1212 with 60 missing, elapsed time: 10.810\n",
      "Imputing row 201/1212 with 68 missing, elapsed time: 10.888\n",
      "Imputing row 301/1212 with 68 missing, elapsed time: 10.982\n",
      "Imputing row 401/1212 with 63 missing, elapsed time: 11.076\n",
      "Imputing row 501/1212 with 66 missing, elapsed time: 11.169\n",
      "Imputing row 601/1212 with 77 missing, elapsed time: 11.279\n",
      "Imputing row 701/1212 with 65 missing, elapsed time: 11.357\n",
      "Imputing row 801/1212 with 61 missing, elapsed time: 11.435\n",
      "Imputing row 901/1212 with 73 missing, elapsed time: 11.544\n",
      "Imputing row 1001/1212 with 58 missing, elapsed time: 11.638\n",
      "Imputing row 1101/1212 with 73 missing, elapsed time: 11.716\n",
      "Imputing row 1201/1212 with 53 missing, elapsed time: 11.825\n"
     ]
    }
   ],
   "source": [
    "k = 12\n",
    "\n",
    "# Use nearest rows which have a feature to fill in each row's missing features\n",
    "X = KNN(k=k).fit_transform(X_incomplete)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### singular values thresholding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instead of solving the nuclear norm objective directly, instead\n",
    "# induce sparsity using singular value thresholding\n",
    "X_incomplete_normalized = BiScaler().fit_transform(X_incomplete)\n",
    "X = SoftImpute().fit_transform(X_incomplete_normalized)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### use matrix factorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = MatrixFactorization(learning_rate= 0.001, rank=40).fit_transform(X_incomplete)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mean_values = train_data.mean()\n",
    "train_data_mean =  train_data.fillna(train_mean_values)\n",
    "X = train_data_mean.drop([\"id\", \"y\"], axis=1).values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Normalization / Standardization\n",
    "\n",
    "use one of the methods provided to normalize the data (expects no NaNs)\n",
    "\n",
    "[Compare the effect of different scalers on data with outliers](http://scikit-learn.org/stable/auto_examples/preprocessing/plot_all_scaling.html#sphx-glr-auto-examples-preprocessing-plot-all-scaling-py)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### L1 - Normalization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = normalize(X, axis=0, norm='l1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### L2 - Normalization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = normalize(X, axis=0, norm='l2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Standard Scalar\n",
    "removes mean and divides by std (**sensitive to outliers** => probably not a good idea)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = StandardScaler().fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Robust Scaler\n",
    "Scale features using statistics that are robust to outliers. [scikit doc](http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.RobustScaler.html#sklearn.preprocessing.RobustScaler)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = RobustScaler(quantile_range=(10, 90)).fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outlier Detection and Removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 887 features.\n",
      "Fitting estimator with 883 features.\n",
      "Fitting estimator with 879 features.\n",
      "Fitting estimator with 875 features.\n",
      "Fitting estimator with 871 features.\n",
      "Fitting estimator with 867 features.\n",
      "Fitting estimator with 863 features.\n",
      "Fitting estimator with 859 features.\n",
      "Fitting estimator with 855 features.\n",
      "Fitting estimator with 851 features.\n",
      "Fitting estimator with 847 features.\n",
      "Fitting estimator with 843 features.\n",
      "Fitting estimator with 839 features.\n",
      "Fitting estimator with 835 features.\n",
      "Fitting estimator with 831 features.\n",
      "Fitting estimator with 827 features.\n",
      "Fitting estimator with 823 features.\n",
      "Fitting estimator with 819 features.\n",
      "Fitting estimator with 815 features.\n",
      "Fitting estimator with 811 features.\n",
      "Fitting estimator with 807 features.\n",
      "Fitting estimator with 803 features.\n",
      "Fitting estimator with 799 features.\n",
      "Fitting estimator with 795 features.\n",
      "Fitting estimator with 791 features.\n",
      "Fitting estimator with 787 features.\n",
      "Fitting estimator with 783 features.\n",
      "Fitting estimator with 779 features.\n",
      "Fitting estimator with 775 features.\n",
      "Fitting estimator with 771 features.\n",
      "Fitting estimator with 767 features.\n",
      "Fitting estimator with 763 features.\n",
      "Fitting estimator with 759 features.\n",
      "Fitting estimator with 755 features.\n",
      "Fitting estimator with 751 features.\n",
      "Fitting estimator with 747 features.\n",
      "Fitting estimator with 743 features.\n",
      "Fitting estimator with 739 features.\n",
      "Fitting estimator with 735 features.\n",
      "Fitting estimator with 731 features.\n",
      "Fitting estimator with 727 features.\n",
      "Fitting estimator with 723 features.\n",
      "Fitting estimator with 719 features.\n",
      "Fitting estimator with 715 features.\n",
      "Fitting estimator with 711 features.\n",
      "Fitting estimator with 707 features.\n",
      "Fitting estimator with 703 features.\n",
      "Fitting estimator with 699 features.\n",
      "Fitting estimator with 695 features.\n",
      "Fitting estimator with 691 features.\n",
      "Fitting estimator with 687 features.\n",
      "Fitting estimator with 683 features.\n",
      "Fitting estimator with 679 features.\n",
      "Fitting estimator with 675 features.\n",
      "Fitting estimator with 671 features.\n",
      "Fitting estimator with 667 features.\n",
      "Fitting estimator with 663 features.\n",
      "Fitting estimator with 659 features.\n",
      "Fitting estimator with 655 features.\n",
      "Fitting estimator with 651 features.\n",
      "Fitting estimator with 647 features.\n",
      "Fitting estimator with 643 features.\n",
      "Fitting estimator with 639 features.\n",
      "Fitting estimator with 635 features.\n",
      "Fitting estimator with 631 features.\n",
      "Fitting estimator with 627 features.\n",
      "Fitting estimator with 623 features.\n",
      "Fitting estimator with 619 features.\n",
      "Fitting estimator with 615 features.\n",
      "Fitting estimator with 611 features.\n",
      "Fitting estimator with 607 features.\n",
      "Fitting estimator with 603 features.\n",
      "Fitting estimator with 599 features.\n",
      "Fitting estimator with 595 features.\n",
      "Fitting estimator with 591 features.\n",
      "Fitting estimator with 587 features.\n",
      "Fitting estimator with 583 features.\n",
      "Fitting estimator with 579 features.\n",
      "Fitting estimator with 575 features.\n",
      "Fitting estimator with 571 features.\n",
      "Fitting estimator with 567 features.\n",
      "Fitting estimator with 563 features.\n",
      "Fitting estimator with 559 features.\n",
      "Fitting estimator with 555 features.\n",
      "Fitting estimator with 551 features.\n",
      "Fitting estimator with 547 features.\n",
      "Fitting estimator with 543 features.\n",
      "Fitting estimator with 539 features.\n",
      "Fitting estimator with 535 features.\n",
      "Fitting estimator with 531 features.\n",
      "Fitting estimator with 527 features.\n",
      "Fitting estimator with 523 features.\n",
      "Fitting estimator with 519 features.\n",
      "Fitting estimator with 515 features.\n",
      "Fitting estimator with 511 features.\n",
      "Fitting estimator with 507 features.\n",
      "Fitting estimator with 503 features.\n",
      "Fitting estimator with 499 features.\n",
      "Fitting estimator with 495 features.\n",
      "Fitting estimator with 491 features.\n",
      "Fitting estimator with 487 features.\n",
      "Fitting estimator with 483 features.\n",
      "Fitting estimator with 479 features.\n",
      "Fitting estimator with 475 features.\n",
      "Fitting estimator with 471 features.\n",
      "Fitting estimator with 467 features.\n",
      "Fitting estimator with 463 features.\n",
      "Fitting estimator with 459 features.\n",
      "Fitting estimator with 455 features.\n",
      "Fitting estimator with 451 features.\n",
      "Fitting estimator with 447 features.\n",
      "Fitting estimator with 443 features.\n",
      "Fitting estimator with 439 features.\n",
      "Fitting estimator with 435 features.\n",
      "Fitting estimator with 431 features.\n",
      "Fitting estimator with 427 features.\n",
      "Fitting estimator with 423 features.\n",
      "Fitting estimator with 419 features.\n",
      "Fitting estimator with 415 features.\n",
      "Fitting estimator with 411 features.\n",
      "Fitting estimator with 407 features.\n",
      "Fitting estimator with 403 features.\n",
      "Fitting estimator with 399 features.\n",
      "Fitting estimator with 395 features.\n",
      "Fitting estimator with 391 features.\n",
      "Fitting estimator with 387 features.\n",
      "Fitting estimator with 383 features.\n",
      "Fitting estimator with 379 features.\n",
      "Fitting estimator with 375 features.\n",
      "Fitting estimator with 371 features.\n",
      "Fitting estimator with 367 features.\n",
      "Fitting estimator with 363 features.\n",
      "Fitting estimator with 359 features.\n",
      "Fitting estimator with 355 features.\n",
      "Fitting estimator with 351 features.\n",
      "Fitting estimator with 347 features.\n",
      "Fitting estimator with 343 features.\n",
      "Fitting estimator with 339 features.\n",
      "Fitting estimator with 335 features.\n",
      "Fitting estimator with 331 features.\n",
      "Fitting estimator with 327 features.\n",
      "Fitting estimator with 323 features.\n",
      "Fitting estimator with 319 features.\n",
      "Fitting estimator with 315 features.\n",
      "Fitting estimator with 311 features.\n",
      "Fitting estimator with 307 features.\n",
      "Fitting estimator with 303 features.\n",
      "Fitting estimator with 299 features.\n",
      "Fitting estimator with 295 features.\n",
      "Fitting estimator with 291 features.\n",
      "Fitting estimator with 287 features.\n",
      "Fitting estimator with 283 features.\n",
      "Fitting estimator with 279 features.\n",
      "Fitting estimator with 275 features.\n",
      "Fitting estimator with 271 features.\n",
      "Fitting estimator with 267 features.\n",
      "Fitting estimator with 263 features.\n",
      "Fitting estimator with 259 features.\n",
      "Fitting estimator with 255 features.\n",
      "Fitting estimator with 251 features.\n",
      "Fitting estimator with 247 features.\n",
      "Fitting estimator with 243 features.\n",
      "Fitting estimator with 239 features.\n",
      "Fitting estimator with 235 features.\n",
      "Fitting estimator with 231 features.\n",
      "Fitting estimator with 227 features.\n",
      "Fitting estimator with 223 features.\n",
      "Fitting estimator with 219 features.\n",
      "Fitting estimator with 215 features.\n",
      "Fitting estimator with 211 features.\n",
      "Fitting estimator with 207 features.\n",
      "Fitting estimator with 203 features.\n",
      "Fitting estimator with 199 features.\n",
      "Fitting estimator with 195 features.\n",
      "Fitting estimator with 191 features.\n",
      "Fitting estimator with 187 features.\n",
      "Fitting estimator with 183 features.\n",
      "Fitting estimator with 179 features.\n",
      "Fitting estimator with 175 features.\n",
      "Fitting estimator with 171 features.\n",
      "Fitting estimator with 167 features.\n",
      "Fitting estimator with 163 features.\n",
      "Fitting estimator with 159 features.\n",
      "Fitting estimator with 155 features.\n",
      "Fitting estimator with 151 features.\n",
      "Fitting estimator with 147 features.\n",
      "Fitting estimator with 143 features.\n",
      "Fitting estimator with 139 features.\n",
      "Fitting estimator with 135 features.\n",
      "Fitting estimator with 131 features.\n",
      "Fitting estimator with 127 features.\n",
      "Fitting estimator with 123 features.\n",
      "Fitting estimator with 119 features.\n",
      "Fitting estimator with 115 features.\n",
      "Fitting estimator with 111 features.\n",
      "Fitting estimator with 107 features.\n",
      "Fitting estimator with 103 features.\n",
      "Fitting estimator with 99 features.\n",
      "Fitting estimator with 95 features.\n",
      "Fitting estimator with 91 features.\n",
      "Fitting estimator with 87 features.\n",
      "Fitting estimator with 83 features.\n",
      "Fitting estimator with 79 features.\n",
      "Fitting estimator with 75 features.\n",
      "Fitting estimator with 71 features.\n",
      "Fitting estimator with 67 features.\n",
      "Fitting estimator with 63 features.\n",
      "Fitting estimator with 59 features.\n",
      "Fitting estimator with 55 features.\n",
      "Fitting estimator with 51 features.\n",
      "Fitting estimator with 47 features.\n",
      "Fitting estimator with 43 features.\n",
      "Fitting estimator with 39 features.\n",
      "Fitting estimator with 35 features.\n",
      "Fitting estimator with 31 features.\n",
      "Fitting estimator with 27 features.\n",
      "Fitting estimator with 23 features.\n",
      "Fitting estimator with 19 features.\n",
      "Fitting estimator with 15 features.\n",
      "Fitting estimator with 11 features.\n",
      "Fitting estimator with 7 features.\n",
      "Fitting estimator with 3 features.\n",
      "Fitting estimator with 887 features.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 883 features.\n",
      "Fitting estimator with 879 features.\n",
      "Fitting estimator with 875 features.\n",
      "Fitting estimator with 871 features.\n",
      "Fitting estimator with 867 features.\n",
      "Fitting estimator with 863 features.\n",
      "Fitting estimator with 859 features.\n",
      "Fitting estimator with 855 features.\n",
      "Fitting estimator with 851 features.\n",
      "Fitting estimator with 847 features.\n",
      "Fitting estimator with 843 features.\n",
      "Fitting estimator with 839 features.\n",
      "Fitting estimator with 835 features.\n",
      "Fitting estimator with 831 features.\n",
      "Fitting estimator with 827 features.\n",
      "Fitting estimator with 823 features.\n",
      "Fitting estimator with 819 features.\n",
      "Fitting estimator with 815 features.\n",
      "Fitting estimator with 811 features.\n",
      "Fitting estimator with 807 features.\n",
      "Fitting estimator with 803 features.\n",
      "Fitting estimator with 799 features.\n",
      "Fitting estimator with 795 features.\n",
      "Fitting estimator with 791 features.\n",
      "Fitting estimator with 787 features.\n",
      "Fitting estimator with 783 features.\n",
      "Fitting estimator with 779 features.\n",
      "Fitting estimator with 775 features.\n",
      "Fitting estimator with 771 features.\n",
      "Fitting estimator with 767 features.\n",
      "Fitting estimator with 763 features.\n",
      "Fitting estimator with 759 features.\n",
      "Fitting estimator with 755 features.\n",
      "Fitting estimator with 751 features.\n",
      "Fitting estimator with 747 features.\n",
      "Fitting estimator with 743 features.\n",
      "Fitting estimator with 739 features.\n",
      "Fitting estimator with 735 features.\n",
      "Fitting estimator with 731 features.\n",
      "Fitting estimator with 727 features.\n",
      "Fitting estimator with 723 features.\n",
      "Fitting estimator with 719 features.\n",
      "Fitting estimator with 715 features.\n",
      "Fitting estimator with 711 features.\n",
      "Fitting estimator with 707 features.\n",
      "Fitting estimator with 703 features.\n",
      "Fitting estimator with 699 features.\n",
      "Fitting estimator with 695 features.\n",
      "Fitting estimator with 691 features.\n",
      "Fitting estimator with 687 features.\n",
      "Fitting estimator with 683 features.\n",
      "Fitting estimator with 679 features.\n",
      "Fitting estimator with 675 features.\n",
      "Fitting estimator with 671 features.\n",
      "Fitting estimator with 667 features.\n",
      "Fitting estimator with 663 features.\n",
      "Fitting estimator with 659 features.\n",
      "Fitting estimator with 655 features.\n",
      "Fitting estimator with 651 features.\n",
      "Fitting estimator with 647 features.\n",
      "Fitting estimator with 643 features.\n",
      "Fitting estimator with 639 features.\n",
      "Fitting estimator with 635 features.\n",
      "Fitting estimator with 631 features.\n",
      "Fitting estimator with 627 features.\n",
      "Fitting estimator with 623 features.\n",
      "Fitting estimator with 619 features.\n",
      "Fitting estimator with 615 features.\n",
      "Fitting estimator with 611 features.\n",
      "Fitting estimator with 607 features.\n",
      "Fitting estimator with 603 features.\n",
      "Fitting estimator with 599 features.\n",
      "Fitting estimator with 595 features.\n",
      "Fitting estimator with 591 features.\n",
      "Fitting estimator with 587 features.\n",
      "Fitting estimator with 583 features.\n",
      "Fitting estimator with 579 features.\n",
      "Fitting estimator with 575 features.\n",
      "Fitting estimator with 571 features.\n",
      "Fitting estimator with 567 features.\n",
      "Fitting estimator with 563 features.\n",
      "Fitting estimator with 559 features.\n",
      "Fitting estimator with 555 features.\n",
      "Fitting estimator with 551 features.\n",
      "Fitting estimator with 547 features.\n",
      "Fitting estimator with 543 features.\n",
      "Fitting estimator with 539 features.\n",
      "Fitting estimator with 535 features.\n",
      "Fitting estimator with 531 features.\n",
      "Fitting estimator with 527 features.\n",
      "Fitting estimator with 523 features.\n",
      "Fitting estimator with 519 features.\n",
      "Fitting estimator with 515 features.\n",
      "Fitting estimator with 511 features.\n",
      "Fitting estimator with 507 features.\n",
      "Fitting estimator with 503 features.\n",
      "Fitting estimator with 499 features.\n",
      "Fitting estimator with 495 features.\n",
      "Fitting estimator with 491 features.\n",
      "Fitting estimator with 487 features.\n",
      "Fitting estimator with 483 features.\n",
      "Fitting estimator with 479 features.\n",
      "Fitting estimator with 475 features.\n",
      "Fitting estimator with 471 features.\n",
      "Fitting estimator with 467 features.\n",
      "Fitting estimator with 463 features.\n",
      "Fitting estimator with 459 features.\n",
      "Fitting estimator with 455 features.\n",
      "Fitting estimator with 451 features.\n",
      "Fitting estimator with 447 features.\n",
      "Fitting estimator with 443 features.\n",
      "Fitting estimator with 439 features.\n",
      "Fitting estimator with 435 features.\n",
      "Fitting estimator with 431 features.\n",
      "Fitting estimator with 427 features.\n",
      "Fitting estimator with 423 features.\n",
      "Fitting estimator with 419 features.\n",
      "Fitting estimator with 415 features.\n",
      "Fitting estimator with 411 features.\n",
      "Fitting estimator with 407 features.\n",
      "Fitting estimator with 403 features.\n",
      "Fitting estimator with 399 features.\n",
      "Fitting estimator with 395 features.\n",
      "Fitting estimator with 391 features.\n",
      "Fitting estimator with 387 features.\n",
      "Fitting estimator with 383 features.\n",
      "Fitting estimator with 379 features.\n",
      "Fitting estimator with 375 features.\n",
      "Fitting estimator with 371 features.\n",
      "Fitting estimator with 367 features.\n",
      "Fitting estimator with 363 features.\n",
      "Fitting estimator with 359 features.\n",
      "Fitting estimator with 355 features.\n",
      "Fitting estimator with 351 features.\n",
      "Fitting estimator with 347 features.\n",
      "Fitting estimator with 343 features.\n",
      "Fitting estimator with 339 features.\n",
      "Fitting estimator with 335 features.\n",
      "Fitting estimator with 331 features.\n",
      "Fitting estimator with 327 features.\n",
      "Fitting estimator with 323 features.\n",
      "Fitting estimator with 319 features.\n",
      "Fitting estimator with 315 features.\n",
      "Fitting estimator with 311 features.\n",
      "Fitting estimator with 307 features.\n",
      "Fitting estimator with 303 features.\n",
      "Fitting estimator with 299 features.\n",
      "Fitting estimator with 295 features.\n",
      "Fitting estimator with 291 features.\n",
      "Fitting estimator with 287 features.\n",
      "Fitting estimator with 283 features.\n",
      "Fitting estimator with 279 features.\n",
      "Fitting estimator with 275 features.\n",
      "Fitting estimator with 271 features.\n",
      "Fitting estimator with 267 features.\n",
      "Fitting estimator with 263 features.\n",
      "Fitting estimator with 259 features.\n",
      "Fitting estimator with 255 features.\n",
      "Fitting estimator with 251 features.\n",
      "Fitting estimator with 247 features.\n",
      "Fitting estimator with 243 features.\n",
      "Fitting estimator with 239 features.\n",
      "Fitting estimator with 235 features.\n",
      "Fitting estimator with 231 features.\n",
      "Fitting estimator with 227 features.\n",
      "Fitting estimator with 223 features.\n",
      "Fitting estimator with 219 features.\n",
      "Fitting estimator with 215 features.\n",
      "Fitting estimator with 211 features.\n",
      "Fitting estimator with 207 features.\n",
      "Fitting estimator with 203 features.\n",
      "Fitting estimator with 199 features.\n",
      "Fitting estimator with 195 features.\n",
      "Fitting estimator with 191 features.\n",
      "Fitting estimator with 187 features.\n",
      "Fitting estimator with 183 features.\n",
      "Fitting estimator with 179 features.\n",
      "Fitting estimator with 175 features.\n",
      "Fitting estimator with 171 features.\n",
      "Fitting estimator with 167 features.\n",
      "Fitting estimator with 163 features.\n",
      "Fitting estimator with 159 features.\n",
      "Fitting estimator with 155 features.\n",
      "Fitting estimator with 151 features.\n",
      "Fitting estimator with 147 features.\n",
      "Fitting estimator with 143 features.\n",
      "Fitting estimator with 139 features.\n",
      "Fitting estimator with 135 features.\n",
      "Fitting estimator with 131 features.\n",
      "Fitting estimator with 127 features.\n",
      "Fitting estimator with 123 features.\n",
      "Fitting estimator with 119 features.\n",
      "Fitting estimator with 115 features.\n",
      "Fitting estimator with 111 features.\n",
      "Fitting estimator with 107 features.\n",
      "Fitting estimator with 103 features.\n",
      "Fitting estimator with 99 features.\n",
      "Fitting estimator with 95 features.\n",
      "Fitting estimator with 91 features.\n",
      "Fitting estimator with 87 features.\n",
      "Fitting estimator with 83 features.\n",
      "Fitting estimator with 79 features.\n",
      "Fitting estimator with 75 features.\n",
      "Fitting estimator with 71 features.\n",
      "Fitting estimator with 67 features.\n",
      "Fitting estimator with 63 features.\n",
      "Fitting estimator with 59 features.\n",
      "Fitting estimator with 55 features.\n",
      "Fitting estimator with 51 features.\n",
      "Fitting estimator with 47 features.\n",
      "Fitting estimator with 43 features.\n",
      "Fitting estimator with 39 features.\n",
      "Fitting estimator with 35 features.\n",
      "Fitting estimator with 31 features.\n",
      "Fitting estimator with 27 features.\n",
      "Fitting estimator with 23 features.\n",
      "Fitting estimator with 19 features.\n",
      "Fitting estimator with 15 features.\n",
      "Fitting estimator with 11 features.\n",
      "Fitting estimator with 7 features.\n",
      "Fitting estimator with 3 features.\n",
      "Fitting estimator with 887 features.\n",
      "Fitting estimator with 883 features.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 879 features.\n",
      "Fitting estimator with 875 features.\n",
      "Fitting estimator with 871 features.\n",
      "Fitting estimator with 867 features.\n",
      "Fitting estimator with 863 features.\n",
      "Fitting estimator with 859 features.\n",
      "Fitting estimator with 855 features.\n",
      "Fitting estimator with 851 features.\n",
      "Fitting estimator with 847 features.\n",
      "Fitting estimator with 843 features.\n",
      "Fitting estimator with 839 features.\n",
      "Fitting estimator with 835 features.\n",
      "Fitting estimator with 831 features.\n",
      "Fitting estimator with 827 features.\n",
      "Fitting estimator with 823 features.\n",
      "Fitting estimator with 819 features.\n",
      "Fitting estimator with 815 features.\n",
      "Fitting estimator with 811 features.\n",
      "Fitting estimator with 807 features.\n",
      "Fitting estimator with 803 features.\n",
      "Fitting estimator with 799 features.\n",
      "Fitting estimator with 795 features.\n",
      "Fitting estimator with 791 features.\n",
      "Fitting estimator with 787 features.\n",
      "Fitting estimator with 783 features.\n",
      "Fitting estimator with 779 features.\n",
      "Fitting estimator with 775 features.\n",
      "Fitting estimator with 771 features.\n",
      "Fitting estimator with 767 features.\n",
      "Fitting estimator with 763 features.\n",
      "Fitting estimator with 759 features.\n",
      "Fitting estimator with 755 features.\n",
      "Fitting estimator with 751 features.\n",
      "Fitting estimator with 747 features.\n",
      "Fitting estimator with 743 features.\n",
      "Fitting estimator with 739 features.\n",
      "Fitting estimator with 735 features.\n",
      "Fitting estimator with 731 features.\n",
      "Fitting estimator with 727 features.\n",
      "Fitting estimator with 723 features.\n",
      "Fitting estimator with 719 features.\n",
      "Fitting estimator with 715 features.\n",
      "Fitting estimator with 711 features.\n",
      "Fitting estimator with 707 features.\n",
      "Fitting estimator with 703 features.\n",
      "Fitting estimator with 699 features.\n",
      "Fitting estimator with 695 features.\n",
      "Fitting estimator with 691 features.\n",
      "Fitting estimator with 687 features.\n",
      "Fitting estimator with 683 features.\n",
      "Fitting estimator with 679 features.\n",
      "Fitting estimator with 675 features.\n",
      "Fitting estimator with 671 features.\n",
      "Fitting estimator with 667 features.\n",
      "Fitting estimator with 663 features.\n",
      "Fitting estimator with 659 features.\n",
      "Fitting estimator with 655 features.\n",
      "Fitting estimator with 651 features.\n",
      "Fitting estimator with 647 features.\n",
      "Fitting estimator with 643 features.\n",
      "Fitting estimator with 639 features.\n",
      "Fitting estimator with 635 features.\n",
      "Fitting estimator with 631 features.\n",
      "Fitting estimator with 627 features.\n",
      "Fitting estimator with 623 features.\n",
      "Fitting estimator with 619 features.\n",
      "Fitting estimator with 615 features.\n",
      "Fitting estimator with 611 features.\n",
      "Fitting estimator with 607 features.\n",
      "Fitting estimator with 603 features.\n",
      "Fitting estimator with 599 features.\n",
      "Fitting estimator with 595 features.\n",
      "Fitting estimator with 591 features.\n",
      "Fitting estimator with 587 features.\n",
      "Fitting estimator with 583 features.\n",
      "Fitting estimator with 579 features.\n",
      "Fitting estimator with 575 features.\n",
      "Fitting estimator with 571 features.\n",
      "Fitting estimator with 567 features.\n",
      "Fitting estimator with 563 features.\n",
      "Fitting estimator with 559 features.\n",
      "Fitting estimator with 555 features.\n",
      "Fitting estimator with 551 features.\n",
      "Fitting estimator with 547 features.\n",
      "Fitting estimator with 543 features.\n",
      "Fitting estimator with 539 features.\n",
      "Fitting estimator with 535 features.\n",
      "Fitting estimator with 531 features.\n",
      "Fitting estimator with 527 features.\n",
      "Fitting estimator with 523 features.\n",
      "Fitting estimator with 519 features.\n",
      "Fitting estimator with 515 features.\n",
      "Fitting estimator with 511 features.\n",
      "Fitting estimator with 507 features.\n",
      "Fitting estimator with 503 features.\n",
      "Fitting estimator with 499 features.\n",
      "Fitting estimator with 495 features.\n",
      "Fitting estimator with 491 features.\n",
      "Fitting estimator with 487 features.\n",
      "Fitting estimator with 483 features.\n",
      "Fitting estimator with 479 features.\n",
      "Fitting estimator with 475 features.\n",
      "Fitting estimator with 471 features.\n",
      "Fitting estimator with 467 features.\n",
      "Fitting estimator with 463 features.\n",
      "Fitting estimator with 459 features.\n",
      "Fitting estimator with 455 features.\n",
      "Fitting estimator with 451 features.\n",
      "Fitting estimator with 447 features.\n",
      "Fitting estimator with 443 features.\n",
      "Fitting estimator with 439 features.\n",
      "Fitting estimator with 435 features.\n",
      "Fitting estimator with 431 features.\n",
      "Fitting estimator with 427 features.\n",
      "Fitting estimator with 423 features.\n",
      "Fitting estimator with 419 features.\n",
      "Fitting estimator with 415 features.\n",
      "Fitting estimator with 411 features.\n",
      "Fitting estimator with 407 features.\n",
      "Fitting estimator with 403 features.\n",
      "Fitting estimator with 399 features.\n",
      "Fitting estimator with 395 features.\n",
      "Fitting estimator with 391 features.\n",
      "Fitting estimator with 387 features.\n",
      "Fitting estimator with 383 features.\n",
      "Fitting estimator with 379 features.\n",
      "Fitting estimator with 375 features.\n",
      "Fitting estimator with 371 features.\n",
      "Fitting estimator with 367 features.\n",
      "Fitting estimator with 363 features.\n",
      "Fitting estimator with 359 features.\n",
      "Fitting estimator with 355 features.\n",
      "Fitting estimator with 351 features.\n",
      "Fitting estimator with 347 features.\n",
      "Fitting estimator with 343 features.\n",
      "Fitting estimator with 339 features.\n",
      "Fitting estimator with 335 features.\n",
      "Fitting estimator with 331 features.\n",
      "Fitting estimator with 327 features.\n",
      "Fitting estimator with 323 features.\n",
      "Fitting estimator with 319 features.\n",
      "Fitting estimator with 315 features.\n",
      "Fitting estimator with 311 features.\n",
      "Fitting estimator with 307 features.\n",
      "Fitting estimator with 303 features.\n",
      "Fitting estimator with 299 features.\n",
      "Fitting estimator with 295 features.\n",
      "Fitting estimator with 291 features.\n",
      "Fitting estimator with 287 features.\n",
      "Fitting estimator with 283 features.\n",
      "Fitting estimator with 279 features.\n",
      "Fitting estimator with 275 features.\n",
      "Fitting estimator with 271 features.\n",
      "Fitting estimator with 267 features.\n",
      "Fitting estimator with 263 features.\n",
      "Fitting estimator with 259 features.\n",
      "Fitting estimator with 255 features.\n",
      "Fitting estimator with 251 features.\n",
      "Fitting estimator with 247 features.\n",
      "Fitting estimator with 243 features.\n",
      "Fitting estimator with 239 features.\n",
      "Fitting estimator with 235 features.\n",
      "Fitting estimator with 231 features.\n",
      "Fitting estimator with 227 features.\n",
      "Fitting estimator with 223 features.\n",
      "Fitting estimator with 219 features.\n",
      "Fitting estimator with 215 features.\n",
      "Fitting estimator with 211 features.\n",
      "Fitting estimator with 207 features.\n",
      "Fitting estimator with 203 features.\n",
      "Fitting estimator with 199 features.\n",
      "Fitting estimator with 195 features.\n",
      "Fitting estimator with 191 features.\n",
      "Fitting estimator with 187 features.\n",
      "Fitting estimator with 183 features.\n",
      "Fitting estimator with 179 features.\n",
      "Fitting estimator with 175 features.\n",
      "Fitting estimator with 171 features.\n",
      "Fitting estimator with 167 features.\n",
      "Fitting estimator with 163 features.\n",
      "Fitting estimator with 159 features.\n",
      "Fitting estimator with 155 features.\n",
      "Fitting estimator with 151 features.\n",
      "Fitting estimator with 147 features.\n",
      "Fitting estimator with 143 features.\n",
      "Fitting estimator with 139 features.\n",
      "Fitting estimator with 135 features.\n",
      "Fitting estimator with 131 features.\n",
      "Fitting estimator with 127 features.\n",
      "Fitting estimator with 123 features.\n",
      "Fitting estimator with 119 features.\n",
      "Fitting estimator with 115 features.\n",
      "Fitting estimator with 111 features.\n",
      "Fitting estimator with 107 features.\n",
      "Fitting estimator with 103 features.\n",
      "Fitting estimator with 99 features.\n",
      "Fitting estimator with 95 features.\n",
      "Fitting estimator with 91 features.\n",
      "Fitting estimator with 87 features.\n",
      "Fitting estimator with 83 features.\n",
      "Fitting estimator with 79 features.\n",
      "Fitting estimator with 75 features.\n",
      "Fitting estimator with 71 features.\n",
      "Fitting estimator with 67 features.\n",
      "Fitting estimator with 63 features.\n",
      "Fitting estimator with 59 features.\n",
      "Fitting estimator with 55 features.\n",
      "Fitting estimator with 51 features.\n",
      "Fitting estimator with 47 features.\n",
      "Fitting estimator with 43 features.\n",
      "Fitting estimator with 39 features.\n",
      "Fitting estimator with 35 features.\n",
      "Fitting estimator with 31 features.\n",
      "Fitting estimator with 27 features.\n",
      "Fitting estimator with 23 features.\n",
      "Fitting estimator with 19 features.\n",
      "Fitting estimator with 15 features.\n",
      "Fitting estimator with 11 features.\n",
      "Fitting estimator with 7 features.\n",
      "Fitting estimator with 3 features.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RFECV(cv=3,\n",
       "   estimator=RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "           max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=1, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=50, n_jobs=-1,\n",
       "           oob_score=False, random_state=None, verbose=0, warm_start=False),\n",
       "   n_jobs=1, scoring='r2', step=4, verbose=1)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Feature Selection with Recursive Feature Elimination with Cross Validation (RFECV)\n",
    "\n",
    "n_rm_features_per_iteration = 4\n",
    "cv_k = 3\n",
    "\n",
    "estimator = RandomForestRegressor(n_jobs=-1, n_estimators=50)\n",
    "\n",
    "rfecv = RFECV(estimator, step=n_rm_features_per_iteration, cv=cv_k, scoring='r2', verbose=1)\n",
    "rfecv.fit(X, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal number of features : 63\n",
      "Validation Score: 0.5184571953409342\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1d48c888a58>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected Features: \n",
      "['x0' 'x42' 'x80' 'x82' 'x89' 'x94' 'x96' 'x120' 'x137' 'x178' 'x185'\n",
      " 'x186' 'x192' 'x224' 'x234' 'x237' 'x264' 'x273' 'x280' 'x291' 'x300'\n",
      " 'x309' 'x320' 'x328' 'x331' 'x333' 'x340' 'x349' 'x391' 'x400' 'x424'\n",
      " 'x426' 'x449' 'x450' 'x470' 'x479' 'x499' 'x520' 'x529' 'x536' 'x547'\n",
      " 'x555' 'x559' 'x604' 'x618' 'x644' 'x651' 'x658' 'x664' 'x673' 'x685'\n",
      " 'x686' 'x687' 'x722' 'x730' 'x739' 'x743' 'x746' 'x751' 'x800' 'x810'\n",
      " 'x871' 'x882']\n"
     ]
    }
   ],
   "source": [
    "print(\"Optimal number of features : %d\" % rfecv.n_features_) #47\n",
    "print(f\"Validation Score: {max(rfecv.grid_scores_)}\")\n",
    "\n",
    "# Plot number of features VS. cross-validation scores\n",
    "plt.figure()\n",
    "plt.xlabel(\"Number of features selected\")\n",
    "plt.ylabel(\"Cross validation score (nb of correct classifications)\")\n",
    "plt.plot(range(1, n_rm_features_per_iteration * len(rfecv.grid_scores_) + 1, n_rm_features_per_iteration), rfecv.grid_scores_)\n",
    "plt.show()\n",
    "\n",
    "selected_feature_cols = train_data.columns.values[1:-1][rfecv.support_]\n",
    "\n",
    "print('Selected Features: ')\n",
    "print(selected_feature_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### K-Fold Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imputing row 1/1212 with 4 missing, elapsed time: 0.859\n",
      "Imputing row 101/1212 with 6 missing, elapsed time: 0.875\n",
      "Imputing row 201/1212 with 8 missing, elapsed time: 0.875\n",
      "Imputing row 301/1212 with 5 missing, elapsed time: 0.875\n",
      "Imputing row 401/1212 with 3 missing, elapsed time: 0.890\n",
      "Imputing row 501/1212 with 2 missing, elapsed time: 0.890\n",
      "Imputing row 601/1212 with 4 missing, elapsed time: 0.906\n",
      "Imputing row 701/1212 with 5 missing, elapsed time: 0.906\n",
      "Imputing row 801/1212 with 2 missing, elapsed time: 0.906\n",
      "Imputing row 901/1212 with 2 missing, elapsed time: 0.922\n",
      "Imputing row 1001/1212 with 5 missing, elapsed time: 0.922\n",
      "Imputing row 1101/1212 with 3 missing, elapsed time: 0.937\n",
      "Imputing row 1201/1212 with 5 missing, elapsed time: 0.937\n",
      "Iteration 1, loss = 2544.80719867\n",
      "Validation score: -49.019070\n",
      "Iteration 2, loss = 2542.33425286\n",
      "Validation score: -48.970829\n",
      "Iteration 3, loss = 2539.85603463\n",
      "Validation score: -48.922707\n",
      "Iteration 4, loss = 2537.38738331\n",
      "Validation score: -48.874683\n",
      "Iteration 5, loss = 2534.92186015\n",
      "Validation score: -48.826794\n",
      "Iteration 6, loss = 2532.47298872\n",
      "Validation score: -48.778987\n",
      "Iteration 7, loss = 2530.01689885\n",
      "Validation score: -48.731347\n",
      "Iteration 8, loss = 2527.57681288\n",
      "Validation score: -48.683830\n",
      "Iteration 9, loss = 2525.13720771\n",
      "Validation score: -48.636462\n",
      "Iteration 10, loss = 2522.71136133\n",
      "Validation score: -48.589202\n",
      "Iteration 11, loss = 2520.28329328\n",
      "Validation score: -48.542148\n",
      "Iteration 12, loss = 2517.86849736\n",
      "Validation score: -48.495193\n",
      "Iteration 13, loss = 2515.45859995\n",
      "Validation score: -48.448346\n",
      "Iteration 14, loss = 2513.05869090\n",
      "Validation score: -48.401601\n",
      "Iteration 15, loss = 2510.65895163\n",
      "Validation score: -48.355083\n",
      "Iteration 16, loss = 2508.26296486\n",
      "Validation score: -48.308761\n",
      "Iteration 17, loss = 2505.88286379\n",
      "Validation score: -48.262518\n",
      "Iteration 18, loss = 2503.50741954\n",
      "Validation score: -48.216386\n",
      "Iteration 19, loss = 2501.13468248\n",
      "Validation score: -48.170444\n",
      "Iteration 20, loss = 2498.76984069\n",
      "Validation score: -48.124637\n",
      "Iteration 21, loss = 2496.41731084\n",
      "Validation score: -48.078910\n",
      "Iteration 22, loss = 2494.06447238\n",
      "Validation score: -48.033335\n",
      "Iteration 23, loss = 2491.71984245\n",
      "Validation score: -47.987984\n",
      "Iteration 24, loss = 2489.38642401\n",
      "Validation score: -47.942828\n",
      "Iteration 25, loss = 2487.06066550\n",
      "Validation score: -47.897779\n",
      "Iteration 26, loss = 2484.74301665\n",
      "Validation score: -47.852850\n",
      "Iteration 27, loss = 2482.42900382\n",
      "Validation score: -47.808078\n",
      "Iteration 28, loss = 2480.11841758\n",
      "Validation score: -47.763555\n",
      "Iteration 29, loss = 2477.82319766\n",
      "Validation score: -47.719188\n",
      "Iteration 30, loss = 2475.53900749\n",
      "Validation score: -47.674992\n",
      "Iteration 31, loss = 2473.26062161\n",
      "Validation score: -47.631029\n",
      "Iteration 32, loss = 2470.99730753\n",
      "Validation score: -47.587164\n",
      "Iteration 33, loss = 2468.72367488\n",
      "Validation score: -47.543636\n",
      "Iteration 34, loss = 2466.48146678\n",
      "Validation score: -47.500155\n",
      "Iteration 35, loss = 2464.23611876\n",
      "Validation score: -47.456905\n",
      "Iteration 36, loss = 2462.00524227\n",
      "Validation score: -47.413841\n",
      "Iteration 37, loss = 2459.78161979\n",
      "Validation score: -47.371016\n",
      "Iteration 38, loss = 2457.56532286\n",
      "Validation score: -47.328427\n",
      "Iteration 39, loss = 2455.36409581\n",
      "Validation score: -47.286071\n",
      "Iteration 40, loss = 2453.17836788\n",
      "Validation score: -47.243879\n",
      "Iteration 41, loss = 2450.99190660\n",
      "Validation score: -47.202011\n",
      "Iteration 42, loss = 2448.82992359\n",
      "Validation score: -47.160243\n",
      "Iteration 43, loss = 2446.67248607\n",
      "Validation score: -47.118786\n",
      "Iteration 44, loss = 2444.52711122\n",
      "Validation score: -47.077591\n",
      "Iteration 45, loss = 2442.39209408\n",
      "Validation score: -47.036608\n",
      "Iteration 46, loss = 2440.27347925\n",
      "Validation score: -46.995827\n",
      "Iteration 47, loss = 2438.15741314\n",
      "Validation score: -46.955353\n",
      "Iteration 48, loss = 2436.06542682\n",
      "Validation score: -46.914999\n",
      "Iteration 49, loss = 2433.97749117\n",
      "Validation score: -46.874854\n",
      "Iteration 50, loss = 2431.90407078\n",
      "Validation score: -46.835034\n",
      "Iteration 51, loss = 2429.84151107\n",
      "Validation score: -46.795457\n",
      "Iteration 52, loss = 2427.79748728\n",
      "Validation score: -46.756118\n",
      "Iteration 53, loss = 2425.76171369\n",
      "Validation score: -46.717058\n",
      "Iteration 54, loss = 2423.74122858\n",
      "Validation score: -46.678226\n",
      "Iteration 55, loss = 2421.72802066\n",
      "Validation score: -46.639638\n",
      "Iteration 56, loss = 2419.73536476\n",
      "Validation score: -46.601237\n",
      "Iteration 57, loss = 2417.74622288\n",
      "Validation score: -46.563217\n",
      "Iteration 58, loss = 2415.78059968\n",
      "Validation score: -46.525409\n",
      "Iteration 59, loss = 2413.81829544\n",
      "Validation score: -46.487850\n",
      "Iteration 60, loss = 2411.88016944\n",
      "Validation score: -46.450474\n",
      "Iteration 61, loss = 2409.94175012\n",
      "Validation score: -46.413412\n",
      "Iteration 62, loss = 2408.02460128\n",
      "Validation score: -46.376535\n",
      "Iteration 63, loss = 2406.11623202\n",
      "Validation score: -46.339932\n",
      "Iteration 64, loss = 2404.21968736\n",
      "Validation score: -46.303635\n",
      "Iteration 65, loss = 2402.34625264\n",
      "Validation score: -46.267515\n",
      "Iteration 66, loss = 2400.47018978\n",
      "Validation score: -46.231704\n",
      "Iteration 67, loss = 2398.62018699\n",
      "Validation score: -46.196029\n",
      "Iteration 68, loss = 2396.77489480\n",
      "Validation score: -46.160582\n",
      "Iteration 69, loss = 2394.94335029\n",
      "Validation score: -46.125330\n",
      "Iteration 70, loss = 2393.12449864\n",
      "Validation score: -46.090336\n",
      "Iteration 71, loss = 2391.31234145\n",
      "Validation score: -46.055642\n",
      "Iteration 72, loss = 2389.51652622\n",
      "Validation score: -46.021195\n",
      "Iteration 73, loss = 2387.73917118\n",
      "Validation score: -45.986835\n",
      "Iteration 74, loss = 2385.96222184\n",
      "Validation score: -45.952778\n",
      "Iteration 75, loss = 2384.20761598\n",
      "Validation score: -45.918909\n",
      "Iteration 76, loss = 2382.45434700\n",
      "Validation score: -45.885338\n",
      "Iteration 77, loss = 2380.72146448\n",
      "Validation score: -45.851898\n",
      "Iteration 78, loss = 2378.99557090\n",
      "Validation score: -45.818670\n",
      "Iteration 79, loss = 2377.27980892\n",
      "Validation score: -45.785667\n",
      "Iteration 80, loss = 2375.57481242\n",
      "Validation score: -45.752893\n",
      "Iteration 81, loss = 2373.88027486\n",
      "Validation score: -45.720307\n",
      "Iteration 82, loss = 2372.20037549\n",
      "Validation score: -45.687859\n",
      "Iteration 83, loss = 2370.53087044\n",
      "Validation score: -45.655656\n",
      "Iteration 84, loss = 2368.86885006\n",
      "Validation score: -45.623555\n",
      "Iteration 85, loss = 2367.21545237\n",
      "Validation score: -45.591660\n",
      "Iteration 86, loss = 2365.57194175\n",
      "Validation score: -45.559992\n",
      "Iteration 87, loss = 2363.94401416\n",
      "Validation score: -45.528503\n",
      "Iteration 88, loss = 2362.32094694\n",
      "Validation score: -45.497180\n",
      "Iteration 89, loss = 2360.70698248\n",
      "Validation score: -45.466075\n",
      "Iteration 90, loss = 2359.10434602\n",
      "Validation score: -45.435059\n",
      "Iteration 91, loss = 2357.51104792\n",
      "Validation score: -45.404235\n",
      "Iteration 92, loss = 2355.92498593\n",
      "Validation score: -45.373575\n",
      "Iteration 93, loss = 2354.34990061\n",
      "Validation score: -45.343017\n",
      "Iteration 94, loss = 2352.77889806\n",
      "Validation score: -45.312676\n",
      "Iteration 95, loss = 2351.22044086\n",
      "Validation score: -45.282421\n",
      "Iteration 96, loss = 2349.66705262\n",
      "Validation score: -45.252419\n",
      "Iteration 97, loss = 2348.12364636\n",
      "Validation score: -45.222441\n",
      "Iteration 98, loss = 2346.58636665\n",
      "Validation score: -45.192641\n",
      "Iteration 99, loss = 2345.05547913\n",
      "Validation score: -45.162915\n",
      "Iteration 100, loss = 2343.52999502\n",
      "Validation score: -45.133397\n",
      "Iteration 101, loss = 2342.01445454\n",
      "Validation score: -45.103966\n",
      "Iteration 102, loss = 2340.50244313\n",
      "Validation score: -45.074593\n",
      "Iteration 103, loss = 2338.99845187\n",
      "Validation score: -45.045347\n",
      "Iteration 104, loss = 2337.49612455\n",
      "Validation score: -45.016214\n",
      "Iteration 105, loss = 2336.00456991\n",
      "Validation score: -44.987164\n",
      "Iteration 106, loss = 2334.51664977\n",
      "Validation score: -44.958222\n",
      "Iteration 107, loss = 2333.03402401\n",
      "Validation score: -44.929452\n",
      "Iteration 108, loss = 2331.55888929\n",
      "Validation score: -44.900714\n",
      "Iteration 109, loss = 2330.08652500\n",
      "Validation score: -44.872048\n",
      "Iteration 110, loss = 2328.62058891\n",
      "Validation score: -44.843503\n",
      "Iteration 111, loss = 2327.15978174\n",
      "Validation score: -44.815052\n",
      "Iteration 112, loss = 2325.69940215\n",
      "Validation score: -44.786728\n",
      "Iteration 113, loss = 2324.24969832\n",
      "Validation score: -44.758397\n",
      "Iteration 114, loss = 2322.80156303\n",
      "Validation score: -44.730192\n",
      "Iteration 115, loss = 2321.35709915\n",
      "Validation score: -44.702023\n",
      "Iteration 116, loss = 2319.91784873\n",
      "Validation score: -44.673901\n",
      "Iteration 117, loss = 2318.48137784\n",
      "Validation score: -44.645816\n",
      "Iteration 118, loss = 2317.04524989\n",
      "Validation score: -44.617862\n",
      "Iteration 119, loss = 2315.62092638\n",
      "Validation score: -44.589903\n",
      "Iteration 120, loss = 2314.19322959\n",
      "Validation score: -44.562043\n",
      "Iteration 121, loss = 2312.77277576\n",
      "Validation score: -44.534232\n",
      "Iteration 122, loss = 2311.35226818\n",
      "Validation score: -44.506468\n",
      "Iteration 123, loss = 2309.93888637\n",
      "Validation score: -44.478811\n",
      "Iteration 124, loss = 2308.52609288\n",
      "Validation score: -44.451238\n",
      "Iteration 125, loss = 2307.11465106\n",
      "Validation score: -44.423717\n",
      "Iteration 126, loss = 2305.71142835\n",
      "Validation score: -44.396182\n",
      "Iteration 127, loss = 2304.30593525\n",
      "Validation score: -44.368686\n",
      "Iteration 128, loss = 2302.90381665\n",
      "Validation score: -44.341295\n",
      "Iteration 129, loss = 2301.50611850\n",
      "Validation score: -44.313919\n",
      "Iteration 130, loss = 2300.10884098\n",
      "Validation score: -44.286556\n",
      "Iteration 131, loss = 2298.71534202\n",
      "Validation score: -44.259254\n",
      "Iteration 132, loss = 2297.32384407\n",
      "Validation score: -44.232008\n",
      "Iteration 133, loss = 2295.93730561\n",
      "Validation score: -44.204804\n",
      "Iteration 134, loss = 2294.55142077\n",
      "Validation score: -44.177648\n",
      "Iteration 135, loss = 2293.16818301\n",
      "Validation score: -44.150572\n",
      "Iteration 136, loss = 2291.79192126\n",
      "Validation score: -44.123540\n",
      "Iteration 137, loss = 2290.41589927\n",
      "Validation score: -44.096616\n",
      "Iteration 138, loss = 2289.04370529\n",
      "Validation score: -44.069701\n",
      "Iteration 139, loss = 2287.67574634\n",
      "Validation score: -44.042864\n",
      "Iteration 140, loss = 2286.31020708\n",
      "Validation score: -44.016096\n",
      "Iteration 141, loss = 2284.94864858\n",
      "Validation score: -43.989404\n",
      "Iteration 142, loss = 2283.59067858\n",
      "Validation score: -43.962781\n",
      "Iteration 143, loss = 2282.24009447\n",
      "Validation score: -43.936155\n",
      "Iteration 144, loss = 2280.88483129\n",
      "Validation score: -43.909686\n",
      "Iteration 145, loss = 2279.54042475\n",
      "Validation score: -43.883262\n",
      "Iteration 146, loss = 2278.19473185\n",
      "Validation score: -43.856940\n",
      "Iteration 147, loss = 2276.85895492\n",
      "Validation score: -43.830635\n",
      "Iteration 148, loss = 2275.52156074\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation score: -43.804413\n",
      "Iteration 149, loss = 2274.18992558\n",
      "Validation score: -43.778238\n",
      "Iteration 150, loss = 2272.86165931\n",
      "Validation score: -43.752134\n",
      "Iteration 151, loss = 2271.53380687\n",
      "Validation score: -43.726106\n",
      "Iteration 152, loss = 2270.21558293\n",
      "Validation score: -43.700166\n",
      "Iteration 153, loss = 2268.89753187\n",
      "Validation score: -43.674327\n",
      "Iteration 154, loss = 2267.58384465\n",
      "Validation score: -43.648536\n",
      "Iteration 155, loss = 2266.27836156\n",
      "Validation score: -43.622840\n",
      "Iteration 156, loss = 2264.97603953\n",
      "Validation score: -43.597244\n",
      "Iteration 157, loss = 2263.67300997\n",
      "Validation score: -43.571753\n",
      "Iteration 158, loss = 2262.38050349\n",
      "Validation score: -43.546237\n",
      "Iteration 159, loss = 2261.08436101\n",
      "Validation score: -43.520858\n",
      "Iteration 160, loss = 2259.79657980\n",
      "Validation score: -43.495521\n",
      "Iteration 161, loss = 2258.51241685\n",
      "Validation score: -43.470219\n",
      "Iteration 162, loss = 2257.23354686\n",
      "Validation score: -43.445044\n",
      "Iteration 163, loss = 2255.95740141\n",
      "Validation score: -43.419993\n",
      "Iteration 164, loss = 2254.68550750\n",
      "Validation score: -43.395028\n",
      "Iteration 165, loss = 2253.42116313\n",
      "Validation score: -43.370103\n",
      "Iteration 166, loss = 2252.15877635\n",
      "Validation score: -43.345264\n",
      "Iteration 167, loss = 2250.89904166\n",
      "Validation score: -43.320526\n",
      "Iteration 168, loss = 2249.64657854\n",
      "Validation score: -43.295842\n",
      "Iteration 169, loss = 2248.39346686\n",
      "Validation score: -43.271266\n",
      "Iteration 170, loss = 2247.14750566\n",
      "Validation score: -43.246708\n",
      "Iteration 171, loss = 2245.90315775\n",
      "Validation score: -43.222226\n",
      "Iteration 172, loss = 2244.66365739\n",
      "Validation score: -43.197858\n",
      "Iteration 173, loss = 2243.42793872\n",
      "Validation score: -43.173560\n",
      "Iteration 174, loss = 2242.19813145\n",
      "Validation score: -43.149308\n",
      "Iteration 175, loss = 2240.96821969\n",
      "Validation score: -43.125160\n",
      "Iteration 176, loss = 2239.74311381\n",
      "Validation score: -43.101033\n",
      "Iteration 177, loss = 2238.52248298\n",
      "Validation score: -43.076984\n",
      "Iteration 178, loss = 2237.30361810\n",
      "Validation score: -43.053012\n",
      "Iteration 179, loss = 2236.08946478\n",
      "Validation score: -43.029105\n",
      "Iteration 180, loss = 2234.87815715\n",
      "Validation score: -43.005299\n",
      "Iteration 181, loss = 2233.67322241\n",
      "Validation score: -42.981534\n",
      "Iteration 182, loss = 2232.46980111\n",
      "Validation score: -42.957870\n",
      "Iteration 183, loss = 2231.27159552\n",
      "Validation score: -42.934278\n",
      "Iteration 184, loss = 2230.07448698\n",
      "Validation score: -42.910710\n",
      "Iteration 185, loss = 2228.88134057\n",
      "Validation score: -42.887197\n",
      "Iteration 186, loss = 2227.68928936\n",
      "Validation score: -42.863764\n",
      "Iteration 187, loss = 2226.50187676\n",
      "Validation score: -42.840401\n",
      "Iteration 188, loss = 2225.31685342\n",
      "Validation score: -42.817073\n",
      "Iteration 189, loss = 2224.13829476\n",
      "Validation score: -42.793761\n",
      "Iteration 190, loss = 2222.95679779\n",
      "Validation score: -42.770530\n",
      "Iteration 191, loss = 2221.78151374\n",
      "Validation score: -42.747298\n",
      "Iteration 192, loss = 2220.60705348\n",
      "Validation score: -42.724149\n",
      "Iteration 193, loss = 2219.43182257\n",
      "Validation score: -42.701095\n",
      "Iteration 194, loss = 2218.26470980\n",
      "Validation score: -42.678053\n",
      "Iteration 195, loss = 2217.09643466\n",
      "Validation score: -42.655037\n",
      "Iteration 196, loss = 2215.92902718\n",
      "Validation score: -42.632055\n",
      "Iteration 197, loss = 2214.76740404\n",
      "Validation score: -42.609073\n",
      "Iteration 198, loss = 2213.60395325\n",
      "Validation score: -42.586152\n",
      "Iteration 199, loss = 2212.44332746\n",
      "Validation score: -42.563327\n",
      "Iteration 200, loss = 2211.28614521\n",
      "Validation score: -42.540513\n",
      "Iteration 201, loss = 2210.12884621\n",
      "Validation score: -42.517773\n",
      "Iteration 202, loss = 2208.97492490\n",
      "Validation score: -42.495036\n",
      "Iteration 203, loss = 2207.82100481\n",
      "Validation score: -42.472306\n",
      "Iteration 204, loss = 2206.66948369\n",
      "Validation score: -42.449606\n",
      "Iteration 205, loss = 2205.51722820\n",
      "Validation score: -42.426935\n",
      "Iteration 206, loss = 2204.36935953\n",
      "Validation score: -42.404268\n",
      "Iteration 207, loss = 2203.21834679\n",
      "Validation score: -42.381648\n",
      "Iteration 208, loss = 2202.07052583\n",
      "Validation score: -42.359040\n",
      "Iteration 209, loss = 2200.92325508\n",
      "Validation score: -42.336402\n",
      "Iteration 210, loss = 2199.77768628\n",
      "Validation score: -42.313818\n",
      "Iteration 211, loss = 2198.62941377\n",
      "Validation score: -42.291278\n",
      "Iteration 212, loss = 2197.48623202\n",
      "Validation score: -42.268729\n",
      "Iteration 213, loss = 2196.34425067\n",
      "Validation score: -42.246190\n",
      "Iteration 214, loss = 2195.19803059\n",
      "Validation score: -42.223731\n",
      "Iteration 215, loss = 2194.05745583\n",
      "Validation score: -42.201245\n",
      "Iteration 216, loss = 2192.91636286\n",
      "Validation score: -42.178803\n",
      "Iteration 217, loss = 2191.77373525\n",
      "Validation score: -42.156372\n",
      "Iteration 218, loss = 2190.63422460\n",
      "Validation score: -42.133963\n",
      "Iteration 219, loss = 2189.49723607\n",
      "Validation score: -42.111539\n",
      "Iteration 220, loss = 2188.35954111\n",
      "Validation score: -42.089154\n",
      "Iteration 221, loss = 2187.22085240\n",
      "Validation score: -42.066778\n",
      "Iteration 222, loss = 2186.08435499\n",
      "Validation score: -42.044432\n",
      "Iteration 223, loss = 2184.94654927\n",
      "Validation score: -42.022097\n",
      "Iteration 224, loss = 2183.81078530\n",
      "Validation score: -41.999747\n",
      "Iteration 225, loss = 2182.67625158\n",
      "Validation score: -41.977420\n",
      "Iteration 226, loss = 2181.54192083\n",
      "Validation score: -41.955132\n",
      "Iteration 227, loss = 2180.40749973\n",
      "Validation score: -41.932845\n",
      "Iteration 228, loss = 2179.27446950\n",
      "Validation score: -41.910549\n",
      "Iteration 229, loss = 2178.14432353\n",
      "Validation score: -41.888288\n",
      "Iteration 230, loss = 2177.00999464\n",
      "Validation score: -41.866065\n",
      "Iteration 231, loss = 2175.88191949\n",
      "Validation score: -41.843879\n",
      "Iteration 232, loss = 2174.75172076\n",
      "Validation score: -41.821730\n",
      "Iteration 233, loss = 2173.62512169\n",
      "Validation score: -41.799588\n",
      "Iteration 234, loss = 2172.49983653\n",
      "Validation score: -41.777465\n",
      "Iteration 235, loss = 2171.37401019\n",
      "Validation score: -41.755345\n",
      "Iteration 236, loss = 2170.25181044\n",
      "Validation score: -41.733297\n",
      "Iteration 237, loss = 2169.12971931\n",
      "Validation score: -41.711309\n",
      "Iteration 238, loss = 2168.01119972\n",
      "Validation score: -41.689346\n",
      "Iteration 239, loss = 2166.89612736\n",
      "Validation score: -41.667399\n",
      "Iteration 240, loss = 2165.77881224\n",
      "Validation score: -41.645486\n",
      "Iteration 241, loss = 2164.66249217\n",
      "Validation score: -41.623613\n",
      "Iteration 242, loss = 2163.55124719\n",
      "Validation score: -41.601724\n",
      "Iteration 243, loss = 2162.43803120\n",
      "Validation score: -41.579897\n",
      "Iteration 244, loss = 2161.33001085\n",
      "Validation score: -41.558117\n",
      "Iteration 245, loss = 2160.22416127\n",
      "Validation score: -41.536365\n",
      "Iteration 246, loss = 2159.11806543\n",
      "Validation score: -41.514660\n",
      "Iteration 247, loss = 2158.01765752\n",
      "Validation score: -41.492988\n",
      "Iteration 248, loss = 2156.91457088\n",
      "Validation score: -41.471355\n",
      "Iteration 249, loss = 2155.81749148\n",
      "Validation score: -41.449739\n",
      "Iteration 250, loss = 2154.71958061\n",
      "Validation score: -41.428177\n",
      "Iteration 251, loss = 2153.62173521\n",
      "Validation score: -41.406698\n",
      "Iteration 252, loss = 2152.52914351\n",
      "Validation score: -41.385212\n",
      "Iteration 253, loss = 2151.43597881\n",
      "Validation score: -41.363772\n",
      "Iteration 254, loss = 2150.34676771\n",
      "Validation score: -41.342361\n",
      "Iteration 255, loss = 2149.25737963\n",
      "Validation score: -41.320997\n",
      "Iteration 256, loss = 2148.17025300\n",
      "Validation score: -41.299684\n",
      "Iteration 257, loss = 2147.08712440\n",
      "Validation score: -41.278364\n",
      "Iteration 258, loss = 2146.00425072\n",
      "Validation score: -41.257093\n",
      "Iteration 259, loss = 2144.92286735\n",
      "Validation score: -41.235901\n",
      "Iteration 260, loss = 2143.84378236\n",
      "Validation score: -41.214692\n",
      "Iteration 261, loss = 2142.76633113\n",
      "Validation score: -41.193565\n",
      "Iteration 262, loss = 2141.69102485\n",
      "Validation score: -41.172495\n",
      "Iteration 263, loss = 2140.62040729\n",
      "Validation score: -41.151436\n",
      "Iteration 264, loss = 2139.54957692\n",
      "Validation score: -41.130428\n",
      "Iteration 265, loss = 2138.47910516\n",
      "Validation score: -41.109483\n",
      "Iteration 266, loss = 2137.41282354\n",
      "Validation score: -41.088550\n",
      "Iteration 267, loss = 2136.34822623\n",
      "Validation score: -41.067621\n",
      "Iteration 268, loss = 2135.28205085\n",
      "Validation score: -41.046745\n",
      "Iteration 269, loss = 2134.21977181\n",
      "Validation score: -41.025892\n",
      "Iteration 270, loss = 2133.15861598\n",
      "Validation score: -41.005046\n",
      "Iteration 271, loss = 2132.10123364\n",
      "Validation score: -40.984204\n",
      "Iteration 272, loss = 2131.04205373\n",
      "Validation score: -40.963458\n",
      "Iteration 273, loss = 2129.98344017\n",
      "Validation score: -40.942787\n",
      "Iteration 274, loss = 2128.93010854\n",
      "Validation score: -40.922082\n",
      "Iteration 275, loss = 2127.87863629\n",
      "Validation score: -40.901418\n",
      "Iteration 276, loss = 2126.82751334\n",
      "Validation score: -40.880773\n",
      "Iteration 277, loss = 2125.77731195\n",
      "Validation score: -40.860185\n",
      "Iteration 278, loss = 2124.72841305\n",
      "Validation score: -40.839639\n",
      "Iteration 279, loss = 2123.68360505\n",
      "Validation score: -40.819102\n",
      "Iteration 280, loss = 2122.63824729\n",
      "Validation score: -40.798596\n",
      "Iteration 281, loss = 2121.59262732\n",
      "Validation score: -40.778128\n",
      "Iteration 282, loss = 2120.55223260\n",
      "Validation score: -40.757607\n",
      "Iteration 283, loss = 2119.50936801\n",
      "Validation score: -40.737154\n",
      "Iteration 284, loss = 2118.46726607\n",
      "Validation score: -40.716737\n",
      "Iteration 285, loss = 2117.42937368\n",
      "Validation score: -40.696314\n",
      "Iteration 286, loss = 2116.39003236\n",
      "Validation score: -40.675936\n",
      "Iteration 287, loss = 2115.35165719\n",
      "Validation score: -40.655590\n",
      "Iteration 288, loss = 2114.31729900\n",
      "Validation score: -40.635250\n",
      "Iteration 289, loss = 2113.28112631\n",
      "Validation score: -40.614939\n",
      "Iteration 290, loss = 2112.24447588\n",
      "Validation score: -40.594639\n",
      "Iteration 291, loss = 2111.21136660\n",
      "Validation score: -40.574308\n",
      "Iteration 292, loss = 2110.17566349\n",
      "Validation score: -40.553980\n",
      "Iteration 293, loss = 2109.14106142\n",
      "Validation score: -40.533682\n",
      "Iteration 294, loss = 2108.10601065\n",
      "Validation score: -40.513409\n",
      "Iteration 295, loss = 2107.07332812\n",
      "Validation score: -40.493123\n",
      "Iteration 296, loss = 2106.03985037\n",
      "Validation score: -40.472830\n",
      "Iteration 297, loss = 2105.00597540\n",
      "Validation score: -40.452535\n",
      "Iteration 298, loss = 2103.97302187\n",
      "Validation score: -40.432215\n",
      "Iteration 299, loss = 2102.93729340\n",
      "Validation score: -40.411930\n",
      "Iteration 300, loss = 2101.90355401\n",
      "Validation score: -40.391606\n",
      "Iteration 301, loss = 2100.86782779\n",
      "Validation score: -40.371316\n",
      "Iteration 302, loss = 2099.83317869\n",
      "Validation score: -40.350998\n",
      "Iteration 303, loss = 2098.79773368\n",
      "Validation score: -40.330664\n",
      "Iteration 304, loss = 2097.76228321\n",
      "Validation score: -40.310289\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 305, loss = 2096.72244776\n",
      "Validation score: -40.289908\n",
      "Iteration 306, loss = 2095.68495429\n",
      "Validation score: -40.269463\n",
      "Iteration 307, loss = 2094.64144561\n",
      "Validation score: -40.249010\n",
      "Iteration 308, loss = 2093.59794618\n",
      "Validation score: -40.228525\n",
      "Iteration 309, loss = 2092.55223777\n",
      "Validation score: -40.207985\n",
      "Iteration 310, loss = 2091.50320941\n",
      "Validation score: -40.187399\n",
      "Iteration 311, loss = 2090.45455067\n",
      "Validation score: -40.166737\n",
      "Iteration 312, loss = 2089.40061190\n",
      "Validation score: -40.146036\n",
      "Iteration 313, loss = 2088.34611580\n",
      "Validation score: -40.125287\n",
      "Iteration 314, loss = 2087.28457724\n",
      "Validation score: -40.104535\n",
      "Iteration 315, loss = 2086.22561097\n",
      "Validation score: -40.083713\n",
      "Iteration 316, loss = 2085.16221424\n",
      "Validation score: -40.062827\n",
      "Iteration 317, loss = 2084.09663943\n",
      "Validation score: -40.041852\n",
      "Iteration 318, loss = 2083.02432924\n",
      "Validation score: -40.020865\n",
      "Iteration 319, loss = 2081.95216113\n",
      "Validation score: -39.999759\n",
      "Iteration 320, loss = 2080.87412672\n",
      "Validation score: -39.978633\n",
      "Iteration 321, loss = 2079.79497657\n",
      "Validation score: -39.957465\n",
      "Iteration 322, loss = 2078.71425945\n",
      "Validation score: -39.936211\n",
      "Iteration 323, loss = 2077.62811105\n",
      "Validation score: -39.914923\n",
      "Iteration 324, loss = 2076.53806161\n",
      "Validation score: -39.893587\n",
      "Iteration 325, loss = 2075.44746093\n",
      "Validation score: -39.872193\n",
      "Iteration 326, loss = 2074.35690350\n",
      "Validation score: -39.850685\n",
      "Iteration 327, loss = 2073.25610130\n",
      "Validation score: -39.829209\n",
      "Iteration 328, loss = 2072.15994169\n",
      "Validation score: -39.807643\n",
      "Iteration 329, loss = 2071.05887130\n",
      "Validation score: -39.786049\n",
      "Iteration 330, loss = 2069.95544452\n",
      "Validation score: -39.764457\n",
      "Iteration 331, loss = 2068.85094306\n",
      "Validation score: -39.742856\n",
      "Iteration 332, loss = 2067.74661298\n",
      "Validation score: -39.721210\n",
      "Iteration 333, loss = 2066.64252510\n",
      "Validation score: -39.699554\n",
      "Iteration 334, loss = 2065.53692520\n",
      "Validation score: -39.677922\n",
      "Iteration 335, loss = 2064.43106214\n",
      "Validation score: -39.656288\n",
      "Iteration 336, loss = 2063.32519388\n",
      "Validation score: -39.634658\n",
      "Iteration 337, loss = 2062.22088187\n",
      "Validation score: -39.612985\n",
      "Iteration 338, loss = 2061.11292559\n",
      "Validation score: -39.591339\n",
      "Iteration 339, loss = 2060.00617582\n",
      "Validation score: -39.569704\n",
      "Iteration 340, loss = 2058.90151297\n",
      "Validation score: -39.548064\n",
      "Iteration 341, loss = 2057.79459712\n",
      "Validation score: -39.526447\n",
      "Iteration 342, loss = 2056.69083655\n",
      "Validation score: -39.504816\n",
      "Iteration 343, loss = 2055.58406540\n",
      "Validation score: -39.483192\n",
      "Iteration 344, loss = 2054.47945492\n",
      "Validation score: -39.461574\n",
      "Iteration 345, loss = 2053.37550469\n",
      "Validation score: -39.439934\n",
      "Iteration 346, loss = 2052.27205203\n",
      "Validation score: -39.418300\n",
      "Iteration 347, loss = 2051.16505086\n",
      "Validation score: -39.396731\n",
      "Iteration 348, loss = 2050.06587931\n",
      "Validation score: -39.375148\n",
      "Iteration 349, loss = 2048.96266961\n",
      "Validation score: -39.353581\n",
      "Iteration 350, loss = 2047.85818603\n",
      "Validation score: -39.332009\n",
      "Iteration 351, loss = 2046.75713888\n",
      "Validation score: -39.310395\n",
      "Iteration 352, loss = 2045.65255899\n",
      "Validation score: -39.288816\n",
      "Iteration 353, loss = 2044.55012060\n",
      "Validation score: -39.267215\n",
      "Iteration 354, loss = 2043.44744459\n",
      "Validation score: -39.245607\n",
      "Iteration 355, loss = 2042.34377421\n",
      "Validation score: -39.223991\n",
      "Iteration 356, loss = 2041.23794794\n",
      "Validation score: -39.202407\n",
      "Iteration 357, loss = 2040.13522761\n",
      "Validation score: -39.180817\n",
      "Iteration 358, loss = 2039.03269446\n",
      "Validation score: -39.159190\n",
      "Iteration 359, loss = 2037.92756481\n",
      "Validation score: -39.137558\n",
      "Iteration 360, loss = 2036.82433927\n",
      "Validation score: -39.115920\n",
      "Iteration 361, loss = 2035.71780615\n",
      "Validation score: -39.094284\n",
      "Iteration 362, loss = 2034.61311199\n",
      "Validation score: -39.072639\n",
      "Iteration 363, loss = 2033.50627186\n",
      "Validation score: -39.051007\n",
      "Iteration 364, loss = 2032.40044947\n",
      "Validation score: -39.029337\n",
      "Iteration 365, loss = 2031.29471369\n",
      "Validation score: -39.007643\n",
      "Iteration 366, loss = 2030.18360702\n",
      "Validation score: -38.985952\n",
      "Iteration 367, loss = 2029.07692280\n",
      "Validation score: -38.964225\n",
      "Iteration 368, loss = 2027.96292955\n",
      "Validation score: -38.942523\n",
      "Iteration 369, loss = 2026.85527814\n",
      "Validation score: -38.920785\n",
      "Iteration 370, loss = 2025.74262083\n",
      "Validation score: -38.899057\n",
      "Iteration 371, loss = 2024.63198900\n",
      "Validation score: -38.877306\n",
      "Iteration 372, loss = 2023.52007177\n",
      "Validation score: -38.855552\n",
      "Iteration 373, loss = 2022.41130493\n",
      "Validation score: -38.833784\n",
      "Iteration 374, loss = 2021.29611796\n",
      "Validation score: -38.812055\n",
      "Iteration 375, loss = 2020.18667517\n",
      "Validation score: -38.790278\n",
      "Iteration 376, loss = 2019.07481383\n",
      "Validation score: -38.768536\n",
      "Iteration 377, loss = 2017.96222076\n",
      "Validation score: -38.746808\n",
      "Iteration 378, loss = 2016.85108766\n",
      "Validation score: -38.725128\n",
      "Iteration 379, loss = 2015.74410300\n",
      "Validation score: -38.703417\n",
      "Iteration 380, loss = 2014.63305124\n",
      "Validation score: -38.681756\n",
      "Iteration 381, loss = 2013.52555236\n",
      "Validation score: -38.660080\n",
      "Iteration 382, loss = 2012.41681039\n",
      "Validation score: -38.638449\n",
      "Iteration 383, loss = 2011.31294037\n",
      "Validation score: -38.616830\n",
      "Iteration 384, loss = 2010.20875727\n",
      "Validation score: -38.595243\n",
      "Iteration 385, loss = 2009.10690966\n",
      "Validation score: -38.573697\n",
      "Iteration 386, loss = 2008.00630800\n",
      "Validation score: -38.552196\n",
      "Iteration 387, loss = 2006.90888014\n",
      "Validation score: -38.530720\n",
      "Iteration 388, loss = 2005.81151906\n",
      "Validation score: -38.509281\n",
      "Iteration 389, loss = 2004.71463570\n",
      "Validation score: -38.487883\n",
      "Iteration 390, loss = 2003.62359777\n",
      "Validation score: -38.466457\n",
      "Iteration 391, loss = 2002.53151059\n",
      "Validation score: -38.445074\n",
      "Iteration 392, loss = 2001.43848909\n",
      "Validation score: -38.423753\n",
      "Iteration 393, loss = 2000.34845854\n",
      "Validation score: -38.402510\n",
      "Iteration 394, loss = 1999.26501582\n",
      "Validation score: -38.381301\n",
      "Iteration 395, loss = 1998.18184630\n",
      "Validation score: -38.360149\n",
      "Iteration 396, loss = 1997.10145922\n",
      "Validation score: -38.339023\n",
      "Iteration 397, loss = 1996.02329322\n",
      "Validation score: -38.317885\n",
      "Iteration 398, loss = 1994.94529031\n",
      "Validation score: -38.296806\n",
      "Iteration 399, loss = 1993.87080505\n",
      "Validation score: -38.275768\n",
      "Iteration 400, loss = 1992.79652594\n",
      "Validation score: -38.254821\n",
      "Iteration 401, loss = 1991.72505187\n",
      "Validation score: -38.233917\n",
      "Iteration 402, loss = 1990.65827406\n",
      "Validation score: -38.213006\n",
      "Iteration 403, loss = 1989.59055547\n",
      "Validation score: -38.192159\n",
      "Iteration 404, loss = 1988.52624638\n",
      "Validation score: -38.171350\n",
      "Iteration 405, loss = 1987.46577084\n",
      "Validation score: -38.150555\n",
      "Iteration 406, loss = 1986.40155709\n",
      "Validation score: -38.129841\n",
      "Iteration 407, loss = 1985.34510850\n",
      "Validation score: -38.109136\n",
      "Iteration 408, loss = 1984.28669964\n",
      "Validation score: -38.088479\n",
      "Iteration 409, loss = 1983.23514660\n",
      "Validation score: -38.067822\n",
      "Iteration 410, loss = 1982.18044236\n",
      "Validation score: -38.047244\n",
      "Iteration 411, loss = 1981.13002307\n",
      "Validation score: -38.026715\n",
      "Iteration 412, loss = 1980.08262741\n",
      "Validation score: -38.006216\n",
      "Iteration 413, loss = 1979.03573669\n",
      "Validation score: -37.985765\n",
      "Iteration 414, loss = 1977.99033030\n",
      "Validation score: -37.965359\n",
      "Iteration 415, loss = 1976.94967656\n",
      "Validation score: -37.944951\n",
      "Iteration 416, loss = 1975.90664744\n",
      "Validation score: -37.924617\n",
      "Iteration 417, loss = 1974.87142033\n",
      "Validation score: -37.904262\n",
      "Iteration 418, loss = 1973.83216060\n",
      "Validation score: -37.883997\n",
      "Iteration 419, loss = 1972.79634058\n",
      "Validation score: -37.863777\n",
      "Iteration 420, loss = 1971.76632725\n",
      "Validation score: -37.843532\n",
      "Iteration 421, loss = 1970.72961301\n",
      "Validation score: -37.823378\n",
      "Iteration 422, loss = 1969.70148672\n",
      "Validation score: -37.803209\n",
      "Iteration 423, loss = 1968.67244160\n",
      "Validation score: -37.783082\n",
      "Iteration 424, loss = 1967.64708948\n",
      "Validation score: -37.762989\n",
      "Iteration 425, loss = 1966.62180154\n",
      "Validation score: -37.742948\n",
      "Iteration 426, loss = 1965.59799465\n",
      "Validation score: -37.722936\n",
      "Iteration 427, loss = 1964.57669445\n",
      "Validation score: -37.702950\n",
      "Iteration 428, loss = 1963.55614986\n",
      "Validation score: -37.683002\n",
      "Iteration 429, loss = 1962.53687538\n",
      "Validation score: -37.663075\n",
      "Iteration 430, loss = 1961.52076651\n",
      "Validation score: -37.643136\n",
      "Iteration 431, loss = 1960.50396415\n",
      "Validation score: -37.623232\n",
      "Iteration 432, loss = 1959.48850460\n",
      "Validation score: -37.603361\n",
      "Iteration 433, loss = 1958.47297569\n",
      "Validation score: -37.583550\n",
      "Iteration 434, loss = 1957.46233598\n",
      "Validation score: -37.563738\n",
      "Iteration 435, loss = 1956.45011056\n",
      "Validation score: -37.543986\n",
      "Iteration 436, loss = 1955.44084475\n",
      "Validation score: -37.524240\n",
      "Iteration 437, loss = 1954.43488701\n",
      "Validation score: -37.504515\n",
      "Iteration 438, loss = 1953.42655299\n",
      "Validation score: -37.484837\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 439, loss = 1952.42234373\n",
      "Validation score: -37.465189\n",
      "Iteration 440, loss = 1951.41837461\n",
      "Validation score: -37.445549\n",
      "Iteration 441, loss = 1950.41611313\n",
      "Validation score: -37.425932\n",
      "Iteration 442, loss = 1949.41442172\n",
      "Validation score: -37.406354\n",
      "Iteration 443, loss = 1948.41602673\n",
      "Validation score: -37.386772\n",
      "Iteration 444, loss = 1947.41801701\n",
      "Validation score: -37.367215\n",
      "Iteration 445, loss = 1946.41670194\n",
      "Validation score: -37.347708\n",
      "Iteration 446, loss = 1945.42425078\n",
      "Validation score: -37.328170\n",
      "Iteration 447, loss = 1944.42624402\n",
      "Validation score: -37.308716\n",
      "Iteration 448, loss = 1943.43081836\n",
      "Validation score: -37.289289\n",
      "Iteration 449, loss = 1942.43936133\n",
      "Validation score: -37.269863\n",
      "Iteration 450, loss = 1941.44728172\n",
      "Validation score: -37.250447\n",
      "Iteration 451, loss = 1940.45547299\n",
      "Validation score: -37.231027\n",
      "Iteration 452, loss = 1939.46456935\n",
      "Validation score: -37.211646\n",
      "Iteration 453, loss = 1938.47592416\n",
      "Validation score: -37.192284\n",
      "Iteration 454, loss = 1937.48556498\n",
      "Validation score: -37.172955\n",
      "Iteration 455, loss = 1936.49884630\n",
      "Validation score: -37.153652\n",
      "Iteration 456, loss = 1935.51412833\n",
      "Validation score: -37.134321\n",
      "Iteration 457, loss = 1934.52900838\n",
      "Validation score: -37.115019\n",
      "Iteration 458, loss = 1933.54133440\n",
      "Validation score: -37.095807\n",
      "Iteration 459, loss = 1932.55923121\n",
      "Validation score: -37.076572\n",
      "Iteration 460, loss = 1931.57775638\n",
      "Validation score: -37.057325\n",
      "Iteration 461, loss = 1930.59496628\n",
      "Validation score: -37.038104\n",
      "Iteration 462, loss = 1929.61188949\n",
      "Validation score: -37.018902\n",
      "Iteration 463, loss = 1928.63268689\n",
      "Validation score: -36.999693\n",
      "Iteration 464, loss = 1927.65177619\n",
      "Validation score: -36.980485\n",
      "Iteration 465, loss = 1926.67287836\n",
      "Validation score: -36.961288\n",
      "Iteration 466, loss = 1925.69453978\n",
      "Validation score: -36.942129\n",
      "Iteration 467, loss = 1924.71676906\n",
      "Validation score: -36.923010\n",
      "Iteration 468, loss = 1923.73838636\n",
      "Validation score: -36.903941\n",
      "Iteration 469, loss = 1922.76458231\n",
      "Validation score: -36.884834\n",
      "Iteration 470, loss = 1921.78856102\n",
      "Validation score: -36.865741\n",
      "Iteration 471, loss = 1920.81512211\n",
      "Validation score: -36.846647\n",
      "Iteration 472, loss = 1919.84055325\n",
      "Validation score: -36.827551\n",
      "Iteration 473, loss = 1918.86547785\n",
      "Validation score: -36.808495\n",
      "Iteration 474, loss = 1917.89376795\n",
      "Validation score: -36.789428\n",
      "Iteration 475, loss = 1916.91878337\n",
      "Validation score: -36.770371\n",
      "Iteration 476, loss = 1915.94490591\n",
      "Validation score: -36.751315\n",
      "Iteration 477, loss = 1914.97128678\n",
      "Validation score: -36.732265\n",
      "Iteration 478, loss = 1913.99954924\n",
      "Validation score: -36.713190\n",
      "Iteration 479, loss = 1913.02738420\n",
      "Validation score: -36.694132\n",
      "Iteration 480, loss = 1912.05456001\n",
      "Validation score: -36.675110\n",
      "Iteration 481, loss = 1911.08221940\n",
      "Validation score: -36.656101\n",
      "Iteration 482, loss = 1910.11176523\n",
      "Validation score: -36.637092\n",
      "Iteration 483, loss = 1909.13847572\n",
      "Validation score: -36.618067\n",
      "Iteration 484, loss = 1908.16601541\n",
      "Validation score: -36.599033\n",
      "Iteration 485, loss = 1907.19473828\n",
      "Validation score: -36.579949\n",
      "Iteration 486, loss = 1906.22095511\n",
      "Validation score: -36.560839\n",
      "Iteration 487, loss = 1905.24731435\n",
      "Validation score: -36.541717\n",
      "Iteration 488, loss = 1904.26826629\n",
      "Validation score: -36.522654\n",
      "Iteration 489, loss = 1903.29636418\n",
      "Validation score: -36.503527\n",
      "Iteration 490, loss = 1902.31672356\n",
      "Validation score: -36.484390\n",
      "Iteration 491, loss = 1901.33764245\n",
      "Validation score: -36.465214\n",
      "Iteration 492, loss = 1900.35750865\n",
      "Validation score: -36.445988\n",
      "Iteration 493, loss = 1899.37533174\n",
      "Validation score: -36.426724\n",
      "Iteration 494, loss = 1898.39363350\n",
      "Validation score: -36.407401\n",
      "Iteration 495, loss = 1897.40660124\n",
      "Validation score: -36.388082\n",
      "Iteration 496, loss = 1896.41732079\n",
      "Validation score: -36.368729\n",
      "Iteration 497, loss = 1895.42949615\n",
      "Validation score: -36.349298\n",
      "Iteration 498, loss = 1894.43550611\n",
      "Validation score: -36.329828\n",
      "Iteration 499, loss = 1893.43871196\n",
      "Validation score: -36.310273\n",
      "Iteration 500, loss = 1892.43885054\n",
      "Validation score: -36.290625\n",
      "Iteration 501, loss = 1891.43457389\n",
      "Validation score: -36.270906\n",
      "Iteration 502, loss = 1890.42579090\n",
      "Validation score: -36.251106\n",
      "Iteration 503, loss = 1889.41108280\n",
      "Validation score: -36.231220\n",
      "Iteration 504, loss = 1888.39524151\n",
      "Validation score: -36.211208\n",
      "Iteration 505, loss = 1887.36999939\n",
      "Validation score: -36.191124\n",
      "Iteration 506, loss = 1886.34281334\n",
      "Validation score: -36.170922\n",
      "Iteration 507, loss = 1885.30665704\n",
      "Validation score: -36.150594\n",
      "Iteration 508, loss = 1884.26520960\n",
      "Validation score: -36.130174\n",
      "Iteration 509, loss = 1883.22138169\n",
      "Validation score: -36.109610\n",
      "Iteration 510, loss = 1882.17031027\n",
      "Validation score: -36.088952\n",
      "Iteration 511, loss = 1881.10879851\n",
      "Validation score: -36.068240\n",
      "Iteration 512, loss = 1880.04970278\n",
      "Validation score: -36.047390\n",
      "Iteration 513, loss = 1878.98186854\n",
      "Validation score: -36.026442\n",
      "Iteration 514, loss = 1877.90759204\n",
      "Validation score: -36.005453\n",
      "Iteration 515, loss = 1876.83342488\n",
      "Validation score: -35.984329\n",
      "Iteration 516, loss = 1875.74853362\n",
      "Validation score: -35.963157\n",
      "Iteration 517, loss = 1874.66461867\n",
      "Validation score: -35.941872\n",
      "Iteration 518, loss = 1873.57324320\n",
      "Validation score: -35.920518\n",
      "Iteration 519, loss = 1872.47962651\n",
      "Validation score: -35.899127\n",
      "Iteration 520, loss = 1871.38606894\n",
      "Validation score: -35.877680\n",
      "Iteration 521, loss = 1870.28924070\n",
      "Validation score: -35.856211\n",
      "Iteration 522, loss = 1869.18802166\n",
      "Validation score: -35.834759\n",
      "Iteration 523, loss = 1868.09008989\n",
      "Validation score: -35.813279\n",
      "Iteration 524, loss = 1866.99133761\n",
      "Validation score: -35.791783\n",
      "Iteration 525, loss = 1865.89248301\n",
      "Validation score: -35.770310\n",
      "Iteration 526, loss = 1864.79288926\n",
      "Validation score: -35.748892\n",
      "Iteration 527, loss = 1863.69683666\n",
      "Validation score: -35.727512\n",
      "Iteration 528, loss = 1862.60080285\n",
      "Validation score: -35.706191\n",
      "Iteration 529, loss = 1861.51188379\n",
      "Validation score: -35.684872\n",
      "Iteration 530, loss = 1860.42075857\n",
      "Validation score: -35.663627\n",
      "Iteration 531, loss = 1859.33535698\n",
      "Validation score: -35.642422\n",
      "Iteration 532, loss = 1858.25214112\n",
      "Validation score: -35.621267\n",
      "Iteration 533, loss = 1857.16904598\n",
      "Validation score: -35.600204\n",
      "Iteration 534, loss = 1856.09422884\n",
      "Validation score: -35.579150\n",
      "Iteration 535, loss = 1855.01643870\n",
      "Validation score: -35.558200\n",
      "Iteration 536, loss = 1853.94862080\n",
      "Validation score: -35.537292\n",
      "Iteration 537, loss = 1852.88002326\n",
      "Validation score: -35.516476\n",
      "Iteration 538, loss = 1851.81406078\n",
      "Validation score: -35.495717\n",
      "Iteration 539, loss = 1850.75336162\n",
      "Validation score: -35.475026\n",
      "Iteration 540, loss = 1849.69736343\n",
      "Validation score: -35.454358\n",
      "Iteration 541, loss = 1848.64025109\n",
      "Validation score: -35.433781\n",
      "Iteration 542, loss = 1847.59037638\n",
      "Validation score: -35.413233\n",
      "Iteration 543, loss = 1846.54002843\n",
      "Validation score: -35.392766\n",
      "Iteration 544, loss = 1845.49653298\n",
      "Validation score: -35.372356\n",
      "Iteration 545, loss = 1844.45284033\n",
      "Validation score: -35.352059\n",
      "Iteration 546, loss = 1843.41944102\n",
      "Validation score: -35.331764\n",
      "Iteration 547, loss = 1842.37999588\n",
      "Validation score: -35.311574\n",
      "Iteration 548, loss = 1841.34797301\n",
      "Validation score: -35.291420\n",
      "Iteration 549, loss = 1840.31747832\n",
      "Validation score: -35.271315\n",
      "Iteration 550, loss = 1839.28989515\n",
      "Validation score: -35.251235\n",
      "Iteration 551, loss = 1838.26558464\n",
      "Validation score: -35.231166\n",
      "Iteration 552, loss = 1837.24347428\n",
      "Validation score: -35.211156\n",
      "Iteration 553, loss = 1836.21793491\n",
      "Validation score: -35.191266\n",
      "Iteration 554, loss = 1835.20347953\n",
      "Validation score: -35.171379\n",
      "Iteration 555, loss = 1834.18699217\n",
      "Validation score: -35.151528\n",
      "Iteration 556, loss = 1833.17389183\n",
      "Validation score: -35.131699\n",
      "Iteration 557, loss = 1832.16264648\n",
      "Validation score: -35.111904\n",
      "Iteration 558, loss = 1831.15010431\n",
      "Validation score: -35.092182\n",
      "Iteration 559, loss = 1830.14515449\n",
      "Validation score: -35.072494\n",
      "Iteration 560, loss = 1829.13636557\n",
      "Validation score: -35.052912\n",
      "Iteration 561, loss = 1828.13729133\n",
      "Validation score: -35.033318\n",
      "Iteration 562, loss = 1827.13697842\n",
      "Validation score: -35.013741\n",
      "Iteration 563, loss = 1826.13830738\n",
      "Validation score: -34.994212\n",
      "Iteration 564, loss = 1825.13938671\n",
      "Validation score: -34.974728\n",
      "Iteration 565, loss = 1824.14563260\n",
      "Validation score: -34.955275\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 566, loss = 1823.14975806\n",
      "Validation score: -34.935885\n",
      "Iteration 567, loss = 1822.16032937\n",
      "Validation score: -34.916502\n",
      "Iteration 568, loss = 1821.17028617\n",
      "Validation score: -34.897148\n",
      "Iteration 569, loss = 1820.18297383\n",
      "Validation score: -34.877821\n",
      "Iteration 570, loss = 1819.19899433\n",
      "Validation score: -34.858523\n",
      "Iteration 571, loss = 1818.21018384\n",
      "Validation score: -34.839315\n",
      "Iteration 572, loss = 1817.22980080\n",
      "Validation score: -34.820094\n",
      "Iteration 573, loss = 1816.24829990\n",
      "Validation score: -34.800893\n",
      "Iteration 574, loss = 1815.26828770\n",
      "Validation score: -34.781719\n",
      "Iteration 575, loss = 1814.28708539\n",
      "Validation score: -34.762597\n",
      "Iteration 576, loss = 1813.31032034\n",
      "Validation score: -34.743481\n",
      "Iteration 577, loss = 1812.33563815\n",
      "Validation score: -34.724362\n",
      "Iteration 578, loss = 1811.35801924\n",
      "Validation score: -34.705304\n",
      "Iteration 579, loss = 1810.38602298\n",
      "Validation score: -34.686256\n",
      "Iteration 580, loss = 1809.41364593\n",
      "Validation score: -34.667248\n",
      "Iteration 581, loss = 1808.44216404\n",
      "Validation score: -34.648281\n",
      "Iteration 582, loss = 1807.47169330\n",
      "Validation score: -34.629320\n",
      "Iteration 583, loss = 1806.50357171\n",
      "Validation score: -34.610343\n",
      "Iteration 584, loss = 1805.53474142\n",
      "Validation score: -34.591382\n",
      "Iteration 585, loss = 1804.56466797\n",
      "Validation score: -34.572498\n",
      "Iteration 586, loss = 1803.60222000\n",
      "Validation score: -34.553594\n",
      "Iteration 587, loss = 1802.63627430\n",
      "Validation score: -34.534733\n",
      "Iteration 588, loss = 1801.67432608\n",
      "Validation score: -34.515877\n",
      "Iteration 589, loss = 1800.71127048\n",
      "Validation score: -34.497046\n",
      "Iteration 590, loss = 1799.75017032\n",
      "Validation score: -34.478255\n",
      "Iteration 591, loss = 1798.79162508\n",
      "Validation score: -34.459479\n",
      "Iteration 592, loss = 1797.83199131\n",
      "Validation score: -34.440737\n",
      "Iteration 593, loss = 1796.87583998\n",
      "Validation score: -34.421972\n",
      "Iteration 594, loss = 1795.91522401\n",
      "Validation score: -34.403284\n",
      "Iteration 595, loss = 1794.96102622\n",
      "Validation score: -34.384575\n",
      "Iteration 596, loss = 1794.00659649\n",
      "Validation score: -34.365883\n",
      "Iteration 597, loss = 1793.05004383\n",
      "Validation score: -34.347229\n",
      "Iteration 598, loss = 1792.09857604\n",
      "Validation score: -34.328574\n",
      "Iteration 599, loss = 1791.14581166\n",
      "Validation score: -34.309939\n",
      "Iteration 600, loss = 1790.19421853\n",
      "Validation score: -34.291338\n",
      "Iteration 601, loss = 1789.24576303\n",
      "Validation score: -34.272760\n",
      "Iteration 602, loss = 1788.29777849\n",
      "Validation score: -34.254188\n",
      "Iteration 603, loss = 1787.34698192\n",
      "Validation score: -34.235690\n",
      "Iteration 604, loss = 1786.40410041\n",
      "Validation score: -34.217158\n",
      "Iteration 605, loss = 1785.45598064\n",
      "Validation score: -34.198670\n",
      "Iteration 606, loss = 1784.51326978\n",
      "Validation score: -34.180186\n",
      "Iteration 607, loss = 1783.56844538\n",
      "Validation score: -34.161728\n",
      "Iteration 608, loss = 1782.62605845\n",
      "Validation score: -34.143286\n",
      "Iteration 609, loss = 1781.68351145\n",
      "Validation score: -34.124873\n",
      "Iteration 610, loss = 1780.74313913\n",
      "Validation score: -34.106469\n",
      "Iteration 611, loss = 1779.80293850\n",
      "Validation score: -34.088045\n",
      "Iteration 612, loss = 1778.86002673\n",
      "Validation score: -34.069670\n",
      "Iteration 613, loss = 1777.92476448\n",
      "Validation score: -34.051264\n",
      "Iteration 614, loss = 1776.98423043\n",
      "Validation score: -34.032915\n",
      "Iteration 615, loss = 1776.04720782\n",
      "Validation score: -34.014583\n",
      "Iteration 616, loss = 1775.10964394\n",
      "Validation score: -33.996288\n",
      "Iteration 617, loss = 1774.17580372\n",
      "Validation score: -33.977951\n",
      "Iteration 618, loss = 1773.23821134\n",
      "Validation score: -33.959647\n",
      "Iteration 619, loss = 1772.30526007\n",
      "Validation score: -33.941337\n",
      "Iteration 620, loss = 1771.36953425\n",
      "Validation score: -33.923067\n",
      "Iteration 621, loss = 1770.43765311\n",
      "Validation score: -33.904788\n",
      "Iteration 622, loss = 1769.50265020\n",
      "Validation score: -33.886547\n",
      "Iteration 623, loss = 1768.57086920\n",
      "Validation score: -33.868314\n",
      "Iteration 624, loss = 1767.64017384\n",
      "Validation score: -33.850078\n",
      "Iteration 625, loss = 1766.70740561\n",
      "Validation score: -33.831865\n",
      "Iteration 626, loss = 1765.77872460\n",
      "Validation score: -33.813638\n",
      "Iteration 627, loss = 1764.84889509\n",
      "Validation score: -33.795424\n",
      "Iteration 628, loss = 1763.91833591\n",
      "Validation score: -33.777281\n",
      "Iteration 629, loss = 1762.99269295\n",
      "Validation score: -33.759150\n",
      "Iteration 630, loss = 1762.06448337\n",
      "Validation score: -33.741033\n",
      "Iteration 631, loss = 1761.13880250\n",
      "Validation score: -33.722905\n",
      "Iteration 632, loss = 1760.21401761\n",
      "Validation score: -33.704775\n",
      "Iteration 633, loss = 1759.28915923\n",
      "Validation score: -33.686660\n",
      "Iteration 634, loss = 1758.36275270\n",
      "Validation score: -33.668605\n",
      "Iteration 635, loss = 1757.44009094\n",
      "Validation score: -33.650557\n",
      "Iteration 636, loss = 1756.51932809\n",
      "Validation score: -33.632503\n",
      "Iteration 637, loss = 1755.59623677\n",
      "Validation score: -33.614477\n",
      "Iteration 638, loss = 1754.67720116\n",
      "Validation score: -33.596422\n",
      "Iteration 639, loss = 1753.75567900\n",
      "Validation score: -33.578386\n",
      "Iteration 640, loss = 1752.83499719\n",
      "Validation score: -33.560399\n",
      "Iteration 641, loss = 1751.91604866\n",
      "Validation score: -33.542458\n",
      "Iteration 642, loss = 1750.99822387\n",
      "Validation score: -33.524521\n",
      "Iteration 643, loss = 1750.08212232\n",
      "Validation score: -33.506578\n",
      "Iteration 644, loss = 1749.16491109\n",
      "Validation score: -33.488638\n",
      "Iteration 645, loss = 1748.24827932\n",
      "Validation score: -33.470712\n",
      "Iteration 646, loss = 1747.33279751\n",
      "Validation score: -33.452765\n",
      "Iteration 647, loss = 1746.41591959\n",
      "Validation score: -33.434834\n",
      "Iteration 648, loss = 1745.49972551\n",
      "Validation score: -33.416927\n",
      "Iteration 649, loss = 1744.58317385\n",
      "Validation score: -33.399034\n",
      "Iteration 650, loss = 1743.66993774\n",
      "Validation score: -33.381111\n",
      "Iteration 651, loss = 1742.75487180\n",
      "Validation score: -33.363206\n",
      "Iteration 652, loss = 1741.84210294\n",
      "Validation score: -33.345319\n",
      "Iteration 653, loss = 1740.92773635\n",
      "Validation score: -33.327443\n",
      "Iteration 654, loss = 1740.01572198\n",
      "Validation score: -33.309582\n",
      "Iteration 655, loss = 1739.10300666\n",
      "Validation score: -33.291744\n",
      "Iteration 656, loss = 1738.19000229\n",
      "Validation score: -33.273925\n",
      "Iteration 657, loss = 1737.28152012\n",
      "Validation score: -33.256086\n",
      "Iteration 658, loss = 1736.37010416\n",
      "Validation score: -33.238282\n",
      "Iteration 659, loss = 1735.46114775\n",
      "Validation score: -33.220486\n",
      "Iteration 660, loss = 1734.54949500\n",
      "Validation score: -33.202720\n",
      "Iteration 661, loss = 1733.64489044\n",
      "Validation score: -33.184909\n",
      "Iteration 662, loss = 1732.73525945\n",
      "Validation score: -33.167145\n",
      "Iteration 663, loss = 1731.82760091\n",
      "Validation score: -33.149411\n",
      "Iteration 664, loss = 1730.92117290\n",
      "Validation score: -33.131674\n",
      "Iteration 665, loss = 1730.01475209\n",
      "Validation score: -33.113943\n",
      "Iteration 666, loss = 1729.10740758\n",
      "Validation score: -33.096237\n",
      "Iteration 667, loss = 1728.20366418\n",
      "Validation score: -33.078504\n",
      "Iteration 668, loss = 1727.29903027\n",
      "Validation score: -33.060760\n",
      "Iteration 669, loss = 1726.39249296\n",
      "Validation score: -33.043051\n",
      "Iteration 670, loss = 1725.48864834\n",
      "Validation score: -33.025345\n",
      "Iteration 671, loss = 1724.58433648\n",
      "Validation score: -33.007640\n",
      "Iteration 672, loss = 1723.67851063\n",
      "Validation score: -32.989962\n",
      "Iteration 673, loss = 1722.77642483\n",
      "Validation score: -32.972294\n",
      "Iteration 674, loss = 1721.87392373\n",
      "Validation score: -32.954635\n",
      "Iteration 675, loss = 1720.97103038\n",
      "Validation score: -32.937008\n",
      "Iteration 676, loss = 1720.07098323\n",
      "Validation score: -32.919364\n",
      "Iteration 677, loss = 1719.16810726\n",
      "Validation score: -32.901736\n",
      "Iteration 678, loss = 1718.26848779\n",
      "Validation score: -32.884097\n",
      "Iteration 679, loss = 1717.36788499\n",
      "Validation score: -32.866479\n",
      "Iteration 680, loss = 1716.46571136\n",
      "Validation score: -32.848869\n",
      "Iteration 681, loss = 1715.56896127\n",
      "Validation score: -32.831219\n",
      "Iteration 682, loss = 1714.66736274\n",
      "Validation score: -32.813627\n",
      "Iteration 683, loss = 1713.76878422\n",
      "Validation score: -32.796061\n",
      "Iteration 684, loss = 1712.86912521\n",
      "Validation score: -32.778497\n",
      "Iteration 685, loss = 1711.97364022\n",
      "Validation score: -32.760912\n",
      "Iteration 686, loss = 1711.07650981\n",
      "Validation score: -32.743357\n",
      "Iteration 687, loss = 1710.17938321\n",
      "Validation score: -32.725819\n",
      "Iteration 688, loss = 1709.28374298\n",
      "Validation score: -32.708273\n",
      "Iteration 689, loss = 1708.38624691\n",
      "Validation score: -32.690746\n",
      "Iteration 690, loss = 1707.49068694\n",
      "Validation score: -32.673220\n",
      "Iteration 691, loss = 1706.59545472\n",
      "Validation score: -32.655696\n",
      "Iteration 692, loss = 1705.70307233\n",
      "Validation score: -32.638147\n",
      "Iteration 693, loss = 1704.80337600\n",
      "Validation score: -32.620670\n",
      "Iteration 694, loss = 1703.91102358\n",
      "Validation score: -32.603167\n",
      "Iteration 695, loss = 1703.01746576\n",
      "Validation score: -32.585660\n",
      "Iteration 696, loss = 1702.12296540\n",
      "Validation score: -32.568180\n",
      "Iteration 697, loss = 1701.23074550\n",
      "Validation score: -32.550689\n",
      "Iteration 698, loss = 1700.33853240\n",
      "Validation score: -32.533191\n",
      "Iteration 699, loss = 1699.44343669\n",
      "Validation score: -32.515739\n",
      "Iteration 700, loss = 1698.55399119\n",
      "Validation score: -32.498257\n",
      "Iteration 701, loss = 1697.65991653\n",
      "Validation score: -32.480812\n",
      "Iteration 702, loss = 1696.76877334\n",
      "Validation score: -32.463376\n",
      "Iteration 703, loss = 1695.87683708\n",
      "Validation score: -32.445944\n",
      "Iteration 704, loss = 1694.98569638\n",
      "Validation score: -32.428502\n",
      "Iteration 705, loss = 1694.09437713\n",
      "Validation score: -32.411045\n",
      "Iteration 706, loss = 1693.20223272\n",
      "Validation score: -32.393596\n",
      "Iteration 707, loss = 1692.31247900\n",
      "Validation score: -32.376138\n",
      "Iteration 708, loss = 1691.42071629\n",
      "Validation score: -32.358696\n",
      "Iteration 709, loss = 1690.53030794\n",
      "Validation score: -32.341230\n",
      "Iteration 710, loss = 1689.63754704\n",
      "Validation score: -32.323775\n",
      "Iteration 711, loss = 1688.74486620\n",
      "Validation score: -32.306329\n",
      "Iteration 712, loss = 1687.85514250\n",
      "Validation score: -32.288885\n",
      "Iteration 713, loss = 1686.96314353\n",
      "Validation score: -32.271452\n",
      "Iteration 714, loss = 1686.07268296\n",
      "Validation score: -32.254007\n",
      "Iteration 715, loss = 1685.18184753\n",
      "Validation score: -32.236563\n",
      "Iteration 716, loss = 1684.29146060\n",
      "Validation score: -32.219084\n",
      "Iteration 717, loss = 1683.39805447\n",
      "Validation score: -32.201635\n",
      "Iteration 718, loss = 1682.50572379\n",
      "Validation score: -32.184199\n",
      "Iteration 719, loss = 1681.61433176\n",
      "Validation score: -32.166746\n",
      "Iteration 720, loss = 1680.72226025\n",
      "Validation score: -32.149268\n",
      "Iteration 721, loss = 1679.82992062\n",
      "Validation score: -32.131777\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 722, loss = 1678.93681833\n",
      "Validation score: -32.114299\n",
      "Iteration 723, loss = 1678.04286329\n",
      "Validation score: -32.096829\n",
      "Iteration 724, loss = 1677.15165685\n",
      "Validation score: -32.079329\n",
      "Iteration 725, loss = 1676.25649156\n",
      "Validation score: -32.061825\n",
      "Iteration 726, loss = 1675.36374833\n",
      "Validation score: -32.044305\n",
      "Iteration 727, loss = 1674.46732887\n",
      "Validation score: -32.026775\n",
      "Iteration 728, loss = 1673.57380634\n",
      "Validation score: -32.009211\n",
      "Iteration 729, loss = 1672.67495708\n",
      "Validation score: -31.991652\n",
      "Iteration 730, loss = 1671.77758334\n",
      "Validation score: -31.974057\n",
      "Iteration 731, loss = 1670.87788859\n",
      "Validation score: -31.956441\n",
      "Iteration 732, loss = 1669.97840995\n",
      "Validation score: -31.938796\n",
      "Iteration 733, loss = 1669.07578379\n",
      "Validation score: -31.921119\n",
      "Iteration 734, loss = 1668.17176232\n",
      "Validation score: -31.903416\n",
      "Iteration 735, loss = 1667.26727200\n",
      "Validation score: -31.885652\n",
      "Iteration 736, loss = 1666.35727173\n",
      "Validation score: -31.867854\n",
      "Iteration 737, loss = 1665.44898435\n",
      "Validation score: -31.849984\n",
      "Iteration 738, loss = 1664.53349351\n",
      "Validation score: -31.832073\n",
      "Iteration 739, loss = 1663.61854674\n",
      "Validation score: -31.814067\n",
      "Iteration 740, loss = 1662.69824524\n",
      "Validation score: -31.796016\n",
      "Iteration 741, loss = 1661.77352598\n",
      "Validation score: -31.777898\n",
      "Iteration 742, loss = 1660.84498982\n",
      "Validation score: -31.759679\n",
      "Iteration 743, loss = 1659.91289951\n",
      "Validation score: -31.741324\n",
      "Iteration 744, loss = 1658.97285620\n",
      "Validation score: -31.722875\n",
      "Iteration 745, loss = 1658.02943840\n",
      "Validation score: -31.704274\n",
      "Iteration 746, loss = 1657.07620720\n",
      "Validation score: -31.685594\n",
      "Iteration 747, loss = 1656.11862001\n",
      "Validation score: -31.666779\n",
      "Iteration 748, loss = 1655.15181109\n",
      "Validation score: -31.647815\n",
      "Iteration 749, loss = 1654.18028618\n",
      "Validation score: -31.628663\n",
      "Iteration 750, loss = 1653.19792567\n",
      "Validation score: -31.609352\n",
      "Iteration 751, loss = 1652.20730338\n",
      "Validation score: -31.589842\n",
      "Iteration 752, loss = 1651.20749956\n",
      "Validation score: -31.570161\n",
      "Iteration 753, loss = 1650.19716236\n",
      "Validation score: -31.550338\n",
      "Iteration 754, loss = 1649.18117501\n",
      "Validation score: -31.530337\n",
      "Iteration 755, loss = 1648.15283940\n",
      "Validation score: -31.510173\n",
      "Iteration 756, loss = 1647.12012827\n",
      "Validation score: -31.489796\n",
      "Iteration 757, loss = 1646.07245261\n",
      "Validation score: -31.469270\n",
      "Iteration 758, loss = 1645.01727603\n",
      "Validation score: -31.448543\n",
      "Iteration 759, loss = 1643.95523788\n",
      "Validation score: -31.427626\n",
      "Iteration 760, loss = 1642.88030113\n",
      "Validation score: -31.406559\n",
      "Iteration 761, loss = 1641.80177037\n",
      "Validation score: -31.385334\n",
      "Iteration 762, loss = 1640.71168455\n",
      "Validation score: -31.364025\n",
      "Iteration 763, loss = 1639.61525299\n",
      "Validation score: -31.342593\n",
      "Iteration 764, loss = 1638.51574482\n",
      "Validation score: -31.321020\n",
      "Iteration 765, loss = 1637.41020887\n",
      "Validation score: -31.299300\n",
      "Iteration 766, loss = 1636.29838668\n",
      "Validation score: -31.277465\n",
      "Iteration 767, loss = 1635.18011236\n",
      "Validation score: -31.255531\n",
      "Iteration 768, loss = 1634.05208077\n",
      "Validation score: -31.233543\n",
      "Iteration 769, loss = 1632.92335213\n",
      "Validation score: -31.211454\n",
      "Iteration 770, loss = 1631.79175715\n",
      "Validation score: -31.189223\n",
      "Iteration 771, loss = 1630.65018683\n",
      "Validation score: -31.166916\n",
      "Iteration 772, loss = 1629.50765713\n",
      "Validation score: -31.144465\n",
      "Iteration 773, loss = 1628.35657745\n",
      "Validation score: -31.121907\n",
      "Iteration 774, loss = 1627.19682494\n",
      "Validation score: -31.099237\n",
      "Iteration 775, loss = 1626.03711398\n",
      "Validation score: -31.076427\n",
      "Iteration 776, loss = 1624.86754814\n",
      "Validation score: -31.053546\n",
      "Iteration 777, loss = 1623.69654539\n",
      "Validation score: -31.030559\n",
      "Iteration 778, loss = 1622.51536729\n",
      "Validation score: -31.007520\n",
      "Iteration 779, loss = 1621.33395561\n",
      "Validation score: -30.984401\n",
      "Iteration 780, loss = 1620.14827193\n",
      "Validation score: -30.961224\n",
      "Iteration 781, loss = 1618.96046849\n",
      "Validation score: -30.937990\n",
      "Iteration 782, loss = 1617.77115859\n",
      "Validation score: -30.914717\n",
      "Iteration 783, loss = 1616.58065789\n",
      "Validation score: -30.891399\n",
      "Iteration 784, loss = 1615.38365609\n",
      "Validation score: -30.868116\n",
      "Iteration 785, loss = 1614.19143007\n",
      "Validation score: -30.844826\n",
      "Iteration 786, loss = 1612.99527400\n",
      "Validation score: -30.821582\n",
      "Iteration 787, loss = 1611.80718434\n",
      "Validation score: -30.798339\n",
      "Iteration 788, loss = 1610.61809077\n",
      "Validation score: -30.775156\n",
      "Iteration 789, loss = 1609.43081877\n",
      "Validation score: -30.752048\n",
      "Iteration 790, loss = 1608.24720995\n",
      "Validation score: -30.729008\n",
      "Iteration 791, loss = 1607.07154471\n",
      "Validation score: -30.706054\n",
      "Iteration 792, loss = 1605.89570167\n",
      "Validation score: -30.683235\n",
      "Iteration 793, loss = 1604.73010709\n",
      "Validation score: -30.660517\n",
      "Iteration 794, loss = 1603.57256713\n",
      "Validation score: -30.637881\n",
      "Iteration 795, loss = 1602.41559325\n",
      "Validation score: -30.615406\n",
      "Iteration 796, loss = 1601.26518013\n",
      "Validation score: -30.593080\n",
      "Iteration 797, loss = 1600.12757310\n",
      "Validation score: -30.570845\n",
      "Iteration 798, loss = 1598.99188966\n",
      "Validation score: -30.548767\n",
      "Iteration 799, loss = 1597.86409148\n",
      "Validation score: -30.526827\n",
      "Iteration 800, loss = 1596.74409846\n",
      "Validation score: -30.505021\n",
      "Iteration 801, loss = 1595.63045590\n",
      "Validation score: -30.483325\n",
      "Iteration 802, loss = 1594.52364840\n",
      "Validation score: -30.461731\n",
      "Iteration 803, loss = 1593.42205686\n",
      "Validation score: -30.440257\n",
      "Iteration 804, loss = 1592.32574911\n",
      "Validation score: -30.418910\n",
      "Iteration 805, loss = 1591.23557462\n",
      "Validation score: -30.397658\n",
      "Iteration 806, loss = 1590.14850457\n",
      "Validation score: -30.376510\n",
      "Iteration 807, loss = 1589.07123856\n",
      "Validation score: -30.355435\n",
      "Iteration 808, loss = 1587.99758221\n",
      "Validation score: -30.334444\n",
      "Iteration 809, loss = 1586.92640881\n",
      "Validation score: -30.313591\n",
      "Iteration 810, loss = 1585.86293055\n",
      "Validation score: -30.292847\n",
      "Iteration 811, loss = 1584.80425243\n",
      "Validation score: -30.272190\n",
      "Iteration 812, loss = 1583.74927194\n",
      "Validation score: -30.251626\n",
      "Iteration 813, loss = 1582.69934235\n",
      "Validation score: -30.231133\n",
      "Iteration 814, loss = 1581.65425971\n",
      "Validation score: -30.210697\n",
      "Iteration 815, loss = 1580.61063930\n",
      "Validation score: -30.190345\n",
      "Iteration 816, loss = 1579.57238079\n",
      "Validation score: -30.170064\n",
      "Iteration 817, loss = 1578.53742301\n",
      "Validation score: -30.149857\n",
      "Iteration 818, loss = 1577.50697294\n",
      "Validation score: -30.129719\n",
      "Iteration 819, loss = 1576.48020771\n",
      "Validation score: -30.109631\n",
      "Iteration 820, loss = 1575.45714675\n",
      "Validation score: -30.089612\n",
      "Iteration 821, loss = 1574.43566591\n",
      "Validation score: -30.069695\n",
      "Iteration 822, loss = 1573.42014195\n",
      "Validation score: -30.049842\n",
      "Iteration 823, loss = 1572.40781878\n",
      "Validation score: -30.030028\n",
      "Iteration 824, loss = 1571.39417613\n",
      "Validation score: -30.010296\n",
      "Iteration 825, loss = 1570.38731288\n",
      "Validation score: -29.990570\n",
      "Iteration 826, loss = 1569.38094969\n",
      "Validation score: -29.970887\n",
      "Iteration 827, loss = 1568.37872845\n",
      "Validation score: -29.951234\n",
      "Iteration 828, loss = 1567.37555627\n",
      "Validation score: -29.931658\n",
      "Iteration 829, loss = 1566.37738778\n",
      "Validation score: -29.912150\n",
      "Iteration 830, loss = 1565.38223360\n",
      "Validation score: -29.892696\n",
      "Iteration 831, loss = 1564.38840914\n",
      "Validation score: -29.873307\n",
      "Iteration 832, loss = 1563.40047726\n",
      "Validation score: -29.853947\n",
      "Iteration 833, loss = 1562.41209685\n",
      "Validation score: -29.834614\n",
      "Iteration 834, loss = 1561.42521482\n",
      "Validation score: -29.815314\n",
      "Iteration 835, loss = 1560.44009246\n",
      "Validation score: -29.796073\n",
      "Iteration 836, loss = 1559.45840139\n",
      "Validation score: -29.776854\n",
      "Iteration 837, loss = 1558.47716625\n",
      "Validation score: -29.757663\n",
      "Iteration 838, loss = 1557.49936847\n",
      "Validation score: -29.738516\n",
      "Iteration 839, loss = 1556.52336174\n",
      "Validation score: -29.719405\n",
      "Iteration 840, loss = 1555.54601800\n",
      "Validation score: -29.700338\n",
      "Iteration 841, loss = 1554.57376800\n",
      "Validation score: -29.681300\n",
      "Iteration 842, loss = 1553.60358058\n",
      "Validation score: -29.662271\n",
      "Iteration 843, loss = 1552.63171879\n",
      "Validation score: -29.643292\n",
      "Iteration 844, loss = 1551.66258547\n",
      "Validation score: -29.624350\n",
      "Iteration 845, loss = 1550.69472595\n",
      "Validation score: -29.605434\n",
      "Iteration 846, loss = 1549.72958952\n",
      "Validation score: -29.586515\n",
      "Iteration 847, loss = 1548.76602551\n",
      "Validation score: -29.567650\n",
      "Iteration 848, loss = 1547.80367004\n",
      "Validation score: -29.548793\n",
      "Iteration 849, loss = 1546.84016150\n",
      "Validation score: -29.529973\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 850, loss = 1545.88064695\n",
      "Validation score: -29.511174\n",
      "Iteration 851, loss = 1544.92068191\n",
      "Validation score: -29.492424\n",
      "Iteration 852, loss = 1543.96555587\n",
      "Validation score: -29.473668\n",
      "Iteration 853, loss = 1543.00551104\n",
      "Validation score: -29.454958\n",
      "Iteration 854, loss = 1542.05316598\n",
      "Validation score: -29.436248\n",
      "Iteration 855, loss = 1541.09889741\n",
      "Validation score: -29.417577\n",
      "Iteration 856, loss = 1540.14392640\n",
      "Validation score: -29.398953\n",
      "Iteration 857, loss = 1539.19617387\n",
      "Validation score: -29.380327\n",
      "Iteration 858, loss = 1538.24534437\n",
      "Validation score: -29.361734\n",
      "Iteration 859, loss = 1537.29560563\n",
      "Validation score: -29.343163\n",
      "Iteration 860, loss = 1536.34953947\n",
      "Validation score: -29.324588\n",
      "Iteration 861, loss = 1535.40161661\n",
      "Validation score: -29.306043\n",
      "Iteration 862, loss = 1534.45646076\n",
      "Validation score: -29.287522\n",
      "Iteration 863, loss = 1533.50990838\n",
      "Validation score: -29.269035\n",
      "Iteration 864, loss = 1532.56630746\n",
      "Validation score: -29.250547\n",
      "Iteration 865, loss = 1531.62224708\n",
      "Validation score: -29.232071\n",
      "Iteration 866, loss = 1530.68030013\n",
      "Validation score: -29.213605\n",
      "Iteration 867, loss = 1529.73631888\n",
      "Validation score: -29.195164\n",
      "Iteration 868, loss = 1528.79563809\n",
      "Validation score: -29.176708\n",
      "Iteration 869, loss = 1527.85303625\n",
      "Validation score: -29.158256\n",
      "Iteration 870, loss = 1526.91071111\n",
      "Validation score: -29.139830\n",
      "Iteration 871, loss = 1525.97175685\n",
      "Validation score: -29.121397\n",
      "Iteration 872, loss = 1525.02897514\n",
      "Validation score: -29.102988\n",
      "Iteration 873, loss = 1524.09038492\n",
      "Validation score: -29.084559\n",
      "Iteration 874, loss = 1523.14997869\n",
      "Validation score: -29.066150\n",
      "Iteration 875, loss = 1522.21007969\n",
      "Validation score: -29.047756\n",
      "Iteration 876, loss = 1521.27019867\n",
      "Validation score: -29.029342\n",
      "Iteration 877, loss = 1520.32929647\n",
      "Validation score: -29.010917\n",
      "Iteration 878, loss = 1519.38924055\n",
      "Validation score: -28.992448\n",
      "Iteration 879, loss = 1518.44845493\n",
      "Validation score: -28.973981\n",
      "Iteration 880, loss = 1517.50474343\n",
      "Validation score: -28.955514\n",
      "Iteration 881, loss = 1516.56142554\n",
      "Validation score: -28.937031\n",
      "Iteration 882, loss = 1515.61807105\n",
      "Validation score: -28.918501\n",
      "Iteration 883, loss = 1514.67222145\n",
      "Validation score: -28.899938\n",
      "Iteration 884, loss = 1513.72171004\n",
      "Validation score: -28.881364\n",
      "Iteration 885, loss = 1512.77407547\n",
      "Validation score: -28.862718\n",
      "Iteration 886, loss = 1511.82001932\n",
      "Validation score: -28.844016\n",
      "Iteration 887, loss = 1510.86510096\n",
      "Validation score: -28.825240\n",
      "Iteration 888, loss = 1509.90830829\n",
      "Validation score: -28.806391\n",
      "Iteration 889, loss = 1508.94207011\n",
      "Validation score: -28.787490\n",
      "Iteration 890, loss = 1507.97473134\n",
      "Validation score: -28.768490\n",
      "Iteration 891, loss = 1507.00287446\n",
      "Validation score: -28.749383\n",
      "Iteration 892, loss = 1506.02451716\n",
      "Validation score: -28.730150\n",
      "Iteration 893, loss = 1505.04166792\n",
      "Validation score: -28.710767\n",
      "Iteration 894, loss = 1504.04881736\n",
      "Validation score: -28.691281\n",
      "Iteration 895, loss = 1503.05127376\n",
      "Validation score: -28.671619\n",
      "Iteration 896, loss = 1502.04377853\n",
      "Validation score: -28.651785\n",
      "Iteration 897, loss = 1501.02514060\n",
      "Validation score: -28.631745\n",
      "Iteration 898, loss = 1499.99898921\n",
      "Validation score: -28.611482\n",
      "Iteration 899, loss = 1498.96035528\n",
      "Validation score: -28.591052\n",
      "Iteration 900, loss = 1497.91276000\n",
      "Validation score: -28.570450\n",
      "Iteration 901, loss = 1496.85253212\n",
      "Validation score: -28.549676\n",
      "Iteration 902, loss = 1495.78762746\n",
      "Validation score: -28.528644\n",
      "Iteration 903, loss = 1494.71012419\n",
      "Validation score: -28.507431\n",
      "Iteration 904, loss = 1493.62336182\n",
      "Validation score: -28.486051\n",
      "Iteration 905, loss = 1492.52744135\n",
      "Validation score: -28.464557\n",
      "Iteration 906, loss = 1491.42331924\n",
      "Validation score: -28.442980\n",
      "Iteration 907, loss = 1490.31575365\n",
      "Validation score: -28.421303\n",
      "Iteration 908, loss = 1489.20251106\n",
      "Validation score: -28.399533\n",
      "Iteration 909, loss = 1488.09083521\n",
      "Validation score: -28.377655\n",
      "Iteration 910, loss = 1486.96667175\n",
      "Validation score: -28.355782\n",
      "Iteration 911, loss = 1485.84931797\n",
      "Validation score: -28.333870\n",
      "Iteration 912, loss = 1484.72679710\n",
      "Validation score: -28.312021\n",
      "Iteration 913, loss = 1483.60722009\n",
      "Validation score: -28.290216\n",
      "Iteration 914, loss = 1482.49275598\n",
      "Validation score: -28.268446\n",
      "Iteration 915, loss = 1481.37866732\n",
      "Validation score: -28.246760\n",
      "Iteration 916, loss = 1480.27207214\n",
      "Validation score: -28.225136\n",
      "Iteration 917, loss = 1479.16659189\n",
      "Validation score: -28.203628\n",
      "Iteration 918, loss = 1478.06769132\n",
      "Validation score: -28.182189\n",
      "Iteration 919, loss = 1476.97105832\n",
      "Validation score: -28.160881\n",
      "Iteration 920, loss = 1475.88311527\n",
      "Validation score: -28.139652\n",
      "Iteration 921, loss = 1474.79976417\n",
      "Validation score: -28.118543\n",
      "Iteration 922, loss = 1473.72075745\n",
      "Validation score: -28.097536\n",
      "Iteration 923, loss = 1472.65316730\n",
      "Validation score: -28.076626\n",
      "Iteration 924, loss = 1471.58447403\n",
      "Validation score: -28.055884\n",
      "Iteration 925, loss = 1470.52322873\n",
      "Validation score: -28.035242\n",
      "Iteration 926, loss = 1469.47012875\n",
      "Validation score: -28.014654\n",
      "Iteration 927, loss = 1468.41876591\n",
      "Validation score: -27.994142\n",
      "Iteration 928, loss = 1467.37314464\n",
      "Validation score: -27.973715\n",
      "Iteration 929, loss = 1466.33088245\n",
      "Validation score: -27.953404\n",
      "Iteration 930, loss = 1465.29540013\n",
      "Validation score: -27.933210\n",
      "Iteration 931, loss = 1464.26472924\n",
      "Validation score: -27.913103\n",
      "Iteration 932, loss = 1463.23859614\n",
      "Validation score: -27.893087\n",
      "Iteration 933, loss = 1462.21704912\n",
      "Validation score: -27.873146\n",
      "Iteration 934, loss = 1461.19969975\n",
      "Validation score: -27.853282\n",
      "Iteration 935, loss = 1460.18524052\n",
      "Validation score: -27.833493\n",
      "Iteration 936, loss = 1459.17670477\n",
      "Validation score: -27.813746\n",
      "Iteration 937, loss = 1458.17076787\n",
      "Validation score: -27.794080\n",
      "Iteration 938, loss = 1457.16614644\n",
      "Validation score: -27.774501\n",
      "Iteration 939, loss = 1456.16806302\n",
      "Validation score: -27.754968\n",
      "Iteration 940, loss = 1455.17319170\n",
      "Validation score: -27.735486\n",
      "Iteration 941, loss = 1454.17601751\n",
      "Validation score: -27.716097\n",
      "Iteration 942, loss = 1453.18955045\n",
      "Validation score: -27.696735\n",
      "Iteration 943, loss = 1452.20208568\n",
      "Validation score: -27.677456\n",
      "Iteration 944, loss = 1451.21950290\n",
      "Validation score: -27.658225\n",
      "Iteration 945, loss = 1450.23745074\n",
      "Validation score: -27.639083\n",
      "Iteration 946, loss = 1449.25981081\n",
      "Validation score: -27.619977\n",
      "Iteration 947, loss = 1448.28518816\n",
      "Validation score: -27.600905\n",
      "Iteration 948, loss = 1447.31303587\n",
      "Validation score: -27.581843\n",
      "Iteration 949, loss = 1446.34071642\n",
      "Validation score: -27.562826\n",
      "Iteration 950, loss = 1445.37232993\n",
      "Validation score: -27.543866\n",
      "Iteration 951, loss = 1444.40368042\n",
      "Validation score: -27.524991\n",
      "Iteration 952, loss = 1443.44117921\n",
      "Validation score: -27.506151\n",
      "Iteration 953, loss = 1442.47951854\n",
      "Validation score: -27.487380\n",
      "Iteration 954, loss = 1441.52228930\n",
      "Validation score: -27.468639\n",
      "Iteration 955, loss = 1440.56404019\n",
      "Validation score: -27.449916\n",
      "Iteration 956, loss = 1439.60899927\n",
      "Validation score: -27.431192\n",
      "Iteration 957, loss = 1438.65555382\n",
      "Validation score: -27.412498\n",
      "Iteration 958, loss = 1437.70097152\n",
      "Validation score: -27.393863\n",
      "Iteration 959, loss = 1436.75286845\n",
      "Validation score: -27.375238\n",
      "Iteration 960, loss = 1435.80016363\n",
      "Validation score: -27.356686\n",
      "Iteration 961, loss = 1434.85443990\n",
      "Validation score: -27.338130\n",
      "Iteration 962, loss = 1433.90728828\n",
      "Validation score: -27.319645\n",
      "Iteration 963, loss = 1432.96272751\n",
      "Validation score: -27.301186\n",
      "Iteration 964, loss = 1432.02100014\n",
      "Validation score: -27.282721\n",
      "Iteration 965, loss = 1431.07792934\n",
      "Validation score: -27.264286\n",
      "Iteration 966, loss = 1430.13907958\n",
      "Validation score: -27.245849\n",
      "Iteration 967, loss = 1429.19775518\n",
      "Validation score: -27.227483\n",
      "Iteration 968, loss = 1428.26028857\n",
      "Validation score: -27.209114\n",
      "Iteration 969, loss = 1427.32335027\n",
      "Validation score: -27.190802\n",
      "Iteration 970, loss = 1426.38960339\n",
      "Validation score: -27.172503\n",
      "Iteration 971, loss = 1425.45599511\n",
      "Validation score: -27.154208\n",
      "Iteration 972, loss = 1424.52284989\n",
      "Validation score: -27.135941\n",
      "Iteration 973, loss = 1423.59059676\n",
      "Validation score: -27.117703\n",
      "Iteration 974, loss = 1422.65899690\n",
      "Validation score: -27.099486\n",
      "Iteration 975, loss = 1421.73034149\n",
      "Validation score: -27.081255\n",
      "Iteration 976, loss = 1420.79874384\n",
      "Validation score: -27.063074\n",
      "Iteration 977, loss = 1419.87596739\n",
      "Validation score: -27.044885\n",
      "Iteration 978, loss = 1418.94341183\n",
      "Validation score: -27.026769\n",
      "Iteration 979, loss = 1418.02079680\n",
      "Validation score: -27.008616\n",
      "Iteration 980, loss = 1417.09239699\n",
      "Validation score: -26.990529\n",
      "Iteration 981, loss = 1416.17275834\n",
      "Validation score: -26.972406\n",
      "Iteration 982, loss = 1415.24604006\n",
      "Validation score: -26.954355\n",
      "Iteration 983, loss = 1414.32677067\n",
      "Validation score: -26.936271\n",
      "Iteration 984, loss = 1413.40565012\n",
      "Validation score: -26.918220\n",
      "Iteration 985, loss = 1412.48418078\n",
      "Validation score: -26.900223\n",
      "Iteration 986, loss = 1411.56394095\n",
      "Validation score: -26.882249\n",
      "Iteration 987, loss = 1410.64534166\n",
      "Validation score: -26.864274\n",
      "Iteration 988, loss = 1409.73154440\n",
      "Validation score: -26.846265\n",
      "Iteration 989, loss = 1408.80848302\n",
      "Validation score: -26.828330\n",
      "Iteration 990, loss = 1407.89622950\n",
      "Validation score: -26.810349\n",
      "Iteration 991, loss = 1406.97771867\n",
      "Validation score: -26.792411\n",
      "Iteration 992, loss = 1406.06198160\n",
      "Validation score: -26.774471\n",
      "Iteration 993, loss = 1405.14711842\n",
      "Validation score: -26.756535\n",
      "Iteration 994, loss = 1404.23117373\n",
      "Validation score: -26.738614\n",
      "Iteration 995, loss = 1403.31723993\n",
      "Validation score: -26.720681\n",
      "Iteration 996, loss = 1402.40238598\n",
      "Validation score: -26.702771\n",
      "Iteration 997, loss = 1401.49043642\n",
      "Validation score: -26.684870\n",
      "Iteration 998, loss = 1400.57461628\n",
      "Validation score: -26.666999\n",
      "Iteration 999, loss = 1399.66134159\n",
      "Validation score: -26.649139\n",
      "Iteration 1000, loss = 1398.75200502\n",
      "Validation score: -26.631242\n",
      "Iteration 1001, loss = 1397.83728781\n",
      "Validation score: -26.613335\n",
      "Iteration 1002, loss = 1396.92274595\n",
      "Validation score: -26.595417\n",
      "Iteration 1003, loss = 1396.00800944\n",
      "Validation score: -26.577453\n",
      "Iteration 1004, loss = 1395.08951578\n",
      "Validation score: -26.559483\n",
      "Iteration 1005, loss = 1394.17437261\n",
      "Validation score: -26.541478\n",
      "Iteration 1006, loss = 1393.25285527\n",
      "Validation score: -26.523485\n",
      "Iteration 1007, loss = 1392.33470256\n",
      "Validation score: -26.505416\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1008, loss = 1391.41228256\n",
      "Validation score: -26.487303\n",
      "Iteration 1009, loss = 1390.48829973\n",
      "Validation score: -26.469155\n",
      "Iteration 1010, loss = 1389.56093860\n",
      "Validation score: -26.450959\n",
      "Iteration 1011, loss = 1388.63155803\n",
      "Validation score: -26.432692\n",
      "Iteration 1012, loss = 1387.69660384\n",
      "Validation score: -26.414357\n",
      "Iteration 1013, loss = 1386.76086209\n",
      "Validation score: -26.395894\n",
      "Iteration 1014, loss = 1385.81590806\n",
      "Validation score: -26.377367\n",
      "Iteration 1015, loss = 1384.86896074\n",
      "Validation score: -26.358670\n",
      "Iteration 1016, loss = 1383.91103294\n",
      "Validation score: -26.339852\n",
      "Iteration 1017, loss = 1382.94850923\n",
      "Validation score: -26.320865\n",
      "Iteration 1018, loss = 1381.97858484\n",
      "Validation score: -26.301710\n",
      "Iteration 1019, loss = 1380.99610495\n",
      "Validation score: -26.282414\n",
      "Iteration 1020, loss = 1380.00653051\n",
      "Validation score: -26.262914\n",
      "Iteration 1021, loss = 1379.00560965\n",
      "Validation score: -26.243190\n",
      "Iteration 1022, loss = 1377.99511534\n",
      "Validation score: -26.223194\n",
      "Iteration 1023, loss = 1376.96852614\n",
      "Validation score: -26.202973\n",
      "Iteration 1024, loss = 1375.93175503\n",
      "Validation score: -26.182518\n",
      "Iteration 1025, loss = 1374.88115028\n",
      "Validation score: -26.161804\n",
      "Iteration 1026, loss = 1373.81636312\n",
      "Validation score: -26.140844\n",
      "Iteration 1027, loss = 1372.74234567\n",
      "Validation score: -26.119658\n",
      "Iteration 1028, loss = 1371.65623495\n",
      "Validation score: -26.098270\n",
      "Iteration 1029, loss = 1370.55713133\n",
      "Validation score: -26.076686\n",
      "Iteration 1030, loss = 1369.44860593\n",
      "Validation score: -26.054961\n",
      "Iteration 1031, loss = 1368.33517397\n",
      "Validation score: -26.033103\n",
      "Iteration 1032, loss = 1367.21569309\n",
      "Validation score: -26.011149\n",
      "Iteration 1033, loss = 1366.08699715\n",
      "Validation score: -25.989177\n",
      "Iteration 1034, loss = 1364.96373492\n",
      "Validation score: -25.967106\n",
      "Iteration 1035, loss = 1363.83171855\n",
      "Validation score: -25.945065\n",
      "Iteration 1036, loss = 1362.70235522\n",
      "Validation score: -25.923052\n",
      "Iteration 1037, loss = 1361.57434158\n",
      "Validation score: -25.901087\n",
      "Iteration 1038, loss = 1360.45230468\n",
      "Validation score: -25.879183\n",
      "Iteration 1039, loss = 1359.33238867\n",
      "Validation score: -25.857387\n",
      "Iteration 1040, loss = 1358.22011629\n",
      "Validation score: -25.835689\n",
      "Iteration 1041, loss = 1357.11451363\n",
      "Validation score: -25.814140\n",
      "Iteration 1042, loss = 1356.01200127\n",
      "Validation score: -25.792746\n",
      "Iteration 1043, loss = 1354.91751633\n",
      "Validation score: -25.771476\n",
      "Iteration 1044, loss = 1353.83055032\n",
      "Validation score: -25.750334\n",
      "Iteration 1045, loss = 1352.75044136\n",
      "Validation score: -25.729339\n",
      "Iteration 1046, loss = 1351.68115028\n",
      "Validation score: -25.708444\n",
      "Iteration 1047, loss = 1350.61454392\n",
      "Validation score: -25.687725\n",
      "Iteration 1048, loss = 1349.55434261\n",
      "Validation score: -25.667140\n",
      "Iteration 1049, loss = 1348.50588080\n",
      "Validation score: -25.646612\n",
      "Iteration 1050, loss = 1347.45996327\n",
      "Validation score: -25.626208\n",
      "Iteration 1051, loss = 1346.42044544\n",
      "Validation score: -25.605938\n",
      "Iteration 1052, loss = 1345.38511746\n",
      "Validation score: -25.585801\n",
      "Iteration 1053, loss = 1344.35935522\n",
      "Validation score: -25.565791\n",
      "Iteration 1054, loss = 1343.33946877\n",
      "Validation score: -25.545888\n",
      "Iteration 1055, loss = 1342.32517830\n",
      "Validation score: -25.526065\n",
      "Iteration 1056, loss = 1341.31421141\n",
      "Validation score: -25.506349\n",
      "Iteration 1057, loss = 1340.30848285\n",
      "Validation score: -25.486725\n",
      "Iteration 1058, loss = 1339.30810863\n",
      "Validation score: -25.467168\n",
      "Iteration 1059, loss = 1338.30981313\n",
      "Validation score: -25.447721\n",
      "Iteration 1060, loss = 1337.32011884\n",
      "Validation score: -25.428321\n",
      "Iteration 1061, loss = 1336.33131667\n",
      "Validation score: -25.409008\n",
      "Iteration 1062, loss = 1335.34413842\n",
      "Validation score: -25.389805\n",
      "Iteration 1063, loss = 1334.36422642\n",
      "Validation score: -25.370647\n",
      "Iteration 1064, loss = 1333.39054119\n",
      "Validation score: -25.351496\n",
      "Iteration 1065, loss = 1332.41256042\n",
      "Validation score: -25.332450\n",
      "Iteration 1066, loss = 1331.44433058\n",
      "Validation score: -25.313441\n",
      "Iteration 1067, loss = 1330.47414441\n",
      "Validation score: -25.294549\n",
      "Iteration 1068, loss = 1329.51132292\n",
      "Validation score: -25.275688\n",
      "Iteration 1069, loss = 1328.54823161\n",
      "Validation score: -25.256865\n",
      "Iteration 1070, loss = 1327.58737702\n",
      "Validation score: -25.238110\n",
      "Iteration 1071, loss = 1326.63235768\n",
      "Validation score: -25.219391\n",
      "Iteration 1072, loss = 1325.67659238\n",
      "Validation score: -25.200739\n",
      "Iteration 1073, loss = 1324.72606049\n",
      "Validation score: -25.182107\n",
      "Iteration 1074, loss = 1323.77641549\n",
      "Validation score: -25.163515\n",
      "Iteration 1075, loss = 1322.82737551\n",
      "Validation score: -25.144961\n",
      "Iteration 1076, loss = 1321.88274063\n",
      "Validation score: -25.126399\n",
      "Iteration 1077, loss = 1320.93715041\n",
      "Validation score: -25.107906\n",
      "Iteration 1078, loss = 1319.99477146\n",
      "Validation score: -25.089471\n",
      "Iteration 1079, loss = 1319.05307154\n",
      "Validation score: -25.071103\n",
      "Iteration 1080, loss = 1318.11880275\n",
      "Validation score: -25.052726\n",
      "Iteration 1081, loss = 1317.18292586\n",
      "Validation score: -25.034404\n",
      "Iteration 1082, loss = 1316.24648843\n",
      "Validation score: -25.016164\n",
      "Iteration 1083, loss = 1315.31632379\n",
      "Validation score: -24.997948\n",
      "Iteration 1084, loss = 1314.38621122\n",
      "Validation score: -24.979763\n",
      "Iteration 1085, loss = 1313.45970121\n",
      "Validation score: -24.961587\n",
      "Iteration 1086, loss = 1312.53155168\n",
      "Validation score: -24.943441\n",
      "Iteration 1087, loss = 1311.60846847\n",
      "Validation score: -24.925294\n",
      "Iteration 1088, loss = 1310.68213236\n",
      "Validation score: -24.907193\n",
      "Iteration 1089, loss = 1309.75878182\n",
      "Validation score: -24.889134\n",
      "Iteration 1090, loss = 1308.83750630\n",
      "Validation score: -24.871087\n",
      "Iteration 1091, loss = 1307.91792455\n",
      "Validation score: -24.853063\n",
      "Iteration 1092, loss = 1306.99861878\n",
      "Validation score: -24.835049\n",
      "Iteration 1093, loss = 1306.07992983\n",
      "Validation score: -24.817056\n",
      "Iteration 1094, loss = 1305.16348009\n",
      "Validation score: -24.799120\n",
      "Iteration 1095, loss = 1304.24915700\n",
      "Validation score: -24.781207\n",
      "Iteration 1096, loss = 1303.33634799\n",
      "Validation score: -24.763320\n",
      "Iteration 1097, loss = 1302.42204666\n",
      "Validation score: -24.745485\n",
      "Iteration 1098, loss = 1301.51457293\n",
      "Validation score: -24.727640\n",
      "Iteration 1099, loss = 1300.60292815\n",
      "Validation score: -24.709830\n",
      "Iteration 1100, loss = 1299.69449803\n",
      "Validation score: -24.692018\n",
      "Iteration 1101, loss = 1298.78639890\n",
      "Validation score: -24.674246\n",
      "Iteration 1102, loss = 1297.87978658\n",
      "Validation score: -24.656486\n",
      "Iteration 1103, loss = 1296.97208236\n",
      "Validation score: -24.638786\n",
      "Iteration 1104, loss = 1296.06790976\n",
      "Validation score: -24.621058\n",
      "Iteration 1105, loss = 1295.16403568\n",
      "Validation score: -24.603328\n",
      "Iteration 1106, loss = 1294.26121188\n",
      "Validation score: -24.585610\n",
      "Iteration 1107, loss = 1293.36040369\n",
      "Validation score: -24.567907\n",
      "Iteration 1108, loss = 1292.45598899\n",
      "Validation score: -24.550243\n",
      "Iteration 1109, loss = 1291.55389711\n",
      "Validation score: -24.532595\n",
      "Iteration 1110, loss = 1290.65470358\n",
      "Validation score: -24.514933\n",
      "Iteration 1111, loss = 1289.75349130\n",
      "Validation score: -24.497323\n",
      "Iteration 1112, loss = 1288.85292905\n",
      "Validation score: -24.479748\n",
      "Iteration 1113, loss = 1287.95889129\n",
      "Validation score: -24.462159\n",
      "Iteration 1114, loss = 1287.05963831\n",
      "Validation score: -24.444599\n",
      "Iteration 1115, loss = 1286.16340384\n",
      "Validation score: -24.427026\n",
      "Iteration 1116, loss = 1285.26751371\n",
      "Validation score: -24.409464\n",
      "Iteration 1117, loss = 1284.37323800\n",
      "Validation score: -24.391898\n",
      "Iteration 1118, loss = 1283.47518415\n",
      "Validation score: -24.374354\n",
      "Iteration 1119, loss = 1282.58306394\n",
      "Validation score: -24.356792\n",
      "Iteration 1120, loss = 1281.68688536\n",
      "Validation score: -24.339288\n",
      "Iteration 1121, loss = 1280.79141182\n",
      "Validation score: -24.321814\n",
      "Iteration 1122, loss = 1279.90097141\n",
      "Validation score: -24.304281\n",
      "Iteration 1123, loss = 1279.00624504\n",
      "Validation score: -24.286758\n",
      "Iteration 1124, loss = 1278.11163330\n",
      "Validation score: -24.269234\n",
      "Iteration 1125, loss = 1277.21593008\n",
      "Validation score: -24.251708\n",
      "Iteration 1126, loss = 1276.32247108\n",
      "Validation score: -24.234164\n",
      "Iteration 1127, loss = 1275.42876737\n",
      "Validation score: -24.216600\n",
      "Iteration 1128, loss = 1274.53041029\n",
      "Validation score: -24.199082\n",
      "Iteration 1129, loss = 1273.63670807\n",
      "Validation score: -24.181496\n",
      "Iteration 1130, loss = 1272.74052538\n",
      "Validation score: -24.163865\n",
      "Iteration 1131, loss = 1271.83801430\n",
      "Validation score: -24.146218\n",
      "Iteration 1132, loss = 1270.93782021\n",
      "Validation score: -24.128507\n",
      "Iteration 1133, loss = 1270.03262926\n",
      "Validation score: -24.110757\n",
      "Iteration 1134, loss = 1269.12511955\n",
      "Validation score: -24.092938\n",
      "Iteration 1135, loss = 1268.21749795\n",
      "Validation score: -24.075015\n",
      "Iteration 1136, loss = 1267.29807634\n",
      "Validation score: -24.057080\n",
      "Iteration 1137, loss = 1266.38387356\n",
      "Validation score: -24.038993\n",
      "Iteration 1138, loss = 1265.45734818\n",
      "Validation score: -24.020848\n",
      "Iteration 1139, loss = 1264.52992646\n",
      "Validation score: -24.002569\n",
      "Iteration 1140, loss = 1263.59382219\n",
      "Validation score: -23.984177\n",
      "Iteration 1141, loss = 1262.65246888\n",
      "Validation score: -23.965609\n",
      "Iteration 1142, loss = 1261.70134178\n",
      "Validation score: -23.946886\n",
      "Iteration 1143, loss = 1260.74129240\n",
      "Validation score: -23.927971\n",
      "Iteration 1144, loss = 1259.77287502\n",
      "Validation score: -23.908840\n",
      "Iteration 1145, loss = 1258.79192145\n",
      "Validation score: -23.889465\n",
      "Iteration 1146, loss = 1257.79862462\n",
      "Validation score: -23.869876\n",
      "Iteration 1147, loss = 1256.79157507\n",
      "Validation score: -23.850070\n",
      "Iteration 1148, loss = 1255.77605760\n",
      "Validation score: -23.829997\n",
      "Iteration 1149, loss = 1254.74542692\n",
      "Validation score: -23.809717\n",
      "Iteration 1150, loss = 1253.70138399\n",
      "Validation score: -23.789246\n",
      "Iteration 1151, loss = 1252.64822751\n",
      "Validation score: -23.768525\n",
      "Iteration 1152, loss = 1251.58676011\n",
      "Validation score: -23.747571\n",
      "Iteration 1153, loss = 1250.50999233\n",
      "Validation score: -23.726464\n",
      "Iteration 1154, loss = 1249.42835331\n",
      "Validation score: -23.705206\n",
      "Iteration 1155, loss = 1248.33605563\n",
      "Validation score: -23.683882\n",
      "Iteration 1156, loss = 1247.24594766\n",
      "Validation score: -23.662470\n",
      "Iteration 1157, loss = 1246.14624383\n",
      "Validation score: -23.641078\n",
      "Iteration 1158, loss = 1245.05226490\n",
      "Validation score: -23.619660\n",
      "Iteration 1159, loss = 1243.95239693\n",
      "Validation score: -23.598279\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1160, loss = 1242.86010313\n",
      "Validation score: -23.576880\n",
      "Iteration 1161, loss = 1241.76525544\n",
      "Validation score: -23.555619\n",
      "Iteration 1162, loss = 1240.67993587\n",
      "Validation score: -23.534413\n",
      "Iteration 1163, loss = 1239.59632904\n",
      "Validation score: -23.513332\n",
      "Iteration 1164, loss = 1238.52076994\n",
      "Validation score: -23.492348\n",
      "Iteration 1165, loss = 1237.44867386\n",
      "Validation score: -23.471532\n",
      "Iteration 1166, loss = 1236.38737873\n",
      "Validation score: -23.450803\n",
      "Iteration 1167, loss = 1235.32741113\n",
      "Validation score: -23.430215\n",
      "Iteration 1168, loss = 1234.27862456\n",
      "Validation score: -23.409737\n",
      "Iteration 1169, loss = 1233.23263511\n",
      "Validation score: -23.389375\n",
      "Iteration 1170, loss = 1232.19683336\n",
      "Validation score: -23.369130\n",
      "Iteration 1171, loss = 1231.16706538\n",
      "Validation score: -23.349004\n",
      "Iteration 1172, loss = 1230.13882955\n",
      "Validation score: -23.329064\n",
      "Iteration 1173, loss = 1229.12504927\n",
      "Validation score: -23.309172\n",
      "Iteration 1174, loss = 1228.10958240\n",
      "Validation score: -23.289446\n",
      "Iteration 1175, loss = 1227.10352713\n",
      "Validation score: -23.269820\n",
      "Iteration 1176, loss = 1226.10641372\n",
      "Validation score: -23.250249\n",
      "Iteration 1177, loss = 1225.10739088\n",
      "Validation score: -23.230825\n",
      "Iteration 1178, loss = 1224.11776931\n",
      "Validation score: -23.211475\n",
      "Iteration 1179, loss = 1223.13094546\n",
      "Validation score: -23.192242\n",
      "Iteration 1180, loss = 1222.15328902\n",
      "Validation score: -23.173054\n",
      "Iteration 1181, loss = 1221.17716321\n",
      "Validation score: -23.153946\n",
      "Iteration 1182, loss = 1220.20232996\n",
      "Validation score: -23.134968\n",
      "Iteration 1183, loss = 1219.23415712\n",
      "Validation score: -23.116058\n",
      "Iteration 1184, loss = 1218.27079235\n",
      "Validation score: -23.097181\n",
      "Iteration 1185, loss = 1217.31045857\n",
      "Validation score: -23.078362\n",
      "Iteration 1186, loss = 1216.35158014\n",
      "Validation score: -23.059641\n",
      "Iteration 1187, loss = 1215.39834001\n",
      "Validation score: -23.040961\n",
      "Iteration 1188, loss = 1214.44605806\n",
      "Validation score: -23.022342\n",
      "Iteration 1189, loss = 1213.49759534\n",
      "Validation score: -23.003794\n",
      "Iteration 1190, loss = 1212.55359881\n",
      "Validation score: -22.985296\n",
      "Iteration 1191, loss = 1211.61243048\n",
      "Validation score: -22.966862\n",
      "Iteration 1192, loss = 1210.67311614\n",
      "Validation score: -22.948474\n",
      "Iteration 1193, loss = 1209.73604902\n",
      "Validation score: -22.930159\n",
      "Iteration 1194, loss = 1208.80304020\n",
      "Validation score: -22.911889\n",
      "Iteration 1195, loss = 1207.87211506\n",
      "Validation score: -22.893667\n",
      "Iteration 1196, loss = 1206.94034257\n",
      "Validation score: -22.875519\n",
      "Iteration 1197, loss = 1206.01760962\n",
      "Validation score: -22.857353\n",
      "Iteration 1198, loss = 1205.09053052\n",
      "Validation score: -22.839246\n",
      "Iteration 1199, loss = 1204.16974356\n",
      "Validation score: -22.821166\n",
      "Iteration 1200, loss = 1203.24918481\n",
      "Validation score: -22.803140\n",
      "Iteration 1201, loss = 1202.32987174\n",
      "Validation score: -22.785151\n",
      "Iteration 1202, loss = 1201.41095818\n",
      "Validation score: -22.767222\n",
      "Iteration 1203, loss = 1200.49850577\n",
      "Validation score: -22.749274\n",
      "Iteration 1204, loss = 1199.58389954\n",
      "Validation score: -22.731367\n",
      "Iteration 1205, loss = 1198.67351850\n",
      "Validation score: -22.713487\n",
      "Iteration 1206, loss = 1197.76184115\n",
      "Validation score: -22.695680\n",
      "Iteration 1207, loss = 1196.85326017\n",
      "Validation score: -22.677896\n",
      "Iteration 1208, loss = 1195.94611076\n",
      "Validation score: -22.660156\n",
      "Iteration 1209, loss = 1195.04410404\n",
      "Validation score: -22.642426\n",
      "Iteration 1210, loss = 1194.14065217\n",
      "Validation score: -22.624741\n",
      "Iteration 1211, loss = 1193.23715345\n",
      "Validation score: -22.607099\n",
      "Iteration 1212, loss = 1192.33933220\n",
      "Validation score: -22.589450\n",
      "Iteration 1213, loss = 1191.44103925\n",
      "Validation score: -22.571830\n",
      "Iteration 1214, loss = 1190.54389150\n",
      "Validation score: -22.554233\n",
      "Iteration 1215, loss = 1189.64476740\n",
      "Validation score: -22.536727\n",
      "Iteration 1216, loss = 1188.75231507\n",
      "Validation score: -22.519210\n",
      "Iteration 1217, loss = 1187.86014197\n",
      "Validation score: -22.501709\n",
      "Iteration 1218, loss = 1186.96879050\n",
      "Validation score: -22.484199\n",
      "Iteration 1219, loss = 1186.07513464\n",
      "Validation score: -22.466762\n",
      "Iteration 1220, loss = 1185.18711390\n",
      "Validation score: -22.449319\n",
      "Iteration 1221, loss = 1184.29889351\n",
      "Validation score: -22.431891\n",
      "Iteration 1222, loss = 1183.40950076\n",
      "Validation score: -22.414533\n",
      "Iteration 1223, loss = 1182.52606867\n",
      "Validation score: -22.397199\n",
      "Iteration 1224, loss = 1181.64173846\n",
      "Validation score: -22.379904\n",
      "Iteration 1225, loss = 1180.75766132\n",
      "Validation score: -22.362619\n",
      "Iteration 1226, loss = 1179.87535748\n",
      "Validation score: -22.345343\n",
      "Iteration 1227, loss = 1178.99594823\n",
      "Validation score: -22.328060\n",
      "Iteration 1228, loss = 1178.11414293\n",
      "Validation score: -22.310805\n",
      "Iteration 1229, loss = 1177.23688490\n",
      "Validation score: -22.293555\n",
      "Iteration 1230, loss = 1176.35774944\n",
      "Validation score: -22.276346\n",
      "Iteration 1231, loss = 1175.48026522\n",
      "Validation score: -22.259160\n",
      "Iteration 1232, loss = 1174.60260096\n",
      "Validation score: -22.242000\n",
      "Iteration 1233, loss = 1173.72770496\n",
      "Validation score: -22.224850\n",
      "Iteration 1234, loss = 1172.85248683\n",
      "Validation score: -22.207731\n",
      "Iteration 1235, loss = 1171.97980606\n",
      "Validation score: -22.190591\n",
      "Iteration 1236, loss = 1171.10532447\n",
      "Validation score: -22.173472\n",
      "Iteration 1237, loss = 1170.23446569\n",
      "Validation score: -22.156356\n",
      "Iteration 1238, loss = 1169.36214022\n",
      "Validation score: -22.139265\n",
      "Iteration 1239, loss = 1168.49168797\n",
      "Validation score: -22.122220\n",
      "Iteration 1240, loss = 1167.62071398\n",
      "Validation score: -22.105212\n",
      "Iteration 1241, loss = 1166.75110829\n",
      "Validation score: -22.088223\n",
      "Iteration 1242, loss = 1165.88556702\n",
      "Validation score: -22.071210\n",
      "Iteration 1243, loss = 1165.01935725\n",
      "Validation score: -22.054201\n",
      "Iteration 1244, loss = 1164.15316604\n",
      "Validation score: -22.037200\n",
      "Iteration 1245, loss = 1163.28435518\n",
      "Validation score: -22.020227\n",
      "Iteration 1246, loss = 1162.41746081\n",
      "Validation score: -22.003266\n",
      "Iteration 1247, loss = 1161.55372884\n",
      "Validation score: -21.986297\n",
      "Iteration 1248, loss = 1160.68857869\n",
      "Validation score: -21.969357\n",
      "Iteration 1249, loss = 1159.82342900\n",
      "Validation score: -21.952447\n",
      "Iteration 1250, loss = 1158.96406808\n",
      "Validation score: -21.935532\n",
      "Iteration 1251, loss = 1158.10250575\n",
      "Validation score: -21.918652\n",
      "Iteration 1252, loss = 1157.23808522\n",
      "Validation score: -21.901830\n",
      "Iteration 1253, loss = 1156.38239559\n",
      "Validation score: -21.884972\n",
      "Iteration 1254, loss = 1155.52114070\n",
      "Validation score: -21.868125\n",
      "Iteration 1255, loss = 1154.66373904\n",
      "Validation score: -21.851256\n",
      "Iteration 1256, loss = 1153.80531553\n",
      "Validation score: -21.834408\n",
      "Iteration 1257, loss = 1152.94417016\n",
      "Validation score: -21.817625\n",
      "Iteration 1258, loss = 1152.08446994\n",
      "Validation score: -21.800878\n",
      "Iteration 1259, loss = 1151.23327410\n",
      "Validation score: -21.784066\n",
      "Iteration 1260, loss = 1150.37626635\n",
      "Validation score: -21.767287\n",
      "Iteration 1261, loss = 1149.52260064\n",
      "Validation score: -21.750502\n",
      "Iteration 1262, loss = 1148.66549776\n",
      "Validation score: -21.733740\n",
      "Iteration 1263, loss = 1147.81120425\n",
      "Validation score: -21.716995\n",
      "Iteration 1264, loss = 1146.95660111\n",
      "Validation score: -21.700290\n",
      "Iteration 1265, loss = 1146.10524306\n",
      "Validation score: -21.683588\n",
      "Iteration 1266, loss = 1145.25355536\n",
      "Validation score: -21.666892\n",
      "Iteration 1267, loss = 1144.40071898\n",
      "Validation score: -21.650222\n",
      "Iteration 1268, loss = 1143.55012119\n",
      "Validation score: -21.633522\n",
      "Iteration 1269, loss = 1142.69680389\n",
      "Validation score: -21.616836\n",
      "Iteration 1270, loss = 1141.84745755\n",
      "Validation score: -21.600121\n",
      "Iteration 1271, loss = 1140.99390331\n",
      "Validation score: -21.583447\n",
      "Iteration 1272, loss = 1140.14481688\n",
      "Validation score: -21.566784\n",
      "Iteration 1273, loss = 1139.29543448\n",
      "Validation score: -21.550110\n",
      "Iteration 1274, loss = 1138.44416029\n",
      "Validation score: -21.533432\n",
      "Iteration 1275, loss = 1137.59259971\n",
      "Validation score: -21.516759\n",
      "Iteration 1276, loss = 1136.74119652\n",
      "Validation score: -21.500065\n",
      "Iteration 1277, loss = 1135.88969302\n",
      "Validation score: -21.483351\n",
      "Iteration 1278, loss = 1135.03986637\n",
      "Validation score: -21.466629\n",
      "Iteration 1279, loss = 1134.18608321\n",
      "Validation score: -21.449949\n",
      "Iteration 1280, loss = 1133.33396616\n",
      "Validation score: -21.433273\n",
      "Iteration 1281, loss = 1132.48335811\n",
      "Validation score: -21.416550\n",
      "Iteration 1282, loss = 1131.62927660\n",
      "Validation score: -21.399819\n",
      "Iteration 1283, loss = 1130.77848092\n",
      "Validation score: -21.383047\n",
      "Iteration 1284, loss = 1129.92366841\n",
      "Validation score: -21.366284\n",
      "Iteration 1285, loss = 1129.06768403\n",
      "Validation score: -21.349505\n",
      "Iteration 1286, loss = 1128.20991026\n",
      "Validation score: -21.332709\n",
      "Iteration 1287, loss = 1127.35310459\n",
      "Validation score: -21.315846\n",
      "Iteration 1288, loss = 1126.49212955\n",
      "Validation score: -21.298933\n",
      "Iteration 1289, loss = 1125.62796188\n",
      "Validation score: -21.281972\n",
      "Iteration 1290, loss = 1124.76112437\n",
      "Validation score: -21.264929\n",
      "Iteration 1291, loss = 1123.89158950\n",
      "Validation score: -21.247772\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1292, loss = 1123.01447283\n",
      "Validation score: -21.230549\n",
      "Iteration 1293, loss = 1122.13622955\n",
      "Validation score: -21.213202\n",
      "Iteration 1294, loss = 1121.24929953\n",
      "Validation score: -21.195738\n",
      "Iteration 1295, loss = 1120.35275284\n",
      "Validation score: -21.178154\n",
      "Iteration 1296, loss = 1119.45520031\n",
      "Validation score: -21.160337\n",
      "Iteration 1297, loss = 1118.54305166\n",
      "Validation score: -21.142357\n",
      "Iteration 1298, loss = 1117.62067918\n",
      "Validation score: -21.124182\n",
      "Iteration 1299, loss = 1116.69019069\n",
      "Validation score: -21.105753\n",
      "Iteration 1300, loss = 1115.74639120\n",
      "Validation score: -21.087118\n",
      "Iteration 1301, loss = 1114.79064481\n",
      "Validation score: -21.068213\n",
      "Iteration 1302, loss = 1113.81953233\n",
      "Validation score: -21.049077\n",
      "Iteration 1303, loss = 1112.83892658\n",
      "Validation score: -21.029674\n",
      "Iteration 1304, loss = 1111.84281589\n",
      "Validation score: -21.010008\n",
      "Iteration 1305, loss = 1110.83241540\n",
      "Validation score: -20.990094\n",
      "Iteration 1306, loss = 1109.80898479\n",
      "Validation score: -20.969976\n",
      "Iteration 1307, loss = 1108.77769533\n",
      "Validation score: -20.949605\n",
      "Iteration 1308, loss = 1107.73154700\n",
      "Validation score: -20.929043\n",
      "Iteration 1309, loss = 1106.67670668\n",
      "Validation score: -20.908325\n",
      "Iteration 1310, loss = 1105.61260392\n",
      "Validation score: -20.887452\n",
      "Iteration 1311, loss = 1104.54275460\n",
      "Validation score: -20.866521\n",
      "Iteration 1312, loss = 1103.47226511\n",
      "Validation score: -20.845505\n",
      "Iteration 1313, loss = 1102.39553858\n",
      "Validation score: -20.824497\n",
      "Iteration 1314, loss = 1101.31968692\n",
      "Validation score: -20.803572\n",
      "Iteration 1315, loss = 1100.25073538\n",
      "Validation score: -20.782656\n",
      "Iteration 1316, loss = 1099.18217666\n",
      "Validation score: -20.761822\n",
      "Iteration 1317, loss = 1098.11628523\n",
      "Validation score: -20.741062\n",
      "Iteration 1318, loss = 1097.05881050\n",
      "Validation score: -20.720376\n",
      "Iteration 1319, loss = 1096.00233038\n",
      "Validation score: -20.699834\n",
      "Iteration 1320, loss = 1094.95251167\n",
      "Validation score: -20.679386\n",
      "Iteration 1321, loss = 1093.91151634\n",
      "Validation score: -20.658987\n",
      "Iteration 1322, loss = 1092.87131720\n",
      "Validation score: -20.638707\n",
      "Iteration 1323, loss = 1091.83461878\n",
      "Validation score: -20.618554\n",
      "Iteration 1324, loss = 1090.80798615\n",
      "Validation score: -20.598452\n",
      "Iteration 1325, loss = 1089.78233540\n",
      "Validation score: -20.578405\n",
      "Iteration 1326, loss = 1088.76030482\n",
      "Validation score: -20.558353\n",
      "Iteration 1327, loss = 1087.73656004\n",
      "Validation score: -20.538347\n",
      "Iteration 1328, loss = 1086.71630097\n",
      "Validation score: -20.518348\n",
      "Iteration 1329, loss = 1085.69522861\n",
      "Validation score: -20.498331\n",
      "Iteration 1330, loss = 1084.67305644\n",
      "Validation score: -20.478261\n",
      "Iteration 1331, loss = 1083.64913372\n",
      "Validation score: -20.458093\n",
      "Iteration 1332, loss = 1082.61938340\n",
      "Validation score: -20.437806\n",
      "Iteration 1333, loss = 1081.57973546\n",
      "Validation score: -20.417401\n",
      "Iteration 1334, loss = 1080.53618558\n",
      "Validation score: -20.396758\n",
      "Iteration 1335, loss = 1079.47687211\n",
      "Validation score: -20.375932\n",
      "Iteration 1336, loss = 1078.41131281\n",
      "Validation score: -20.354818\n",
      "Iteration 1337, loss = 1077.33021403\n",
      "Validation score: -20.333350\n",
      "Iteration 1338, loss = 1076.22392361\n",
      "Validation score: -20.311557\n",
      "Iteration 1339, loss = 1075.10466062\n",
      "Validation score: -20.289312\n",
      "Iteration 1340, loss = 1073.96137419\n",
      "Validation score: -20.266604\n",
      "Iteration 1341, loss = 1072.79504132\n",
      "Validation score: -20.243427\n",
      "Iteration 1342, loss = 1071.60213841\n",
      "Validation score: -20.219825\n",
      "Iteration 1343, loss = 1070.38543730\n",
      "Validation score: -20.195720\n",
      "Iteration 1344, loss = 1069.14383867\n",
      "Validation score: -20.171112\n",
      "Iteration 1345, loss = 1067.87791423\n",
      "Validation score: -20.146028\n",
      "Iteration 1346, loss = 1066.58478855\n",
      "Validation score: -20.120559\n",
      "Iteration 1347, loss = 1065.26876881\n",
      "Validation score: -20.094674\n",
      "Iteration 1348, loss = 1063.94151250\n",
      "Validation score: -20.068363\n",
      "Iteration 1349, loss = 1062.58698738\n",
      "Validation score: -20.041855\n",
      "Iteration 1350, loss = 1061.22669657\n",
      "Validation score: -20.015113\n",
      "Iteration 1351, loss = 1059.85659145\n",
      "Validation score: -19.988208\n",
      "Iteration 1352, loss = 1058.47131200\n",
      "Validation score: -19.961342\n",
      "Iteration 1353, loss = 1057.09621705\n",
      "Validation score: -19.934467\n",
      "Iteration 1354, loss = 1055.72047159\n",
      "Validation score: -19.907644\n",
      "Iteration 1355, loss = 1054.35292327\n",
      "Validation score: -19.880969\n",
      "Iteration 1356, loss = 1052.98579373\n",
      "Validation score: -19.854566\n",
      "Iteration 1357, loss = 1051.63921313\n",
      "Validation score: -19.828315\n",
      "Iteration 1358, loss = 1050.30199957\n",
      "Validation score: -19.802304\n",
      "Iteration 1359, loss = 1048.97354382\n",
      "Validation score: -19.776585\n",
      "Iteration 1360, loss = 1047.66416280\n",
      "Validation score: -19.751132\n",
      "Iteration 1361, loss = 1046.36769091\n",
      "Validation score: -19.726032\n",
      "Iteration 1362, loss = 1045.09445178\n",
      "Validation score: -19.701213\n",
      "Iteration 1363, loss = 1043.83088518\n",
      "Validation score: -19.676727\n",
      "Iteration 1364, loss = 1042.58848839\n",
      "Validation score: -19.652538\n",
      "Iteration 1365, loss = 1041.35669017\n",
      "Validation score: -19.628677\n",
      "Iteration 1366, loss = 1040.14364813\n",
      "Validation score: -19.605072\n",
      "Iteration 1367, loss = 1038.94175006\n",
      "Validation score: -19.581751\n",
      "Iteration 1368, loss = 1037.75965904\n",
      "Validation score: -19.558644\n",
      "Iteration 1369, loss = 1036.58695043\n",
      "Validation score: -19.535808\n",
      "Iteration 1370, loss = 1035.42714859\n",
      "Validation score: -19.513260\n",
      "Iteration 1371, loss = 1034.27989671\n",
      "Validation score: -19.490942\n",
      "Iteration 1372, loss = 1033.14649512\n",
      "Validation score: -19.468830\n",
      "Iteration 1373, loss = 1032.02446665\n",
      "Validation score: -19.446890\n",
      "Iteration 1374, loss = 1030.91326712\n",
      "Validation score: -19.425139\n",
      "Iteration 1375, loss = 1029.80533543\n",
      "Validation score: -19.403635\n",
      "Iteration 1376, loss = 1028.71160136\n",
      "Validation score: -19.382284\n",
      "Iteration 1377, loss = 1027.62653907\n",
      "Validation score: -19.361093\n",
      "Iteration 1378, loss = 1026.55124568\n",
      "Validation score: -19.340063\n",
      "Iteration 1379, loss = 1025.48265355\n",
      "Validation score: -19.319191\n",
      "Iteration 1380, loss = 1024.42141842\n",
      "Validation score: -19.298482\n",
      "Iteration 1381, loss = 1023.36994727\n",
      "Validation score: -19.277881\n",
      "Iteration 1382, loss = 1022.32153290\n",
      "Validation score: -19.257423\n",
      "Iteration 1383, loss = 1021.28471281\n",
      "Validation score: -19.237068\n",
      "Iteration 1384, loss = 1020.24985498\n",
      "Validation score: -19.216862\n",
      "Iteration 1385, loss = 1019.22383409\n",
      "Validation score: -19.196778\n",
      "Iteration 1386, loss = 1018.20258783\n",
      "Validation score: -19.176805\n",
      "Iteration 1387, loss = 1017.18697608\n",
      "Validation score: -19.156938\n",
      "Iteration 1388, loss = 1016.17826533\n",
      "Validation score: -19.137166\n",
      "Iteration 1389, loss = 1015.17380788\n",
      "Validation score: -19.117501\n",
      "Iteration 1390, loss = 1014.17341312\n",
      "Validation score: -19.097929\n",
      "Iteration 1391, loss = 1013.17793085\n",
      "Validation score: -19.078433\n",
      "Iteration 1392, loss = 1012.18829533\n",
      "Validation score: -19.058990\n",
      "Iteration 1393, loss = 1011.19906174\n",
      "Validation score: -19.039656\n",
      "Iteration 1394, loss = 1010.21632242\n",
      "Validation score: -19.020398\n",
      "Iteration 1395, loss = 1009.23602737\n",
      "Validation score: -19.001241\n",
      "Iteration 1396, loss = 1008.26277946\n",
      "Validation score: -18.982132\n",
      "Iteration 1397, loss = 1007.29101616\n",
      "Validation score: -18.963096\n",
      "Iteration 1398, loss = 1006.32324806\n",
      "Validation score: -18.944142\n",
      "Iteration 1399, loss = 1005.35706020\n",
      "Validation score: -18.925286\n",
      "Iteration 1400, loss = 1004.39843436\n",
      "Validation score: -18.906440\n",
      "Iteration 1401, loss = 1003.44095693\n",
      "Validation score: -18.887639\n",
      "Iteration 1402, loss = 1002.48458970\n",
      "Validation score: -18.868955\n",
      "Iteration 1403, loss = 1001.53307902\n",
      "Validation score: -18.850310\n",
      "Iteration 1404, loss = 1000.58745144\n",
      "Validation score: -18.831689\n",
      "Iteration 1405, loss = 999.63970870\n",
      "Validation score: -18.813174\n",
      "Iteration 1406, loss = 998.69533156\n",
      "Validation score: -18.794728\n",
      "Iteration 1407, loss = 997.75934902\n",
      "Validation score: -18.776286\n",
      "Iteration 1408, loss = 996.82017344\n",
      "Validation score: -18.757942\n",
      "Iteration 1409, loss = 995.88710451\n",
      "Validation score: -18.739620\n",
      "Iteration 1410, loss = 994.95410543\n",
      "Validation score: -18.721351\n",
      "Iteration 1411, loss = 994.02482143\n",
      "Validation score: -18.703118\n",
      "Iteration 1412, loss = 993.09520248\n",
      "Validation score: -18.684952\n",
      "Iteration 1413, loss = 992.17041756\n",
      "Validation score: -18.666788\n",
      "Iteration 1414, loss = 991.24775354\n",
      "Validation score: -18.648622\n",
      "Iteration 1415, loss = 990.32330879\n",
      "Validation score: -18.630519\n",
      "Iteration 1416, loss = 989.40206315\n",
      "Validation score: -18.612481\n",
      "Iteration 1417, loss = 988.48606592\n",
      "Validation score: -18.594455\n",
      "Iteration 1418, loss = 987.56771175\n",
      "Validation score: -18.576505\n",
      "Iteration 1419, loss = 986.65348167\n",
      "Validation score: -18.558581\n",
      "Iteration 1420, loss = 985.74182369\n",
      "Validation score: -18.540681\n",
      "Iteration 1421, loss = 984.83173540\n",
      "Validation score: -18.522828\n",
      "Iteration 1422, loss = 983.92513412\n",
      "Validation score: -18.505018\n",
      "Iteration 1423, loss = 983.01776845\n",
      "Validation score: -18.487290\n",
      "Iteration 1424, loss = 982.11554021\n",
      "Validation score: -18.469588\n",
      "Iteration 1425, loss = 981.21446376\n",
      "Validation score: -18.451888\n",
      "Iteration 1426, loss = 980.31534670\n",
      "Validation score: -18.434196\n",
      "Iteration 1427, loss = 979.41469182\n",
      "Validation score: -18.416576\n",
      "Iteration 1428, loss = 978.51668665\n",
      "Validation score: -18.399034\n",
      "Iteration 1429, loss = 977.62383284\n",
      "Validation score: -18.381482\n",
      "Iteration 1430, loss = 976.73139654\n",
      "Validation score: -18.363921\n",
      "Iteration 1431, loss = 975.83371414\n",
      "Validation score: -18.346438\n",
      "Iteration 1432, loss = 974.94682301\n",
      "Validation score: -18.328922\n",
      "Iteration 1433, loss = 974.05306357\n",
      "Validation score: -18.311491\n",
      "Iteration 1434, loss = 973.16658124\n",
      "Validation score: -18.294072\n",
      "Iteration 1435, loss = 972.28226703\n",
      "Validation score: -18.276685\n",
      "Iteration 1436, loss = 971.39428986\n",
      "Validation score: -18.259374\n",
      "Iteration 1437, loss = 970.51566224\n",
      "Validation score: -18.242011\n",
      "Iteration 1438, loss = 969.62977039\n",
      "Validation score: -18.224725\n",
      "Iteration 1439, loss = 968.74834312\n",
      "Validation score: -18.207453\n",
      "Iteration 1440, loss = 967.87174038\n",
      "Validation score: -18.190136\n",
      "Iteration 1441, loss = 966.98957403\n",
      "Validation score: -18.172924\n",
      "Iteration 1442, loss = 966.11497041\n",
      "Validation score: -18.155713\n",
      "Iteration 1443, loss = 965.23863073\n",
      "Validation score: -18.138542\n",
      "Iteration 1444, loss = 964.36272462\n",
      "Validation score: -18.121416\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1445, loss = 963.48814082\n",
      "Validation score: -18.104291\n",
      "Iteration 1446, loss = 962.61996046\n",
      "Validation score: -18.087133\n",
      "Iteration 1447, loss = 961.74999512\n",
      "Validation score: -18.070010\n",
      "Iteration 1448, loss = 960.87795226\n",
      "Validation score: -18.052974\n",
      "Iteration 1449, loss = 960.00883816\n",
      "Validation score: -18.036003\n",
      "Iteration 1450, loss = 959.14361039\n",
      "Validation score: -18.019020\n",
      "Iteration 1451, loss = 958.28084230\n",
      "Validation score: -18.002052\n",
      "Iteration 1452, loss = 957.41447748\n",
      "Validation score: -17.985151\n",
      "Iteration 1453, loss = 956.55354684\n",
      "Validation score: -17.968240\n",
      "Iteration 1454, loss = 955.69220500\n",
      "Validation score: -17.951325\n",
      "Iteration 1455, loss = 954.83065109\n",
      "Validation score: -17.934441\n",
      "Iteration 1456, loss = 953.97223430\n",
      "Validation score: -17.917555\n",
      "Iteration 1457, loss = 953.10963800\n",
      "Validation score: -17.900729\n",
      "Iteration 1458, loss = 952.25202977\n",
      "Validation score: -17.883898\n",
      "Iteration 1459, loss = 951.39506716\n",
      "Validation score: -17.867110\n",
      "Iteration 1460, loss = 950.54332137\n",
      "Validation score: -17.850302\n",
      "Iteration 1461, loss = 949.68736954\n",
      "Validation score: -17.833529\n",
      "Iteration 1462, loss = 948.83185193\n",
      "Validation score: -17.816789\n",
      "Iteration 1463, loss = 947.97965767\n",
      "Validation score: -17.800054\n",
      "Iteration 1464, loss = 947.12578526\n",
      "Validation score: -17.783374\n",
      "Iteration 1465, loss = 946.27758960\n",
      "Validation score: -17.766685\n",
      "Iteration 1466, loss = 945.42787192\n",
      "Validation score: -17.750027\n",
      "Iteration 1467, loss = 944.57866102\n",
      "Validation score: -17.733397\n",
      "Iteration 1468, loss = 943.73277340\n",
      "Validation score: -17.716749\n",
      "Iteration 1469, loss = 942.88311222\n",
      "Validation score: -17.700157\n",
      "Iteration 1470, loss = 942.03822977\n",
      "Validation score: -17.683560\n",
      "Iteration 1471, loss = 941.19378872\n",
      "Validation score: -17.666978\n",
      "Iteration 1472, loss = 940.35041687\n",
      "Validation score: -17.650403\n",
      "Iteration 1473, loss = 939.50457483\n",
      "Validation score: -17.633858\n",
      "Iteration 1474, loss = 938.66092760\n",
      "Validation score: -17.617320\n",
      "Iteration 1475, loss = 937.82022521\n",
      "Validation score: -17.600789\n",
      "Iteration 1476, loss = 936.97839543\n",
      "Validation score: -17.584309\n",
      "Iteration 1477, loss = 936.13919426\n",
      "Validation score: -17.567826\n",
      "Iteration 1478, loss = 935.29969841\n",
      "Validation score: -17.551368\n",
      "Iteration 1479, loss = 934.46146762\n",
      "Validation score: -17.534917\n",
      "Iteration 1480, loss = 933.62171903\n",
      "Validation score: -17.518491\n",
      "Iteration 1481, loss = 932.78377774\n",
      "Validation score: -17.502073\n",
      "Iteration 1482, loss = 931.94888345\n",
      "Validation score: -17.485666\n",
      "Iteration 1483, loss = 931.11490961\n",
      "Validation score: -17.469273\n",
      "Iteration 1484, loss = 930.27633104\n",
      "Validation score: -17.452917\n",
      "Iteration 1485, loss = 929.44572115\n",
      "Validation score: -17.436532\n",
      "Iteration 1486, loss = 928.61038868\n",
      "Validation score: -17.420194\n",
      "Iteration 1487, loss = 927.78035916\n",
      "Validation score: -17.403849\n",
      "Iteration 1488, loss = 926.94634375\n",
      "Validation score: -17.387534\n",
      "Iteration 1489, loss = 926.11564907\n",
      "Validation score: -17.371236\n",
      "Iteration 1490, loss = 925.28642244\n",
      "Validation score: -17.354931\n",
      "Iteration 1491, loss = 924.45662342\n",
      "Validation score: -17.338659\n",
      "Iteration 1492, loss = 923.62575062\n",
      "Validation score: -17.322455\n",
      "Iteration 1493, loss = 922.80096128\n",
      "Validation score: -17.306227\n",
      "Iteration 1494, loss = 921.97237815\n",
      "Validation score: -17.290018\n",
      "Iteration 1495, loss = 921.14805509\n",
      "Validation score: -17.273783\n",
      "Iteration 1496, loss = 920.32138535\n",
      "Validation score: -17.257555\n",
      "Iteration 1497, loss = 919.49382956\n",
      "Validation score: -17.241368\n",
      "Iteration 1498, loss = 918.66782580\n",
      "Validation score: -17.225190\n",
      "Iteration 1499, loss = 917.84592343\n",
      "Validation score: -17.208994\n",
      "Iteration 1500, loss = 917.01960184\n",
      "Validation score: -17.192836\n",
      "Iteration 1501, loss = 916.19873461\n",
      "Validation score: -17.176680\n",
      "Iteration 1502, loss = 915.37582274\n",
      "Validation score: -17.160564\n",
      "Iteration 1503, loss = 914.55514996\n",
      "Validation score: -17.144473\n",
      "Iteration 1504, loss = 913.73477424\n",
      "Validation score: -17.128383\n",
      "Iteration 1505, loss = 912.91740170\n",
      "Validation score: -17.112280\n",
      "Iteration 1506, loss = 912.09447580\n",
      "Validation score: -17.096250\n",
      "Iteration 1507, loss = 911.27952347\n",
      "Validation score: -17.080200\n",
      "Iteration 1508, loss = 910.46046023\n",
      "Validation score: -17.064185\n",
      "Iteration 1509, loss = 909.64616363\n",
      "Validation score: -17.048157\n",
      "Iteration 1510, loss = 908.83047591\n",
      "Validation score: -17.032144\n",
      "Iteration 1511, loss = 908.01593274\n",
      "Validation score: -17.016171\n",
      "Iteration 1512, loss = 907.20268107\n",
      "Validation score: -17.000210\n",
      "Iteration 1513, loss = 906.38733492\n",
      "Validation score: -16.984268\n",
      "Iteration 1514, loss = 905.57413111\n",
      "Validation score: -16.968360\n",
      "Iteration 1515, loss = 904.76438110\n",
      "Validation score: -16.952425\n",
      "Iteration 1516, loss = 903.95218974\n",
      "Validation score: -16.936487\n",
      "Iteration 1517, loss = 903.14026052\n",
      "Validation score: -16.920564\n",
      "Iteration 1518, loss = 902.32953500\n",
      "Validation score: -16.904665\n",
      "Iteration 1519, loss = 901.52060554\n",
      "Validation score: -16.888771\n",
      "Iteration 1520, loss = 900.71185181\n",
      "Validation score: -16.872890\n",
      "Iteration 1521, loss = 899.90238560\n",
      "Validation score: -16.857050\n",
      "Iteration 1522, loss = 899.09523448\n",
      "Validation score: -16.841213\n",
      "Iteration 1523, loss = 898.28881666\n",
      "Validation score: -16.825377\n",
      "Iteration 1524, loss = 897.47968556\n",
      "Validation score: -16.809571\n",
      "Iteration 1525, loss = 896.67687507\n",
      "Validation score: -16.793730\n",
      "Iteration 1526, loss = 895.86795090\n",
      "Validation score: -16.777943\n",
      "Iteration 1527, loss = 895.06423232\n",
      "Validation score: -16.762156\n",
      "Iteration 1528, loss = 894.26247243\n",
      "Validation score: -16.746366\n",
      "Iteration 1529, loss = 893.45639694\n",
      "Validation score: -16.730609\n",
      "Iteration 1530, loss = 892.65371745\n",
      "Validation score: -16.714843\n",
      "Iteration 1531, loss = 891.85253897\n",
      "Validation score: -16.699068\n",
      "Iteration 1532, loss = 891.04712079\n",
      "Validation score: -16.683338\n",
      "Iteration 1533, loss = 890.24545739\n",
      "Validation score: -16.667615\n",
      "Iteration 1534, loss = 889.44725027\n",
      "Validation score: -16.651907\n",
      "Iteration 1535, loss = 888.64679157\n",
      "Validation score: -16.636226\n",
      "Iteration 1536, loss = 887.84609515\n",
      "Validation score: -16.620570\n",
      "Iteration 1537, loss = 887.04897671\n",
      "Validation score: -16.604893\n",
      "Iteration 1538, loss = 886.24996494\n",
      "Validation score: -16.589236\n",
      "Iteration 1539, loss = 885.45209825\n",
      "Validation score: -16.573596\n",
      "Iteration 1540, loss = 884.65670059\n",
      "Validation score: -16.557945\n",
      "Iteration 1541, loss = 883.86114956\n",
      "Validation score: -16.542315\n",
      "Iteration 1542, loss = 883.06490017\n",
      "Validation score: -16.526721\n",
      "Iteration 1543, loss = 882.26866319\n",
      "Validation score: -16.511160\n",
      "Iteration 1544, loss = 881.47965070\n",
      "Validation score: -16.495557\n",
      "Iteration 1545, loss = 880.68234209\n",
      "Validation score: -16.480014\n",
      "Iteration 1546, loss = 879.88949260\n",
      "Validation score: -16.464441\n",
      "Iteration 1547, loss = 879.09674836\n",
      "Validation score: -16.448855\n",
      "Iteration 1548, loss = 878.30268051\n",
      "Validation score: -16.433295\n",
      "Iteration 1549, loss = 877.50915661\n",
      "Validation score: -16.417752\n",
      "Iteration 1550, loss = 876.71625519\n",
      "Validation score: -16.402224\n",
      "Iteration 1551, loss = 875.92662276\n",
      "Validation score: -16.386659\n",
      "Iteration 1552, loss = 875.13395876\n",
      "Validation score: -16.371122\n",
      "Iteration 1553, loss = 874.34071032\n",
      "Validation score: -16.355626\n",
      "Iteration 1554, loss = 873.55227986\n",
      "Validation score: -16.340101\n",
      "Iteration 1555, loss = 872.76286475\n",
      "Validation score: -16.324556\n",
      "Iteration 1556, loss = 871.97005303\n",
      "Validation score: -16.309046\n",
      "Iteration 1557, loss = 871.17807737\n",
      "Validation score: -16.293546\n",
      "Iteration 1558, loss = 870.38892057\n",
      "Validation score: -16.278004\n",
      "Iteration 1559, loss = 869.59756713\n",
      "Validation score: -16.262445\n",
      "Iteration 1560, loss = 868.80477117\n",
      "Validation score: -16.246896\n",
      "Iteration 1561, loss = 868.01446118\n",
      "Validation score: -16.231335\n",
      "Iteration 1562, loss = 867.22296192\n",
      "Validation score: -16.215793\n",
      "Iteration 1563, loss = 866.42775423\n",
      "Validation score: -16.200262\n",
      "Iteration 1564, loss = 865.63722597\n",
      "Validation score: -16.184673\n",
      "Iteration 1565, loss = 864.84216973\n",
      "Validation score: -16.169076\n",
      "Iteration 1566, loss = 864.04818275\n",
      "Validation score: -16.153457\n",
      "Iteration 1567, loss = 863.25207538\n",
      "Validation score: -16.137830\n",
      "Iteration 1568, loss = 862.45674275\n",
      "Validation score: -16.122125\n",
      "Iteration 1569, loss = 861.65492829\n",
      "Validation score: -16.106409\n",
      "Iteration 1570, loss = 860.85407421\n",
      "Validation score: -16.090632\n",
      "Iteration 1571, loss = 860.04772063\n",
      "Validation score: -16.074806\n",
      "Iteration 1572, loss = 859.24283195\n",
      "Validation score: -16.058849\n",
      "Iteration 1573, loss = 858.42438097\n",
      "Validation score: -16.042825\n",
      "Iteration 1574, loss = 857.60921952\n",
      "Validation score: -16.026613\n",
      "Iteration 1575, loss = 856.78077451\n",
      "Validation score: -16.010275\n",
      "Iteration 1576, loss = 855.94556039\n",
      "Validation score: -15.993800\n",
      "Iteration 1577, loss = 855.10623020\n",
      "Validation score: -15.977156\n",
      "Iteration 1578, loss = 854.25302059\n",
      "Validation score: -15.960347\n",
      "Iteration 1579, loss = 853.39331705\n",
      "Validation score: -15.943320\n",
      "Iteration 1580, loss = 852.52157406\n",
      "Validation score: -15.926052\n",
      "Iteration 1581, loss = 851.63740182\n",
      "Validation score: -15.908515\n",
      "Iteration 1582, loss = 850.73993333\n",
      "Validation score: -15.890695\n",
      "Iteration 1583, loss = 849.82467436\n",
      "Validation score: -15.872624\n",
      "Iteration 1584, loss = 848.89639268\n",
      "Validation score: -15.854262\n",
      "Iteration 1585, loss = 847.95387334\n",
      "Validation score: -15.835611\n",
      "Iteration 1586, loss = 846.99712973\n",
      "Validation score: -15.816658\n",
      "Iteration 1587, loss = 846.02566769\n",
      "Validation score: -15.797457\n",
      "Iteration 1588, loss = 845.04026748\n",
      "Validation score: -15.778040\n",
      "Iteration 1589, loss = 844.04408838\n",
      "Validation score: -15.758442\n",
      "Iteration 1590, loss = 843.03950144\n",
      "Validation score: -15.738684\n",
      "Iteration 1591, loss = 842.02681137\n",
      "Validation score: -15.718795\n",
      "Iteration 1592, loss = 841.00922287\n",
      "Validation score: -15.698820\n",
      "Iteration 1593, loss = 839.99026601\n",
      "Validation score: -15.678790\n",
      "Iteration 1594, loss = 838.96711901\n",
      "Validation score: -15.658808\n",
      "Iteration 1595, loss = 837.94881874\n",
      "Validation score: -15.638891\n",
      "Iteration 1596, loss = 836.93409887\n",
      "Validation score: -15.619115\n",
      "Iteration 1597, loss = 835.92447429\n",
      "Validation score: -15.599483\n",
      "Iteration 1598, loss = 834.92775420\n",
      "Validation score: -15.579950\n",
      "Iteration 1599, loss = 833.92971099\n",
      "Validation score: -15.560644\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1600, loss = 832.94715104\n",
      "Validation score: -15.541463\n",
      "Iteration 1601, loss = 831.96855281\n",
      "Validation score: -15.522458\n",
      "Iteration 1602, loss = 831.00241196\n",
      "Validation score: -15.503597\n",
      "Iteration 1603, loss = 830.04437183\n",
      "Validation score: -15.484901\n",
      "Iteration 1604, loss = 829.09606413\n",
      "Validation score: -15.466372\n",
      "Iteration 1605, loss = 828.15262448\n",
      "Validation score: -15.448033\n",
      "Iteration 1606, loss = 827.21864110\n",
      "Validation score: -15.429868\n",
      "Iteration 1607, loss = 826.29488623\n",
      "Validation score: -15.411782\n",
      "Iteration 1608, loss = 825.37463043\n",
      "Validation score: -15.393856\n",
      "Iteration 1609, loss = 824.46672104\n",
      "Validation score: -15.376033\n",
      "Iteration 1610, loss = 823.55752522\n",
      "Validation score: -15.358401\n",
      "Iteration 1611, loss = 822.66496108\n",
      "Validation score: -15.340859\n",
      "Iteration 1612, loss = 821.77351528\n",
      "Validation score: -15.323469\n",
      "Iteration 1613, loss = 820.89262856\n",
      "Validation score: -15.306193\n",
      "Iteration 1614, loss = 820.01244688\n",
      "Validation score: -15.289043\n",
      "Iteration 1615, loss = 819.13842251\n",
      "Validation score: -15.271998\n",
      "Iteration 1616, loss = 818.27176452\n",
      "Validation score: -15.255033\n",
      "Iteration 1617, loss = 817.40983440\n",
      "Validation score: -15.238142\n",
      "Iteration 1618, loss = 816.55361363\n",
      "Validation score: -15.221324\n",
      "Iteration 1619, loss = 815.69615134\n",
      "Validation score: -15.204626\n",
      "Iteration 1620, loss = 814.84944893\n",
      "Validation score: -15.187943\n",
      "Iteration 1621, loss = 813.99995334\n",
      "Validation score: -15.171352\n",
      "Iteration 1622, loss = 813.15717953\n",
      "Validation score: -15.154801\n",
      "Iteration 1623, loss = 812.31356274\n",
      "Validation score: -15.138318\n",
      "Iteration 1624, loss = 811.47524850\n",
      "Validation score: -15.121874\n",
      "Iteration 1625, loss = 810.63713581\n",
      "Validation score: -15.105477\n",
      "Iteration 1626, loss = 809.80405664\n",
      "Validation score: -15.089131\n",
      "Iteration 1627, loss = 808.97230008\n",
      "Validation score: -15.072849\n",
      "Iteration 1628, loss = 808.14608366\n",
      "Validation score: -15.056595\n",
      "Iteration 1629, loss = 807.31765282\n",
      "Validation score: -15.040429\n",
      "Iteration 1630, loss = 806.49747144\n",
      "Validation score: -15.024249\n",
      "Iteration 1631, loss = 805.67481031\n",
      "Validation score: -15.008146\n",
      "Iteration 1632, loss = 804.85653371\n",
      "Validation score: -14.992100\n",
      "Iteration 1633, loss = 804.04070701\n",
      "Validation score: -14.976094\n",
      "Iteration 1634, loss = 803.22624166\n",
      "Validation score: -14.960127\n",
      "Iteration 1635, loss = 802.41406040\n",
      "Validation score: -14.944188\n",
      "Iteration 1636, loss = 801.60541762\n",
      "Validation score: -14.928257\n",
      "Iteration 1637, loss = 800.79327065\n",
      "Validation score: -14.912420\n",
      "Iteration 1638, loss = 799.98699535\n",
      "Validation score: -14.896598\n",
      "Iteration 1639, loss = 799.18447174\n",
      "Validation score: -14.880761\n",
      "Iteration 1640, loss = 798.37840934\n",
      "Validation score: -14.865009\n",
      "Iteration 1641, loss = 797.57745928\n",
      "Validation score: -14.849293\n",
      "Iteration 1642, loss = 796.77838206\n",
      "Validation score: -14.833608\n",
      "Iteration 1643, loss = 795.98046330\n",
      "Validation score: -14.817931\n",
      "Iteration 1644, loss = 795.18231389\n",
      "Validation score: -14.802297\n",
      "Iteration 1645, loss = 794.38782217\n",
      "Validation score: -14.786674\n",
      "Iteration 1646, loss = 793.59226628\n",
      "Validation score: -14.771079\n",
      "Iteration 1647, loss = 792.79666578\n",
      "Validation score: -14.755517\n",
      "Iteration 1648, loss = 792.00669936\n",
      "Validation score: -14.739933\n",
      "Iteration 1649, loss = 791.21310728\n",
      "Validation score: -14.724424\n",
      "Iteration 1650, loss = 790.42485035\n",
      "Validation score: -14.708930\n",
      "Iteration 1651, loss = 789.63611508\n",
      "Validation score: -14.693454\n",
      "Iteration 1652, loss = 788.84878266\n",
      "Validation score: -14.677991\n",
      "Iteration 1653, loss = 788.06423823\n",
      "Validation score: -14.662514\n",
      "Iteration 1654, loss = 787.27398960\n",
      "Validation score: -14.647139\n",
      "Iteration 1655, loss = 786.49012147\n",
      "Validation score: -14.631770\n",
      "Iteration 1656, loss = 785.71214141\n",
      "Validation score: -14.616341\n",
      "Iteration 1657, loss = 784.92641799\n",
      "Validation score: -14.601011\n",
      "Iteration 1658, loss = 784.14690562\n",
      "Validation score: -14.585719\n",
      "Iteration 1659, loss = 783.36950519\n",
      "Validation score: -14.570427\n",
      "Iteration 1660, loss = 782.59140709\n",
      "Validation score: -14.555165\n",
      "Iteration 1661, loss = 781.81482325\n",
      "Validation score: -14.539903\n",
      "Iteration 1662, loss = 781.03891965\n",
      "Validation score: -14.524648\n",
      "Iteration 1663, loss = 780.26418971\n",
      "Validation score: -14.509433\n",
      "Iteration 1664, loss = 779.48976048\n",
      "Validation score: -14.494269\n",
      "Iteration 1665, loss = 778.71862020\n",
      "Validation score: -14.479110\n",
      "Iteration 1666, loss = 777.94562546\n",
      "Validation score: -14.463994\n",
      "Iteration 1667, loss = 777.17552442\n",
      "Validation score: -14.448900\n",
      "Iteration 1668, loss = 776.40746709\n",
      "Validation score: -14.433799\n",
      "Iteration 1669, loss = 775.63962970\n",
      "Validation score: -14.418700\n",
      "Iteration 1670, loss = 774.87161741\n",
      "Validation score: -14.403605\n",
      "Iteration 1671, loss = 774.10267600\n",
      "Validation score: -14.388514\n",
      "Iteration 1672, loss = 773.33427731\n",
      "Validation score: -14.373453\n",
      "Iteration 1673, loss = 772.56933170\n",
      "Validation score: -14.358414\n",
      "Iteration 1674, loss = 771.80534128\n",
      "Validation score: -14.343386\n",
      "Iteration 1675, loss = 771.03903049\n",
      "Validation score: -14.328382\n",
      "Iteration 1676, loss = 770.27560690\n",
      "Validation score: -14.313404\n",
      "Iteration 1677, loss = 769.51530314\n",
      "Validation score: -14.298418\n",
      "Iteration 1678, loss = 768.75075584\n",
      "Validation score: -14.283464\n",
      "Iteration 1679, loss = 767.98940273\n",
      "Validation score: -14.268541\n",
      "Iteration 1680, loss = 767.23072730\n",
      "Validation score: -14.253613\n",
      "Iteration 1681, loss = 766.47197364\n",
      "Validation score: -14.238714\n",
      "Iteration 1682, loss = 765.71499376\n",
      "Validation score: -14.223837\n",
      "Iteration 1683, loss = 764.95547647\n",
      "Validation score: -14.209001\n",
      "Iteration 1684, loss = 764.20030947\n",
      "Validation score: -14.194165\n",
      "Iteration 1685, loss = 763.44892993\n",
      "Validation score: -14.179302\n",
      "Iteration 1686, loss = 762.69147148\n",
      "Validation score: -14.164525\n",
      "Iteration 1687, loss = 761.93669219\n",
      "Validation score: -14.149761\n",
      "Iteration 1688, loss = 761.18737348\n",
      "Validation score: -14.134944\n",
      "Iteration 1689, loss = 760.43376638\n",
      "Validation score: -14.120161\n",
      "Iteration 1690, loss = 759.68222087\n",
      "Validation score: -14.105422\n",
      "Iteration 1691, loss = 758.93082859\n",
      "Validation score: -14.090711\n",
      "Iteration 1692, loss = 758.18275022\n",
      "Validation score: -14.075991\n",
      "Iteration 1693, loss = 757.43417189\n",
      "Validation score: -14.061281\n",
      "Iteration 1694, loss = 756.68429729\n",
      "Validation score: -14.046593\n",
      "Iteration 1695, loss = 755.93546269\n",
      "Validation score: -14.031909\n",
      "Iteration 1696, loss = 755.19068711\n",
      "Validation score: -14.017200\n",
      "Iteration 1697, loss = 754.44018895\n",
      "Validation score: -14.002540\n",
      "Iteration 1698, loss = 753.69569201\n",
      "Validation score: -13.987863\n",
      "Iteration 1699, loss = 752.94762518\n",
      "Validation score: -13.973236\n",
      "Iteration 1700, loss = 752.20256332\n",
      "Validation score: -13.958605\n",
      "Iteration 1701, loss = 751.45953150\n",
      "Validation score: -13.943953\n",
      "Iteration 1702, loss = 750.71388181\n",
      "Validation score: -13.929352\n",
      "Iteration 1703, loss = 749.97162882\n",
      "Validation score: -13.914737\n",
      "Iteration 1704, loss = 749.22866029\n",
      "Validation score: -13.900133\n",
      "Iteration 1705, loss = 748.48177402\n",
      "Validation score: -13.885578\n",
      "Iteration 1706, loss = 747.74455395\n",
      "Validation score: -13.870968\n",
      "Iteration 1707, loss = 746.99847095\n",
      "Validation score: -13.856450\n",
      "Iteration 1708, loss = 746.26055917\n",
      "Validation score: -13.841915\n",
      "Iteration 1709, loss = 745.52296136\n",
      "Validation score: -13.827408\n",
      "Iteration 1710, loss = 744.78612853\n",
      "Validation score: -13.812904\n",
      "Iteration 1711, loss = 744.04671762\n",
      "Validation score: -13.798434\n",
      "Iteration 1712, loss = 743.30967659\n",
      "Validation score: -13.783950\n",
      "Iteration 1713, loss = 742.57141112\n",
      "Validation score: -13.769493\n",
      "Iteration 1714, loss = 741.83450822\n",
      "Validation score: -13.755024\n",
      "Iteration 1715, loss = 741.10165124\n",
      "Validation score: -13.740538\n",
      "Iteration 1716, loss = 740.36191418\n",
      "Validation score: -13.726124\n",
      "Iteration 1717, loss = 739.63132589\n",
      "Validation score: -13.711671\n",
      "Iteration 1718, loss = 738.89728844\n",
      "Validation score: -13.697248\n",
      "Iteration 1719, loss = 738.16137203\n",
      "Validation score: -13.682881\n",
      "Iteration 1720, loss = 737.42768873\n",
      "Validation score: -13.668521\n",
      "Iteration 1721, loss = 736.69757858\n",
      "Validation score: -13.654144\n",
      "Iteration 1722, loss = 735.96501137\n",
      "Validation score: -13.639768\n",
      "Iteration 1723, loss = 735.23527170\n",
      "Validation score: -13.625388\n",
      "Iteration 1724, loss = 734.50461208\n",
      "Validation score: -13.611012\n",
      "Iteration 1725, loss = 733.76965766\n",
      "Validation score: -13.596680\n",
      "Iteration 1726, loss = 733.04227164\n",
      "Validation score: -13.582337\n",
      "Iteration 1727, loss = 732.31428587\n",
      "Validation score: -13.567994\n",
      "Iteration 1728, loss = 731.58198158\n",
      "Validation score: -13.553705\n",
      "Iteration 1729, loss = 730.85498657\n",
      "Validation score: -13.539402\n",
      "Iteration 1730, loss = 730.12646954\n",
      "Validation score: -13.525114\n",
      "Iteration 1731, loss = 729.40020107\n",
      "Validation score: -13.510811\n",
      "Iteration 1732, loss = 728.67387952\n",
      "Validation score: -13.496524\n",
      "Iteration 1733, loss = 727.94588856\n",
      "Validation score: -13.482293\n",
      "Iteration 1734, loss = 727.22124702\n",
      "Validation score: -13.468060\n",
      "Iteration 1735, loss = 726.49551272\n",
      "Validation score: -13.453855\n",
      "Iteration 1736, loss = 725.77496778\n",
      "Validation score: -13.439605\n",
      "Iteration 1737, loss = 725.05097383\n",
      "Validation score: -13.425354\n",
      "Iteration 1738, loss = 724.32592853\n",
      "Validation score: -13.411144\n",
      "Iteration 1739, loss = 723.60204646\n",
      "Validation score: -13.396952\n",
      "Iteration 1740, loss = 722.87993577\n",
      "Validation score: -13.382744\n",
      "Iteration 1741, loss = 722.15700088\n",
      "Validation score: -13.368557\n",
      "Iteration 1742, loss = 721.43346531\n",
      "Validation score: -13.354383\n",
      "Iteration 1743, loss = 720.71021167\n",
      "Validation score: -13.340229\n",
      "Iteration 1744, loss = 719.99351822\n",
      "Validation score: -13.326030\n",
      "Iteration 1745, loss = 719.27337660\n",
      "Validation score: -13.311860\n",
      "Iteration 1746, loss = 718.55013891\n",
      "Validation score: -13.297790\n",
      "Iteration 1747, loss = 717.83643464\n",
      "Validation score: -13.283672\n",
      "Iteration 1748, loss = 717.11665597\n",
      "Validation score: -13.269597\n",
      "Iteration 1749, loss = 716.40019600\n",
      "Validation score: -13.255506\n",
      "Iteration 1750, loss = 715.68175752\n",
      "Validation score: -13.241430\n",
      "Iteration 1751, loss = 714.96593303\n",
      "Validation score: -13.227343\n",
      "Iteration 1752, loss = 714.24774954\n",
      "Validation score: -13.213284\n",
      "Iteration 1753, loss = 713.53382643\n",
      "Validation score: -13.199206\n",
      "Iteration 1754, loss = 712.81717153\n",
      "Validation score: -13.185129\n",
      "Iteration 1755, loss = 712.10050852\n",
      "Validation score: -13.171090\n",
      "Iteration 1756, loss = 711.38637633\n",
      "Validation score: -13.157051\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1757, loss = 710.67252882\n",
      "Validation score: -13.142989\n",
      "Iteration 1758, loss = 709.95547856\n",
      "Validation score: -13.128947\n",
      "Iteration 1759, loss = 709.24160088\n",
      "Validation score: -13.114899\n",
      "Iteration 1760, loss = 708.52648929\n",
      "Validation score: -13.100852\n",
      "Iteration 1761, loss = 707.81366586\n",
      "Validation score: -13.086781\n",
      "Iteration 1762, loss = 707.09669162\n",
      "Validation score: -13.072760\n",
      "Iteration 1763, loss = 706.38398968\n",
      "Validation score: -13.058727\n",
      "Iteration 1764, loss = 705.66898214\n",
      "Validation score: -13.044692\n",
      "Iteration 1765, loss = 704.95404423\n",
      "Validation score: -13.030671\n",
      "Iteration 1766, loss = 704.23985353\n",
      "Validation score: -13.016615\n",
      "Iteration 1767, loss = 703.52422101\n",
      "Validation score: -13.002507\n",
      "Iteration 1768, loss = 702.80784311\n",
      "Validation score: -12.988371\n",
      "Iteration 1769, loss = 702.08719871\n",
      "Validation score: -12.974221\n",
      "Iteration 1770, loss = 701.36702081\n",
      "Validation score: -12.960046\n",
      "Iteration 1771, loss = 700.64466175\n",
      "Validation score: -12.945860\n",
      "Iteration 1772, loss = 699.92338354\n",
      "Validation score: -12.931588\n",
      "Iteration 1773, loss = 699.19333804\n",
      "Validation score: -12.917268\n",
      "Iteration 1774, loss = 698.46459639\n",
      "Validation score: -12.902841\n",
      "Iteration 1775, loss = 697.73308546\n",
      "Validation score: -12.888314\n",
      "Iteration 1776, loss = 696.98976130\n",
      "Validation score: -12.873736\n",
      "Iteration 1777, loss = 696.24612006\n",
      "Validation score: -12.859036\n",
      "Iteration 1778, loss = 695.49437105\n",
      "Validation score: -12.844172\n",
      "Iteration 1779, loss = 694.73835898\n",
      "Validation score: -12.829116\n",
      "Iteration 1780, loss = 693.96717301\n",
      "Validation score: -12.813913\n",
      "Iteration 1781, loss = 693.18751363\n",
      "Validation score: -12.798537\n",
      "Iteration 1782, loss = 692.40272729\n",
      "Validation score: -12.782862\n",
      "Iteration 1783, loss = 691.59919190\n",
      "Validation score: -12.766969\n",
      "Iteration 1784, loss = 690.78791232\n",
      "Validation score: -12.750767\n",
      "Iteration 1785, loss = 689.95717158\n",
      "Validation score: -12.734312\n",
      "Iteration 1786, loss = 689.11243563\n",
      "Validation score: -12.717622\n",
      "Iteration 1787, loss = 688.25719346\n",
      "Validation score: -12.700637\n",
      "Iteration 1788, loss = 687.38765349\n",
      "Validation score: -12.683361\n",
      "Iteration 1789, loss = 686.50139735\n",
      "Validation score: -12.665831\n",
      "Iteration 1790, loss = 685.60499736\n",
      "Validation score: -12.648050\n",
      "Iteration 1791, loss = 684.69471834\n",
      "Validation score: -12.630091\n",
      "Iteration 1792, loss = 683.77630828\n",
      "Validation score: -12.611982\n",
      "Iteration 1793, loss = 682.84685428\n",
      "Validation score: -12.593776\n",
      "Iteration 1794, loss = 681.91897628\n",
      "Validation score: -12.575421\n",
      "Iteration 1795, loss = 680.97962050\n",
      "Validation score: -12.557086\n",
      "Iteration 1796, loss = 680.04186201\n",
      "Validation score: -12.538754\n",
      "Iteration 1797, loss = 679.10895191\n",
      "Validation score: -12.520423\n",
      "Iteration 1798, loss = 678.17476925\n",
      "Validation score: -12.502220\n",
      "Iteration 1799, loss = 677.25063923\n",
      "Validation score: -12.484119\n",
      "Iteration 1800, loss = 676.32773461\n",
      "Validation score: -12.466205\n",
      "Iteration 1801, loss = 675.41824253\n",
      "Validation score: -12.448435\n",
      "Iteration 1802, loss = 674.51631599\n",
      "Validation score: -12.430829\n",
      "Iteration 1803, loss = 673.61927915\n",
      "Validation score: -12.413425\n",
      "Iteration 1804, loss = 672.73618656\n",
      "Validation score: -12.396153\n",
      "Iteration 1805, loss = 671.85750032\n",
      "Validation score: -12.379053\n",
      "Iteration 1806, loss = 670.98979512\n",
      "Validation score: -12.362125\n",
      "Iteration 1807, loss = 670.12753991\n",
      "Validation score: -12.345371\n",
      "Iteration 1808, loss = 669.28074906\n",
      "Validation score: -12.328720\n",
      "Iteration 1809, loss = 668.43595223\n",
      "Validation score: -12.312222\n",
      "Iteration 1810, loss = 667.59879263\n",
      "Validation score: -12.295889\n",
      "Iteration 1811, loss = 666.77130003\n",
      "Validation score: -12.279669\n",
      "Iteration 1812, loss = 665.94847867\n",
      "Validation score: -12.263558\n",
      "Iteration 1813, loss = 665.12953264\n",
      "Validation score: -12.247573\n",
      "Iteration 1814, loss = 664.31900158\n",
      "Validation score: -12.231716\n",
      "Iteration 1815, loss = 663.51094214\n",
      "Validation score: -12.215953\n",
      "Iteration 1816, loss = 662.71042393\n",
      "Validation score: -12.200199\n",
      "Iteration 1817, loss = 661.91135677\n",
      "Validation score: -12.184526\n",
      "Iteration 1818, loss = 661.11739597\n",
      "Validation score: -12.168903\n",
      "Iteration 1819, loss = 660.32375646\n",
      "Validation score: -12.153353\n",
      "Iteration 1820, loss = 659.53229697\n",
      "Validation score: -12.137882\n",
      "Iteration 1821, loss = 658.74700825\n",
      "Validation score: -12.122438\n",
      "Iteration 1822, loss = 657.96634216\n",
      "Validation score: -12.106996\n",
      "Iteration 1823, loss = 657.18059027\n",
      "Validation score: -12.091633\n",
      "Iteration 1824, loss = 656.39916822\n",
      "Validation score: -12.076280\n",
      "Iteration 1825, loss = 655.61790219\n",
      "Validation score: -12.060900\n",
      "Iteration 1826, loss = 654.83952867\n",
      "Validation score: -12.045489\n",
      "Iteration 1827, loss = 654.05317424\n",
      "Validation score: -12.030084\n",
      "Iteration 1828, loss = 653.27025222\n",
      "Validation score: -12.014594\n",
      "Iteration 1829, loss = 652.48211770\n",
      "Validation score: -11.999037\n",
      "Iteration 1830, loss = 651.68748071\n",
      "Validation score: -11.983401\n",
      "Iteration 1831, loss = 650.89442632\n",
      "Validation score: -11.967583\n",
      "Iteration 1832, loss = 650.08768286\n",
      "Validation score: -11.951682\n",
      "Iteration 1833, loss = 649.27552202\n",
      "Validation score: -11.935656\n",
      "Iteration 1834, loss = 648.45892309\n",
      "Validation score: -11.919391\n",
      "Iteration 1835, loss = 647.62777824\n",
      "Validation score: -11.902940\n",
      "Iteration 1836, loss = 646.78722285\n",
      "Validation score: -11.886226\n",
      "Iteration 1837, loss = 645.93402669\n",
      "Validation score: -11.869272\n",
      "Iteration 1838, loss = 645.06989445\n",
      "Validation score: -11.852016\n",
      "Iteration 1839, loss = 644.18691005\n",
      "Validation score: -11.834495\n",
      "Iteration 1840, loss = 643.28998800\n",
      "Validation score: -11.816679\n",
      "Iteration 1841, loss = 642.37855114\n",
      "Validation score: -11.798564\n",
      "Iteration 1842, loss = 641.44984745\n",
      "Validation score: -11.780205\n",
      "Iteration 1843, loss = 640.50780677\n",
      "Validation score: -11.761561\n",
      "Iteration 1844, loss = 639.56280463\n",
      "Validation score: -11.742541\n",
      "Iteration 1845, loss = 638.58506760\n",
      "Validation score: -11.723395\n",
      "Iteration 1846, loss = 637.60698155\n",
      "Validation score: -11.703980\n",
      "Iteration 1847, loss = 636.61601866\n",
      "Validation score: -11.684332\n",
      "Iteration 1848, loss = 635.60932539\n",
      "Validation score: -11.664488\n",
      "Iteration 1849, loss = 634.59685451\n",
      "Validation score: -11.644447\n",
      "Iteration 1850, loss = 633.57405402\n",
      "Validation score: -11.624194\n",
      "Iteration 1851, loss = 632.53637508\n",
      "Validation score: -11.603823\n",
      "Iteration 1852, loss = 631.49556753\n",
      "Validation score: -11.583216\n",
      "Iteration 1853, loss = 630.44466530\n",
      "Validation score: -11.562374\n",
      "Iteration 1854, loss = 629.37636621\n",
      "Validation score: -11.541354\n",
      "Iteration 1855, loss = 628.30438613\n",
      "Validation score: -11.520033\n",
      "Iteration 1856, loss = 627.21365037\n",
      "Validation score: -11.498477\n",
      "Iteration 1857, loss = 626.11205842\n",
      "Validation score: -11.476597\n",
      "Iteration 1858, loss = 624.99369657\n",
      "Validation score: -11.454385\n",
      "Iteration 1859, loss = 623.85614654\n",
      "Validation score: -11.431859\n",
      "Iteration 1860, loss = 622.70489187\n",
      "Validation score: -11.408982\n",
      "Iteration 1861, loss = 621.53071044\n",
      "Validation score: -11.385790\n",
      "Iteration 1862, loss = 620.34607334\n",
      "Validation score: -11.362277\n",
      "Iteration 1863, loss = 619.14287311\n",
      "Validation score: -11.338534\n",
      "Iteration 1864, loss = 617.92819262\n",
      "Validation score: -11.314552\n",
      "Iteration 1865, loss = 616.69799406\n",
      "Validation score: -11.290416\n",
      "Iteration 1866, loss = 615.46850956\n",
      "Validation score: -11.266156\n",
      "Iteration 1867, loss = 614.23187873\n",
      "Validation score: -11.241914\n",
      "Iteration 1868, loss = 613.00025952\n",
      "Validation score: -11.217697\n",
      "Iteration 1869, loss = 611.76576066\n",
      "Validation score: -11.193606\n",
      "Iteration 1870, loss = 610.53817063\n",
      "Validation score: -11.169659\n",
      "Iteration 1871, loss = 609.32315820\n",
      "Validation score: -11.145822\n",
      "Iteration 1872, loss = 608.10807113\n",
      "Validation score: -11.122259\n",
      "Iteration 1873, loss = 606.91169754\n",
      "Validation score: -11.098894\n",
      "Iteration 1874, loss = 605.72570680\n",
      "Validation score: -11.075776\n",
      "Iteration 1875, loss = 604.55360001\n",
      "Validation score: -11.052921\n",
      "Iteration 1876, loss = 603.39368129\n",
      "Validation score: -11.030367\n",
      "Iteration 1877, loss = 602.24935209\n",
      "Validation score: -11.008111\n",
      "Iteration 1878, loss = 601.12037774\n",
      "Validation score: -10.986055\n",
      "Iteration 1879, loss = 600.00213540\n",
      "Validation score: -10.964214\n",
      "Iteration 1880, loss = 598.89422491\n",
      "Validation score: -10.942525\n",
      "Iteration 1881, loss = 597.79621170\n",
      "Validation score: -10.920946\n",
      "Iteration 1882, loss = 596.69808397\n",
      "Validation score: -10.899550\n",
      "Iteration 1883, loss = 595.61136153\n",
      "Validation score: -10.878210\n",
      "Iteration 1884, loss = 594.53132406\n",
      "Validation score: -10.856896\n",
      "Iteration 1885, loss = 593.44654307\n",
      "Validation score: -10.835638\n",
      "Iteration 1886, loss = 592.36560654\n",
      "Validation score: -10.814355\n",
      "Iteration 1887, loss = 591.28578568\n",
      "Validation score: -10.793037\n",
      "Iteration 1888, loss = 590.20133866\n",
      "Validation score: -10.771695\n",
      "Iteration 1889, loss = 589.11695948\n",
      "Validation score: -10.750256\n",
      "Iteration 1890, loss = 588.02549617\n",
      "Validation score: -10.728794\n",
      "Iteration 1891, loss = 586.93132698\n",
      "Validation score: -10.707264\n",
      "Iteration 1892, loss = 585.83939133\n",
      "Validation score: -10.685625\n",
      "Iteration 1893, loss = 584.73873989\n",
      "Validation score: -10.663943\n",
      "Iteration 1894, loss = 583.63586093\n",
      "Validation score: -10.642239\n",
      "Iteration 1895, loss = 582.52934245\n",
      "Validation score: -10.620518\n",
      "Iteration 1896, loss = 581.42072823\n",
      "Validation score: -10.598835\n",
      "Iteration 1897, loss = 580.32465607\n",
      "Validation score: -10.577071\n",
      "Iteration 1898, loss = 579.21818450\n",
      "Validation score: -10.555385\n",
      "Iteration 1899, loss = 578.11483385\n",
      "Validation score: -10.533832\n",
      "Iteration 1900, loss = 577.02062692\n",
      "Validation score: -10.512363\n",
      "Iteration 1901, loss = 575.93434904\n",
      "Validation score: -10.490924\n",
      "Iteration 1902, loss = 574.84390069\n",
      "Validation score: -10.469695\n",
      "Iteration 1903, loss = 573.76790187\n",
      "Validation score: -10.448484\n",
      "Iteration 1904, loss = 572.69031291\n",
      "Validation score: -10.427400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1905, loss = 571.61776924\n",
      "Validation score: -10.406407\n",
      "Iteration 1906, loss = 570.55349137\n",
      "Validation score: -10.385370\n",
      "Iteration 1907, loss = 569.49147851\n",
      "Validation score: -10.364329\n",
      "Iteration 1908, loss = 568.41942963\n",
      "Validation score: -10.343439\n",
      "Iteration 1909, loss = 567.35578699\n",
      "Validation score: -10.322500\n",
      "Iteration 1910, loss = 566.29135942\n",
      "Validation score: -10.301501\n",
      "Iteration 1911, loss = 565.22118792\n",
      "Validation score: -10.280427\n",
      "Iteration 1912, loss = 564.15232839\n",
      "Validation score: -10.259275\n",
      "Iteration 1913, loss = 563.07591525\n",
      "Validation score: -10.238076\n",
      "Iteration 1914, loss = 561.99862126\n",
      "Validation score: -10.216795\n",
      "Iteration 1915, loss = 560.91855322\n",
      "Validation score: -10.195461\n",
      "Iteration 1916, loss = 559.83388929\n",
      "Validation score: -10.174138\n",
      "Iteration 1917, loss = 558.74548046\n",
      "Validation score: -10.152850\n",
      "Iteration 1918, loss = 557.66152503\n",
      "Validation score: -10.131569\n",
      "Iteration 1919, loss = 556.58082592\n",
      "Validation score: -10.110368\n",
      "Iteration 1920, loss = 555.50473532\n",
      "Validation score: -10.089280\n",
      "Iteration 1921, loss = 554.43564598\n",
      "Validation score: -10.068319\n",
      "Iteration 1922, loss = 553.37115996\n",
      "Validation score: -10.047533\n",
      "Iteration 1923, loss = 552.32580272\n",
      "Validation score: -10.026856\n",
      "Iteration 1924, loss = 551.27223461\n",
      "Validation score: -10.006545\n",
      "Iteration 1925, loss = 550.24814662\n",
      "Validation score: -9.986384\n",
      "Iteration 1926, loss = 549.22243460\n",
      "Validation score: -9.966552\n",
      "Iteration 1927, loss = 548.21876399\n",
      "Validation score: -9.946882\n",
      "Iteration 1928, loss = 547.22125387\n",
      "Validation score: -9.927442\n",
      "Iteration 1929, loss = 546.23662356\n",
      "Validation score: -9.908230\n",
      "Iteration 1930, loss = 545.26664850\n",
      "Validation score: -9.889187\n",
      "Iteration 1931, loss = 544.30309554\n",
      "Validation score: -9.870396\n",
      "Iteration 1932, loss = 543.35271689\n",
      "Validation score: -9.851810\n",
      "Iteration 1933, loss = 542.40863232\n",
      "Validation score: -9.833427\n",
      "Iteration 1934, loss = 541.47822773\n",
      "Validation score: -9.815200\n",
      "Iteration 1935, loss = 540.55900919\n",
      "Validation score: -9.797143\n",
      "Iteration 1936, loss = 539.64204110\n",
      "Validation score: -9.779343\n",
      "Iteration 1937, loss = 538.74412514\n",
      "Validation score: -9.761665\n",
      "Iteration 1938, loss = 537.85046465\n",
      "Validation score: -9.744124\n",
      "Iteration 1939, loss = 536.95982714\n",
      "Validation score: -9.726792\n",
      "Iteration 1940, loss = 536.08339480\n",
      "Validation score: -9.709579\n",
      "Iteration 1941, loss = 535.21107951\n",
      "Validation score: -9.692502\n",
      "Iteration 1942, loss = 534.34669408\n",
      "Validation score: -9.675518\n",
      "Iteration 1943, loss = 533.48567046\n",
      "Validation score: -9.658681\n",
      "Iteration 1944, loss = 532.63399356\n",
      "Validation score: -9.641929\n",
      "Iteration 1945, loss = 531.78830934\n",
      "Validation score: -9.625254\n",
      "Iteration 1946, loss = 530.94587700\n",
      "Validation score: -9.608711\n",
      "Iteration 1947, loss = 530.10788686\n",
      "Validation score: -9.592312\n",
      "Iteration 1948, loss = 529.27724308\n",
      "Validation score: -9.576001\n",
      "Iteration 1949, loss = 528.44703574\n",
      "Validation score: -9.559788\n",
      "Iteration 1950, loss = 527.62987916\n",
      "Validation score: -9.543589\n",
      "Iteration 1951, loss = 526.80862868\n",
      "Validation score: -9.527497\n",
      "Iteration 1952, loss = 525.99291926\n",
      "Validation score: -9.511501\n",
      "Iteration 1953, loss = 525.18347421\n",
      "Validation score: -9.495570\n",
      "Iteration 1954, loss = 524.37905954\n",
      "Validation score: -9.479681\n",
      "Iteration 1955, loss = 523.57565094\n",
      "Validation score: -9.463878\n",
      "Iteration 1956, loss = 522.77441621\n",
      "Validation score: -9.448192\n",
      "Iteration 1957, loss = 521.97995411\n",
      "Validation score: -9.432559\n",
      "Iteration 1958, loss = 521.18608915\n",
      "Validation score: -9.417028\n",
      "Iteration 1959, loss = 520.39921509\n",
      "Validation score: -9.401546\n",
      "Iteration 1960, loss = 519.61582311\n",
      "Validation score: -9.386101\n",
      "Iteration 1961, loss = 518.83519382\n",
      "Validation score: -9.370680\n",
      "Iteration 1962, loss = 518.05168615\n",
      "Validation score: -9.355368\n",
      "Iteration 1963, loss = 517.28009258\n",
      "Validation score: -9.340054\n",
      "Iteration 1964, loss = 516.50448430\n",
      "Validation score: -9.324842\n",
      "Iteration 1965, loss = 515.73516628\n",
      "Validation score: -9.309693\n",
      "Iteration 1966, loss = 514.96759270\n",
      "Validation score: -9.294602\n",
      "Iteration 1967, loss = 514.20058877\n",
      "Validation score: -9.279577\n",
      "Iteration 1968, loss = 513.43756971\n",
      "Validation score: -9.264591\n",
      "Iteration 1969, loss = 512.67755311\n",
      "Validation score: -9.249617\n",
      "Iteration 1970, loss = 511.92055994\n",
      "Validation score: -9.234680\n",
      "Iteration 1971, loss = 511.16459205\n",
      "Validation score: -9.219782\n",
      "Iteration 1972, loss = 510.40926743\n",
      "Validation score: -9.204935\n",
      "Iteration 1973, loss = 509.65908885\n",
      "Validation score: -9.190114\n",
      "Iteration 1974, loss = 508.90674448\n",
      "Validation score: -9.175331\n",
      "Iteration 1975, loss = 508.15981661\n",
      "Validation score: -9.160563\n",
      "Iteration 1976, loss = 507.41136941\n",
      "Validation score: -9.145892\n",
      "Iteration 1977, loss = 506.66562363\n",
      "Validation score: -9.131275\n",
      "Iteration 1978, loss = 505.92554976\n",
      "Validation score: -9.116676\n",
      "Iteration 1979, loss = 505.18552569\n",
      "Validation score: -9.102106\n",
      "Iteration 1980, loss = 504.44736066\n",
      "Validation score: -9.087558\n",
      "Iteration 1981, loss = 503.71080766\n",
      "Validation score: -9.073058\n",
      "Iteration 1982, loss = 502.97765005\n",
      "Validation score: -9.058603\n",
      "Iteration 1983, loss = 502.24440357\n",
      "Validation score: -9.044181\n",
      "Iteration 1984, loss = 501.51377010\n",
      "Validation score: -9.029770\n",
      "Iteration 1985, loss = 500.78368836\n",
      "Validation score: -9.015389\n",
      "Iteration 1986, loss = 500.05450244\n",
      "Validation score: -9.001044\n",
      "Iteration 1987, loss = 499.32777151\n",
      "Validation score: -8.986714\n",
      "Iteration 1988, loss = 498.60234348\n",
      "Validation score: -8.972426\n",
      "Iteration 1989, loss = 497.87617800\n",
      "Validation score: -8.958222\n",
      "Iteration 1990, loss = 497.15899954\n",
      "Validation score: -8.943995\n",
      "Iteration 1991, loss = 496.43953062\n",
      "Validation score: -8.929846\n",
      "Iteration 1992, loss = 495.72182665\n",
      "Validation score: -8.915742\n",
      "Iteration 1993, loss = 495.00867190\n",
      "Validation score: -8.901629\n",
      "Iteration 1994, loss = 494.29142064\n",
      "Validation score: -8.887611\n",
      "Iteration 1995, loss = 493.58212616\n",
      "Validation score: -8.873587\n",
      "Iteration 1996, loss = 492.87099576\n",
      "Validation score: -8.859602\n",
      "Iteration 1997, loss = 492.16058423\n",
      "Validation score: -8.845646\n",
      "Iteration 1998, loss = 491.45873111\n",
      "Validation score: -8.831653\n",
      "Iteration 1999, loss = 490.74778412\n",
      "Validation score: -8.817764\n",
      "Iteration 2000, loss = 490.04021917\n",
      "Validation score: -8.803912\n",
      "Iteration 2001, loss = 489.33776622\n",
      "Validation score: -8.790058\n",
      "Iteration 2002, loss = 488.63753459\n",
      "Validation score: -8.776205\n",
      "Iteration 2003, loss = 487.93523032\n",
      "Validation score: -8.762380\n",
      "Iteration 2004, loss = 487.23319834\n",
      "Validation score: -8.748619\n",
      "Iteration 2005, loss = 486.53744664\n",
      "Validation score: -8.734852\n",
      "Iteration 2006, loss = 485.83759005\n",
      "Validation score: -8.721121\n",
      "Iteration 2007, loss = 485.14484317\n",
      "Validation score: -8.707353\n",
      "Iteration 2008, loss = 484.44419625\n",
      "Validation score: -8.693701\n",
      "Iteration 2009, loss = 483.75126889\n",
      "Validation score: -8.680055\n",
      "Iteration 2010, loss = 483.05893818\n",
      "Validation score: -8.666396\n",
      "Iteration 2011, loss = 482.36813312\n",
      "Validation score: -8.652731\n",
      "Iteration 2012, loss = 481.67454493\n",
      "Validation score: -8.639133\n",
      "Iteration 2013, loss = 480.98533768\n",
      "Validation score: -8.625523\n",
      "Iteration 2014, loss = 480.29614406\n",
      "Validation score: -8.611926\n",
      "Iteration 2015, loss = 479.60865684\n",
      "Validation score: -8.598363\n",
      "Iteration 2016, loss = 478.92122740\n",
      "Validation score: -8.584850\n",
      "Iteration 2017, loss = 478.23456707\n",
      "Validation score: -8.571407\n",
      "Iteration 2018, loss = 477.55574356\n",
      "Validation score: -8.557919\n",
      "Iteration 2019, loss = 476.86838879\n",
      "Validation score: -8.544531\n",
      "Iteration 2020, loss = 476.19062297\n",
      "Validation score: -8.531109\n",
      "Iteration 2021, loss = 475.51236318\n",
      "Validation score: -8.517673\n",
      "Iteration 2022, loss = 474.83348516\n",
      "Validation score: -8.504261\n",
      "Iteration 2023, loss = 474.15060114\n",
      "Validation score: -8.490916\n",
      "Iteration 2024, loss = 473.47612636\n",
      "Validation score: -8.477578\n",
      "Iteration 2025, loss = 472.80137925\n",
      "Validation score: -8.464286\n",
      "Iteration 2026, loss = 472.12324404\n",
      "Validation score: -8.451035\n",
      "Iteration 2027, loss = 471.45411885\n",
      "Validation score: -8.437730\n",
      "Iteration 2028, loss = 470.77932582\n",
      "Validation score: -8.424434\n",
      "Iteration 2029, loss = 470.10513675\n",
      "Validation score: -8.411173\n",
      "Iteration 2030, loss = 469.43261775\n",
      "Validation score: -8.397957\n",
      "Iteration 2031, loss = 468.76496320\n",
      "Validation score: -8.384721\n",
      "Iteration 2032, loss = 468.09482092\n",
      "Validation score: -8.371538\n",
      "Iteration 2033, loss = 467.42755582\n",
      "Validation score: -8.358369\n",
      "Iteration 2034, loss = 466.75904372\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation score: -8.345246\n",
      "Iteration 2035, loss = 466.09332860\n",
      "Validation score: -8.332152\n",
      "Iteration 2036, loss = 465.43231181\n",
      "Validation score: -8.319056\n",
      "Iteration 2037, loss = 464.76899757\n",
      "Validation score: -8.306010\n",
      "Iteration 2038, loss = 464.10517108\n",
      "Validation score: -8.293025\n",
      "Iteration 2039, loss = 463.44664328\n",
      "Validation score: -8.279990\n",
      "Iteration 2040, loss = 462.78708211\n",
      "Validation score: -8.266979\n",
      "Iteration 2041, loss = 462.12745204\n",
      "Validation score: -8.253982\n",
      "Iteration 2042, loss = 461.46790981\n",
      "Validation score: -8.240997\n",
      "Iteration 2043, loss = 460.80956874\n",
      "Validation score: -8.228006\n",
      "Iteration 2044, loss = 460.15361142\n",
      "Validation score: -8.215030\n",
      "Iteration 2045, loss = 459.49399938\n",
      "Validation score: -8.202137\n",
      "Iteration 2046, loss = 458.84107806\n",
      "Validation score: -8.189223\n",
      "Iteration 2047, loss = 458.18708125\n",
      "Validation score: -8.176315\n",
      "Iteration 2048, loss = 457.53105265\n",
      "Validation score: -8.163480\n",
      "Iteration 2049, loss = 456.88071935\n",
      "Validation score: -8.150616\n",
      "Iteration 2050, loss = 456.22966008\n",
      "Validation score: -8.137752\n",
      "Iteration 2051, loss = 455.57848626\n",
      "Validation score: -8.124917\n",
      "Iteration 2052, loss = 454.92908114\n",
      "Validation score: -8.112126\n",
      "Iteration 2053, loss = 454.28165512\n",
      "Validation score: -8.099395\n",
      "Iteration 2054, loss = 453.63525975\n",
      "Validation score: -8.086651\n",
      "Iteration 2055, loss = 452.98937786\n",
      "Validation score: -8.073896\n",
      "Iteration 2056, loss = 452.34214954\n",
      "Validation score: -8.061170\n",
      "Iteration 2057, loss = 451.69724840\n",
      "Validation score: -8.048456\n",
      "Iteration 2058, loss = 451.05441409\n",
      "Validation score: -8.035723\n",
      "Iteration 2059, loss = 450.40652954\n",
      "Validation score: -8.023071\n",
      "Iteration 2060, loss = 449.76599335\n",
      "Validation score: -8.010407\n",
      "Iteration 2061, loss = 449.12670109\n",
      "Validation score: -7.997750\n",
      "Iteration 2062, loss = 448.48424895\n",
      "Validation score: -7.985143\n",
      "Iteration 2063, loss = 447.84506803\n",
      "Validation score: -7.972561\n",
      "Iteration 2064, loss = 447.20888128\n",
      "Validation score: -7.959977\n",
      "Iteration 2065, loss = 446.56849368\n",
      "Validation score: -7.947440\n",
      "Iteration 2066, loss = 445.93565022\n",
      "Validation score: -7.934867\n",
      "Iteration 2067, loss = 445.29722311\n",
      "Validation score: -7.922371\n",
      "Iteration 2068, loss = 444.66645720\n",
      "Validation score: -7.909829\n",
      "Iteration 2069, loss = 444.03138786\n",
      "Validation score: -7.897327\n",
      "Iteration 2070, loss = 443.39620400\n",
      "Validation score: -7.884859\n",
      "Iteration 2071, loss = 442.76115727\n",
      "Validation score: -7.872414\n",
      "Iteration 2072, loss = 442.13195305\n",
      "Validation score: -7.859923\n",
      "Iteration 2073, loss = 441.49784484\n",
      "Validation score: -7.847463\n",
      "Iteration 2074, loss = 440.86694171\n",
      "Validation score: -7.835024\n",
      "Iteration 2075, loss = 440.23717401\n",
      "Validation score: -7.822608\n",
      "Iteration 2076, loss = 439.60799374\n",
      "Validation score: -7.810196\n",
      "Iteration 2077, loss = 438.97670390\n",
      "Validation score: -7.797782\n",
      "Iteration 2078, loss = 438.35130665\n",
      "Validation score: -7.785321\n",
      "Iteration 2079, loss = 437.71914792\n",
      "Validation score: -7.772945\n",
      "Iteration 2080, loss = 437.09084318\n",
      "Validation score: -7.760580\n",
      "Iteration 2081, loss = 436.46641140\n",
      "Validation score: -7.748206\n",
      "Iteration 2082, loss = 435.83874398\n",
      "Validation score: -7.735857\n",
      "Iteration 2083, loss = 435.21382272\n",
      "Validation score: -7.723525\n",
      "Iteration 2084, loss = 434.58749681\n",
      "Validation score: -7.711230\n",
      "Iteration 2085, loss = 433.96656160\n",
      "Validation score: -7.698921\n",
      "Iteration 2086, loss = 433.34181289\n",
      "Validation score: -7.686661\n",
      "Iteration 2087, loss = 432.72160756\n",
      "Validation score: -7.674406\n",
      "Iteration 2088, loss = 432.10130149\n",
      "Validation score: -7.662189\n",
      "Iteration 2089, loss = 431.48074915\n",
      "Validation score: -7.649983\n",
      "Iteration 2090, loss = 430.86257016\n",
      "Validation score: -7.637777\n",
      "Iteration 2091, loss = 430.24471309\n",
      "Validation score: -7.625585\n",
      "Iteration 2092, loss = 429.62661427\n",
      "Validation score: -7.613439\n",
      "Iteration 2093, loss = 429.01102912\n",
      "Validation score: -7.601289\n",
      "Iteration 2094, loss = 428.39557001\n",
      "Validation score: -7.589157\n",
      "Iteration 2095, loss = 427.78301771\n",
      "Validation score: -7.577032\n",
      "Iteration 2096, loss = 427.16566977\n",
      "Validation score: -7.564939\n",
      "Iteration 2097, loss = 426.55211591\n",
      "Validation score: -7.552838\n",
      "Iteration 2098, loss = 425.94015441\n",
      "Validation score: -7.540702\n",
      "Iteration 2099, loss = 425.32698963\n",
      "Validation score: -7.528595\n",
      "Iteration 2100, loss = 424.71447681\n",
      "Validation score: -7.516499\n",
      "Iteration 2101, loss = 424.10125662\n",
      "Validation score: -7.504444\n",
      "Iteration 2102, loss = 423.48905945\n",
      "Validation score: -7.492414\n",
      "Iteration 2103, loss = 422.87987797\n",
      "Validation score: -7.480394\n",
      "Iteration 2104, loss = 422.27001393\n",
      "Validation score: -7.468399\n",
      "Iteration 2105, loss = 421.66045531\n",
      "Validation score: -7.456415\n",
      "Iteration 2106, loss = 421.05614517\n",
      "Validation score: -7.444390\n",
      "Iteration 2107, loss = 420.44772333\n",
      "Validation score: -7.432405\n",
      "Iteration 2108, loss = 419.84063251\n",
      "Validation score: -7.420450\n",
      "Iteration 2109, loss = 419.23458081\n",
      "Validation score: -7.408542\n",
      "Iteration 2110, loss = 418.63170642\n",
      "Validation score: -7.396644\n",
      "Iteration 2111, loss = 418.02956241\n",
      "Validation score: -7.384746\n",
      "Iteration 2112, loss = 417.42750085\n",
      "Validation score: -7.372899\n",
      "Iteration 2113, loss = 416.82646904\n",
      "Validation score: -7.361067\n",
      "Iteration 2114, loss = 416.22387837\n",
      "Validation score: -7.349239\n",
      "Iteration 2115, loss = 415.62521900\n",
      "Validation score: -7.337363\n",
      "Iteration 2116, loss = 415.02543362\n",
      "Validation score: -7.325492\n",
      "Iteration 2117, loss = 414.42237698\n",
      "Validation score: -7.313672\n",
      "Iteration 2118, loss = 413.82628760\n",
      "Validation score: -7.301846\n",
      "Iteration 2119, loss = 413.22532647\n",
      "Validation score: -7.290097\n",
      "Iteration 2120, loss = 412.63152245\n",
      "Validation score: -7.278330\n",
      "Iteration 2121, loss = 412.03538835\n",
      "Validation score: -7.266585\n",
      "Iteration 2122, loss = 411.44171151\n",
      "Validation score: -7.254825\n",
      "Iteration 2123, loss = 410.84371276\n",
      "Validation score: -7.243113\n",
      "Iteration 2124, loss = 410.25018537\n",
      "Validation score: -7.231376\n",
      "Iteration 2125, loss = 409.65592830\n",
      "Validation score: -7.219641\n",
      "Iteration 2126, loss = 409.06036848\n",
      "Validation score: -7.207939\n",
      "Iteration 2127, loss = 408.46839230\n",
      "Validation score: -7.196227\n",
      "Iteration 2128, loss = 407.87538038\n",
      "Validation score: -7.184512\n",
      "Iteration 2129, loss = 407.28029191\n",
      "Validation score: -7.172844\n",
      "Iteration 2130, loss = 406.69155568\n",
      "Validation score: -7.161135\n",
      "Iteration 2131, loss = 406.09784411\n",
      "Validation score: -7.149487\n",
      "Iteration 2132, loss = 405.51028675\n",
      "Validation score: -7.137868\n",
      "Iteration 2133, loss = 404.92029929\n",
      "Validation score: -7.126261\n",
      "Iteration 2134, loss = 404.33496339\n",
      "Validation score: -7.114625\n",
      "Iteration 2135, loss = 403.74368828\n",
      "Validation score: -7.103030\n",
      "Iteration 2136, loss = 403.15757569\n",
      "Validation score: -7.091444\n",
      "Iteration 2137, loss = 402.56846392\n",
      "Validation score: -7.079882\n",
      "Iteration 2138, loss = 401.98516020\n",
      "Validation score: -7.068322\n",
      "Iteration 2139, loss = 401.40099133\n",
      "Validation score: -7.056785\n",
      "Iteration 2140, loss = 400.81655190\n",
      "Validation score: -7.045272\n",
      "Iteration 2141, loss = 400.23388518\n",
      "Validation score: -7.033791\n",
      "Iteration 2142, loss = 399.65024667\n",
      "Validation score: -7.022341\n",
      "Iteration 2143, loss = 399.07295183\n",
      "Validation score: -7.010858\n",
      "Iteration 2144, loss = 398.48818631\n",
      "Validation score: -6.999403\n",
      "Iteration 2145, loss = 397.90978824\n",
      "Validation score: -6.987907\n",
      "Iteration 2146, loss = 397.32563111\n",
      "Validation score: -6.976468\n",
      "Iteration 2147, loss = 396.74928469\n",
      "Validation score: -6.965005\n",
      "Iteration 2148, loss = 396.16779543\n",
      "Validation score: -6.953617\n",
      "Iteration 2149, loss = 395.58986687\n",
      "Validation score: -6.942234\n",
      "Iteration 2150, loss = 395.01442537\n",
      "Validation score: -6.930823\n",
      "Iteration 2151, loss = 394.43681301\n",
      "Validation score: -6.919446\n",
      "Iteration 2152, loss = 393.85936302\n",
      "Validation score: -6.908103\n",
      "Iteration 2153, loss = 393.28618231\n",
      "Validation score: -6.896727\n",
      "Iteration 2154, loss = 392.71185261\n",
      "Validation score: -6.885344\n",
      "Iteration 2155, loss = 392.13423949\n",
      "Validation score: -6.874021\n",
      "Iteration 2156, loss = 391.55979386\n",
      "Validation score: -6.862727\n",
      "Iteration 2157, loss = 390.98979453\n",
      "Validation score: -6.851406\n",
      "Iteration 2158, loss = 390.41928058\n",
      "Validation score: -6.840081\n",
      "Iteration 2159, loss = 389.84076122\n",
      "Validation score: -6.828841\n",
      "Iteration 2160, loss = 389.27267070\n",
      "Validation score: -6.817549\n",
      "Iteration 2161, loss = 388.70022291\n",
      "Validation score: -6.806269\n",
      "Iteration 2162, loss = 388.13210481\n",
      "Validation score: -6.794974\n",
      "Iteration 2163, loss = 387.55971997\n",
      "Validation score: -6.783725\n",
      "Iteration 2164, loss = 386.99080858\n",
      "Validation score: -6.772504\n",
      "Iteration 2165, loss = 386.42225126\n",
      "Validation score: -6.761320\n",
      "Iteration 2166, loss = 385.85647238\n",
      "Validation score: -6.750122\n",
      "Iteration 2167, loss = 385.28959776\n",
      "Validation score: -6.738945\n",
      "Iteration 2168, loss = 384.72352926\n",
      "Validation score: -6.727799\n",
      "Iteration 2169, loss = 384.15952779\n",
      "Validation score: -6.716657\n",
      "Iteration 2170, loss = 383.59497431\n",
      "Validation score: -6.705522\n",
      "Iteration 2171, loss = 383.03092738\n",
      "Validation score: -6.694372\n",
      "Iteration 2172, loss = 382.46603091\n",
      "Validation score: -6.683234\n",
      "Iteration 2173, loss = 381.90431084\n",
      "Validation score: -6.672097\n",
      "Iteration 2174, loss = 381.33778300\n",
      "Validation score: -6.661019\n",
      "Iteration 2175, loss = 380.77843239\n",
      "Validation score: -6.649933\n",
      "Iteration 2176, loss = 380.21535271\n",
      "Validation score: -6.638886\n",
      "Iteration 2177, loss = 379.65642855\n",
      "Validation score: -6.627813\n",
      "Iteration 2178, loss = 379.09876361\n",
      "Validation score: -6.616734\n",
      "Iteration 2179, loss = 378.53610426\n",
      "Validation score: -6.605700\n",
      "Iteration 2180, loss = 377.97866051\n",
      "Validation score: -6.594674\n",
      "Iteration 2181, loss = 377.41944757\n",
      "Validation score: -6.583686\n",
      "Iteration 2182, loss = 376.86420082\n",
      "Validation score: -6.572662\n",
      "Iteration 2183, loss = 376.30633860\n",
      "Validation score: -6.561676\n",
      "Iteration 2184, loss = 375.74856675\n",
      "Validation score: -6.550720\n",
      "Iteration 2185, loss = 375.19538172\n",
      "Validation score: -6.539725\n",
      "Iteration 2186, loss = 374.63790966\n",
      "Validation score: -6.528784\n",
      "Iteration 2187, loss = 374.08632068\n",
      "Validation score: -6.517847\n",
      "Iteration 2188, loss = 373.52972422\n",
      "Validation score: -6.506979\n",
      "Iteration 2189, loss = 372.98048672\n",
      "Validation score: -6.496057\n",
      "Iteration 2190, loss = 372.42701708\n",
      "Validation score: -6.485140\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 2191, loss = 371.87614119\n",
      "Validation score: -6.474195\n",
      "Iteration 2192, loss = 371.32293014\n",
      "Validation score: -6.463288\n",
      "Iteration 2193, loss = 370.76948141\n",
      "Validation score: -6.452410\n",
      "Iteration 2194, loss = 370.21945568\n",
      "Validation score: -6.441538\n",
      "Iteration 2195, loss = 369.66786885\n",
      "Validation score: -6.430690\n",
      "Iteration 2196, loss = 369.11983393\n",
      "Validation score: -6.419834\n",
      "Iteration 2197, loss = 368.56954486\n",
      "Validation score: -6.408990\n",
      "Iteration 2198, loss = 368.02033699\n",
      "Validation score: -6.398149\n",
      "Iteration 2199, loss = 367.47421542\n",
      "Validation score: -6.387288\n",
      "Iteration 2200, loss = 366.92297710\n",
      "Validation score: -6.376496\n",
      "Iteration 2201, loss = 366.37905474\n",
      "Validation score: -6.365699\n",
      "Iteration 2202, loss = 365.83467055\n",
      "Validation score: -6.354935\n",
      "Iteration 2203, loss = 365.28579738\n",
      "Validation score: -6.344187\n",
      "Iteration 2204, loss = 364.74242329\n",
      "Validation score: -6.333426\n",
      "Iteration 2205, loss = 364.19719577\n",
      "Validation score: -6.322671\n",
      "Iteration 2206, loss = 363.65353005\n",
      "Validation score: -6.311910\n",
      "Iteration 2207, loss = 363.10828289\n",
      "Validation score: -6.301151\n",
      "Iteration 2208, loss = 362.56303739\n",
      "Validation score: -6.290406\n",
      "Iteration 2209, loss = 362.02427519\n",
      "Validation score: -6.279619\n",
      "Iteration 2210, loss = 361.47552979\n",
      "Validation score: -6.268940\n",
      "Iteration 2211, loss = 360.93452379\n",
      "Validation score: -6.258217\n",
      "Iteration 2212, loss = 360.39364348\n",
      "Validation score: -6.247495\n",
      "Iteration 2213, loss = 359.85255534\n",
      "Validation score: -6.236820\n",
      "Iteration 2214, loss = 359.30864774\n",
      "Validation score: -6.226183\n",
      "Iteration 2215, loss = 358.77201463\n",
      "Validation score: -6.215510\n",
      "Iteration 2216, loss = 358.23358455\n",
      "Validation score: -6.204835\n",
      "Iteration 2217, loss = 357.69323011\n",
      "Validation score: -6.194213\n",
      "Iteration 2218, loss = 357.15716279\n",
      "Validation score: -6.183616\n",
      "Iteration 2219, loss = 356.62081711\n",
      "Validation score: -6.173054\n",
      "Iteration 2220, loss = 356.08536008\n",
      "Validation score: -6.162530\n",
      "Iteration 2221, loss = 355.55373176\n",
      "Validation score: -6.151988\n",
      "Iteration 2222, loss = 355.02064509\n",
      "Validation score: -6.141450\n",
      "Iteration 2223, loss = 354.48898416\n",
      "Validation score: -6.130878\n",
      "Iteration 2224, loss = 353.95217776\n",
      "Validation score: -6.120396\n",
      "Iteration 2225, loss = 353.42067283\n",
      "Validation score: -6.109867\n",
      "Iteration 2226, loss = 352.88866332\n",
      "Validation score: -6.099323\n",
      "Iteration 2227, loss = 352.35529699\n",
      "Validation score: -6.088808\n",
      "Iteration 2228, loss = 351.82346030\n",
      "Validation score: -6.078297\n",
      "Iteration 2229, loss = 351.29507608\n",
      "Validation score: -6.067774\n",
      "Iteration 2230, loss = 350.76198650\n",
      "Validation score: -6.057323\n",
      "Iteration 2231, loss = 350.23192354\n",
      "Validation score: -6.046885\n",
      "Iteration 2232, loss = 349.70342376\n",
      "Validation score: -6.036434\n",
      "Iteration 2233, loss = 349.17458458\n",
      "Validation score: -6.025979\n",
      "Iteration 2234, loss = 348.64622679\n",
      "Validation score: -6.015529\n",
      "Iteration 2235, loss = 348.11756442\n",
      "Validation score: -6.005125\n",
      "Iteration 2236, loss = 347.59361460\n",
      "Validation score: -5.994745\n",
      "Iteration 2237, loss = 347.06706419\n",
      "Validation score: -5.984399\n",
      "Iteration 2238, loss = 346.54618710\n",
      "Validation score: -5.974027\n",
      "Iteration 2239, loss = 346.01896210\n",
      "Validation score: -5.963704\n",
      "Iteration 2240, loss = 345.49711250\n",
      "Validation score: -5.953350\n",
      "Iteration 2241, loss = 344.97479213\n",
      "Validation score: -5.943024\n",
      "Iteration 2242, loss = 344.45061668\n",
      "Validation score: -5.932739\n",
      "Iteration 2243, loss = 343.93181979\n",
      "Validation score: -5.922415\n",
      "Iteration 2244, loss = 343.41072233\n",
      "Validation score: -5.912099\n",
      "Iteration 2245, loss = 342.88782094\n",
      "Validation score: -5.901830\n",
      "Iteration 2246, loss = 342.36660694\n",
      "Validation score: -5.891574\n",
      "Iteration 2247, loss = 341.85030171\n",
      "Validation score: -5.881254\n",
      "Iteration 2248, loss = 341.32687988\n",
      "Validation score: -5.871003\n",
      "Iteration 2249, loss = 340.81092293\n",
      "Validation score: -5.860740\n",
      "Iteration 2250, loss = 340.29429772\n",
      "Validation score: -5.850507\n",
      "Iteration 2251, loss = 339.77485965\n",
      "Validation score: -5.840334\n",
      "Iteration 2252, loss = 339.25881883\n",
      "Validation score: -5.830166\n",
      "Iteration 2253, loss = 338.74385168\n",
      "Validation score: -5.819983\n",
      "Iteration 2254, loss = 338.23088673\n",
      "Validation score: -5.809757\n",
      "Iteration 2255, loss = 337.71508393\n",
      "Validation score: -5.799555\n",
      "Iteration 2256, loss = 337.19698935\n",
      "Validation score: -5.789399\n",
      "Iteration 2257, loss = 336.68384526\n",
      "Validation score: -5.779246\n",
      "Iteration 2258, loss = 336.16824920\n",
      "Validation score: -5.769120\n",
      "Iteration 2259, loss = 335.65554304\n",
      "Validation score: -5.758991\n",
      "Iteration 2260, loss = 335.14537699\n",
      "Validation score: -5.748811\n",
      "Iteration 2261, loss = 334.63016168\n",
      "Validation score: -5.738661\n",
      "Iteration 2262, loss = 334.11910289\n",
      "Validation score: -5.728502\n",
      "Iteration 2263, loss = 333.60428882\n",
      "Validation score: -5.718378\n",
      "Iteration 2264, loss = 333.09230962\n",
      "Validation score: -5.708275\n",
      "Iteration 2265, loss = 332.58275896\n",
      "Validation score: -5.698164\n",
      "Iteration 2266, loss = 332.07106533\n",
      "Validation score: -5.688092\n",
      "Iteration 2267, loss = 331.56151214\n",
      "Validation score: -5.678039\n",
      "Iteration 2268, loss = 331.05365368\n",
      "Validation score: -5.667962\n",
      "Iteration 2269, loss = 330.54558372\n",
      "Validation score: -5.657910\n",
      "Iteration 2270, loss = 330.03397950\n",
      "Validation score: -5.647919\n",
      "Iteration 2271, loss = 329.53106618\n",
      "Validation score: -5.637847\n",
      "Iteration 2272, loss = 329.02411817\n",
      "Validation score: -5.627801\n",
      "Iteration 2273, loss = 328.51470762\n",
      "Validation score: -5.617814\n",
      "Iteration 2274, loss = 328.00978506\n",
      "Validation score: -5.607817\n",
      "Iteration 2275, loss = 327.50295955\n",
      "Validation score: -5.597822\n",
      "Iteration 2276, loss = 326.99826787\n",
      "Validation score: -5.587815\n",
      "Iteration 2277, loss = 326.49057632\n",
      "Validation score: -5.577822\n",
      "Iteration 2278, loss = 325.98887253\n",
      "Validation score: -5.567800\n",
      "Iteration 2279, loss = 325.48372220\n",
      "Validation score: -5.557844\n",
      "Iteration 2280, loss = 324.97995425\n",
      "Validation score: -5.547905\n",
      "Iteration 2281, loss = 324.47729457\n",
      "Validation score: -5.537995\n",
      "Iteration 2282, loss = 323.97727584\n",
      "Validation score: -5.528098\n",
      "Iteration 2283, loss = 323.47903801\n",
      "Validation score: -5.518212\n",
      "Iteration 2284, loss = 322.97905030\n",
      "Validation score: -5.508380\n",
      "Iteration 2285, loss = 322.48258075\n",
      "Validation score: -5.498537\n",
      "Iteration 2286, loss = 321.98371969\n",
      "Validation score: -5.488721\n",
      "Iteration 2287, loss = 321.48634832\n",
      "Validation score: -5.478940\n",
      "Iteration 2288, loss = 320.99202730\n",
      "Validation score: -5.469120\n",
      "Iteration 2289, loss = 320.49700325\n",
      "Validation score: -5.459277\n",
      "Iteration 2290, loss = 319.99855736\n",
      "Validation score: -5.449467\n",
      "Iteration 2291, loss = 319.50120025\n",
      "Validation score: -5.439685\n",
      "Iteration 2292, loss = 319.00684437\n",
      "Validation score: -5.429895\n",
      "Iteration 2293, loss = 318.51040341\n",
      "Validation score: -5.420094\n",
      "Iteration 2294, loss = 318.01771950\n",
      "Validation score: -5.410259\n",
      "Iteration 2295, loss = 317.52033331\n",
      "Validation score: -5.400461\n",
      "Iteration 2296, loss = 317.02613422\n",
      "Validation score: -5.390682\n",
      "Iteration 2297, loss = 316.53315751\n",
      "Validation score: -5.380900\n",
      "Iteration 2298, loss = 316.03758770\n",
      "Validation score: -5.371171\n",
      "Iteration 2299, loss = 315.54516706\n",
      "Validation score: -5.361430\n",
      "Iteration 2300, loss = 315.05458527\n",
      "Validation score: -5.351689\n",
      "Iteration 2301, loss = 314.56261183\n",
      "Validation score: -5.341983\n",
      "Iteration 2302, loss = 314.07272229\n",
      "Validation score: -5.332299\n",
      "Iteration 2303, loss = 313.58111851\n",
      "Validation score: -5.322625\n",
      "Iteration 2304, loss = 313.09365610\n",
      "Validation score: -5.312916\n",
      "Iteration 2305, loss = 312.60485116\n",
      "Validation score: -5.303236\n",
      "Iteration 2306, loss = 312.11468676\n",
      "Validation score: -5.293601\n",
      "Iteration 2307, loss = 311.62828734\n",
      "Validation score: -5.283965\n",
      "Iteration 2308, loss = 311.14248248\n",
      "Validation score: -5.274335\n",
      "Iteration 2309, loss = 310.65552107\n",
      "Validation score: -5.264707\n",
      "Iteration 2310, loss = 310.16918986\n",
      "Validation score: -5.255093\n",
      "Iteration 2311, loss = 309.68444431\n",
      "Validation score: -5.245489\n",
      "Iteration 2312, loss = 309.19606314\n",
      "Validation score: -5.235955\n",
      "Iteration 2313, loss = 308.71609774\n",
      "Validation score: -5.226353\n",
      "Iteration 2314, loss = 308.23167952\n",
      "Validation score: -5.216741\n",
      "Iteration 2315, loss = 307.74726837\n",
      "Validation score: -5.207184\n",
      "Iteration 2316, loss = 307.26426645\n",
      "Validation score: -5.197640\n",
      "Iteration 2317, loss = 306.78376031\n",
      "Validation score: -5.188098\n",
      "Iteration 2318, loss = 306.29827889\n",
      "Validation score: -5.178623\n",
      "Iteration 2319, loss = 305.82215954\n",
      "Validation score: -5.169099\n",
      "Iteration 2320, loss = 305.34049730\n",
      "Validation score: -5.159603\n",
      "Iteration 2321, loss = 304.86149127\n",
      "Validation score: -5.150145\n",
      "Iteration 2322, loss = 304.38524010\n",
      "Validation score: -5.140669\n",
      "Iteration 2323, loss = 303.90511747\n",
      "Validation score: -5.131207\n",
      "Iteration 2324, loss = 303.42684310\n",
      "Validation score: -5.121775\n",
      "Iteration 2325, loss = 302.95045586\n",
      "Validation score: -5.112326\n",
      "Iteration 2326, loss = 302.47269588\n",
      "Validation score: -5.102853\n",
      "Iteration 2327, loss = 301.99514500\n",
      "Validation score: -5.093385\n",
      "Iteration 2328, loss = 301.51719921\n",
      "Validation score: -5.083951\n",
      "Iteration 2329, loss = 301.03765088\n",
      "Validation score: -5.074540\n",
      "Iteration 2330, loss = 300.56319231\n",
      "Validation score: -5.065102\n",
      "Iteration 2331, loss = 300.08555855\n",
      "Validation score: -5.055703\n",
      "Iteration 2332, loss = 299.61282127\n",
      "Validation score: -5.046292\n",
      "Iteration 2333, loss = 299.13751825\n",
      "Validation score: -5.036908\n",
      "Iteration 2334, loss = 298.66268986\n",
      "Validation score: -5.027527\n",
      "Iteration 2335, loss = 298.18996220\n",
      "Validation score: -5.018112\n",
      "Iteration 2336, loss = 297.71669158\n",
      "Validation score: -5.008711\n",
      "Iteration 2337, loss = 297.24086072\n",
      "Validation score: -4.999369\n",
      "Iteration 2338, loss = 296.77007756\n",
      "Validation score: -4.990049\n",
      "Iteration 2339, loss = 296.30281295\n",
      "Validation score: -4.980740\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 2340, loss = 295.82780328\n",
      "Validation score: -4.971501\n",
      "Iteration 2341, loss = 295.36432465\n",
      "Validation score: -4.962192\n",
      "Iteration 2342, loss = 294.89508101\n",
      "Validation score: -4.952907\n",
      "Iteration 2343, loss = 294.42226878\n",
      "Validation score: -4.943683\n",
      "Iteration 2344, loss = 293.95786208\n",
      "Validation score: -4.934391\n",
      "Iteration 2345, loss = 293.48804419\n",
      "Validation score: -4.925135\n",
      "Iteration 2346, loss = 293.02134757\n",
      "Validation score: -4.915861\n",
      "Iteration 2347, loss = 292.55389463\n",
      "Validation score: -4.906608\n",
      "Iteration 2348, loss = 292.08749271\n",
      "Validation score: -4.897387\n",
      "Iteration 2349, loss = 291.62166094\n",
      "Validation score: -4.888196\n",
      "Iteration 2350, loss = 291.15996257\n",
      "Validation score: -4.878990\n",
      "Iteration 2351, loss = 290.69408436\n",
      "Validation score: -4.869831\n",
      "Iteration 2352, loss = 290.23078886\n",
      "Validation score: -4.860663\n",
      "Iteration 2353, loss = 289.76895110\n",
      "Validation score: -4.851517\n",
      "Iteration 2354, loss = 289.30814648\n",
      "Validation score: -4.842363\n",
      "Iteration 2355, loss = 288.84505909\n",
      "Validation score: -4.833257\n",
      "Iteration 2356, loss = 288.38625775\n",
      "Validation score: -4.824121\n",
      "Iteration 2357, loss = 287.92556395\n",
      "Validation score: -4.815013\n",
      "Iteration 2358, loss = 287.46181318\n",
      "Validation score: -4.805932\n",
      "Iteration 2359, loss = 287.00733392\n",
      "Validation score: -4.796789\n",
      "Iteration 2360, loss = 286.54442324\n",
      "Validation score: -4.787702\n",
      "Iteration 2361, loss = 286.08754929\n",
      "Validation score: -4.778602\n",
      "Iteration 2362, loss = 285.62783667\n",
      "Validation score: -4.769544\n",
      "Iteration 2363, loss = 285.17077378\n",
      "Validation score: -4.760466\n",
      "Iteration 2364, loss = 284.71172241\n",
      "Validation score: -4.751411\n",
      "Iteration 2365, loss = 284.25445194\n",
      "Validation score: -4.742360\n",
      "Iteration 2366, loss = 283.79633449\n",
      "Validation score: -4.733327\n",
      "Iteration 2367, loss = 283.33858107\n",
      "Validation score: -4.724306\n",
      "Iteration 2368, loss = 282.88655937\n",
      "Validation score: -4.715232\n",
      "Iteration 2369, loss = 282.42754279\n",
      "Validation score: -4.706206\n",
      "Iteration 2370, loss = 281.97521212\n",
      "Validation score: -4.697181\n",
      "Iteration 2371, loss = 281.52041453\n",
      "Validation score: -4.688203\n",
      "Iteration 2372, loss = 281.06631194\n",
      "Validation score: -4.679267\n",
      "Iteration 2373, loss = 280.61775999\n",
      "Validation score: -4.670332\n",
      "Iteration 2374, loss = 280.16512481\n",
      "Validation score: -4.661424\n",
      "Iteration 2375, loss = 279.71621813\n",
      "Validation score: -4.652517\n",
      "Iteration 2376, loss = 279.26509403\n",
      "Validation score: -4.643591\n",
      "Iteration 2377, loss = 278.81576476\n",
      "Validation score: -4.634644\n",
      "Iteration 2378, loss = 278.36534563\n",
      "Validation score: -4.625711\n",
      "Iteration 2379, loss = 277.91729093\n",
      "Validation score: -4.616812\n",
      "Iteration 2380, loss = 277.46755532\n",
      "Validation score: -4.607981\n",
      "Iteration 2381, loss = 277.02145705\n",
      "Validation score: -4.599163\n",
      "Iteration 2382, loss = 276.57399891\n",
      "Validation score: -4.590361\n",
      "Iteration 2383, loss = 276.13213768\n",
      "Validation score: -4.581504\n",
      "Iteration 2384, loss = 275.68548745\n",
      "Validation score: -4.572669\n",
      "Iteration 2385, loss = 275.23823984\n",
      "Validation score: -4.563865\n",
      "Iteration 2386, loss = 274.79385079\n",
      "Validation score: -4.555046\n",
      "Iteration 2387, loss = 274.34592271\n",
      "Validation score: -4.546248\n",
      "Iteration 2388, loss = 273.90593751\n",
      "Validation score: -4.537363\n",
      "Iteration 2389, loss = 273.45766759\n",
      "Validation score: -4.528536\n",
      "Iteration 2390, loss = 273.01216554\n",
      "Validation score: -4.519739\n",
      "Iteration 2391, loss = 272.56887522\n",
      "Validation score: -4.510972\n",
      "Iteration 2392, loss = 272.12639902\n",
      "Validation score: -4.502185\n",
      "Iteration 2393, loss = 271.68482248\n",
      "Validation score: -4.493403\n",
      "Iteration 2394, loss = 271.24212172\n",
      "Validation score: -4.484638\n",
      "Iteration 2395, loss = 270.79785842\n",
      "Validation score: -4.475898\n",
      "Iteration 2396, loss = 270.36076361\n",
      "Validation score: -4.467136\n",
      "Iteration 2397, loss = 269.91793377\n",
      "Validation score: -4.458447\n",
      "Iteration 2398, loss = 269.47915511\n",
      "Validation score: -4.449794\n",
      "Iteration 2399, loss = 269.04111510\n",
      "Validation score: -4.441118\n",
      "Iteration 2400, loss = 268.60364284\n",
      "Validation score: -4.432409\n",
      "Iteration 2401, loss = 268.16689166\n",
      "Validation score: -4.423696\n",
      "Iteration 2402, loss = 267.72532341\n",
      "Validation score: -4.415043\n",
      "Iteration 2403, loss = 267.29049098\n",
      "Validation score: -4.406370\n",
      "Iteration 2404, loss = 266.85281579\n",
      "Validation score: -4.397743\n",
      "Iteration 2405, loss = 266.41891097\n",
      "Validation score: -4.389112\n",
      "Iteration 2406, loss = 265.98274462\n",
      "Validation score: -4.380529\n",
      "Iteration 2407, loss = 265.54921458\n",
      "Validation score: -4.371922\n",
      "Iteration 2408, loss = 265.11708069\n",
      "Validation score: -4.363321\n",
      "Iteration 2409, loss = 264.68382655\n",
      "Validation score: -4.354727\n",
      "Iteration 2410, loss = 264.24993668\n",
      "Validation score: -4.346140\n",
      "Iteration 2411, loss = 263.81573791\n",
      "Validation score: -4.337570\n",
      "Iteration 2412, loss = 263.38475593\n",
      "Validation score: -4.328995\n",
      "Iteration 2413, loss = 262.95053912\n",
      "Validation score: -4.320465\n",
      "Iteration 2414, loss = 262.52012772\n",
      "Validation score: -4.311900\n",
      "Iteration 2415, loss = 262.09051111\n",
      "Validation score: -4.303329\n",
      "Iteration 2416, loss = 261.65807501\n",
      "Validation score: -4.294790\n",
      "Iteration 2417, loss = 261.22529932\n",
      "Validation score: -4.286268\n",
      "Iteration 2418, loss = 260.79914381\n",
      "Validation score: -4.277712\n",
      "Iteration 2419, loss = 260.36615393\n",
      "Validation score: -4.269207\n",
      "Iteration 2420, loss = 259.93858237\n",
      "Validation score: -4.260679\n",
      "Iteration 2421, loss = 259.51059825\n",
      "Validation score: -4.252181\n",
      "Iteration 2422, loss = 259.08024020\n",
      "Validation score: -4.243714\n",
      "Iteration 2423, loss = 258.65483455\n",
      "Validation score: -4.235225\n",
      "Iteration 2424, loss = 258.22621584\n",
      "Validation score: -4.226788\n",
      "Iteration 2425, loss = 257.79978133\n",
      "Validation score: -4.218352\n",
      "Iteration 2426, loss = 257.37527669\n",
      "Validation score: -4.209918\n",
      "Iteration 2427, loss = 256.95189286\n",
      "Validation score: -4.201522\n",
      "Iteration 2428, loss = 256.52799185\n",
      "Validation score: -4.193129\n",
      "Iteration 2429, loss = 256.10673337\n",
      "Validation score: -4.184714\n",
      "Iteration 2430, loss = 255.68106782\n",
      "Validation score: -4.176361\n",
      "Iteration 2431, loss = 255.26208976\n",
      "Validation score: -4.167970\n",
      "Iteration 2432, loss = 254.83773396\n",
      "Validation score: -4.159645\n",
      "Iteration 2433, loss = 254.41850559\n",
      "Validation score: -4.151281\n",
      "Iteration 2434, loss = 253.99707511\n",
      "Validation score: -4.142928\n",
      "Iteration 2435, loss = 253.57735923\n",
      "Validation score: -4.134581\n",
      "Iteration 2436, loss = 253.15648576\n",
      "Validation score: -4.126280\n",
      "Iteration 2437, loss = 252.73672548\n",
      "Validation score: -4.117972\n",
      "Iteration 2438, loss = 252.31650234\n",
      "Validation score: -4.109687\n",
      "Iteration 2439, loss = 251.90169346\n",
      "Validation score: -4.101376\n",
      "Iteration 2440, loss = 251.48310008\n",
      "Validation score: -4.093082\n",
      "Iteration 2441, loss = 251.06517020\n",
      "Validation score: -4.084815\n",
      "Iteration 2442, loss = 250.64774978\n",
      "Validation score: -4.076553\n",
      "Iteration 2443, loss = 250.23227911\n",
      "Validation score: -4.068261\n",
      "Iteration 2444, loss = 249.81496387\n",
      "Validation score: -4.059993\n",
      "Iteration 2445, loss = 249.39979831\n",
      "Validation score: -4.051729\n",
      "Iteration 2446, loss = 248.98369483\n",
      "Validation score: -4.043513\n",
      "Iteration 2447, loss = 248.56854305\n",
      "Validation score: -4.035331\n",
      "Iteration 2448, loss = 248.15392423\n",
      "Validation score: -4.027141\n",
      "Iteration 2449, loss = 247.74480128\n",
      "Validation score: -4.018920\n",
      "Iteration 2450, loss = 247.33196199\n",
      "Validation score: -4.010731\n",
      "Iteration 2451, loss = 246.91872515\n",
      "Validation score: -4.002574\n",
      "Iteration 2452, loss = 246.50682424\n",
      "Validation score: -3.994434\n",
      "Iteration 2453, loss = 246.09564936\n",
      "Validation score: -3.986275\n",
      "Iteration 2454, loss = 245.68548669\n",
      "Validation score: -3.978091\n",
      "Iteration 2455, loss = 245.27302337\n",
      "Validation score: -3.969931\n",
      "Iteration 2456, loss = 244.86044107\n",
      "Validation score: -3.961796\n",
      "Iteration 2457, loss = 244.45139018\n",
      "Validation score: -3.953630\n",
      "Iteration 2458, loss = 244.03876049\n",
      "Validation score: -3.945504\n",
      "Iteration 2459, loss = 243.62969817\n",
      "Validation score: -3.937371\n",
      "Iteration 2460, loss = 243.22084561\n",
      "Validation score: -3.929237\n",
      "Iteration 2461, loss = 242.81276163\n",
      "Validation score: -3.921118\n",
      "Iteration 2462, loss = 242.40294866\n",
      "Validation score: -3.913048\n",
      "Iteration 2463, loss = 241.99679125\n",
      "Validation score: -3.904978\n",
      "Iteration 2464, loss = 241.59294381\n",
      "Validation score: -3.896898\n",
      "Iteration 2465, loss = 241.18631991\n",
      "Validation score: -3.888858\n",
      "Iteration 2466, loss = 240.78214105\n",
      "Validation score: -3.880831\n",
      "Iteration 2467, loss = 240.37811773\n",
      "Validation score: -3.872816\n",
      "Iteration 2468, loss = 239.97350224\n",
      "Validation score: -3.864833\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 2469, loss = 239.57120111\n",
      "Validation score: -3.856867\n",
      "Iteration 2470, loss = 239.17290608\n",
      "Validation score: -3.848871\n",
      "Iteration 2471, loss = 238.76932231\n",
      "Validation score: -3.840915\n",
      "Iteration 2472, loss = 238.36950389\n",
      "Validation score: -3.832970\n",
      "Iteration 2473, loss = 237.97018266\n",
      "Validation score: -3.825024\n",
      "Iteration 2474, loss = 237.56749584\n",
      "Validation score: -3.817104\n",
      "Iteration 2475, loss = 237.16862830\n",
      "Validation score: -3.809149\n",
      "Iteration 2476, loss = 236.76849505\n",
      "Validation score: -3.801222\n",
      "Iteration 2477, loss = 236.37010940\n",
      "Validation score: -3.793309\n",
      "Iteration 2478, loss = 235.97175994\n",
      "Validation score: -3.785402\n",
      "Iteration 2479, loss = 235.57306646\n",
      "Validation score: -3.777505\n",
      "Iteration 2480, loss = 235.17628196\n",
      "Validation score: -3.769562\n",
      "Iteration 2481, loss = 234.77798872\n",
      "Validation score: -3.761653\n",
      "Iteration 2482, loss = 234.38306775\n",
      "Validation score: -3.753777\n",
      "Iteration 2483, loss = 233.98278657\n",
      "Validation score: -3.745982\n",
      "Iteration 2484, loss = 233.58955612\n",
      "Validation score: -3.738128\n",
      "Iteration 2485, loss = 233.19317945\n",
      "Validation score: -3.730313\n",
      "Iteration 2486, loss = 232.80129655\n",
      "Validation score: -3.722452\n",
      "Iteration 2487, loss = 232.40612624\n",
      "Validation score: -3.714622\n",
      "Iteration 2488, loss = 232.01209182\n",
      "Validation score: -3.706815\n",
      "Iteration 2489, loss = 231.62174980\n",
      "Validation score: -3.698998\n",
      "Iteration 2490, loss = 231.22605419\n",
      "Validation score: -3.691245\n",
      "Iteration 2491, loss = 230.83738002\n",
      "Validation score: -3.683473\n",
      "Iteration 2492, loss = 230.44484087\n",
      "Validation score: -3.675733\n",
      "Iteration 2493, loss = 230.05572415\n",
      "Validation score: -3.667980\n",
      "Iteration 2494, loss = 229.66680630\n",
      "Validation score: -3.660229\n",
      "Iteration 2495, loss = 229.27385807\n",
      "Validation score: -3.652486\n",
      "Iteration 2496, loss = 228.88524596\n",
      "Validation score: -3.644728\n",
      "Iteration 2497, loss = 228.49383555\n",
      "Validation score: -3.637027\n",
      "Iteration 2498, loss = 228.10729211\n",
      "Validation score: -3.629296\n",
      "Iteration 2499, loss = 227.71933147\n",
      "Validation score: -3.621574\n",
      "Iteration 2500, loss = 227.33009522\n",
      "Validation score: -3.613876\n",
      "Iteration 2501, loss = 226.94364517\n",
      "Validation score: -3.606167\n",
      "Iteration 2502, loss = 226.55696035\n",
      "Validation score: -3.598491\n",
      "Iteration 2503, loss = 226.17026381\n",
      "Validation score: -3.590821\n",
      "Iteration 2504, loss = 225.78350385\n",
      "Validation score: -3.583166\n",
      "Iteration 2505, loss = 225.39999524\n",
      "Validation score: -3.575490\n",
      "Iteration 2506, loss = 225.01042990\n",
      "Validation score: -3.567871\n",
      "Iteration 2507, loss = 224.62988752\n",
      "Validation score: -3.560184\n",
      "Iteration 2508, loss = 224.24260084\n",
      "Validation score: -3.552539\n",
      "Iteration 2509, loss = 223.86161847\n",
      "Validation score: -3.544877\n",
      "Iteration 2510, loss = 223.47277146\n",
      "Validation score: -3.537288\n",
      "Iteration 2511, loss = 223.09031689\n",
      "Validation score: -3.529700\n",
      "Iteration 2512, loss = 222.70953159\n",
      "Validation score: -3.522083\n",
      "Iteration 2513, loss = 222.32825426\n",
      "Validation score: -3.514463\n",
      "Iteration 2514, loss = 221.94490604\n",
      "Validation score: -3.506912\n",
      "Iteration 2515, loss = 221.56456582\n",
      "Validation score: -3.499359\n",
      "Iteration 2516, loss = 221.18429900\n",
      "Validation score: -3.491803\n",
      "Iteration 2517, loss = 220.80455416\n",
      "Validation score: -3.484283\n",
      "Iteration 2518, loss = 220.42461024\n",
      "Validation score: -3.476757\n",
      "Iteration 2519, loss = 220.04785479\n",
      "Validation score: -3.469211\n",
      "Iteration 2520, loss = 219.66684412\n",
      "Validation score: -3.461696\n",
      "Iteration 2521, loss = 219.28890969\n",
      "Validation score: -3.454167\n",
      "Iteration 2522, loss = 218.91269951\n",
      "Validation score: -3.446625\n",
      "Iteration 2523, loss = 218.53188149\n",
      "Validation score: -3.439147\n",
      "Iteration 2524, loss = 218.15668475\n",
      "Validation score: -3.431646\n",
      "Iteration 2525, loss = 217.77995154\n",
      "Validation score: -3.424160\n",
      "Iteration 2526, loss = 217.40684242\n",
      "Validation score: -3.416671\n",
      "Iteration 2527, loss = 217.03092789\n",
      "Validation score: -3.409221\n",
      "Iteration 2528, loss = 216.65565636\n",
      "Validation score: -3.401812\n",
      "Iteration 2529, loss = 216.28276497\n",
      "Validation score: -3.394410\n",
      "Iteration 2530, loss = 215.90947901\n",
      "Validation score: -3.387022\n",
      "Iteration 2531, loss = 215.53814104\n",
      "Validation score: -3.379622\n",
      "Iteration 2532, loss = 215.16527769\n",
      "Validation score: -3.372216\n",
      "Iteration 2533, loss = 214.79195168\n",
      "Validation score: -3.364824\n",
      "Iteration 2534, loss = 214.42357590\n",
      "Validation score: -3.357431\n",
      "Iteration 2535, loss = 214.05102115\n",
      "Validation score: -3.350076\n",
      "Iteration 2536, loss = 213.67938344\n",
      "Validation score: -3.342721\n",
      "Iteration 2537, loss = 213.31129674\n",
      "Validation score: -3.335347\n",
      "Iteration 2538, loss = 212.94074339\n",
      "Validation score: -3.327997\n",
      "Iteration 2539, loss = 212.57120732\n",
      "Validation score: -3.320668\n",
      "Iteration 2540, loss = 212.20500902\n",
      "Validation score: -3.313329\n",
      "Iteration 2541, loss = 211.83193784\n",
      "Validation score: -3.306053\n",
      "Iteration 2542, loss = 211.46759020\n",
      "Validation score: -3.298713\n",
      "Iteration 2543, loss = 211.09905620\n",
      "Validation score: -3.291399\n",
      "Iteration 2544, loss = 210.72991491\n",
      "Validation score: -3.284107\n",
      "Iteration 2545, loss = 210.36654892\n",
      "Validation score: -3.276778\n",
      "Iteration 2546, loss = 209.99840808\n",
      "Validation score: -3.269484\n",
      "Iteration 2547, loss = 209.63252754\n",
      "Validation score: -3.262217\n",
      "Iteration 2548, loss = 209.26587626\n",
      "Validation score: -3.255007\n",
      "Iteration 2549, loss = 208.90545082\n",
      "Validation score: -3.247730\n",
      "Iteration 2550, loss = 208.53935026\n",
      "Validation score: -3.240465\n",
      "Iteration 2551, loss = 208.17114626\n",
      "Validation score: -3.233235\n",
      "Iteration 2552, loss = 207.81157846\n",
      "Validation score: -3.225948\n",
      "Iteration 2553, loss = 207.44634686\n",
      "Validation score: -3.218732\n",
      "Iteration 2554, loss = 207.08254489\n",
      "Validation score: -3.211565\n",
      "Iteration 2555, loss = 206.72413975\n",
      "Validation score: -3.204362\n",
      "Iteration 2556, loss = 206.35872433\n",
      "Validation score: -3.197204\n",
      "Iteration 2557, loss = 206.00150637\n",
      "Validation score: -3.190040\n",
      "Iteration 2558, loss = 205.64188457\n",
      "Validation score: -3.182883\n",
      "Iteration 2559, loss = 205.28523317\n",
      "Validation score: -3.175708\n",
      "Iteration 2560, loss = 204.92319149\n",
      "Validation score: -3.168618\n",
      "Iteration 2561, loss = 204.56572387\n",
      "Validation score: -3.161524\n",
      "Iteration 2562, loss = 204.21108599\n",
      "Validation score: -3.154424\n",
      "Iteration 2563, loss = 203.85370312\n",
      "Validation score: -3.147366\n",
      "Iteration 2564, loss = 203.49823660\n",
      "Validation score: -3.140292\n",
      "Iteration 2565, loss = 203.14113544\n",
      "Validation score: -3.133226\n",
      "Iteration 2566, loss = 202.78904482\n",
      "Validation score: -3.126114\n",
      "Iteration 2567, loss = 202.43339166\n",
      "Validation score: -3.119015\n",
      "Iteration 2568, loss = 202.07382670\n",
      "Validation score: -3.111980\n",
      "Iteration 2569, loss = 201.72226574\n",
      "Validation score: -3.104912\n",
      "Iteration 2570, loss = 201.36839380\n",
      "Validation score: -3.097854\n",
      "Iteration 2571, loss = 201.01329964\n",
      "Validation score: -3.090826\n",
      "Iteration 2572, loss = 200.65935372\n",
      "Validation score: -3.083810\n",
      "Iteration 2573, loss = 200.30907790\n",
      "Validation score: -3.076774\n",
      "Iteration 2574, loss = 199.95316310\n",
      "Validation score: -3.069786\n",
      "Iteration 2575, loss = 199.60356181\n",
      "Validation score: -3.062760\n",
      "Iteration 2576, loss = 199.25021685\n",
      "Validation score: -3.055775\n",
      "Iteration 2577, loss = 198.90035252\n",
      "Validation score: -3.048782\n",
      "Iteration 2578, loss = 198.54967309\n",
      "Validation score: -3.041794\n",
      "Iteration 2579, loss = 198.20144645\n",
      "Validation score: -3.034819\n",
      "Iteration 2580, loss = 197.84947375\n",
      "Validation score: -3.027875\n",
      "Iteration 2581, loss = 197.50051584\n",
      "Validation score: -3.020947\n",
      "Iteration 2582, loss = 197.15040201\n",
      "Validation score: -3.014024\n",
      "Iteration 2583, loss = 196.80676472\n",
      "Validation score: -3.007048\n",
      "Iteration 2584, loss = 196.45684782\n",
      "Validation score: -3.000107\n",
      "Iteration 2585, loss = 196.10705640\n",
      "Validation score: -2.993218\n",
      "Iteration 2586, loss = 195.76363764\n",
      "Validation score: -2.986316\n",
      "Iteration 2587, loss = 195.41769594\n",
      "Validation score: -2.979485\n",
      "Iteration 2588, loss = 195.07283373\n",
      "Validation score: -2.972647\n",
      "Iteration 2589, loss = 194.73032696\n",
      "Validation score: -2.965775\n",
      "Iteration 2590, loss = 194.38342046\n",
      "Validation score: -2.958961\n",
      "Iteration 2591, loss = 194.04415120\n",
      "Validation score: -2.952091\n",
      "Iteration 2592, loss = 193.69958295\n",
      "Validation score: -2.945247\n",
      "Iteration 2593, loss = 193.35766669\n",
      "Validation score: -2.938409\n",
      "Iteration 2594, loss = 193.01161545\n",
      "Validation score: -2.931606\n",
      "Iteration 2595, loss = 192.67146328\n",
      "Validation score: -2.924781\n",
      "Iteration 2596, loss = 192.32828952\n",
      "Validation score: -2.917953\n",
      "Iteration 2597, loss = 191.98570593\n",
      "Validation score: -2.911110\n",
      "Iteration 2598, loss = 191.63892526\n",
      "Validation score: -2.904326\n",
      "Iteration 2599, loss = 191.30288741\n",
      "Validation score: -2.897464\n",
      "Iteration 2600, loss = 190.95880790\n",
      "Validation score: -2.890654\n",
      "Iteration 2601, loss = 190.61552143\n",
      "Validation score: -2.883898\n",
      "Iteration 2602, loss = 190.27742611\n",
      "Validation score: -2.877144\n",
      "Iteration 2603, loss = 189.93893616\n",
      "Validation score: -2.870420\n",
      "Iteration 2604, loss = 189.60212296\n",
      "Validation score: -2.863698\n",
      "Iteration 2605, loss = 189.26415848\n",
      "Validation score: -2.857006\n",
      "Iteration 2606, loss = 188.92808899\n",
      "Validation score: -2.850296\n",
      "Iteration 2607, loss = 188.59344006\n",
      "Validation score: -2.843573\n",
      "Iteration 2608, loss = 188.25362128\n",
      "Validation score: -2.836897\n",
      "Iteration 2609, loss = 187.91745949\n",
      "Validation score: -2.830183\n",
      "Iteration 2610, loss = 187.58391965\n",
      "Validation score: -2.823453\n",
      "Iteration 2611, loss = 187.24670898\n",
      "Validation score: -2.816760\n",
      "Iteration 2612, loss = 186.91062872\n",
      "Validation score: -2.810062\n",
      "Iteration 2613, loss = 186.57629272\n",
      "Validation score: -2.803386\n",
      "Iteration 2614, loss = 186.24036773\n",
      "Validation score: -2.796749\n",
      "Iteration 2615, loss = 185.91082676\n",
      "Validation score: -2.790093\n",
      "Iteration 2616, loss = 185.57386215\n",
      "Validation score: -2.783497\n",
      "Iteration 2617, loss = 185.24440851\n",
      "Validation score: -2.776858\n",
      "Iteration 2618, loss = 184.91053937\n",
      "Validation score: -2.770275\n",
      "Iteration 2619, loss = 184.58434554\n",
      "Validation score: -2.763650\n",
      "Iteration 2620, loss = 184.24976414\n",
      "Validation score: -2.757113\n",
      "Iteration 2621, loss = 183.92156564\n",
      "Validation score: -2.750581\n",
      "Iteration 2622, loss = 183.59525681\n",
      "Validation score: -2.743997\n",
      "Iteration 2623, loss = 183.26313516\n",
      "Validation score: -2.737449\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 2624, loss = 182.93537926\n",
      "Validation score: -2.730888\n",
      "Iteration 2625, loss = 182.60792653\n",
      "Validation score: -2.724339\n",
      "Iteration 2626, loss = 182.27963052\n",
      "Validation score: -2.717824\n",
      "Iteration 2627, loss = 181.95137207\n",
      "Validation score: -2.711334\n",
      "Iteration 2628, loss = 181.62757491\n",
      "Validation score: -2.704792\n",
      "Iteration 2629, loss = 181.29992536\n",
      "Validation score: -2.698273\n",
      "Iteration 2630, loss = 180.97280690\n",
      "Validation score: -2.691764\n",
      "Iteration 2631, loss = 180.64707128\n",
      "Validation score: -2.685281\n",
      "Iteration 2632, loss = 180.32205323\n",
      "Validation score: -2.678824\n",
      "Iteration 2633, loss = 179.99957506\n",
      "Validation score: -2.672351\n",
      "Iteration 2634, loss = 179.67343985\n",
      "Validation score: -2.665922\n",
      "Iteration 2635, loss = 179.35183671\n",
      "Validation score: -2.659479\n",
      "Iteration 2636, loss = 179.03019872\n",
      "Validation score: -2.653027\n",
      "Iteration 2637, loss = 178.70703943\n",
      "Validation score: -2.646590\n",
      "Iteration 2638, loss = 178.38631862\n",
      "Validation score: -2.640150\n",
      "Iteration 2639, loss = 178.06197174\n",
      "Validation score: -2.633763\n",
      "Iteration 2640, loss = 177.74204017\n",
      "Validation score: -2.627376\n",
      "Iteration 2641, loss = 177.42263058\n",
      "Validation score: -2.620986\n",
      "Iteration 2642, loss = 177.10194511\n",
      "Validation score: -2.614608\n",
      "Iteration 2643, loss = 176.78363445\n",
      "Validation score: -2.608240\n",
      "Iteration 2644, loss = 176.46190664\n",
      "Validation score: -2.601927\n",
      "Iteration 2645, loss = 176.14863328\n",
      "Validation score: -2.595551\n",
      "Iteration 2646, loss = 175.82720663\n",
      "Validation score: -2.589228\n",
      "Iteration 2647, loss = 175.51306253\n",
      "Validation score: -2.582874\n",
      "Iteration 2648, loss = 175.19418083\n",
      "Validation score: -2.576588\n",
      "Iteration 2649, loss = 174.88163260\n",
      "Validation score: -2.570270\n",
      "Iteration 2650, loss = 174.56385968\n",
      "Validation score: -2.563986\n",
      "Iteration 2651, loss = 174.25016478\n",
      "Validation score: -2.557677\n",
      "Iteration 2652, loss = 173.93186776\n",
      "Validation score: -2.551393\n",
      "Iteration 2653, loss = 173.61843819\n",
      "Validation score: -2.545080\n",
      "Iteration 2654, loss = 173.30201540\n",
      "Validation score: -2.538790\n",
      "Iteration 2655, loss = 172.98753444\n",
      "Validation score: -2.532515\n",
      "Iteration 2656, loss = 172.67373278\n",
      "Validation score: -2.526245\n",
      "Iteration 2657, loss = 172.35743831\n",
      "Validation score: -2.520023\n",
      "Iteration 2658, loss = 172.04958739\n",
      "Validation score: -2.513760\n",
      "Iteration 2659, loss = 171.73267179\n",
      "Validation score: -2.507584\n",
      "Iteration 2660, loss = 171.42508702\n",
      "Validation score: -2.501344\n",
      "Iteration 2661, loss = 171.11240693\n",
      "Validation score: -2.495135\n",
      "Iteration 2662, loss = 170.80077313\n",
      "Validation score: -2.488934\n",
      "Iteration 2663, loss = 170.49171314\n",
      "Validation score: -2.482745\n",
      "Iteration 2664, loss = 170.18306956\n",
      "Validation score: -2.476562\n",
      "Iteration 2665, loss = 169.87128912\n",
      "Validation score: -2.470420\n",
      "Iteration 2666, loss = 169.56640251\n",
      "Validation score: -2.464242\n",
      "Iteration 2667, loss = 169.25942758\n",
      "Validation score: -2.458088\n",
      "Iteration 2668, loss = 168.94919228\n",
      "Validation score: -2.451974\n",
      "Iteration 2669, loss = 168.64351045\n",
      "Validation score: -2.445840\n",
      "Iteration 2670, loss = 168.33593523\n",
      "Validation score: -2.439736\n",
      "Iteration 2671, loss = 168.03091379\n",
      "Validation score: -2.433638\n",
      "Iteration 2672, loss = 167.72761431\n",
      "Validation score: -2.427538\n",
      "Iteration 2673, loss = 167.42165266\n",
      "Validation score: -2.421477\n",
      "Iteration 2674, loss = 167.11668575\n",
      "Validation score: -2.415396\n",
      "Iteration 2675, loss = 166.81275550\n",
      "Validation score: -2.409298\n",
      "Iteration 2676, loss = 166.50620252\n",
      "Validation score: -2.403234\n",
      "Iteration 2677, loss = 166.20361730\n",
      "Validation score: -2.397173\n",
      "Iteration 2678, loss = 165.90090624\n",
      "Validation score: -2.391126\n",
      "Iteration 2679, loss = 165.60060282\n",
      "Validation score: -2.385077\n",
      "Iteration 2680, loss = 165.29782579\n",
      "Validation score: -2.379057\n",
      "Iteration 2681, loss = 164.99763909\n",
      "Validation score: -2.373052\n",
      "Iteration 2682, loss = 164.69685564\n",
      "Validation score: -2.367079\n",
      "Iteration 2683, loss = 164.39819254\n",
      "Validation score: -2.361122\n",
      "Iteration 2684, loss = 164.09934266\n",
      "Validation score: -2.355188\n",
      "Iteration 2685, loss = 163.80425158\n",
      "Validation score: -2.349203\n",
      "Iteration 2686, loss = 163.50393164\n",
      "Validation score: -2.343227\n",
      "Iteration 2687, loss = 163.20474278\n",
      "Validation score: -2.337280\n",
      "Iteration 2688, loss = 162.90755732\n",
      "Validation score: -2.331322\n",
      "Iteration 2689, loss = 162.60743223\n",
      "Validation score: -2.325376\n",
      "Iteration 2690, loss = 162.31142501\n",
      "Validation score: -2.319424\n",
      "Iteration 2691, loss = 162.01416433\n",
      "Validation score: -2.313500\n",
      "Iteration 2692, loss = 161.71613723\n",
      "Validation score: -2.307575\n",
      "Iteration 2693, loss = 161.42114387\n",
      "Validation score: -2.301643\n",
      "Iteration 2694, loss = 161.12680227\n",
      "Validation score: -2.295742\n",
      "Iteration 2695, loss = 160.82874466\n",
      "Validation score: -2.289894\n",
      "Iteration 2696, loss = 160.53769971\n",
      "Validation score: -2.284005\n",
      "Iteration 2697, loss = 160.24226304\n",
      "Validation score: -2.278138\n",
      "Iteration 2698, loss = 159.95139398\n",
      "Validation score: -2.272255\n",
      "Iteration 2699, loss = 159.65611739\n",
      "Validation score: -2.266433\n",
      "Iteration 2700, loss = 159.36650712\n",
      "Validation score: -2.260596\n",
      "Iteration 2701, loss = 159.07314457\n",
      "Validation score: -2.254808\n",
      "Iteration 2702, loss = 158.78487140\n",
      "Validation score: -2.248994\n",
      "Iteration 2703, loss = 158.49267838\n",
      "Validation score: -2.243190\n",
      "Iteration 2704, loss = 158.20381269\n",
      "Validation score: -2.237341\n",
      "Iteration 2705, loss = 157.91037843\n",
      "Validation score: -2.231550\n",
      "Iteration 2706, loss = 157.62452637\n",
      "Validation score: -2.225700\n",
      "Iteration 2707, loss = 157.33241986\n",
      "Validation score: -2.219930\n",
      "Iteration 2708, loss = 157.04414703\n",
      "Validation score: -2.214200\n",
      "Iteration 2709, loss = 156.75733808\n",
      "Validation score: -2.208476\n",
      "Iteration 2710, loss = 156.47024627\n",
      "Validation score: -2.202748\n",
      "Iteration 2711, loss = 156.18420369\n",
      "Validation score: -2.196982\n",
      "Iteration 2712, loss = 155.89645133\n",
      "Validation score: -2.191237\n",
      "Iteration 2713, loss = 155.60899585\n",
      "Validation score: -2.185528\n",
      "Iteration 2714, loss = 155.32329902\n",
      "Validation score: -2.179868\n",
      "Iteration 2715, loss = 155.03999174\n",
      "Validation score: -2.174206\n",
      "Iteration 2716, loss = 154.75740530\n",
      "Validation score: -2.168497\n",
      "Iteration 2717, loss = 154.47209182\n",
      "Validation score: -2.162775\n",
      "Iteration 2718, loss = 154.18949036\n",
      "Validation score: -2.157052\n",
      "Iteration 2719, loss = 153.90102590\n",
      "Validation score: -2.151391\n",
      "Iteration 2720, loss = 153.61951510\n",
      "Validation score: -2.145724\n",
      "Iteration 2721, loss = 153.33719304\n",
      "Validation score: -2.140077\n",
      "Iteration 2722, loss = 153.05607158\n",
      "Validation score: -2.134452\n",
      "Iteration 2723, loss = 152.77706982\n",
      "Validation score: -2.128816\n",
      "Iteration 2724, loss = 152.49308504\n",
      "Validation score: -2.123292\n",
      "Iteration 2725, loss = 152.21568389\n",
      "Validation score: -2.117726\n",
      "Iteration 2726, loss = 151.93864072\n",
      "Validation score: -2.112119\n",
      "Iteration 2727, loss = 151.65770294\n",
      "Validation score: -2.106519\n",
      "Iteration 2728, loss = 151.37921633\n",
      "Validation score: -2.100913\n",
      "Iteration 2729, loss = 151.10042321\n",
      "Validation score: -2.095320\n",
      "Iteration 2730, loss = 150.82159442\n",
      "Validation score: -2.089759\n",
      "Iteration 2731, loss = 150.54272813\n",
      "Validation score: -2.084247\n",
      "Iteration 2732, loss = 150.26802854\n",
      "Validation score: -2.078715\n",
      "Iteration 2733, loss = 149.99264472\n",
      "Validation score: -2.073187\n",
      "Iteration 2734, loss = 149.71580325\n",
      "Validation score: -2.067660\n",
      "Iteration 2735, loss = 149.43991699\n",
      "Validation score: -2.062132\n",
      "Iteration 2736, loss = 149.16416116\n",
      "Validation score: -2.056628\n",
      "Iteration 2737, loss = 148.88746536\n",
      "Validation score: -2.051134\n",
      "Iteration 2738, loss = 148.61588589\n",
      "Validation score: -2.045586\n",
      "Iteration 2739, loss = 148.33708364\n",
      "Validation score: -2.040075\n",
      "Iteration 2740, loss = 148.06467513\n",
      "Validation score: -2.034538\n",
      "Iteration 2741, loss = 147.78761675\n",
      "Validation score: -2.029050\n",
      "Iteration 2742, loss = 147.51367714\n",
      "Validation score: -2.023568\n",
      "Iteration 2743, loss = 147.24115950\n",
      "Validation score: -2.018095\n",
      "Iteration 2744, loss = 146.96854256\n",
      "Validation score: -2.012654\n",
      "Iteration 2745, loss = 146.69612697\n",
      "Validation score: -2.007237\n",
      "Iteration 2746, loss = 146.42726682\n",
      "Validation score: -2.001789\n",
      "Iteration 2747, loss = 146.15407232\n",
      "Validation score: -1.996379\n",
      "Iteration 2748, loss = 145.88490654\n",
      "Validation score: -1.990952\n",
      "Iteration 2749, loss = 145.61421709\n",
      "Validation score: -1.985525\n",
      "Iteration 2750, loss = 145.34175266\n",
      "Validation score: -1.980131\n",
      "Iteration 2751, loss = 145.07492488\n",
      "Validation score: -1.974683\n",
      "Iteration 2752, loss = 144.80273191\n",
      "Validation score: -1.969284\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 2753, loss = 144.53285890\n",
      "Validation score: -1.963907\n",
      "Iteration 2754, loss = 144.26642136\n",
      "Validation score: -1.958550\n",
      "Iteration 2755, loss = 144.00087698\n",
      "Validation score: -1.953200\n",
      "Iteration 2756, loss = 143.73070184\n",
      "Validation score: -1.947886\n",
      "Iteration 2757, loss = 143.46671790\n",
      "Validation score: -1.942546\n",
      "Iteration 2758, loss = 143.20084709\n",
      "Validation score: -1.937209\n",
      "Iteration 2759, loss = 142.93228087\n",
      "Validation score: -1.931915\n",
      "Iteration 2760, loss = 142.67063084\n",
      "Validation score: -1.926572\n",
      "Iteration 2761, loss = 142.40377478\n",
      "Validation score: -1.921270\n",
      "Iteration 2762, loss = 142.13786965\n",
      "Validation score: -1.915966\n",
      "Iteration 2763, loss = 141.87515103\n",
      "Validation score: -1.910646\n",
      "Iteration 2764, loss = 141.60980317\n",
      "Validation score: -1.905347\n",
      "Iteration 2765, loss = 141.34787464\n",
      "Validation score: -1.900057\n",
      "Iteration 2766, loss = 141.08514680\n",
      "Validation score: -1.894798\n",
      "Iteration 2767, loss = 140.82301549\n",
      "Validation score: -1.889567\n",
      "Iteration 2768, loss = 140.56090010\n",
      "Validation score: -1.884359\n",
      "Iteration 2769, loss = 140.30014343\n",
      "Validation score: -1.879154\n",
      "Iteration 2770, loss = 140.04192859\n",
      "Validation score: -1.873918\n",
      "Iteration 2771, loss = 139.78161914\n",
      "Validation score: -1.868722\n",
      "Iteration 2772, loss = 139.52225570\n",
      "Validation score: -1.863536\n",
      "Iteration 2773, loss = 139.26514811\n",
      "Validation score: -1.858355\n",
      "Iteration 2774, loss = 139.00738002\n",
      "Validation score: -1.853200\n",
      "Iteration 2775, loss = 138.74976404\n",
      "Validation score: -1.848057\n",
      "Iteration 2776, loss = 138.49538848\n",
      "Validation score: -1.842892\n",
      "Iteration 2777, loss = 138.23719515\n",
      "Validation score: -1.837779\n",
      "Iteration 2778, loss = 137.98220295\n",
      "Validation score: -1.832650\n",
      "Iteration 2779, loss = 137.72888698\n",
      "Validation score: -1.827513\n",
      "Iteration 2780, loss = 137.47082561\n",
      "Validation score: -1.822448\n",
      "Iteration 2781, loss = 137.21937481\n",
      "Validation score: -1.817340\n",
      "Iteration 2782, loss = 136.96450364\n",
      "Validation score: -1.812263\n",
      "Iteration 2783, loss = 136.71161934\n",
      "Validation score: -1.807177\n",
      "Iteration 2784, loss = 136.45882964\n",
      "Validation score: -1.802092\n",
      "Iteration 2785, loss = 136.20624814\n",
      "Validation score: -1.797004\n",
      "Iteration 2786, loss = 135.95135084\n",
      "Validation score: -1.791944\n",
      "Iteration 2787, loss = 135.69964455\n",
      "Validation score: -1.786881\n",
      "Iteration 2788, loss = 135.44726024\n",
      "Validation score: -1.781822\n",
      "Iteration 2789, loss = 135.19341032\n",
      "Validation score: -1.776761\n",
      "Iteration 2790, loss = 134.94192520\n",
      "Validation score: -1.771731\n",
      "Iteration 2791, loss = 134.69315331\n",
      "Validation score: -1.766707\n",
      "Iteration 2792, loss = 134.44059083\n",
      "Validation score: -1.761690\n",
      "Iteration 2793, loss = 134.19137343\n",
      "Validation score: -1.756636\n",
      "Iteration 2794, loss = 133.94140578\n",
      "Validation score: -1.751588\n",
      "Iteration 2795, loss = 133.69093835\n",
      "Validation score: -1.746551\n",
      "Iteration 2796, loss = 133.43996657\n",
      "Validation score: -1.741540\n",
      "Iteration 2797, loss = 133.19123351\n",
      "Validation score: -1.736541\n",
      "Iteration 2798, loss = 132.94340015\n",
      "Validation score: -1.731557\n",
      "Iteration 2799, loss = 132.69606514\n",
      "Validation score: -1.726605\n",
      "Iteration 2800, loss = 132.45067392\n",
      "Validation score: -1.721671\n",
      "Iteration 2801, loss = 132.20332658\n",
      "Validation score: -1.716765\n",
      "Iteration 2802, loss = 131.96110089\n",
      "Validation score: -1.711824\n",
      "Iteration 2803, loss = 131.71304470\n",
      "Validation score: -1.706919\n",
      "Iteration 2804, loss = 131.46944294\n",
      "Validation score: -1.702013\n",
      "Iteration 2805, loss = 131.22413507\n",
      "Validation score: -1.697128\n",
      "Iteration 2806, loss = 130.98148528\n",
      "Validation score: -1.692208\n",
      "Iteration 2807, loss = 130.73800792\n",
      "Validation score: -1.687313\n",
      "Iteration 2808, loss = 130.49310192\n",
      "Validation score: -1.682453\n",
      "Iteration 2809, loss = 130.25062917\n",
      "Validation score: -1.677573\n",
      "Iteration 2810, loss = 130.00917214\n",
      "Validation score: -1.672673\n",
      "Iteration 2811, loss = 129.76754970\n",
      "Validation score: -1.667797\n",
      "Iteration 2812, loss = 129.52335798\n",
      "Validation score: -1.662960\n",
      "Iteration 2813, loss = 129.28305349\n",
      "Validation score: -1.658099\n",
      "Iteration 2814, loss = 129.04108986\n",
      "Validation score: -1.653230\n",
      "Iteration 2815, loss = 128.79960237\n",
      "Validation score: -1.648401\n",
      "Iteration 2816, loss = 128.55998829\n",
      "Validation score: -1.643589\n",
      "Iteration 2817, loss = 128.32138300\n",
      "Validation score: -1.638767\n",
      "Iteration 2818, loss = 128.08081521\n",
      "Validation score: -1.633970\n",
      "Iteration 2819, loss = 127.84432415\n",
      "Validation score: -1.629144\n",
      "Iteration 2820, loss = 127.60346039\n",
      "Validation score: -1.624382\n",
      "Iteration 2821, loss = 127.36501486\n",
      "Validation score: -1.619629\n",
      "Iteration 2822, loss = 127.12967379\n",
      "Validation score: -1.614881\n",
      "Iteration 2823, loss = 126.89446913\n",
      "Validation score: -1.610130\n",
      "Iteration 2824, loss = 126.65985416\n",
      "Validation score: -1.605382\n",
      "Iteration 2825, loss = 126.42335803\n",
      "Validation score: -1.600672\n",
      "Iteration 2826, loss = 126.18755786\n",
      "Validation score: -1.595944\n",
      "Iteration 2827, loss = 125.95427329\n",
      "Validation score: -1.591206\n",
      "Iteration 2828, loss = 125.71757677\n",
      "Validation score: -1.586513\n",
      "Iteration 2829, loss = 125.48494521\n",
      "Validation score: -1.581793\n",
      "Iteration 2830, loss = 125.25065009\n",
      "Validation score: -1.577066\n",
      "Iteration 2831, loss = 125.01811119\n",
      "Validation score: -1.572363\n",
      "Iteration 2832, loss = 124.78264056\n",
      "Validation score: -1.567737\n",
      "Iteration 2833, loss = 124.55239041\n",
      "Validation score: -1.563100\n",
      "Iteration 2834, loss = 124.32156483\n",
      "Validation score: -1.558433\n",
      "Iteration 2835, loss = 124.09348309\n",
      "Validation score: -1.553771\n",
      "Iteration 2836, loss = 123.85911418\n",
      "Validation score: -1.549150\n",
      "Iteration 2837, loss = 123.63116104\n",
      "Validation score: -1.544497\n",
      "Iteration 2838, loss = 123.39751657\n",
      "Validation score: -1.539891\n",
      "Iteration 2839, loss = 123.16794161\n",
      "Validation score: -1.535258\n",
      "Iteration 2840, loss = 122.94089208\n",
      "Validation score: -1.530570\n",
      "Iteration 2841, loss = 122.70776610\n",
      "Validation score: -1.525942\n",
      "Iteration 2842, loss = 122.47710105\n",
      "Validation score: -1.521331\n",
      "Iteration 2843, loss = 122.24670342\n",
      "Validation score: -1.516735\n",
      "Iteration 2844, loss = 122.02057256\n",
      "Validation score: -1.512106\n",
      "Iteration 2845, loss = 121.79268484\n",
      "Validation score: -1.507516\n",
      "Iteration 2846, loss = 121.56380392\n",
      "Validation score: -1.502988\n",
      "Iteration 2847, loss = 121.33805560\n",
      "Validation score: -1.498467\n",
      "Iteration 2848, loss = 121.11494798\n",
      "Validation score: -1.493892\n",
      "Iteration 2849, loss = 120.88981898\n",
      "Validation score: -1.489334\n",
      "Iteration 2850, loss = 120.66218580\n",
      "Validation score: -1.484833\n",
      "Iteration 2851, loss = 120.43879469\n",
      "Validation score: -1.480315\n",
      "Iteration 2852, loss = 120.21481391\n",
      "Validation score: -1.475812\n",
      "Iteration 2853, loss = 119.99156307\n",
      "Validation score: -1.471303\n",
      "Iteration 2854, loss = 119.76836064\n",
      "Validation score: -1.466809\n",
      "Iteration 2855, loss = 119.54479570\n",
      "Validation score: -1.462344\n",
      "Iteration 2856, loss = 119.32329471\n",
      "Validation score: -1.457887\n",
      "Iteration 2857, loss = 119.10182890\n",
      "Validation score: -1.453426\n",
      "Iteration 2858, loss = 118.87941417\n",
      "Validation score: -1.448982\n",
      "Iteration 2859, loss = 118.65945506\n",
      "Validation score: -1.444512\n",
      "Iteration 2860, loss = 118.43859488\n",
      "Validation score: -1.440055\n",
      "Iteration 2861, loss = 118.21886898\n",
      "Validation score: -1.435592\n",
      "Iteration 2862, loss = 117.99552085\n",
      "Validation score: -1.431176\n",
      "Iteration 2863, loss = 117.77802850\n",
      "Validation score: -1.426723\n",
      "Iteration 2864, loss = 117.55839062\n",
      "Validation score: -1.422286\n",
      "Iteration 2865, loss = 117.33683116\n",
      "Validation score: -1.417911\n",
      "Iteration 2866, loss = 117.11866009\n",
      "Validation score: -1.413550\n",
      "Iteration 2867, loss = 116.90314912\n",
      "Validation score: -1.409166\n",
      "Iteration 2868, loss = 116.68690222\n",
      "Validation score: -1.404779\n",
      "Iteration 2869, loss = 116.47040128\n",
      "Validation score: -1.400382\n",
      "Iteration 2870, loss = 116.25140433\n",
      "Validation score: -1.396028\n",
      "Iteration 2871, loss = 116.03370622\n",
      "Validation score: -1.391659\n",
      "Iteration 2872, loss = 115.81853479\n",
      "Validation score: -1.387259\n",
      "Iteration 2873, loss = 115.60001305\n",
      "Validation score: -1.382898\n",
      "Iteration 2874, loss = 115.38353505\n",
      "Validation score: -1.378545\n",
      "Iteration 2875, loss = 115.17019450\n",
      "Validation score: -1.374194\n",
      "Iteration 2876, loss = 114.95592496\n",
      "Validation score: -1.369859\n",
      "Iteration 2877, loss = 114.74144577\n",
      "Validation score: -1.365540\n",
      "Iteration 2878, loss = 114.52804502\n",
      "Validation score: -1.361235\n",
      "Iteration 2879, loss = 114.31228109\n",
      "Validation score: -1.356934\n",
      "Iteration 2880, loss = 114.10027891\n",
      "Validation score: -1.352645\n",
      "Iteration 2881, loss = 113.88919319\n",
      "Validation score: -1.348369\n",
      "Iteration 2882, loss = 113.67757349\n",
      "Validation score: -1.344123\n",
      "Iteration 2883, loss = 113.46492922\n",
      "Validation score: -1.339911\n",
      "Iteration 2884, loss = 113.25625905\n",
      "Validation score: -1.335682\n",
      "Iteration 2885, loss = 113.04910180\n",
      "Validation score: -1.331437\n",
      "Iteration 2886, loss = 112.83816816\n",
      "Validation score: -1.327216\n",
      "Iteration 2887, loss = 112.62961714\n",
      "Validation score: -1.322995\n",
      "Iteration 2888, loss = 112.41907279\n",
      "Validation score: -1.318833\n",
      "Iteration 2889, loss = 112.21413017\n",
      "Validation score: -1.314606\n",
      "Iteration 2890, loss = 112.00439353\n",
      "Validation score: -1.310407\n",
      "Iteration 2891, loss = 111.79706751\n",
      "Validation score: -1.306224\n",
      "Iteration 2892, loss = 111.59039553\n",
      "Validation score: -1.302058\n",
      "Iteration 2893, loss = 111.38455594\n",
      "Validation score: -1.297888\n",
      "Iteration 2894, loss = 111.17707936\n",
      "Validation score: -1.293738\n",
      "Iteration 2895, loss = 110.97499071\n",
      "Validation score: -1.289555\n",
      "Iteration 2896, loss = 110.76657046\n",
      "Validation score: -1.285455\n",
      "Iteration 2897, loss = 110.56256945\n",
      "Validation score: -1.281327\n",
      "Iteration 2898, loss = 110.36200871\n",
      "Validation score: -1.277158\n",
      "Iteration 2899, loss = 110.15238237\n",
      "Validation score: -1.273068\n",
      "Iteration 2900, loss = 109.95232918\n",
      "Validation score: -1.268952\n",
      "Iteration 2901, loss = 109.74543700\n",
      "Validation score: -1.264869\n",
      "Iteration 2902, loss = 109.54710224\n",
      "Validation score: -1.260744\n",
      "Iteration 2903, loss = 109.34031490\n",
      "Validation score: -1.256685\n",
      "Iteration 2904, loss = 109.13962364\n",
      "Validation score: -1.252599\n",
      "Iteration 2905, loss = 108.93660359\n",
      "Validation score: -1.248528\n",
      "Iteration 2906, loss = 108.73609417\n",
      "Validation score: -1.244443\n",
      "Iteration 2907, loss = 108.53444388\n",
      "Validation score: -1.240392\n",
      "Iteration 2908, loss = 108.33362252\n",
      "Validation score: -1.236340\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 2909, loss = 108.13550309\n",
      "Validation score: -1.232278\n",
      "Iteration 2910, loss = 107.93480976\n",
      "Validation score: -1.228234\n",
      "Iteration 2911, loss = 107.73502378\n",
      "Validation score: -1.224194\n",
      "Iteration 2912, loss = 107.53392244\n",
      "Validation score: -1.220196\n",
      "Iteration 2913, loss = 107.33738956\n",
      "Validation score: -1.216181\n",
      "Iteration 2914, loss = 107.13900186\n",
      "Validation score: -1.212182\n",
      "Iteration 2915, loss = 106.94053572\n",
      "Validation score: -1.208207\n",
      "Iteration 2916, loss = 106.74324180\n",
      "Validation score: -1.204234\n",
      "Iteration 2917, loss = 106.54892067\n",
      "Validation score: -1.200248\n",
      "Iteration 2918, loss = 106.35097139\n",
      "Validation score: -1.196297\n",
      "Iteration 2919, loss = 106.15546324\n",
      "Validation score: -1.192335\n",
      "Iteration 2920, loss = 105.96137311\n",
      "Validation score: -1.188358\n",
      "Iteration 2921, loss = 105.76314274\n",
      "Validation score: -1.184408\n",
      "Iteration 2922, loss = 105.56963660\n",
      "Validation score: -1.180444\n",
      "Iteration 2923, loss = 105.37474302\n",
      "Validation score: -1.176516\n",
      "Iteration 2924, loss = 105.17894630\n",
      "Validation score: -1.172604\n",
      "Iteration 2925, loss = 104.98661412\n",
      "Validation score: -1.168676\n",
      "Iteration 2926, loss = 104.79230530\n",
      "Validation score: -1.164776\n",
      "Iteration 2927, loss = 104.59855633\n",
      "Validation score: -1.160887\n",
      "Iteration 2928, loss = 104.40615510\n",
      "Validation score: -1.156990\n",
      "Iteration 2929, loss = 104.21562006\n",
      "Validation score: -1.153072\n",
      "Iteration 2930, loss = 104.02607106\n",
      "Validation score: -1.149175\n",
      "Iteration 2931, loss = 103.82988729\n",
      "Validation score: -1.145371\n",
      "Iteration 2932, loss = 103.64305099\n",
      "Validation score: -1.141532\n",
      "Iteration 2933, loss = 103.45376722\n",
      "Validation score: -1.137687\n",
      "Iteration 2934, loss = 103.26417115\n",
      "Validation score: -1.133850\n",
      "Iteration 2935, loss = 103.07497927\n",
      "Validation score: -1.130004\n",
      "Iteration 2936, loss = 102.88470436\n",
      "Validation score: -1.126164\n",
      "Iteration 2937, loss = 102.69460389\n",
      "Validation score: -1.122337\n",
      "Iteration 2938, loss = 102.50643156\n",
      "Validation score: -1.118498\n",
      "Iteration 2939, loss = 102.31816751\n",
      "Validation score: -1.114692\n",
      "Iteration 2940, loss = 102.12951177\n",
      "Validation score: -1.110912\n",
      "Iteration 2941, loss = 101.94118869\n",
      "Validation score: -1.107149\n",
      "Iteration 2942, loss = 101.75752251\n",
      "Validation score: -1.103323\n",
      "Iteration 2943, loss = 101.56780760\n",
      "Validation score: -1.099530\n",
      "Iteration 2944, loss = 101.38226057\n",
      "Validation score: -1.095727\n",
      "Iteration 2945, loss = 101.19603469\n",
      "Validation score: -1.091938\n",
      "Iteration 2946, loss = 101.00836367\n",
      "Validation score: -1.088210\n",
      "Iteration 2947, loss = 100.82756848\n",
      "Validation score: -1.084482\n",
      "Iteration 2948, loss = 100.64163598\n",
      "Validation score: -1.080822\n",
      "Iteration 2949, loss = 100.46046024\n",
      "Validation score: -1.077157\n",
      "Iteration 2950, loss = 100.27807768\n",
      "Validation score: -1.073483\n",
      "Iteration 2951, loss = 100.09604063\n",
      "Validation score: -1.069771\n",
      "Iteration 2952, loss = 99.91634193\n",
      "Validation score: -1.066029\n",
      "Iteration 2953, loss = 99.73073584\n",
      "Validation score: -1.062352\n",
      "Iteration 2954, loss = 99.55061531\n",
      "Validation score: -1.058678\n",
      "Iteration 2955, loss = 99.37001319\n",
      "Validation score: -1.055003\n",
      "Iteration 2956, loss = 99.18876987\n",
      "Validation score: -1.051343\n",
      "Iteration 2957, loss = 99.00770428\n",
      "Validation score: -1.047711\n",
      "Iteration 2958, loss = 98.83049376\n",
      "Validation score: -1.044079\n",
      "Iteration 2959, loss = 98.65098213\n",
      "Validation score: -1.040461\n",
      "Iteration 2960, loss = 98.47411464\n",
      "Validation score: -1.036828\n",
      "Iteration 2961, loss = 98.29150569\n",
      "Validation score: -1.033263\n",
      "Iteration 2962, loss = 98.11739582\n",
      "Validation score: -1.029636\n",
      "Iteration 2963, loss = 97.93822916\n",
      "Validation score: -1.026036\n",
      "Iteration 2964, loss = 97.76160434\n",
      "Validation score: -1.022413\n",
      "Iteration 2965, loss = 97.58277087\n",
      "Validation score: -1.018789\n",
      "Iteration 2966, loss = 97.40556176\n",
      "Validation score: -1.015187\n",
      "Iteration 2967, loss = 97.22782682\n",
      "Validation score: -1.011600\n",
      "Iteration 2968, loss = 97.05017349\n",
      "Validation score: -1.008031\n",
      "Iteration 2969, loss = 96.87707108\n",
      "Validation score: -1.004452\n",
      "Iteration 2970, loss = 96.70028128\n",
      "Validation score: -1.000919\n",
      "Iteration 2971, loss = 96.52764308\n",
      "Validation score: -0.997359\n",
      "Iteration 2972, loss = 96.35154087\n",
      "Validation score: -0.993829\n",
      "Iteration 2973, loss = 96.17737533\n",
      "Validation score: -0.990304\n",
      "Iteration 2974, loss = 96.00560809\n",
      "Validation score: -0.986773\n",
      "Iteration 2975, loss = 95.83127682\n",
      "Validation score: -0.983306\n",
      "Iteration 2976, loss = 95.66080708\n",
      "Validation score: -0.979805\n",
      "Iteration 2977, loss = 95.48831724\n",
      "Validation score: -0.976289\n",
      "Iteration 2978, loss = 95.31551974\n",
      "Validation score: -0.972777\n",
      "Iteration 2979, loss = 95.14253929\n",
      "Validation score: -0.969313\n",
      "Iteration 2980, loss = 94.97227121\n",
      "Validation score: -0.965849\n",
      "Iteration 2981, loss = 94.80020197\n",
      "Validation score: -0.962399\n",
      "Iteration 2982, loss = 94.63225804\n",
      "Validation score: -0.958908\n",
      "Iteration 2983, loss = 94.46160239\n",
      "Validation score: -0.955453\n",
      "Iteration 2984, loss = 94.29015261\n",
      "Validation score: -0.952032\n",
      "Iteration 2985, loss = 94.12340705\n",
      "Validation score: -0.948575\n",
      "Iteration 2986, loss = 93.95279355\n",
      "Validation score: -0.945139\n",
      "Iteration 2987, loss = 93.78541236\n",
      "Validation score: -0.941693\n",
      "Iteration 2988, loss = 93.61673849\n",
      "Validation score: -0.938275\n",
      "Iteration 2989, loss = 93.44512613\n",
      "Validation score: -0.934911\n",
      "Iteration 2990, loss = 93.28091529\n",
      "Validation score: -0.931459\n",
      "Iteration 2991, loss = 93.11318836\n",
      "Validation score: -0.928020\n",
      "Iteration 2992, loss = 92.94376454\n",
      "Validation score: -0.924651\n",
      "Iteration 2993, loss = 92.77769751\n",
      "Validation score: -0.921299\n",
      "Iteration 2994, loss = 92.61598282\n",
      "Validation score: -0.917917\n",
      "Iteration 2995, loss = 92.44907840\n",
      "Validation score: -0.914570\n",
      "Iteration 2996, loss = 92.28254394\n",
      "Validation score: -0.911264\n",
      "Iteration 2997, loss = 92.12212505\n",
      "Validation score: -0.907911\n",
      "Iteration 2998, loss = 91.95705259\n",
      "Validation score: -0.904571\n",
      "Iteration 2999, loss = 91.79387857\n",
      "Validation score: -0.901229\n",
      "Iteration 3000, loss = 91.62978319\n",
      "Validation score: -0.897905\n",
      "Iteration 3001, loss = 91.46522513\n",
      "Validation score: -0.894607\n",
      "Iteration 3002, loss = 91.30652864\n",
      "Validation score: -0.891311\n",
      "Iteration 3003, loss = 91.14468918\n",
      "Validation score: -0.888040\n",
      "Iteration 3004, loss = 90.98348595\n",
      "Validation score: -0.884784\n",
      "Iteration 3005, loss = 90.82182898\n",
      "Validation score: -0.881540\n",
      "Iteration 3006, loss = 90.66387296\n",
      "Validation score: -0.878244\n",
      "Iteration 3007, loss = 90.50117013\n",
      "Validation score: -0.874979\n",
      "Iteration 3008, loss = 90.34078155\n",
      "Validation score: -0.871713\n",
      "Iteration 3009, loss = 90.18224360\n",
      "Validation score: -0.868416\n",
      "Iteration 3010, loss = 90.01880975\n",
      "Validation score: -0.865151\n",
      "Iteration 3011, loss = 89.85886700\n",
      "Validation score: -0.861895\n",
      "Iteration 3012, loss = 89.70044080\n",
      "Validation score: -0.858652\n",
      "Iteration 3013, loss = 89.54091040\n",
      "Validation score: -0.855422\n",
      "Iteration 3014, loss = 89.38321365\n",
      "Validation score: -0.852225\n",
      "Iteration 3015, loss = 89.22555163\n",
      "Validation score: -0.849048\n",
      "Iteration 3016, loss = 89.07041245\n",
      "Validation score: -0.845846\n",
      "Iteration 3017, loss = 88.91441147\n",
      "Validation score: -0.842643\n",
      "Iteration 3018, loss = 88.75913108\n",
      "Validation score: -0.839438\n",
      "Iteration 3019, loss = 88.60142506\n",
      "Validation score: -0.836302\n",
      "Iteration 3020, loss = 88.44859272\n",
      "Validation score: -0.833145\n",
      "Iteration 3021, loss = 88.29156815\n",
      "Validation score: -0.830042\n",
      "Iteration 3022, loss = 88.13964788\n",
      "Validation score: -0.826916\n",
      "Iteration 3023, loss = 87.98837653\n",
      "Validation score: -0.823765\n",
      "Iteration 3024, loss = 87.83216082\n",
      "Validation score: -0.820678\n",
      "Iteration 3025, loss = 87.68419732\n",
      "Validation score: -0.817524\n",
      "Iteration 3026, loss = 87.52857708\n",
      "Validation score: -0.814441\n",
      "Iteration 3027, loss = 87.37577488\n",
      "Validation score: -0.811355\n",
      "Iteration 3028, loss = 87.22602417\n",
      "Validation score: -0.808254\n",
      "Iteration 3029, loss = 87.07401366\n",
      "Validation score: -0.805186\n",
      "Iteration 3030, loss = 86.92437652\n",
      "Validation score: -0.802105\n",
      "Iteration 3031, loss = 86.77372568\n",
      "Validation score: -0.799035\n",
      "Iteration 3032, loss = 86.62434513\n",
      "Validation score: -0.795945\n",
      "Iteration 3033, loss = 86.47251395\n",
      "Validation score: -0.792902\n",
      "Iteration 3034, loss = 86.32339359\n",
      "Validation score: -0.789878\n",
      "Iteration 3035, loss = 86.17797283\n",
      "Validation score: -0.786832\n",
      "Iteration 3036, loss = 86.02719511\n",
      "Validation score: -0.783834\n",
      "Iteration 3037, loss = 85.87846173\n",
      "Validation score: -0.780830\n",
      "Iteration 3038, loss = 85.73342563\n",
      "Validation score: -0.777790\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 3039, loss = 85.58576932\n",
      "Validation score: -0.774756\n",
      "Iteration 3040, loss = 85.43590261\n",
      "Validation score: -0.771753\n",
      "Iteration 3041, loss = 85.28939184\n",
      "Validation score: -0.768757\n",
      "Iteration 3042, loss = 85.14286993\n",
      "Validation score: -0.765763\n",
      "Iteration 3043, loss = 84.99516340\n",
      "Validation score: -0.762770\n",
      "Iteration 3044, loss = 84.84957328\n",
      "Validation score: -0.759746\n",
      "Iteration 3045, loss = 84.70169176\n",
      "Validation score: -0.756741\n",
      "Iteration 3046, loss = 84.55675512\n",
      "Validation score: -0.753747\n",
      "Iteration 3047, loss = 84.40840720\n",
      "Validation score: -0.750832\n",
      "Iteration 3048, loss = 84.26705932\n",
      "Validation score: -0.747895\n",
      "Iteration 3049, loss = 84.12577784\n",
      "Validation score: -0.744943\n",
      "Iteration 3050, loss = 83.97986645\n",
      "Validation score: -0.742042\n",
      "Iteration 3051, loss = 83.83902047\n",
      "Validation score: -0.739095\n",
      "Iteration 3052, loss = 83.69368779\n",
      "Validation score: -0.736180\n",
      "Iteration 3053, loss = 83.55214821\n",
      "Validation score: -0.733262\n",
      "Iteration 3054, loss = 83.41191742\n",
      "Validation score: -0.730329\n",
      "Iteration 3055, loss = 83.26654898\n",
      "Validation score: -0.727475\n",
      "Iteration 3056, loss = 83.12719931\n",
      "Validation score: -0.724585\n",
      "Iteration 3057, loss = 82.98450593\n",
      "Validation score: -0.721691\n",
      "Iteration 3058, loss = 82.84415402\n",
      "Validation score: -0.718764\n",
      "Iteration 3059, loss = 82.70120696\n",
      "Validation score: -0.715863\n",
      "Iteration 3060, loss = 82.56074559\n",
      "Validation score: -0.712961\n",
      "Iteration 3061, loss = 82.41843483\n",
      "Validation score: -0.710098\n",
      "Iteration 3062, loss = 82.27866567\n",
      "Validation score: -0.707238\n",
      "Iteration 3063, loss = 82.14065948\n",
      "Validation score: -0.704379\n",
      "Iteration 3064, loss = 82.00219527\n",
      "Validation score: -0.701505\n",
      "Iteration 3065, loss = 81.86081328\n",
      "Validation score: -0.698698\n",
      "Iteration 3066, loss = 81.72598309\n",
      "Validation score: -0.695860\n",
      "Iteration 3067, loss = 81.58697050\n",
      "Validation score: -0.693083\n",
      "Iteration 3068, loss = 81.45188014\n",
      "Validation score: -0.690301\n",
      "Iteration 3069, loss = 81.31591139\n",
      "Validation score: -0.687539\n",
      "Iteration 3070, loss = 81.18189605\n",
      "Validation score: -0.684791\n",
      "Iteration 3071, loss = 81.04765968\n",
      "Validation score: -0.682040\n",
      "Iteration 3072, loss = 80.91273367\n",
      "Validation score: -0.679311\n",
      "Iteration 3073, loss = 80.78019017\n",
      "Validation score: -0.676568\n",
      "Iteration 3074, loss = 80.64522893\n",
      "Validation score: -0.673827\n",
      "Iteration 3075, loss = 80.51278002\n",
      "Validation score: -0.671053\n",
      "Iteration 3076, loss = 80.37699366\n",
      "Validation score: -0.668326\n",
      "Iteration 3077, loss = 80.24522078\n",
      "Validation score: -0.665571\n",
      "Iteration 3078, loss = 80.11226011\n",
      "Validation score: -0.662843\n",
      "Iteration 3079, loss = 79.97779964\n",
      "Validation score: -0.660131\n",
      "Iteration 3080, loss = 79.84728146\n",
      "Validation score: -0.657403\n",
      "Iteration 3081, loss = 79.71413518\n",
      "Validation score: -0.654706\n",
      "Iteration 3082, loss = 79.58310102\n",
      "Validation score: -0.651990\n",
      "Iteration 3083, loss = 79.45221647\n",
      "Validation score: -0.649289\n",
      "Iteration 3084, loss = 79.32009387\n",
      "Validation score: -0.646629\n",
      "Iteration 3085, loss = 79.18968117\n",
      "Validation score: -0.643973\n",
      "Iteration 3086, loss = 79.05982835\n",
      "Validation score: -0.641284\n",
      "Iteration 3087, loss = 78.92987551\n",
      "Validation score: -0.638588\n",
      "Iteration 3088, loss = 78.79830746\n",
      "Validation score: -0.635915\n",
      "Iteration 3089, loss = 78.66734410\n",
      "Validation score: -0.633274\n",
      "Iteration 3090, loss = 78.53872753\n",
      "Validation score: -0.630625\n",
      "Iteration 3091, loss = 78.41163223\n",
      "Validation score: -0.627956\n",
      "Iteration 3092, loss = 78.28134304\n",
      "Validation score: -0.625298\n",
      "Iteration 3093, loss = 78.15248960\n",
      "Validation score: -0.622640\n",
      "Iteration 3094, loss = 78.02195694\n",
      "Validation score: -0.620036\n",
      "Iteration 3095, loss = 77.89740534\n",
      "Validation score: -0.617416\n",
      "Iteration 3096, loss = 77.77113937\n",
      "Validation score: -0.614808\n",
      "Iteration 3097, loss = 77.64307606\n",
      "Validation score: -0.612230\n",
      "Iteration 3098, loss = 77.52036367\n",
      "Validation score: -0.609633\n",
      "Iteration 3099, loss = 77.39497081\n",
      "Validation score: -0.607049\n",
      "Iteration 3100, loss = 77.26721746\n",
      "Validation score: -0.604506\n",
      "Iteration 3101, loss = 77.14403071\n",
      "Validation score: -0.601952\n",
      "Iteration 3102, loss = 77.02134890\n",
      "Validation score: -0.599401\n",
      "Iteration 3103, loss = 76.89740039\n",
      "Validation score: -0.596844\n",
      "Iteration 3104, loss = 76.77191313\n",
      "Validation score: -0.594331\n",
      "Iteration 3105, loss = 76.64913787\n",
      "Validation score: -0.591821\n",
      "Iteration 3106, loss = 76.52735301\n",
      "Validation score: -0.589288\n",
      "Iteration 3107, loss = 76.40475194\n",
      "Validation score: -0.586756\n",
      "Iteration 3108, loss = 76.28313853\n",
      "Validation score: -0.584207\n",
      "Iteration 3109, loss = 76.15993616\n",
      "Validation score: -0.581685\n",
      "Iteration 3110, loss = 76.03665906\n",
      "Validation score: -0.579174\n",
      "Iteration 3111, loss = 75.91666991\n",
      "Validation score: -0.576657\n",
      "Iteration 3112, loss = 75.79320283\n",
      "Validation score: -0.574198\n",
      "Iteration 3113, loss = 75.67355836\n",
      "Validation score: -0.571740\n",
      "Iteration 3114, loss = 75.55367792\n",
      "Validation score: -0.569286\n",
      "Iteration 3115, loss = 75.43525851\n",
      "Validation score: -0.566797\n",
      "Iteration 3116, loss = 75.31808065\n",
      "Validation score: -0.564300\n",
      "Iteration 3117, loss = 75.19592379\n",
      "Validation score: -0.561846\n",
      "Iteration 3118, loss = 75.07629881\n",
      "Validation score: -0.559404\n",
      "Iteration 3119, loss = 74.95631787\n",
      "Validation score: -0.556974\n",
      "Iteration 3120, loss = 74.83943692\n",
      "Validation score: -0.554521\n",
      "Iteration 3121, loss = 74.71903268\n",
      "Validation score: -0.552107\n",
      "Iteration 3122, loss = 74.60319659\n",
      "Validation score: -0.549672\n",
      "Iteration 3123, loss = 74.48778878\n",
      "Validation score: -0.547212\n",
      "Iteration 3124, loss = 74.36787983\n",
      "Validation score: -0.544821\n",
      "Iteration 3125, loss = 74.25369988\n",
      "Validation score: -0.542450\n",
      "Iteration 3126, loss = 74.13646374\n",
      "Validation score: -0.540135\n",
      "Iteration 3127, loss = 74.02503353\n",
      "Validation score: -0.537770\n",
      "Iteration 3128, loss = 73.91071996\n",
      "Validation score: -0.535394\n",
      "Iteration 3129, loss = 73.79565767\n",
      "Validation score: -0.533011\n",
      "Iteration 3130, loss = 73.68098063\n",
      "Validation score: -0.530646\n",
      "Iteration 3131, loss = 73.56494635\n",
      "Validation score: -0.528309\n",
      "Iteration 3132, loss = 73.45114644\n",
      "Validation score: -0.525961\n",
      "Iteration 3133, loss = 73.34000247\n",
      "Validation score: -0.523594\n",
      "Iteration 3134, loss = 73.22540551\n",
      "Validation score: -0.521276\n",
      "Iteration 3135, loss = 73.11463328\n",
      "Validation score: -0.518946\n",
      "Iteration 3136, loss = 73.00126397\n",
      "Validation score: -0.516632\n",
      "Iteration 3137, loss = 72.88649015\n",
      "Validation score: -0.514337\n",
      "Iteration 3138, loss = 72.77813703\n",
      "Validation score: -0.511993\n",
      "Iteration 3139, loss = 72.66503344\n",
      "Validation score: -0.509685\n",
      "Iteration 3140, loss = 72.55449969\n",
      "Validation score: -0.507361\n",
      "Iteration 3141, loss = 72.44222432\n",
      "Validation score: -0.505090\n",
      "Iteration 3142, loss = 72.33343343\n",
      "Validation score: -0.502823\n",
      "Iteration 3143, loss = 72.22344230\n",
      "Validation score: -0.500578\n",
      "Iteration 3144, loss = 72.11535186\n",
      "Validation score: -0.498304\n",
      "Iteration 3145, loss = 72.00314258\n",
      "Validation score: -0.496071\n",
      "Iteration 3146, loss = 71.89792961\n",
      "Validation score: -0.493794\n",
      "Iteration 3147, loss = 71.78681813\n",
      "Validation score: -0.491559\n",
      "Iteration 3148, loss = 71.67844877\n",
      "Validation score: -0.489322\n",
      "Iteration 3149, loss = 71.57140675\n",
      "Validation score: -0.487074\n",
      "Iteration 3150, loss = 71.46320924\n",
      "Validation score: -0.484860\n",
      "Iteration 3151, loss = 71.35682903\n",
      "Validation score: -0.482648\n",
      "Iteration 3152, loss = 71.25043993\n",
      "Validation score: -0.480450\n",
      "Iteration 3153, loss = 71.14460434\n",
      "Validation score: -0.478250\n",
      "Iteration 3154, loss = 71.03950391\n",
      "Validation score: -0.476031\n",
      "Iteration 3155, loss = 70.93073147\n",
      "Validation score: -0.473876\n",
      "Iteration 3156, loss = 70.82663754\n",
      "Validation score: -0.471691\n",
      "Iteration 3157, loss = 70.72216801\n",
      "Validation score: -0.469508\n",
      "Iteration 3158, loss = 70.61732577\n",
      "Validation score: -0.467318\n",
      "Iteration 3159, loss = 70.51291296\n",
      "Validation score: -0.465130\n",
      "Iteration 3160, loss = 70.40660788\n",
      "Validation score: -0.462982\n",
      "Iteration 3161, loss = 70.30260663\n",
      "Validation score: -0.460832\n",
      "Iteration 3162, loss = 70.19939841\n",
      "Validation score: -0.458668\n",
      "Iteration 3163, loss = 70.09661792\n",
      "Validation score: -0.456507\n",
      "Iteration 3164, loss = 69.99122568\n",
      "Validation score: -0.454404\n",
      "Iteration 3165, loss = 69.89035046\n",
      "Validation score: -0.452284\n",
      "Iteration 3166, loss = 69.78752624\n",
      "Validation score: -0.450179\n",
      "Iteration 3167, loss = 69.68746150\n",
      "Validation score: -0.448049\n",
      "Iteration 3168, loss = 69.58460999\n",
      "Validation score: -0.445928\n",
      "Iteration 3169, loss = 69.48412849\n",
      "Validation score: -0.443783\n",
      "Iteration 3170, loss = 69.37956700\n",
      "Validation score: -0.441683\n",
      "Iteration 3171, loss = 69.27929506\n",
      "Validation score: -0.439581\n",
      "Iteration 3172, loss = 69.17972451\n",
      "Validation score: -0.437494\n",
      "Iteration 3173, loss = 69.07853607\n",
      "Validation score: -0.435455\n",
      "Iteration 3174, loss = 68.98031425\n",
      "Validation score: -0.433414\n",
      "Iteration 3175, loss = 68.88216700\n",
      "Validation score: -0.431358\n",
      "Iteration 3176, loss = 68.78335720\n",
      "Validation score: -0.429308\n",
      "Iteration 3177, loss = 68.68621335\n",
      "Validation score: -0.427244\n",
      "Iteration 3178, loss = 68.58583984\n",
      "Validation score: -0.425214\n",
      "Iteration 3179, loss = 68.48935250\n",
      "Validation score: -0.423171\n",
      "Iteration 3180, loss = 68.38971969\n",
      "Validation score: -0.421166\n",
      "Iteration 3181, loss = 68.29302967\n",
      "Validation score: -0.419152\n",
      "Iteration 3182, loss = 68.19839336\n",
      "Validation score: -0.417112\n",
      "Iteration 3183, loss = 68.09857930\n",
      "Validation score: -0.415128\n",
      "Iteration 3184, loss = 68.00469200\n",
      "Validation score: -0.413120\n",
      "Iteration 3185, loss = 67.91164722\n",
      "Validation score: -0.411106\n",
      "Iteration 3186, loss = 67.81301280\n",
      "Validation score: -0.409165\n",
      "Iteration 3187, loss = 67.71940806\n",
      "Validation score: -0.407206\n",
      "Iteration 3188, loss = 67.62567471\n",
      "Validation score: -0.405243\n",
      "Iteration 3189, loss = 67.53189889\n",
      "Validation score: -0.403296\n",
      "Iteration 3190, loss = 67.43740915\n",
      "Validation score: -0.401352\n",
      "Iteration 3191, loss = 67.34574516\n",
      "Validation score: -0.399397\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 3192, loss = 67.25340232\n",
      "Validation score: -0.397460\n",
      "Iteration 3193, loss = 67.15734831\n",
      "Validation score: -0.395563\n",
      "Iteration 3194, loss = 67.06677127\n",
      "Validation score: -0.393612\n",
      "Iteration 3195, loss = 66.97464503\n",
      "Validation score: -0.391662\n",
      "Iteration 3196, loss = 66.88133438\n",
      "Validation score: -0.389755\n",
      "Iteration 3197, loss = 66.78870655\n",
      "Validation score: -0.387865\n",
      "Iteration 3198, loss = 66.69986747\n",
      "Validation score: -0.385948\n",
      "Iteration 3199, loss = 66.60799713\n",
      "Validation score: -0.384054\n",
      "Iteration 3200, loss = 66.51965045\n",
      "Validation score: -0.382157\n",
      "Iteration 3201, loss = 66.42656084\n",
      "Validation score: -0.380321\n",
      "Iteration 3202, loss = 66.33840725\n",
      "Validation score: -0.378449\n",
      "Iteration 3203, loss = 66.24920433\n",
      "Validation score: -0.376591\n",
      "Iteration 3204, loss = 66.16131775\n",
      "Validation score: -0.374739\n",
      "Iteration 3205, loss = 66.07035417\n",
      "Validation score: -0.372904\n",
      "Iteration 3206, loss = 65.98288907\n",
      "Validation score: -0.371029\n",
      "Iteration 3207, loss = 65.89397264\n",
      "Validation score: -0.369175\n",
      "Iteration 3208, loss = 65.80779401\n",
      "Validation score: -0.367317\n",
      "Iteration 3209, loss = 65.71789945\n",
      "Validation score: -0.365480\n",
      "Iteration 3210, loss = 65.62909457\n",
      "Validation score: -0.363640\n",
      "Iteration 3211, loss = 65.54336969\n",
      "Validation score: -0.361802\n",
      "Iteration 3212, loss = 65.45448623\n",
      "Validation score: -0.360006\n",
      "Iteration 3213, loss = 65.36648040\n",
      "Validation score: -0.358220\n",
      "Iteration 3214, loss = 65.28165751\n",
      "Validation score: -0.356397\n",
      "Iteration 3215, loss = 65.19546578\n",
      "Validation score: -0.354555\n",
      "Iteration 3216, loss = 65.10691271\n",
      "Validation score: -0.352739\n",
      "Iteration 3217, loss = 65.02169977\n",
      "Validation score: -0.350912\n",
      "Iteration 3218, loss = 64.93336164\n",
      "Validation score: -0.349118\n",
      "Iteration 3219, loss = 64.84916979\n",
      "Validation score: -0.347322\n",
      "Iteration 3220, loss = 64.76494946\n",
      "Validation score: -0.345536\n",
      "Iteration 3221, loss = 64.67829551\n",
      "Validation score: -0.343799\n",
      "Iteration 3222, loss = 64.59550266\n",
      "Validation score: -0.342048\n",
      "Iteration 3223, loss = 64.51083669\n",
      "Validation score: -0.340302\n",
      "Iteration 3224, loss = 64.42902675\n",
      "Validation score: -0.338554\n",
      "Iteration 3225, loss = 64.34641118\n",
      "Validation score: -0.336812\n",
      "Iteration 3226, loss = 64.26464274\n",
      "Validation score: -0.335077\n",
      "Iteration 3227, loss = 64.18086888\n",
      "Validation score: -0.333384\n",
      "Iteration 3228, loss = 64.10221790\n",
      "Validation score: -0.331650\n",
      "Iteration 3229, loss = 64.02040885\n",
      "Validation score: -0.329934\n",
      "Iteration 3230, loss = 63.93732288\n",
      "Validation score: -0.328259\n",
      "Iteration 3231, loss = 63.85698699\n",
      "Validation score: -0.326571\n",
      "Iteration 3232, loss = 63.77470599\n",
      "Validation score: -0.324902\n",
      "Iteration 3233, loss = 63.69635669\n",
      "Validation score: -0.323198\n",
      "Iteration 3234, loss = 63.61653240\n",
      "Validation score: -0.321500\n",
      "Iteration 3235, loss = 63.53502897\n",
      "Validation score: -0.319809\n",
      "Iteration 3236, loss = 63.45593863\n",
      "Validation score: -0.318115\n",
      "Iteration 3237, loss = 63.37324669\n",
      "Validation score: -0.316489\n",
      "Iteration 3238, loss = 63.29802481\n",
      "Validation score: -0.314797\n",
      "Iteration 3239, loss = 63.21639988\n",
      "Validation score: -0.313165\n",
      "Iteration 3240, loss = 63.13839851\n",
      "Validation score: -0.311525\n",
      "Iteration 3241, loss = 63.06078720\n",
      "Validation score: -0.309871\n",
      "Iteration 3242, loss = 62.98147419\n",
      "Validation score: -0.308219\n",
      "Iteration 3243, loss = 62.90504770\n",
      "Validation score: -0.306542\n",
      "Iteration 3244, loss = 62.82590098\n",
      "Validation score: -0.304904\n",
      "Iteration 3245, loss = 62.74699958\n",
      "Validation score: -0.303303\n",
      "Iteration 3246, loss = 62.67197621\n",
      "Validation score: -0.301678\n",
      "Iteration 3247, loss = 62.59427047\n",
      "Validation score: -0.300072\n",
      "Iteration 3248, loss = 62.51833943\n",
      "Validation score: -0.298462\n",
      "Iteration 3249, loss = 62.44182280\n",
      "Validation score: -0.296858\n",
      "Iteration 3250, loss = 62.36461093\n",
      "Validation score: -0.295281\n",
      "Iteration 3251, loss = 62.29183872\n",
      "Validation score: -0.293678\n",
      "Iteration 3252, loss = 62.21558468\n",
      "Validation score: -0.292103\n",
      "Iteration 3253, loss = 62.14067522\n",
      "Validation score: -0.290518\n",
      "Iteration 3254, loss = 62.06596197\n",
      "Validation score: -0.288954\n",
      "Iteration 3255, loss = 61.99058509\n",
      "Validation score: -0.287401\n",
      "Iteration 3256, loss = 61.91729324\n",
      "Validation score: -0.285827\n",
      "Iteration 3257, loss = 61.84373068\n",
      "Validation score: -0.284259\n",
      "Iteration 3258, loss = 61.77032776\n",
      "Validation score: -0.282667\n",
      "Iteration 3259, loss = 61.69296650\n",
      "Validation score: -0.281134\n",
      "Iteration 3260, loss = 61.62313797\n",
      "Validation score: -0.279563\n",
      "Iteration 3261, loss = 61.54862854\n",
      "Validation score: -0.278014\n",
      "Iteration 3262, loss = 61.47490712\n",
      "Validation score: -0.276497\n",
      "Iteration 3263, loss = 61.40133941\n",
      "Validation score: -0.274997\n",
      "Iteration 3264, loss = 61.33098635\n",
      "Validation score: -0.273470\n",
      "Iteration 3265, loss = 61.25902633\n",
      "Validation score: -0.271954\n",
      "Iteration 3266, loss = 61.18812055\n",
      "Validation score: -0.270437\n",
      "Iteration 3267, loss = 61.11778340\n",
      "Validation score: -0.268940\n",
      "Iteration 3268, loss = 61.04590368\n",
      "Validation score: -0.267495\n",
      "Iteration 3269, loss = 60.97729780\n",
      "Validation score: -0.266040\n",
      "Iteration 3270, loss = 60.90920405\n",
      "Validation score: -0.264593\n",
      "Iteration 3271, loss = 60.83930425\n",
      "Validation score: -0.263166\n",
      "Iteration 3272, loss = 60.77060584\n",
      "Validation score: -0.261726\n",
      "Iteration 3273, loss = 60.70237581\n",
      "Validation score: -0.260273\n",
      "Iteration 3274, loss = 60.63348931\n",
      "Validation score: -0.258826\n",
      "Iteration 3275, loss = 60.56504756\n",
      "Validation score: -0.257386\n",
      "Iteration 3276, loss = 60.49852611\n",
      "Validation score: -0.255931\n",
      "Iteration 3277, loss = 60.42942005\n",
      "Validation score: -0.254520\n",
      "Iteration 3278, loss = 60.36233363\n",
      "Validation score: -0.253120\n",
      "Iteration 3279, loss = 60.29667858\n",
      "Validation score: -0.251679\n",
      "Iteration 3280, loss = 60.22907880\n",
      "Validation score: -0.250265\n",
      "Iteration 3281, loss = 60.16365241\n",
      "Validation score: -0.248845\n",
      "Iteration 3282, loss = 60.09675304\n",
      "Validation score: -0.247461\n",
      "Iteration 3283, loss = 60.03070794\n",
      "Validation score: -0.246074\n",
      "Iteration 3284, loss = 59.96469644\n",
      "Validation score: -0.244672\n",
      "Iteration 3285, loss = 59.89813394\n",
      "Validation score: -0.243267\n",
      "Iteration 3286, loss = 59.83204102\n",
      "Validation score: -0.241854\n",
      "Iteration 3287, loss = 59.76708127\n",
      "Validation score: -0.240440\n",
      "Iteration 3288, loss = 59.70059831\n",
      "Validation score: -0.239050\n",
      "Iteration 3289, loss = 59.63568894\n",
      "Validation score: -0.237699\n",
      "Iteration 3290, loss = 59.57250921\n",
      "Validation score: -0.236340\n",
      "Iteration 3291, loss = 59.50713582\n",
      "Validation score: -0.235043\n",
      "Iteration 3292, loss = 59.44436039\n",
      "Validation score: -0.233742\n",
      "Iteration 3293, loss = 59.38461235\n",
      "Validation score: -0.232390\n",
      "Iteration 3294, loss = 59.31997327\n",
      "Validation score: -0.231076\n",
      "Iteration 3295, loss = 59.26012106\n",
      "Validation score: -0.229725\n",
      "Iteration 3296, loss = 59.19510317\n",
      "Validation score: -0.228443\n",
      "Iteration 3297, loss = 59.13263351\n",
      "Validation score: -0.227143\n",
      "Iteration 3298, loss = 59.06981376\n",
      "Validation score: -0.225816\n",
      "Iteration 3299, loss = 59.00884137\n",
      "Validation score: -0.224462\n",
      "Iteration 3300, loss = 58.94643542\n",
      "Validation score: -0.223115\n",
      "Iteration 3301, loss = 58.88434092\n",
      "Validation score: -0.221819\n",
      "Iteration 3302, loss = 58.82289604\n",
      "Validation score: -0.220538\n",
      "Iteration 3303, loss = 58.76243262\n",
      "Validation score: -0.219243\n",
      "Iteration 3304, loss = 58.70279251\n",
      "Validation score: -0.217959\n",
      "Iteration 3305, loss = 58.64045266\n",
      "Validation score: -0.216675\n",
      "Iteration 3306, loss = 58.58104229\n",
      "Validation score: -0.215385\n",
      "Iteration 3307, loss = 58.52182573\n",
      "Validation score: -0.214106\n",
      "Iteration 3308, loss = 58.46034402\n",
      "Validation score: -0.212863\n",
      "Iteration 3309, loss = 58.40264412\n",
      "Validation score: -0.211604\n",
      "Iteration 3310, loss = 58.34345614\n",
      "Validation score: -0.210338\n",
      "Iteration 3311, loss = 58.28456375\n",
      "Validation score: -0.209083\n",
      "Iteration 3312, loss = 58.22358144\n",
      "Validation score: -0.207895\n",
      "Iteration 3313, loss = 58.16604585\n",
      "Validation score: -0.206652\n",
      "Iteration 3314, loss = 58.10709057\n",
      "Validation score: -0.205418\n",
      "Iteration 3315, loss = 58.04936745\n",
      "Validation score: -0.204187\n",
      "Iteration 3316, loss = 57.99129721\n",
      "Validation score: -0.203018\n",
      "Iteration 3317, loss = 57.93542411\n",
      "Validation score: -0.201796\n",
      "Iteration 3318, loss = 57.87746006\n",
      "Validation score: -0.200571\n",
      "Iteration 3319, loss = 57.82007774\n",
      "Validation score: -0.199337\n",
      "Iteration 3320, loss = 57.76168863\n",
      "Validation score: -0.198117\n",
      "Iteration 3321, loss = 57.70344530\n",
      "Validation score: -0.196929\n",
      "Iteration 3322, loss = 57.64861798\n",
      "Validation score: -0.195687\n",
      "Iteration 3323, loss = 57.59072672\n",
      "Validation score: -0.194490\n",
      "Iteration 3324, loss = 57.53420413\n",
      "Validation score: -0.193274\n",
      "Iteration 3325, loss = 57.47937731\n",
      "Validation score: -0.192085\n",
      "Iteration 3326, loss = 57.42263533\n",
      "Validation score: -0.190919\n",
      "Iteration 3327, loss = 57.36692937\n",
      "Validation score: -0.189748\n",
      "Iteration 3328, loss = 57.31158481\n",
      "Validation score: -0.188582\n",
      "Iteration 3329, loss = 57.25558110\n",
      "Validation score: -0.187441\n",
      "Iteration 3330, loss = 57.20132348\n",
      "Validation score: -0.186261\n",
      "Iteration 3331, loss = 57.14653000\n",
      "Validation score: -0.185081\n",
      "Iteration 3332, loss = 57.08995187\n",
      "Validation score: -0.183937\n",
      "Iteration 3333, loss = 57.03758253\n",
      "Validation score: -0.182797\n",
      "Iteration 3334, loss = 56.98227586\n",
      "Validation score: -0.181669\n",
      "Iteration 3335, loss = 56.92741522\n",
      "Validation score: -0.180631\n",
      "Iteration 3336, loss = 56.87611236\n",
      "Validation score: -0.179545\n",
      "Iteration 3337, loss = 56.82276728\n",
      "Validation score: -0.178473\n",
      "Iteration 3338, loss = 56.76992578\n",
      "Validation score: -0.177381\n",
      "Iteration 3339, loss = 56.71831677\n",
      "Validation score: -0.176299\n",
      "Iteration 3340, loss = 56.66363840\n",
      "Validation score: -0.175281\n",
      "Iteration 3341, loss = 56.61185867\n",
      "Validation score: -0.174205\n",
      "Iteration 3342, loss = 56.55994037\n",
      "Validation score: -0.173146\n",
      "Iteration 3343, loss = 56.50723473\n",
      "Validation score: -0.172066\n",
      "Iteration 3344, loss = 56.45700032\n",
      "Validation score: -0.171022\n",
      "Iteration 3345, loss = 56.40511484\n",
      "Validation score: -0.169960\n",
      "Iteration 3346, loss = 56.35089979\n",
      "Validation score: -0.168876\n",
      "Iteration 3347, loss = 56.30133983\n",
      "Validation score: -0.167792\n",
      "Iteration 3348, loss = 56.24978437\n",
      "Validation score: -0.166758\n",
      "Iteration 3349, loss = 56.19831451\n",
      "Validation score: -0.165744\n",
      "Iteration 3350, loss = 56.14724766\n",
      "Validation score: -0.164758\n",
      "Iteration 3351, loss = 56.09602294\n",
      "Validation score: -0.163737\n",
      "Iteration 3352, loss = 56.04704621\n",
      "Validation score: -0.162711\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 3353, loss = 55.99614803\n",
      "Validation score: -0.161735\n",
      "Iteration 3354, loss = 55.94630263\n",
      "Validation score: -0.160645\n",
      "Iteration 3355, loss = 55.89673479\n",
      "Validation score: -0.159669\n",
      "Iteration 3356, loss = 55.84614278\n",
      "Validation score: -0.158679\n",
      "Iteration 3357, loss = 55.79761978\n",
      "Validation score: -0.157716\n",
      "Iteration 3358, loss = 55.74678202\n",
      "Validation score: -0.156739\n",
      "Iteration 3359, loss = 55.69660536\n",
      "Validation score: -0.155729\n",
      "Iteration 3360, loss = 55.64736692\n",
      "Validation score: -0.154697\n",
      "Iteration 3361, loss = 55.59760356\n",
      "Validation score: -0.153685\n",
      "Iteration 3362, loss = 55.54995441\n",
      "Validation score: -0.152680\n",
      "Iteration 3363, loss = 55.49987263\n",
      "Validation score: -0.151695\n",
      "Iteration 3364, loss = 55.45091137\n",
      "Validation score: -0.150835\n",
      "Iteration 3365, loss = 55.39909969\n",
      "Validation score: -0.149830\n",
      "Iteration 3366, loss = 55.35102511\n",
      "Validation score: -0.148785\n",
      "Iteration 3367, loss = 55.29997052\n",
      "Validation score: -0.147825\n",
      "Iteration 3368, loss = 55.25045757\n",
      "Validation score: -0.146817\n",
      "Iteration 3369, loss = 55.20141632\n",
      "Validation score: -0.145951\n",
      "Iteration 3370, loss = 55.14998693\n",
      "Validation score: -0.145015\n",
      "Iteration 3371, loss = 55.10283529\n",
      "Validation score: -0.144144\n",
      "Iteration 3372, loss = 55.05026555\n",
      "Validation score: -0.143257\n",
      "Iteration 3373, loss = 55.00247371\n",
      "Validation score: -0.142383\n",
      "Iteration 3374, loss = 54.95323526\n",
      "Validation score: -0.141503\n",
      "Iteration 3375, loss = 54.90408771\n",
      "Validation score: -0.140743\n",
      "Iteration 3376, loss = 54.85462272\n",
      "Validation score: -0.139914\n",
      "Iteration 3377, loss = 54.80527500\n",
      "Validation score: -0.139053\n",
      "Iteration 3378, loss = 54.75427225\n",
      "Validation score: -0.138228\n",
      "Iteration 3379, loss = 54.70854220\n",
      "Validation score: -0.137348\n",
      "Iteration 3380, loss = 54.65517176\n",
      "Validation score: -0.136393\n",
      "Iteration 3381, loss = 54.60842466\n",
      "Validation score: -0.135506\n",
      "Iteration 3382, loss = 54.55764525\n",
      "Validation score: -0.134634\n",
      "Iteration 3383, loss = 54.50871917\n",
      "Validation score: -0.133761\n",
      "Iteration 3384, loss = 54.45696001\n",
      "Validation score: -0.132943\n",
      "Iteration 3385, loss = 54.40934077\n",
      "Validation score: -0.132134\n",
      "Iteration 3386, loss = 54.35708037\n",
      "Validation score: -0.131098\n",
      "Iteration 3387, loss = 54.30701839\n",
      "Validation score: -0.130270\n",
      "Iteration 3388, loss = 54.25683587\n",
      "Validation score: -0.129331\n",
      "Iteration 3389, loss = 54.20719117\n",
      "Validation score: -0.128476\n",
      "Iteration 3390, loss = 54.15303485\n",
      "Validation score: -0.127670\n",
      "Iteration 3391, loss = 54.10422080\n",
      "Validation score: -0.126814\n",
      "Iteration 3392, loss = 54.05308734\n",
      "Validation score: -0.125926\n",
      "Iteration 3393, loss = 54.00044869\n",
      "Validation score: -0.125001\n",
      "Iteration 3394, loss = 53.95028617\n",
      "Validation score: -0.124070\n",
      "Iteration 3395, loss = 53.89727989\n",
      "Validation score: -0.123192\n",
      "Iteration 3396, loss = 53.84945263\n",
      "Validation score: -0.122516\n",
      "Iteration 3397, loss = 53.79191413\n",
      "Validation score: -0.121727\n",
      "Iteration 3398, loss = 53.74080978\n",
      "Validation score: -0.121045\n",
      "Iteration 3399, loss = 53.68858651\n",
      "Validation score: -0.120326\n",
      "Iteration 3400, loss = 53.63226898\n",
      "Validation score: -0.119534\n",
      "Iteration 3401, loss = 53.57796466\n",
      "Validation score: -0.118756\n",
      "Iteration 3402, loss = 53.52463305\n",
      "Validation score: -0.117921\n",
      "Iteration 3403, loss = 53.47178108\n",
      "Validation score: -0.117107\n",
      "Iteration 3404, loss = 53.42241837\n",
      "Validation score: -0.116473\n",
      "Iteration 3405, loss = 53.36158538\n",
      "Validation score: -0.115415\n",
      "Iteration 3406, loss = 53.31001012\n",
      "Validation score: -0.114563\n",
      "Iteration 3407, loss = 53.25567668\n",
      "Validation score: -0.113778\n",
      "Iteration 3408, loss = 53.19882496\n",
      "Validation score: -0.112825\n",
      "Iteration 3409, loss = 53.14490148\n",
      "Validation score: -0.111831\n",
      "Iteration 3410, loss = 53.09086048\n",
      "Validation score: -0.110783\n",
      "Iteration 3411, loss = 53.03780730\n",
      "Validation score: -0.109992\n",
      "Iteration 3412, loss = 52.97844497\n",
      "Validation score: -0.109189\n",
      "Iteration 3413, loss = 52.92120958\n",
      "Validation score: -0.108269\n",
      "Iteration 3414, loss = 52.86764151\n",
      "Validation score: -0.107523\n",
      "Iteration 3415, loss = 52.80776768\n",
      "Validation score: -0.106602\n",
      "Iteration 3416, loss = 52.74955630\n",
      "Validation score: -0.105504\n",
      "Iteration 3417, loss = 52.69403799\n",
      "Validation score: -0.104484\n",
      "Iteration 3418, loss = 52.63559161\n",
      "Validation score: -0.103624\n",
      "Iteration 3419, loss = 52.57791098\n",
      "Validation score: -0.102785\n",
      "Iteration 3420, loss = 52.52163724\n",
      "Validation score: -0.101916\n",
      "Iteration 3421, loss = 52.46074696\n",
      "Validation score: -0.100799\n",
      "Iteration 3422, loss = 52.40154093\n",
      "Validation score: -0.099752\n",
      "Iteration 3423, loss = 52.34052667\n",
      "Validation score: -0.098849\n",
      "Iteration 3424, loss = 52.28069972\n",
      "Validation score: -0.098064\n",
      "Iteration 3425, loss = 52.21758079\n",
      "Validation score: -0.097084\n",
      "Iteration 3426, loss = 52.15938841\n",
      "Validation score: -0.096066\n",
      "Iteration 3427, loss = 52.09461832\n",
      "Validation score: -0.095231\n",
      "Iteration 3428, loss = 52.03824681\n",
      "Validation score: -0.094497\n",
      "Iteration 3429, loss = 51.97111331\n",
      "Validation score: -0.093385\n",
      "Iteration 3430, loss = 51.90911576\n",
      "Validation score: -0.092418\n",
      "Iteration 3431, loss = 51.84690097\n",
      "Validation score: -0.091483\n",
      "Iteration 3432, loss = 51.78367530\n",
      "Validation score: -0.090550\n",
      "Iteration 3433, loss = 51.72739123\n",
      "Validation score: -0.089723\n",
      "Iteration 3434, loss = 51.65577509\n",
      "Validation score: -0.088465\n",
      "Iteration 3435, loss = 51.59344134\n",
      "Validation score: -0.087310\n",
      "Iteration 3436, loss = 51.52844468\n",
      "Validation score: -0.086106\n",
      "Iteration 3437, loss = 51.46184898\n",
      "Validation score: -0.085030\n",
      "Iteration 3438, loss = 51.39822161\n",
      "Validation score: -0.084132\n",
      "Iteration 3439, loss = 51.32853607\n",
      "Validation score: -0.082860\n",
      "Iteration 3440, loss = 51.26297977\n",
      "Validation score: -0.081776\n",
      "Iteration 3441, loss = 51.19775088\n",
      "Validation score: -0.080397\n",
      "Iteration 3442, loss = 51.12694917\n",
      "Validation score: -0.079133\n",
      "Iteration 3443, loss = 51.06405195\n",
      "Validation score: -0.078288\n",
      "Iteration 3444, loss = 50.99115621\n",
      "Validation score: -0.077115\n",
      "Iteration 3445, loss = 50.92238643\n",
      "Validation score: -0.075778\n",
      "Iteration 3446, loss = 50.85104154\n",
      "Validation score: -0.074691\n",
      "Iteration 3447, loss = 50.78321747\n",
      "Validation score: -0.073791\n",
      "Iteration 3448, loss = 50.71450543\n",
      "Validation score: -0.072816\n",
      "Iteration 3449, loss = 50.64574865\n",
      "Validation score: -0.071768\n",
      "Iteration 3450, loss = 50.57145597\n",
      "Validation score: -0.070264\n",
      "Iteration 3451, loss = 50.50334209\n",
      "Validation score: -0.068725\n",
      "Iteration 3452, loss = 50.43129479\n",
      "Validation score: -0.067361\n",
      "Iteration 3453, loss = 50.36150934\n",
      "Validation score: -0.066101\n",
      "Iteration 3454, loss = 50.28906177\n",
      "Validation score: -0.064771\n",
      "Iteration 3455, loss = 50.21568444\n",
      "Validation score: -0.063453\n",
      "Iteration 3456, loss = 50.14285632\n",
      "Validation score: -0.062120\n",
      "Iteration 3457, loss = 50.07244652\n",
      "Validation score: -0.060774\n",
      "Iteration 3458, loss = 49.99802491\n",
      "Validation score: -0.059265\n",
      "Iteration 3459, loss = 49.92475734\n",
      "Validation score: -0.057989\n",
      "Iteration 3460, loss = 49.84997944\n",
      "Validation score: -0.056628\n",
      "Iteration 3461, loss = 49.77760373\n",
      "Validation score: -0.055367\n",
      "Iteration 3462, loss = 49.70167391\n",
      "Validation score: -0.053666\n",
      "Iteration 3463, loss = 49.62434214\n",
      "Validation score: -0.052247\n",
      "Iteration 3464, loss = 49.54957882\n",
      "Validation score: -0.050750\n",
      "Iteration 3465, loss = 49.47335056\n",
      "Validation score: -0.049460\n",
      "Iteration 3466, loss = 49.39614088\n",
      "Validation score: -0.048242\n",
      "Iteration 3467, loss = 49.32090686\n",
      "Validation score: -0.046902\n",
      "Iteration 3468, loss = 49.24317324\n",
      "Validation score: -0.045348\n",
      "Iteration 3469, loss = 49.16699408\n",
      "Validation score: -0.044087\n",
      "Iteration 3470, loss = 49.08492019\n",
      "Validation score: -0.042694\n",
      "Iteration 3471, loss = 49.00782039\n",
      "Validation score: -0.041423\n",
      "Iteration 3472, loss = 48.92919094\n",
      "Validation score: -0.039973\n",
      "Iteration 3473, loss = 48.85300607\n",
      "Validation score: -0.038679\n",
      "Iteration 3474, loss = 48.77266986\n",
      "Validation score: -0.037039\n",
      "Iteration 3475, loss = 48.69358989\n",
      "Validation score: -0.035655\n",
      "Iteration 3476, loss = 48.61253397\n",
      "Validation score: -0.034080\n",
      "Iteration 3477, loss = 48.53148477\n",
      "Validation score: -0.032573\n",
      "Iteration 3478, loss = 48.45423661\n",
      "Validation score: -0.031192\n",
      "Iteration 3479, loss = 48.37208348\n",
      "Validation score: -0.029615\n",
      "Iteration 3480, loss = 48.29095055\n",
      "Validation score: -0.028170\n",
      "Iteration 3481, loss = 48.20957514\n",
      "Validation score: -0.026541\n",
      "Iteration 3482, loss = 48.13121434\n",
      "Validation score: -0.025122\n",
      "Iteration 3483, loss = 48.04727772\n",
      "Validation score: -0.023460\n",
      "Iteration 3484, loss = 47.96519779\n",
      "Validation score: -0.021885\n",
      "Iteration 3485, loss = 47.88690874\n",
      "Validation score: -0.020369\n",
      "Iteration 3486, loss = 47.80244892\n",
      "Validation score: -0.018666\n",
      "Iteration 3487, loss = 47.71987719\n",
      "Validation score: -0.017091\n",
      "Iteration 3488, loss = 47.63820603\n",
      "Validation score: -0.015497\n",
      "Iteration 3489, loss = 47.55786638\n",
      "Validation score: -0.013967\n",
      "Iteration 3490, loss = 47.47486684\n",
      "Validation score: -0.012411\n",
      "Iteration 3491, loss = 47.39463076\n",
      "Validation score: -0.010794\n",
      "Iteration 3492, loss = 47.31126806\n",
      "Validation score: -0.008954\n",
      "Iteration 3493, loss = 47.22956155\n",
      "Validation score: -0.007338\n",
      "Iteration 3494, loss = 47.14516562\n",
      "Validation score: -0.005566\n",
      "Iteration 3495, loss = 47.06372307\n",
      "Validation score: -0.003969\n",
      "Iteration 3496, loss = 46.98087206\n",
      "Validation score: -0.002445\n",
      "Iteration 3497, loss = 46.89852373\n",
      "Validation score: -0.000777\n",
      "Iteration 3498, loss = 46.81246851\n",
      "Validation score: 0.000813\n",
      "Iteration 3499, loss = 46.72934191\n",
      "Validation score: 0.002463\n",
      "Iteration 3500, loss = 46.64852849\n",
      "Validation score: 0.004284\n",
      "Iteration 3501, loss = 46.56135206\n",
      "Validation score: 0.005888\n",
      "Iteration 3502, loss = 46.48056687\n",
      "Validation score: 0.007428\n",
      "Iteration 3503, loss = 46.39575872\n",
      "Validation score: 0.009166\n",
      "Iteration 3504, loss = 46.31202110\n",
      "Validation score: 0.010864\n",
      "Iteration 3505, loss = 46.23125155\n",
      "Validation score: 0.012356\n",
      "Iteration 3506, loss = 46.14211861\n",
      "Validation score: 0.014086\n",
      "Iteration 3507, loss = 46.06162691\n",
      "Validation score: 0.015723\n",
      "Iteration 3508, loss = 45.98142749\n",
      "Validation score: 0.017349\n",
      "Iteration 3509, loss = 45.89701741\n",
      "Validation score: 0.019061\n",
      "Iteration 3510, loss = 45.81264589\n",
      "Validation score: 0.020834\n",
      "Iteration 3511, loss = 45.73091547\n",
      "Validation score: 0.022684\n",
      "Iteration 3512, loss = 45.64864825\n",
      "Validation score: 0.024399\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 3513, loss = 45.56230607\n",
      "Validation score: 0.026212\n",
      "Iteration 3514, loss = 45.48138224\n",
      "Validation score: 0.027971\n",
      "Iteration 3515, loss = 45.39671213\n",
      "Validation score: 0.029566\n",
      "Iteration 3516, loss = 45.31438502\n",
      "Validation score: 0.031268\n",
      "Iteration 3517, loss = 45.23233879\n",
      "Validation score: 0.033006\n",
      "Iteration 3518, loss = 45.15107919\n",
      "Validation score: 0.034713\n",
      "Iteration 3519, loss = 45.07023690\n",
      "Validation score: 0.036591\n",
      "Iteration 3520, loss = 44.98493024\n",
      "Validation score: 0.038336\n",
      "Iteration 3521, loss = 44.90501429\n",
      "Validation score: 0.040013\n",
      "Iteration 3522, loss = 44.82206644\n",
      "Validation score: 0.041714\n",
      "Iteration 3523, loss = 44.74181926\n",
      "Validation score: 0.043379\n",
      "Iteration 3524, loss = 44.65957678\n",
      "Validation score: 0.045103\n",
      "Iteration 3525, loss = 44.57789346\n",
      "Validation score: 0.047082\n",
      "Iteration 3526, loss = 44.49596679\n",
      "Validation score: 0.048949\n",
      "Iteration 3527, loss = 44.41258202\n",
      "Validation score: 0.050651\n",
      "Iteration 3528, loss = 44.33010716\n",
      "Validation score: 0.052360\n",
      "Iteration 3529, loss = 44.24723863\n",
      "Validation score: 0.054006\n",
      "Iteration 3530, loss = 44.16928039\n",
      "Validation score: 0.055699\n",
      "Iteration 3531, loss = 44.08419299\n",
      "Validation score: 0.057410\n",
      "Iteration 3532, loss = 44.01050241\n",
      "Validation score: 0.059086\n",
      "Iteration 3533, loss = 43.92410417\n",
      "Validation score: 0.060792\n",
      "Iteration 3534, loss = 43.84909745\n",
      "Validation score: 0.062341\n",
      "Iteration 3535, loss = 43.76637603\n",
      "Validation score: 0.064139\n",
      "Iteration 3536, loss = 43.68701712\n",
      "Validation score: 0.065849\n",
      "Iteration 3537, loss = 43.60794073\n",
      "Validation score: 0.067565\n",
      "Iteration 3538, loss = 43.52772814\n",
      "Validation score: 0.069262\n",
      "Iteration 3539, loss = 43.45255097\n",
      "Validation score: 0.070832\n",
      "Iteration 3540, loss = 43.36911516\n",
      "Validation score: 0.072523\n",
      "Iteration 3541, loss = 43.28992276\n",
      "Validation score: 0.074268\n",
      "Iteration 3542, loss = 43.21557328\n",
      "Validation score: 0.076014\n",
      "Iteration 3543, loss = 43.13745575\n",
      "Validation score: 0.077839\n",
      "Iteration 3544, loss = 43.05584023\n",
      "Validation score: 0.079670\n",
      "Iteration 3545, loss = 42.98065560\n",
      "Validation score: 0.081492\n",
      "Iteration 3546, loss = 42.90247366\n",
      "Validation score: 0.083222\n",
      "Iteration 3547, loss = 42.82438007\n",
      "Validation score: 0.084944\n",
      "Iteration 3548, loss = 42.74934951\n",
      "Validation score: 0.086671\n",
      "Iteration 3549, loss = 42.67418255\n",
      "Validation score: 0.088316\n",
      "Iteration 3550, loss = 42.59436491\n",
      "Validation score: 0.090035\n",
      "Iteration 3551, loss = 42.51661113\n",
      "Validation score: 0.091601\n",
      "Iteration 3552, loss = 42.44095400\n",
      "Validation score: 0.093257\n",
      "Iteration 3553, loss = 42.36328461\n",
      "Validation score: 0.095061\n",
      "Iteration 3554, loss = 42.28613054\n",
      "Validation score: 0.096764\n",
      "Iteration 3555, loss = 42.21335788\n",
      "Validation score: 0.098470\n",
      "Iteration 3556, loss = 42.13698343\n",
      "Validation score: 0.100156\n",
      "Iteration 3557, loss = 42.06301258\n",
      "Validation score: 0.101732\n",
      "Iteration 3558, loss = 41.98826042\n",
      "Validation score: 0.103349\n",
      "Iteration 3559, loss = 41.91607152\n",
      "Validation score: 0.104980\n",
      "Iteration 3560, loss = 41.84180388\n",
      "Validation score: 0.106568\n",
      "Iteration 3561, loss = 41.76629470\n",
      "Validation score: 0.108339\n",
      "Iteration 3562, loss = 41.69335936\n",
      "Validation score: 0.110013\n",
      "Iteration 3563, loss = 41.62219247\n",
      "Validation score: 0.111718\n",
      "Iteration 3564, loss = 41.54977161\n",
      "Validation score: 0.113389\n",
      "Iteration 3565, loss = 41.47644553\n",
      "Validation score: 0.114983\n",
      "Iteration 3566, loss = 41.40082904\n",
      "Validation score: 0.116495\n",
      "Iteration 3567, loss = 41.32843092\n",
      "Validation score: 0.117979\n",
      "Iteration 3568, loss = 41.25647753\n",
      "Validation score: 0.119433\n",
      "Iteration 3569, loss = 41.18736058\n",
      "Validation score: 0.120838\n",
      "Iteration 3570, loss = 41.11371951\n",
      "Validation score: 0.122462\n",
      "Iteration 3571, loss = 41.04307862\n",
      "Validation score: 0.124027\n",
      "Iteration 3572, loss = 40.97050618\n",
      "Validation score: 0.125627\n",
      "Iteration 3573, loss = 40.89978883\n",
      "Validation score: 0.127178\n",
      "Iteration 3574, loss = 40.82863522\n",
      "Validation score: 0.128770\n",
      "Iteration 3575, loss = 40.76159083\n",
      "Validation score: 0.130483\n",
      "Iteration 3576, loss = 40.68720231\n",
      "Validation score: 0.132074\n",
      "Iteration 3577, loss = 40.62128836\n",
      "Validation score: 0.133644\n",
      "Iteration 3578, loss = 40.55043019\n",
      "Validation score: 0.135132\n",
      "Iteration 3579, loss = 40.48186133\n",
      "Validation score: 0.136631\n",
      "Iteration 3580, loss = 40.41420524\n",
      "Validation score: 0.138142\n",
      "Iteration 3581, loss = 40.34509859\n",
      "Validation score: 0.139641\n",
      "Iteration 3582, loss = 40.27744446\n",
      "Validation score: 0.141156\n",
      "Iteration 3583, loss = 40.20895130\n",
      "Validation score: 0.142689\n",
      "Iteration 3584, loss = 40.14241907\n",
      "Validation score: 0.144139\n",
      "Iteration 3585, loss = 40.07484913\n",
      "Validation score: 0.145628\n",
      "Iteration 3586, loss = 40.00733054\n",
      "Validation score: 0.147138\n",
      "Iteration 3587, loss = 39.94190368\n",
      "Validation score: 0.148582\n",
      "Iteration 3588, loss = 39.87577339\n",
      "Validation score: 0.150101\n",
      "Iteration 3589, loss = 39.81297098\n",
      "Validation score: 0.151676\n",
      "Iteration 3590, loss = 39.74446816\n",
      "Validation score: 0.153181\n",
      "Iteration 3591, loss = 39.68026094\n",
      "Validation score: 0.154594\n",
      "Iteration 3592, loss = 39.61386322\n",
      "Validation score: 0.156093\n",
      "Iteration 3593, loss = 39.54821246\n",
      "Validation score: 0.157608\n",
      "Iteration 3594, loss = 39.48320610\n",
      "Validation score: 0.159031\n",
      "Iteration 3595, loss = 39.41909002\n",
      "Validation score: 0.160396\n",
      "Iteration 3596, loss = 39.35517152\n",
      "Validation score: 0.161826\n",
      "Iteration 3597, loss = 39.28988337\n",
      "Validation score: 0.163166\n",
      "Iteration 3598, loss = 39.22990348\n",
      "Validation score: 0.164440\n",
      "Iteration 3599, loss = 39.16367289\n",
      "Validation score: 0.165817\n",
      "Iteration 3600, loss = 39.10035224\n",
      "Validation score: 0.167172\n",
      "Iteration 3601, loss = 39.03781186\n",
      "Validation score: 0.168556\n",
      "Iteration 3602, loss = 38.97764318\n",
      "Validation score: 0.170034\n",
      "Iteration 3603, loss = 38.91270068\n",
      "Validation score: 0.171430\n",
      "Iteration 3604, loss = 38.85163431\n",
      "Validation score: 0.172801\n",
      "Iteration 3605, loss = 38.78756746\n",
      "Validation score: 0.174079\n",
      "Iteration 3606, loss = 38.72821757\n",
      "Validation score: 0.175392\n",
      "Iteration 3607, loss = 38.66819665\n",
      "Validation score: 0.176787\n",
      "Iteration 3608, loss = 38.60895953\n",
      "Validation score: 0.178164\n",
      "Iteration 3609, loss = 38.54657159\n",
      "Validation score: 0.179465\n",
      "Iteration 3610, loss = 38.48982445\n",
      "Validation score: 0.180693\n",
      "Iteration 3611, loss = 38.43389040\n",
      "Validation score: 0.181961\n",
      "Iteration 3612, loss = 38.36834889\n",
      "Validation score: 0.183339\n",
      "Iteration 3613, loss = 38.30911711\n",
      "Validation score: 0.184709\n",
      "Iteration 3614, loss = 38.24811128\n",
      "Validation score: 0.186012\n",
      "Iteration 3615, loss = 38.18961534\n",
      "Validation score: 0.187325\n",
      "Iteration 3616, loss = 38.13101603\n",
      "Validation score: 0.188695\n",
      "Iteration 3617, loss = 38.07348802\n",
      "Validation score: 0.190043\n",
      "Iteration 3618, loss = 38.01726531\n",
      "Validation score: 0.191290\n",
      "Iteration 3619, loss = 37.95865268\n",
      "Validation score: 0.192623\n",
      "Iteration 3620, loss = 37.90098245\n",
      "Validation score: 0.193848\n",
      "Iteration 3621, loss = 37.84384851\n",
      "Validation score: 0.195142\n",
      "Iteration 3622, loss = 37.78540870\n",
      "Validation score: 0.196385\n",
      "Iteration 3623, loss = 37.73112106\n",
      "Validation score: 0.197670\n",
      "Iteration 3624, loss = 37.67233252\n",
      "Validation score: 0.198909\n",
      "Iteration 3625, loss = 37.61859800\n",
      "Validation score: 0.200139\n",
      "Iteration 3626, loss = 37.56094864\n",
      "Validation score: 0.201320\n",
      "Iteration 3627, loss = 37.50744287\n",
      "Validation score: 0.202549\n",
      "Iteration 3628, loss = 37.44971387\n",
      "Validation score: 0.203749\n",
      "Iteration 3629, loss = 37.39631064\n",
      "Validation score: 0.204877\n",
      "Iteration 3630, loss = 37.34337886\n",
      "Validation score: 0.206122\n",
      "Iteration 3631, loss = 37.28721207\n",
      "Validation score: 0.207294\n",
      "Iteration 3632, loss = 37.23329831\n",
      "Validation score: 0.208463\n",
      "Iteration 3633, loss = 37.18049367\n",
      "Validation score: 0.209709\n",
      "Iteration 3634, loss = 37.12389140\n",
      "Validation score: 0.210950\n",
      "Iteration 3635, loss = 37.07138129\n",
      "Validation score: 0.212173\n",
      "Iteration 3636, loss = 37.01724727\n",
      "Validation score: 0.213442\n",
      "Iteration 3637, loss = 36.96499241\n",
      "Validation score: 0.214692\n",
      "Iteration 3638, loss = 36.90811375\n",
      "Validation score: 0.215898\n",
      "Iteration 3639, loss = 36.85708897\n",
      "Validation score: 0.217110\n",
      "Iteration 3640, loss = 36.80420247\n",
      "Validation score: 0.218284\n",
      "Iteration 3641, loss = 36.75342077\n",
      "Validation score: 0.219498\n",
      "Iteration 3642, loss = 36.69877823\n",
      "Validation score: 0.220599\n",
      "Iteration 3643, loss = 36.64515401\n",
      "Validation score: 0.221683\n",
      "Iteration 3644, loss = 36.59343047\n",
      "Validation score: 0.222826\n",
      "Iteration 3645, loss = 36.54155945\n",
      "Validation score: 0.223941\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 3646, loss = 36.49016137\n",
      "Validation score: 0.225058\n",
      "Iteration 3647, loss = 36.43800289\n",
      "Validation score: 0.226173\n",
      "Iteration 3648, loss = 36.38795247\n",
      "Validation score: 0.227306\n",
      "Iteration 3649, loss = 36.33691538\n",
      "Validation score: 0.228435\n",
      "Iteration 3650, loss = 36.28611131\n",
      "Validation score: 0.229569\n",
      "Iteration 3651, loss = 36.23712424\n",
      "Validation score: 0.230753\n",
      "Iteration 3652, loss = 36.18505938\n",
      "Validation score: 0.231867\n",
      "Iteration 3653, loss = 36.14003498\n",
      "Validation score: 0.233023\n",
      "Iteration 3654, loss = 36.08832421\n",
      "Validation score: 0.234121\n",
      "Iteration 3655, loss = 36.03801830\n",
      "Validation score: 0.235174\n",
      "Iteration 3656, loss = 35.98951792\n",
      "Validation score: 0.236254\n",
      "Iteration 3657, loss = 35.94021629\n",
      "Validation score: 0.237360\n",
      "Iteration 3658, loss = 35.89142289\n",
      "Validation score: 0.238456\n",
      "Iteration 3659, loss = 35.84385253\n",
      "Validation score: 0.239522\n",
      "Iteration 3660, loss = 35.79417242\n",
      "Validation score: 0.240623\n",
      "Iteration 3661, loss = 35.74936945\n",
      "Validation score: 0.241627\n",
      "Iteration 3662, loss = 35.69933978\n",
      "Validation score: 0.242670\n",
      "Iteration 3663, loss = 35.65170018\n",
      "Validation score: 0.243712\n",
      "Iteration 3664, loss = 35.60518564\n",
      "Validation score: 0.244793\n",
      "Iteration 3665, loss = 35.55668990\n",
      "Validation score: 0.245824\n",
      "Iteration 3666, loss = 35.51174320\n",
      "Validation score: 0.246858\n",
      "Iteration 3667, loss = 35.46245357\n",
      "Validation score: 0.247910\n",
      "Iteration 3668, loss = 35.41827032\n",
      "Validation score: 0.248992\n",
      "Iteration 3669, loss = 35.37537216\n",
      "Validation score: 0.250079\n",
      "Iteration 3670, loss = 35.32688220\n",
      "Validation score: 0.251004\n",
      "Iteration 3671, loss = 35.28156812\n",
      "Validation score: 0.252049\n",
      "Iteration 3672, loss = 35.23494108\n",
      "Validation score: 0.253086\n",
      "Iteration 3673, loss = 35.18941630\n",
      "Validation score: 0.254081\n",
      "Iteration 3674, loss = 35.14773787\n",
      "Validation score: 0.255160\n",
      "Iteration 3675, loss = 35.10060037\n",
      "Validation score: 0.256150\n",
      "Iteration 3676, loss = 35.05715342\n",
      "Validation score: 0.257073\n",
      "Iteration 3677, loss = 35.01137535\n",
      "Validation score: 0.258048\n",
      "Iteration 3678, loss = 34.97135381\n",
      "Validation score: 0.258957\n",
      "Iteration 3679, loss = 34.92253587\n",
      "Validation score: 0.259891\n",
      "Iteration 3680, loss = 34.88103322\n",
      "Validation score: 0.260831\n",
      "Iteration 3681, loss = 34.83473529\n",
      "Validation score: 0.261891\n",
      "Iteration 3682, loss = 34.79208821\n",
      "Validation score: 0.262950\n",
      "Iteration 3683, loss = 34.74761639\n",
      "Validation score: 0.263930\n",
      "Iteration 3684, loss = 34.70425652\n",
      "Validation score: 0.264879\n",
      "Iteration 3685, loss = 34.66189007\n",
      "Validation score: 0.265821\n",
      "Iteration 3686, loss = 34.61843660\n",
      "Validation score: 0.266760\n",
      "Iteration 3687, loss = 34.57669204\n",
      "Validation score: 0.267674\n",
      "Iteration 3688, loss = 34.53384077\n",
      "Validation score: 0.268633\n",
      "Iteration 3689, loss = 34.49052749\n",
      "Validation score: 0.269574\n",
      "Iteration 3690, loss = 34.44850408\n",
      "Validation score: 0.270521\n",
      "Iteration 3691, loss = 34.40694871\n",
      "Validation score: 0.271442\n",
      "Iteration 3692, loss = 34.36431401\n",
      "Validation score: 0.272324\n",
      "Iteration 3693, loss = 34.32406983\n",
      "Validation score: 0.273283\n",
      "Iteration 3694, loss = 34.28332740\n",
      "Validation score: 0.274221\n",
      "Iteration 3695, loss = 34.24078721\n",
      "Validation score: 0.275097\n",
      "Iteration 3696, loss = 34.19780741\n",
      "Validation score: 0.275922\n",
      "Iteration 3697, loss = 34.15995662\n",
      "Validation score: 0.276858\n",
      "Iteration 3698, loss = 34.11828974\n",
      "Validation score: 0.277731\n",
      "Iteration 3699, loss = 34.07573046\n",
      "Validation score: 0.278656\n",
      "Iteration 3700, loss = 34.03733351\n",
      "Validation score: 0.279569\n",
      "Iteration 3701, loss = 33.99903365\n",
      "Validation score: 0.280377\n",
      "Iteration 3702, loss = 33.95703806\n",
      "Validation score: 0.281189\n",
      "Iteration 3703, loss = 33.91681804\n",
      "Validation score: 0.282041\n",
      "Iteration 3704, loss = 33.87511700\n",
      "Validation score: 0.283021\n",
      "Iteration 3705, loss = 33.83762231\n",
      "Validation score: 0.283978\n",
      "Iteration 3706, loss = 33.79553215\n",
      "Validation score: 0.284825\n",
      "Iteration 3707, loss = 33.75910271\n",
      "Validation score: 0.285734\n",
      "Iteration 3708, loss = 33.71948533\n",
      "Validation score: 0.286549\n",
      "Iteration 3709, loss = 33.67900329\n",
      "Validation score: 0.287397\n",
      "Iteration 3710, loss = 33.64190916\n",
      "Validation score: 0.288288\n",
      "Iteration 3711, loss = 33.60357144\n",
      "Validation score: 0.289089\n",
      "Iteration 3712, loss = 33.56519846\n",
      "Validation score: 0.289951\n",
      "Iteration 3713, loss = 33.52685132\n",
      "Validation score: 0.290783\n",
      "Iteration 3714, loss = 33.49157589\n",
      "Validation score: 0.291496\n",
      "Iteration 3715, loss = 33.45218595\n",
      "Validation score: 0.292322\n",
      "Iteration 3716, loss = 33.41355201\n",
      "Validation score: 0.293198\n",
      "Iteration 3717, loss = 33.37579371\n",
      "Validation score: 0.294051\n",
      "Iteration 3718, loss = 33.34034022\n",
      "Validation score: 0.294874\n",
      "Iteration 3719, loss = 33.30180796\n",
      "Validation score: 0.295679\n",
      "Iteration 3720, loss = 33.26749260\n",
      "Validation score: 0.296420\n",
      "Iteration 3721, loss = 33.22809996\n",
      "Validation score: 0.297227\n",
      "Iteration 3722, loss = 33.19051005\n",
      "Validation score: 0.297963\n",
      "Iteration 3723, loss = 33.15490187\n",
      "Validation score: 0.298732\n",
      "Iteration 3724, loss = 33.11895651\n",
      "Validation score: 0.299501\n",
      "Iteration 3725, loss = 33.08400969\n",
      "Validation score: 0.300359\n",
      "Iteration 3726, loss = 33.04710165\n",
      "Validation score: 0.301222\n",
      "Iteration 3727, loss = 33.01019474\n",
      "Validation score: 0.302050\n",
      "Iteration 3728, loss = 32.97416540\n",
      "Validation score: 0.302814\n",
      "Iteration 3729, loss = 32.94084355\n",
      "Validation score: 0.303616\n",
      "Iteration 3730, loss = 32.90602926\n",
      "Validation score: 0.304267\n",
      "Iteration 3731, loss = 32.87124511\n",
      "Validation score: 0.304936\n",
      "Iteration 3732, loss = 32.83457650\n",
      "Validation score: 0.305696\n",
      "Iteration 3733, loss = 32.80001024\n",
      "Validation score: 0.306455\n",
      "Iteration 3734, loss = 32.76486205\n",
      "Validation score: 0.307193\n",
      "Iteration 3735, loss = 32.73001994\n",
      "Validation score: 0.308051\n",
      "Iteration 3736, loss = 32.69292697\n",
      "Validation score: 0.308826\n",
      "Iteration 3737, loss = 32.65664725\n",
      "Validation score: 0.309642\n",
      "Iteration 3738, loss = 32.62357833\n",
      "Validation score: 0.310496\n",
      "Iteration 3739, loss = 32.58793917\n",
      "Validation score: 0.311352\n",
      "Iteration 3740, loss = 32.55684803\n",
      "Validation score: 0.312174\n",
      "Iteration 3741, loss = 32.51910941\n",
      "Validation score: 0.312894\n",
      "Iteration 3742, loss = 32.48588258\n",
      "Validation score: 0.313584\n",
      "Iteration 3743, loss = 32.45123735\n",
      "Validation score: 0.314333\n",
      "Iteration 3744, loss = 32.41728054\n",
      "Validation score: 0.315111\n",
      "Iteration 3745, loss = 32.38551926\n",
      "Validation score: 0.315818\n",
      "Iteration 3746, loss = 32.35097622\n",
      "Validation score: 0.316544\n",
      "Iteration 3747, loss = 32.31791821\n",
      "Validation score: 0.317282\n",
      "Iteration 3748, loss = 32.28504536\n",
      "Validation score: 0.318024\n",
      "Iteration 3749, loss = 32.25184587\n",
      "Validation score: 0.318745\n",
      "Iteration 3750, loss = 32.21947901\n",
      "Validation score: 0.319515\n",
      "Iteration 3751, loss = 32.18734099\n",
      "Validation score: 0.320233\n",
      "Iteration 3752, loss = 32.15275104\n",
      "Validation score: 0.320931\n",
      "Iteration 3753, loss = 32.12293605\n",
      "Validation score: 0.321672\n",
      "Iteration 3754, loss = 32.09010295\n",
      "Validation score: 0.322366\n",
      "Iteration 3755, loss = 32.05634154\n",
      "Validation score: 0.323017\n",
      "Iteration 3756, loss = 32.02619781\n",
      "Validation score: 0.323687\n",
      "Iteration 3757, loss = 31.99160415\n",
      "Validation score: 0.324404\n",
      "Iteration 3758, loss = 31.95915513\n",
      "Validation score: 0.325088\n",
      "Iteration 3759, loss = 31.92704265\n",
      "Validation score: 0.325728\n",
      "Iteration 3760, loss = 31.89331313\n",
      "Validation score: 0.326384\n",
      "Iteration 3761, loss = 31.86170631\n",
      "Validation score: 0.326971\n",
      "Iteration 3762, loss = 31.83566018\n",
      "Validation score: 0.327519\n",
      "Iteration 3763, loss = 31.79856137\n",
      "Validation score: 0.328224\n",
      "Iteration 3764, loss = 31.76818874\n",
      "Validation score: 0.328962\n",
      "Iteration 3765, loss = 31.73570440\n",
      "Validation score: 0.329798\n",
      "Iteration 3766, loss = 31.70219902\n",
      "Validation score: 0.330560\n",
      "Iteration 3767, loss = 31.67148258\n",
      "Validation score: 0.331299\n",
      "Iteration 3768, loss = 31.64133564\n",
      "Validation score: 0.332007\n",
      "Iteration 3769, loss = 31.61085899\n",
      "Validation score: 0.332730\n",
      "Iteration 3770, loss = 31.57970439\n",
      "Validation score: 0.333400\n",
      "Iteration 3771, loss = 31.54879287\n",
      "Validation score: 0.334010\n",
      "Iteration 3772, loss = 31.51829390\n",
      "Validation score: 0.334687\n",
      "Iteration 3773, loss = 31.48808126\n",
      "Validation score: 0.335328\n",
      "Iteration 3774, loss = 31.46181117\n",
      "Validation score: 0.336001\n",
      "Iteration 3775, loss = 31.42972262\n",
      "Validation score: 0.336615\n",
      "Iteration 3776, loss = 31.40025821\n",
      "Validation score: 0.337230\n",
      "Iteration 3777, loss = 31.37037323\n",
      "Validation score: 0.337826\n",
      "Iteration 3778, loss = 31.33821316\n",
      "Validation score: 0.338446\n",
      "Iteration 3779, loss = 31.30878547\n",
      "Validation score: 0.339073\n",
      "Iteration 3780, loss = 31.27853603\n",
      "Validation score: 0.339646\n",
      "Iteration 3781, loss = 31.25003616\n",
      "Validation score: 0.340274\n",
      "Iteration 3782, loss = 31.21862771\n",
      "Validation score: 0.340845\n",
      "Iteration 3783, loss = 31.19156733\n",
      "Validation score: 0.341370\n",
      "Iteration 3784, loss = 31.15970480\n",
      "Validation score: 0.341974\n",
      "Iteration 3785, loss = 31.13072940\n",
      "Validation score: 0.342571\n",
      "Iteration 3786, loss = 31.10216919\n",
      "Validation score: 0.343192\n",
      "Iteration 3787, loss = 31.07320269\n",
      "Validation score: 0.343796\n",
      "Iteration 3788, loss = 31.04583191\n",
      "Validation score: 0.344403\n",
      "Iteration 3789, loss = 31.01524254\n",
      "Validation score: 0.345007\n",
      "Iteration 3790, loss = 30.98923504\n",
      "Validation score: 0.345527\n",
      "Iteration 3791, loss = 30.95897330\n",
      "Validation score: 0.346148\n",
      "Iteration 3792, loss = 30.93119052\n",
      "Validation score: 0.346795\n",
      "Iteration 3793, loss = 30.90374309\n",
      "Validation score: 0.347423\n",
      "Iteration 3794, loss = 30.87260970\n",
      "Validation score: 0.348081\n",
      "Iteration 3795, loss = 30.84414445\n",
      "Validation score: 0.348740\n",
      "Iteration 3796, loss = 30.81718178\n",
      "Validation score: 0.349470\n",
      "Iteration 3797, loss = 30.78872677\n",
      "Validation score: 0.350083\n",
      "Iteration 3798, loss = 30.76094805\n",
      "Validation score: 0.350701\n",
      "Iteration 3799, loss = 30.73336468\n",
      "Validation score: 0.351263\n",
      "Iteration 3800, loss = 30.70632597\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation score: 0.351820\n",
      "Iteration 3801, loss = 30.67983922\n",
      "Validation score: 0.352378\n",
      "Iteration 3802, loss = 30.65183391\n",
      "Validation score: 0.352961\n",
      "Iteration 3803, loss = 30.62395608\n",
      "Validation score: 0.353591\n",
      "Iteration 3804, loss = 30.59789521\n",
      "Validation score: 0.354176\n",
      "Iteration 3805, loss = 30.57148397\n",
      "Validation score: 0.354669\n",
      "Iteration 3806, loss = 30.54537217\n",
      "Validation score: 0.355189\n",
      "Iteration 3807, loss = 30.51696447\n",
      "Validation score: 0.355768\n",
      "Iteration 3808, loss = 30.48942673\n",
      "Validation score: 0.356329\n",
      "Iteration 3809, loss = 30.46165014\n",
      "Validation score: 0.356854\n",
      "Iteration 3810, loss = 30.43593267\n",
      "Validation score: 0.357351\n",
      "Iteration 3811, loss = 30.40898480\n",
      "Validation score: 0.357878\n",
      "Iteration 3812, loss = 30.38166467\n",
      "Validation score: 0.358439\n",
      "Iteration 3813, loss = 30.35611121\n",
      "Validation score: 0.358963\n",
      "Iteration 3814, loss = 30.33035682\n",
      "Validation score: 0.359446\n",
      "Iteration 3815, loss = 30.30254301\n",
      "Validation score: 0.360058\n",
      "Iteration 3816, loss = 30.27512435\n",
      "Validation score: 0.360722\n",
      "Iteration 3817, loss = 30.24818694\n",
      "Validation score: 0.361324\n",
      "Iteration 3818, loss = 30.22181086\n",
      "Validation score: 0.361836\n",
      "Iteration 3819, loss = 30.19592238\n",
      "Validation score: 0.362371\n",
      "Iteration 3820, loss = 30.17120794\n",
      "Validation score: 0.363015\n",
      "Iteration 3821, loss = 30.14372248\n",
      "Validation score: 0.363570\n",
      "Iteration 3822, loss = 30.12247674\n",
      "Validation score: 0.364246\n",
      "Iteration 3823, loss = 30.09499345\n",
      "Validation score: 0.364743\n",
      "Iteration 3824, loss = 30.06562498\n",
      "Validation score: 0.365257\n",
      "Iteration 3825, loss = 30.04608049\n",
      "Validation score: 0.365874\n",
      "Iteration 3826, loss = 30.01567647\n",
      "Validation score: 0.366373\n",
      "Iteration 3827, loss = 29.99287162\n",
      "Validation score: 0.366821\n",
      "Iteration 3828, loss = 29.96541963\n",
      "Validation score: 0.367354\n",
      "Iteration 3829, loss = 29.94048098\n",
      "Validation score: 0.367868\n",
      "Iteration 3830, loss = 29.91753081\n",
      "Validation score: 0.368256\n",
      "Iteration 3831, loss = 29.88938451\n",
      "Validation score: 0.368725\n",
      "Iteration 3832, loss = 29.86416147\n",
      "Validation score: 0.369156\n",
      "Iteration 3833, loss = 29.83964863\n",
      "Validation score: 0.369710\n",
      "Iteration 3834, loss = 29.81519327\n",
      "Validation score: 0.370297\n",
      "Iteration 3835, loss = 29.79092578\n",
      "Validation score: 0.370776\n",
      "Iteration 3836, loss = 29.76735606\n",
      "Validation score: 0.371369\n",
      "Iteration 3837, loss = 29.74382645\n",
      "Validation score: 0.371911\n",
      "Iteration 3838, loss = 29.71805401\n",
      "Validation score: 0.372381\n",
      "Iteration 3839, loss = 29.69642090\n",
      "Validation score: 0.372878\n",
      "Iteration 3840, loss = 29.67053151\n",
      "Validation score: 0.373297\n",
      "Iteration 3841, loss = 29.64727212\n",
      "Validation score: 0.373663\n",
      "Iteration 3842, loss = 29.62494159\n",
      "Validation score: 0.374086\n",
      "Iteration 3843, loss = 29.60015485\n",
      "Validation score: 0.374687\n",
      "Iteration 3844, loss = 29.57426037\n",
      "Validation score: 0.375181\n",
      "Iteration 3845, loss = 29.55095865\n",
      "Validation score: 0.375610\n",
      "Iteration 3846, loss = 29.52751909\n",
      "Validation score: 0.376127\n",
      "Iteration 3847, loss = 29.50286520\n",
      "Validation score: 0.376641\n",
      "Iteration 3848, loss = 29.47753094\n",
      "Validation score: 0.377217\n",
      "Iteration 3849, loss = 29.45773663\n",
      "Validation score: 0.377798\n",
      "Iteration 3850, loss = 29.43054755\n",
      "Validation score: 0.378330\n",
      "Iteration 3851, loss = 29.40687630\n",
      "Validation score: 0.378871\n",
      "Iteration 3852, loss = 29.38506666\n",
      "Validation score: 0.379396\n",
      "Iteration 3853, loss = 29.36305466\n",
      "Validation score: 0.379755\n",
      "Iteration 3854, loss = 29.33894787\n",
      "Validation score: 0.380281\n",
      "Iteration 3855, loss = 29.31380872\n",
      "Validation score: 0.380693\n",
      "Iteration 3856, loss = 29.28736611\n",
      "Validation score: 0.381225\n",
      "Iteration 3857, loss = 29.26533695\n",
      "Validation score: 0.381725\n",
      "Iteration 3858, loss = 29.24613967\n",
      "Validation score: 0.382198\n",
      "Iteration 3859, loss = 29.22254336\n",
      "Validation score: 0.382620\n",
      "Iteration 3860, loss = 29.20311567\n",
      "Validation score: 0.383063\n",
      "Iteration 3861, loss = 29.18045874\n",
      "Validation score: 0.383496\n",
      "Iteration 3862, loss = 29.15676034\n",
      "Validation score: 0.383914\n",
      "Iteration 3863, loss = 29.13594591\n",
      "Validation score: 0.384313\n",
      "Iteration 3864, loss = 29.11012393\n",
      "Validation score: 0.384816\n",
      "Iteration 3865, loss = 29.08984241\n",
      "Validation score: 0.385189\n",
      "Iteration 3866, loss = 29.06369450\n",
      "Validation score: 0.385671\n",
      "Iteration 3867, loss = 29.04158790\n",
      "Validation score: 0.386103\n",
      "Iteration 3868, loss = 29.01928116\n",
      "Validation score: 0.386486\n",
      "Iteration 3869, loss = 28.99865205\n",
      "Validation score: 0.386826\n",
      "Iteration 3870, loss = 28.97749874\n",
      "Validation score: 0.387287\n",
      "Iteration 3871, loss = 28.95477864\n",
      "Validation score: 0.387737\n",
      "Iteration 3872, loss = 28.93422197\n",
      "Validation score: 0.388250\n",
      "Iteration 3873, loss = 28.90952565\n",
      "Validation score: 0.388694\n",
      "Iteration 3874, loss = 28.89055792\n",
      "Validation score: 0.389157\n",
      "Iteration 3875, loss = 28.86772911\n",
      "Validation score: 0.389509\n",
      "Iteration 3876, loss = 28.84517564\n",
      "Validation score: 0.389945\n",
      "Iteration 3877, loss = 28.82420992\n",
      "Validation score: 0.390440\n",
      "Iteration 3878, loss = 28.80260736\n",
      "Validation score: 0.390898\n",
      "Iteration 3879, loss = 28.78082645\n",
      "Validation score: 0.391355\n",
      "Iteration 3880, loss = 28.76011830\n",
      "Validation score: 0.391793\n",
      "Iteration 3881, loss = 28.73959168\n",
      "Validation score: 0.392172\n",
      "Iteration 3882, loss = 28.71819708\n",
      "Validation score: 0.392623\n",
      "Iteration 3883, loss = 28.69652115\n",
      "Validation score: 0.393049\n",
      "Iteration 3884, loss = 28.67655007\n",
      "Validation score: 0.393488\n",
      "Iteration 3885, loss = 28.65347540\n",
      "Validation score: 0.393933\n",
      "Iteration 3886, loss = 28.63364504\n",
      "Validation score: 0.394441\n",
      "Iteration 3887, loss = 28.61384132\n",
      "Validation score: 0.394861\n",
      "Iteration 3888, loss = 28.59175634\n",
      "Validation score: 0.395281\n",
      "Iteration 3889, loss = 28.57070678\n",
      "Validation score: 0.395710\n",
      "Iteration 3890, loss = 28.54857965\n",
      "Validation score: 0.396071\n",
      "Iteration 3891, loss = 28.53297801\n",
      "Validation score: 0.396388\n",
      "Iteration 3892, loss = 28.50698895\n",
      "Validation score: 0.396791\n",
      "Iteration 3893, loss = 28.48679900\n",
      "Validation score: 0.397211\n",
      "Iteration 3894, loss = 28.46681952\n",
      "Validation score: 0.397674\n",
      "Iteration 3895, loss = 28.44538699\n",
      "Validation score: 0.398124\n",
      "Iteration 3896, loss = 28.42623670\n",
      "Validation score: 0.398514\n",
      "Iteration 3897, loss = 28.40543733\n",
      "Validation score: 0.398905\n",
      "Iteration 3898, loss = 28.38477105\n",
      "Validation score: 0.399240\n",
      "Iteration 3899, loss = 28.36526257\n",
      "Validation score: 0.399597\n",
      "Iteration 3900, loss = 28.34654861\n",
      "Validation score: 0.399870\n",
      "Iteration 3901, loss = 28.32824778\n",
      "Validation score: 0.400195\n",
      "Iteration 3902, loss = 28.30946753\n",
      "Validation score: 0.400617\n",
      "Iteration 3903, loss = 28.28775249\n",
      "Validation score: 0.400875\n",
      "Iteration 3904, loss = 28.26827725\n",
      "Validation score: 0.401212\n",
      "Iteration 3905, loss = 28.24964687\n",
      "Validation score: 0.401631\n",
      "Iteration 3906, loss = 28.23013072\n",
      "Validation score: 0.401998\n",
      "Iteration 3907, loss = 28.21072783\n",
      "Validation score: 0.402373\n",
      "Iteration 3908, loss = 28.19181425\n",
      "Validation score: 0.402676\n",
      "Iteration 3909, loss = 28.17321012\n",
      "Validation score: 0.403149\n",
      "Iteration 3910, loss = 28.15276481\n",
      "Validation score: 0.403504\n",
      "Iteration 3911, loss = 28.13438776\n",
      "Validation score: 0.403905\n",
      "Iteration 3912, loss = 28.11404287\n",
      "Validation score: 0.404217\n",
      "Iteration 3913, loss = 28.09598286\n",
      "Validation score: 0.404581\n",
      "Iteration 3914, loss = 28.07690536\n",
      "Validation score: 0.404955\n",
      "Iteration 3915, loss = 28.06199057\n",
      "Validation score: 0.405402\n",
      "Iteration 3916, loss = 28.03967040\n",
      "Validation score: 0.405727\n",
      "Iteration 3917, loss = 28.02055466\n",
      "Validation score: 0.406003\n",
      "Iteration 3918, loss = 28.00333994\n",
      "Validation score: 0.406233\n",
      "Iteration 3919, loss = 27.98670008\n",
      "Validation score: 0.406578\n",
      "Iteration 3920, loss = 27.96746171\n",
      "Validation score: 0.406872\n",
      "Iteration 3921, loss = 27.94914725\n",
      "Validation score: 0.407267\n",
      "Iteration 3922, loss = 27.93021738\n",
      "Validation score: 0.407588\n",
      "Iteration 3923, loss = 27.91688082\n",
      "Validation score: 0.407862\n",
      "Iteration 3924, loss = 27.89348279\n",
      "Validation score: 0.408333\n",
      "Iteration 3925, loss = 27.87806845\n",
      "Validation score: 0.408838\n",
      "Iteration 3926, loss = 27.85719703\n",
      "Validation score: 0.409228\n",
      "Iteration 3927, loss = 27.83775830\n",
      "Validation score: 0.409506\n",
      "Iteration 3928, loss = 27.81994011\n",
      "Validation score: 0.409786\n",
      "Iteration 3929, loss = 27.80263100\n",
      "Validation score: 0.410131\n",
      "Iteration 3930, loss = 27.78652574\n",
      "Validation score: 0.410545\n",
      "Iteration 3931, loss = 27.76746587\n",
      "Validation score: 0.410901\n",
      "Iteration 3932, loss = 27.75159860\n",
      "Validation score: 0.411227\n",
      "Iteration 3933, loss = 27.73255721\n",
      "Validation score: 0.411560\n",
      "Iteration 3934, loss = 27.71531752\n",
      "Validation score: 0.411885\n",
      "Iteration 3935, loss = 27.69696551\n",
      "Validation score: 0.412237\n",
      "Iteration 3936, loss = 27.68010799\n",
      "Validation score: 0.412553\n",
      "Iteration 3937, loss = 27.66412317\n",
      "Validation score: 0.412788\n",
      "Iteration 3938, loss = 27.64712476\n",
      "Validation score: 0.413183\n",
      "Iteration 3939, loss = 27.62895657\n",
      "Validation score: 0.413519\n",
      "Iteration 3940, loss = 27.61155610\n",
      "Validation score: 0.413835\n",
      "Iteration 3941, loss = 27.59421466\n",
      "Validation score: 0.414101\n",
      "Iteration 3942, loss = 27.57769145\n",
      "Validation score: 0.414379\n",
      "Iteration 3943, loss = 27.56115903\n",
      "Validation score: 0.414691\n",
      "Iteration 3944, loss = 27.54507168\n",
      "Validation score: 0.415041\n",
      "Iteration 3945, loss = 27.52842085\n",
      "Validation score: 0.415288\n",
      "Iteration 3946, loss = 27.50938203\n",
      "Validation score: 0.415650\n",
      "Iteration 3947, loss = 27.49392094\n",
      "Validation score: 0.416025\n",
      "Iteration 3948, loss = 27.47576412\n",
      "Validation score: 0.416333\n",
      "Iteration 3949, loss = 27.45841588\n",
      "Validation score: 0.416676\n",
      "Iteration 3950, loss = 27.44219340\n",
      "Validation score: 0.416999\n",
      "Iteration 3951, loss = 27.42730706\n",
      "Validation score: 0.417244\n",
      "Iteration 3952, loss = 27.40800048\n",
      "Validation score: 0.417593\n",
      "Iteration 3953, loss = 27.39577037\n",
      "Validation score: 0.417976\n",
      "Iteration 3954, loss = 27.37401211\n",
      "Validation score: 0.418223\n",
      "Iteration 3955, loss = 27.35751055\n",
      "Validation score: 0.418511\n",
      "Iteration 3956, loss = 27.34155127\n",
      "Validation score: 0.418814\n",
      "Iteration 3957, loss = 27.32590144\n",
      "Validation score: 0.419071\n",
      "Iteration 3958, loss = 27.30936561\n",
      "Validation score: 0.419318\n",
      "Iteration 3959, loss = 27.29168481\n",
      "Validation score: 0.419607\n",
      "Iteration 3960, loss = 27.27545262\n",
      "Validation score: 0.419926\n",
      "Iteration 3961, loss = 27.25886748\n",
      "Validation score: 0.420223\n",
      "Iteration 3962, loss = 27.24286164\n",
      "Validation score: 0.420484\n",
      "Iteration 3963, loss = 27.22742758\n",
      "Validation score: 0.420717\n",
      "Iteration 3964, loss = 27.21023159\n",
      "Validation score: 0.421011\n",
      "Iteration 3965, loss = 27.19495998\n",
      "Validation score: 0.421296\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 3966, loss = 27.18002439\n",
      "Validation score: 0.421634\n",
      "Iteration 3967, loss = 27.16325279\n",
      "Validation score: 0.421892\n",
      "Iteration 3968, loss = 27.14777202\n",
      "Validation score: 0.422143\n",
      "Iteration 3969, loss = 27.13314956\n",
      "Validation score: 0.422459\n",
      "Iteration 3970, loss = 27.11554973\n",
      "Validation score: 0.422680\n",
      "Iteration 3971, loss = 27.10356139\n",
      "Validation score: 0.422882\n",
      "Iteration 3972, loss = 27.08733537\n",
      "Validation score: 0.423171\n",
      "Iteration 3973, loss = 27.06752020\n",
      "Validation score: 0.423674\n",
      "Iteration 3974, loss = 27.05499738\n",
      "Validation score: 0.424174\n",
      "Iteration 3975, loss = 27.03704024\n",
      "Validation score: 0.424512\n",
      "Iteration 3976, loss = 27.02407536\n",
      "Validation score: 0.424831\n",
      "Iteration 3977, loss = 27.00742779\n",
      "Validation score: 0.425090\n",
      "Iteration 3978, loss = 26.99038257\n",
      "Validation score: 0.425372\n",
      "Iteration 3979, loss = 26.97645007\n",
      "Validation score: 0.425678\n",
      "Iteration 3980, loss = 26.95951779\n",
      "Validation score: 0.425976\n",
      "Iteration 3981, loss = 26.94539147\n",
      "Validation score: 0.426269\n",
      "Iteration 3982, loss = 26.92917370\n",
      "Validation score: 0.426442\n",
      "Iteration 3983, loss = 26.91397604\n",
      "Validation score: 0.426692\n",
      "Iteration 3984, loss = 26.90054705\n",
      "Validation score: 0.426853\n",
      "Iteration 3985, loss = 26.88475292\n",
      "Validation score: 0.427153\n",
      "Iteration 3986, loss = 26.86765524\n",
      "Validation score: 0.427361\n",
      "Iteration 3987, loss = 26.85384324\n",
      "Validation score: 0.427645\n",
      "Iteration 3988, loss = 26.83955237\n",
      "Validation score: 0.427873\n",
      "Iteration 3989, loss = 26.82352613\n",
      "Validation score: 0.428188\n",
      "Iteration 3990, loss = 26.80794397\n",
      "Validation score: 0.428471\n",
      "Iteration 3991, loss = 26.79339136\n",
      "Validation score: 0.428717\n",
      "Iteration 3992, loss = 26.77996647\n",
      "Validation score: 0.428930\n",
      "Iteration 3993, loss = 26.76409975\n",
      "Validation score: 0.429216\n",
      "Iteration 3994, loss = 26.74976382\n",
      "Validation score: 0.429567\n",
      "Iteration 3995, loss = 26.73482325\n",
      "Validation score: 0.429846\n",
      "Iteration 3996, loss = 26.72094320\n",
      "Validation score: 0.430106\n",
      "Iteration 3997, loss = 26.70615665\n",
      "Validation score: 0.430365\n",
      "Iteration 3998, loss = 26.69144480\n",
      "Validation score: 0.430582\n",
      "Iteration 3999, loss = 26.67778979\n",
      "Validation score: 0.430791\n",
      "Iteration 4000, loss = 26.66310176\n",
      "Validation score: 0.431054\n",
      "Iteration 4001, loss = 26.64820276\n",
      "Validation score: 0.431263\n",
      "Iteration 4002, loss = 26.63425508\n",
      "Validation score: 0.431552\n",
      "Iteration 4003, loss = 26.62076117\n",
      "Validation score: 0.431788\n",
      "Iteration 4004, loss = 26.60625360\n",
      "Validation score: 0.432072\n",
      "Iteration 4005, loss = 26.59251658\n",
      "Validation score: 0.432390\n",
      "Iteration 4006, loss = 26.57795976\n",
      "Validation score: 0.432642\n",
      "Iteration 4007, loss = 26.56351256\n",
      "Validation score: 0.432916\n",
      "Iteration 4008, loss = 26.54941470\n",
      "Validation score: 0.433168\n",
      "Iteration 4009, loss = 26.53954204\n",
      "Validation score: 0.433490\n",
      "Iteration 4010, loss = 26.52185270\n",
      "Validation score: 0.433687\n",
      "Iteration 4011, loss = 26.50741959\n",
      "Validation score: 0.433873\n",
      "Iteration 4012, loss = 26.49531745\n",
      "Validation score: 0.434038\n",
      "Iteration 4013, loss = 26.47935293\n",
      "Validation score: 0.434249\n",
      "Iteration 4014, loss = 26.46592912\n",
      "Validation score: 0.434420\n",
      "Iteration 4015, loss = 26.45445362\n",
      "Validation score: 0.434736\n",
      "Iteration 4016, loss = 26.43731558\n",
      "Validation score: 0.434898\n",
      "Iteration 4017, loss = 26.42354155\n",
      "Validation score: 0.435035\n",
      "Iteration 4018, loss = 26.41170932\n",
      "Validation score: 0.435211\n",
      "Iteration 4019, loss = 26.39687102\n",
      "Validation score: 0.435430\n",
      "Iteration 4020, loss = 26.38361231\n",
      "Validation score: 0.435647\n",
      "Iteration 4021, loss = 26.36893887\n",
      "Validation score: 0.436012\n",
      "Iteration 4022, loss = 26.35489337\n",
      "Validation score: 0.436317\n",
      "Iteration 4023, loss = 26.34469613\n",
      "Validation score: 0.436640\n",
      "Iteration 4024, loss = 26.33022045\n",
      "Validation score: 0.436813\n",
      "Iteration 4025, loss = 26.31645973\n",
      "Validation score: 0.437042\n",
      "Iteration 4026, loss = 26.30568931\n",
      "Validation score: 0.437253\n",
      "Iteration 4027, loss = 26.28995499\n",
      "Validation score: 0.437348\n",
      "Iteration 4028, loss = 26.28146150\n",
      "Validation score: 0.437347\n",
      "Iteration 4029, loss = 26.26394714\n",
      "Validation score: 0.437581\n",
      "Iteration 4030, loss = 26.25015594\n",
      "Validation score: 0.437810\n",
      "Iteration 4031, loss = 26.23752407\n",
      "Validation score: 0.438004\n",
      "Iteration 4032, loss = 26.22550688\n",
      "Validation score: 0.438202\n",
      "Iteration 4033, loss = 26.21116870\n",
      "Validation score: 0.438393\n",
      "Iteration 4034, loss = 26.20034773\n",
      "Validation score: 0.438571\n",
      "Iteration 4035, loss = 26.18656790\n",
      "Validation score: 0.438720\n",
      "Iteration 4036, loss = 26.17445230\n",
      "Validation score: 0.438878\n",
      "Iteration 4037, loss = 26.16038005\n",
      "Validation score: 0.439137\n",
      "Iteration 4038, loss = 26.14682315\n",
      "Validation score: 0.439381\n",
      "Iteration 4039, loss = 26.13867178\n",
      "Validation score: 0.439670\n",
      "Iteration 4040, loss = 26.12167796\n",
      "Validation score: 0.439863\n",
      "Iteration 4041, loss = 26.10877402\n",
      "Validation score: 0.440010\n",
      "Iteration 4042, loss = 26.09630425\n",
      "Validation score: 0.440244\n",
      "Iteration 4043, loss = 26.08331117\n",
      "Validation score: 0.440395\n",
      "Iteration 4044, loss = 26.07042721\n",
      "Validation score: 0.440536\n",
      "Iteration 4045, loss = 26.05841461\n",
      "Validation score: 0.440665\n",
      "Iteration 4046, loss = 26.04491216\n",
      "Validation score: 0.440890\n",
      "Iteration 4047, loss = 26.03293292\n",
      "Validation score: 0.441124\n",
      "Iteration 4048, loss = 26.01839562\n",
      "Validation score: 0.441442\n",
      "Iteration 4049, loss = 26.01147887\n",
      "Validation score: 0.441780\n",
      "Iteration 4050, loss = 25.99652547\n",
      "Validation score: 0.441997\n",
      "Iteration 4051, loss = 25.98329109\n",
      "Validation score: 0.442224\n",
      "Iteration 4052, loss = 25.96972382\n",
      "Validation score: 0.442380\n",
      "Iteration 4053, loss = 25.95849689\n",
      "Validation score: 0.442564\n",
      "Iteration 4054, loss = 25.94489352\n",
      "Validation score: 0.442680\n",
      "Iteration 4055, loss = 25.93386851\n",
      "Validation score: 0.442864\n",
      "Iteration 4056, loss = 25.92067504\n",
      "Validation score: 0.443109\n",
      "Iteration 4057, loss = 25.90746503\n",
      "Validation score: 0.443411\n",
      "Iteration 4058, loss = 25.89569853\n",
      "Validation score: 0.443687\n",
      "Iteration 4059, loss = 25.88495565\n",
      "Validation score: 0.443920\n",
      "Iteration 4060, loss = 25.87318417\n",
      "Validation score: 0.444068\n",
      "Iteration 4061, loss = 25.86223911\n",
      "Validation score: 0.444259\n",
      "Iteration 4062, loss = 25.84798895\n",
      "Validation score: 0.444498\n",
      "Iteration 4063, loss = 25.83662371\n",
      "Validation score: 0.444712\n",
      "Iteration 4064, loss = 25.82442724\n",
      "Validation score: 0.444885\n",
      "Iteration 4065, loss = 25.81329958\n",
      "Validation score: 0.445085\n",
      "Iteration 4066, loss = 25.80150881\n",
      "Validation score: 0.445107\n",
      "Iteration 4067, loss = 25.79012213\n",
      "Validation score: 0.445281\n",
      "Iteration 4068, loss = 25.77548618\n",
      "Validation score: 0.445503\n",
      "Iteration 4069, loss = 25.76422275\n",
      "Validation score: 0.445783\n",
      "Iteration 4070, loss = 25.75290173\n",
      "Validation score: 0.445929\n",
      "Iteration 4071, loss = 25.74054618\n",
      "Validation score: 0.446085\n",
      "Iteration 4072, loss = 25.73042075\n",
      "Validation score: 0.446138\n",
      "Iteration 4073, loss = 25.71626146\n",
      "Validation score: 0.446294\n",
      "Iteration 4074, loss = 25.70995028\n",
      "Validation score: 0.446383\n",
      "Iteration 4075, loss = 25.69481741\n",
      "Validation score: 0.446528\n",
      "Iteration 4076, loss = 25.68269849\n",
      "Validation score: 0.446742\n",
      "Iteration 4077, loss = 25.67346743\n",
      "Validation score: 0.446970\n",
      "Iteration 4078, loss = 25.66073781\n",
      "Validation score: 0.447118\n",
      "Iteration 4079, loss = 25.64884878\n",
      "Validation score: 0.447326\n",
      "Iteration 4080, loss = 25.63726282\n",
      "Validation score: 0.447495\n",
      "Iteration 4081, loss = 25.62541741\n",
      "Validation score: 0.447654\n",
      "Iteration 4082, loss = 25.61489642\n",
      "Validation score: 0.447835\n",
      "Iteration 4083, loss = 25.60319248\n",
      "Validation score: 0.448053\n",
      "Iteration 4084, loss = 25.59339386\n",
      "Validation score: 0.448248\n",
      "Iteration 4085, loss = 25.58213098\n",
      "Validation score: 0.448504\n",
      "Iteration 4086, loss = 25.57046943\n",
      "Validation score: 0.448676\n",
      "Iteration 4087, loss = 25.55976571\n",
      "Validation score: 0.448900\n",
      "Iteration 4088, loss = 25.54910913\n",
      "Validation score: 0.449152\n",
      "Iteration 4089, loss = 25.53811260\n",
      "Validation score: 0.449300\n",
      "Iteration 4090, loss = 25.52711793\n",
      "Validation score: 0.449445\n",
      "Iteration 4091, loss = 25.51648437\n",
      "Validation score: 0.449561\n",
      "Iteration 4092, loss = 25.50615312\n",
      "Validation score: 0.449793\n",
      "Iteration 4093, loss = 25.49352920\n",
      "Validation score: 0.449940\n",
      "Iteration 4094, loss = 25.48428626\n",
      "Validation score: 0.450139\n",
      "Iteration 4095, loss = 25.47098420\n",
      "Validation score: 0.450274\n",
      "Iteration 4096, loss = 25.46030748\n",
      "Validation score: 0.450381\n",
      "Iteration 4097, loss = 25.44876322\n",
      "Validation score: 0.450574\n",
      "Iteration 4098, loss = 25.43793583\n",
      "Validation score: 0.450766\n",
      "Iteration 4099, loss = 25.42814049\n",
      "Validation score: 0.450931\n",
      "Iteration 4100, loss = 25.41869069\n",
      "Validation score: 0.450816\n",
      "Iteration 4101, loss = 25.40554225\n",
      "Validation score: 0.450911\n",
      "Iteration 4102, loss = 25.39540457\n",
      "Validation score: 0.451081\n",
      "Iteration 4103, loss = 25.38695982\n",
      "Validation score: 0.451287\n",
      "Iteration 4104, loss = 25.37307878\n",
      "Validation score: 0.451392\n",
      "Iteration 4105, loss = 25.36385033\n",
      "Validation score: 0.451513\n",
      "Iteration 4106, loss = 25.35160141\n",
      "Validation score: 0.451628\n",
      "Iteration 4107, loss = 25.34233904\n",
      "Validation score: 0.451749\n",
      "Iteration 4108, loss = 25.33303899\n",
      "Validation score: 0.451812\n",
      "Iteration 4109, loss = 25.32119080\n",
      "Validation score: 0.451953\n",
      "Iteration 4110, loss = 25.31496078\n",
      "Validation score: 0.452245\n",
      "Iteration 4111, loss = 25.29948042\n",
      "Validation score: 0.452432\n",
      "Iteration 4112, loss = 25.29029307\n",
      "Validation score: 0.452663\n",
      "Iteration 4113, loss = 25.27761430\n",
      "Validation score: 0.452766\n",
      "Iteration 4114, loss = 25.26919565\n",
      "Validation score: 0.452802\n",
      "Iteration 4115, loss = 25.25785386\n",
      "Validation score: 0.452987\n",
      "Iteration 4116, loss = 25.24762371\n",
      "Validation score: 0.453085\n",
      "Iteration 4117, loss = 25.23807815\n",
      "Validation score: 0.453248\n",
      "Iteration 4118, loss = 25.22728059\n",
      "Validation score: 0.453543\n",
      "Iteration 4119, loss = 25.21479650\n",
      "Validation score: 0.453714\n",
      "Iteration 4120, loss = 25.20622088\n",
      "Validation score: 0.453964\n",
      "Iteration 4121, loss = 25.19580773\n",
      "Validation score: 0.454184\n",
      "Iteration 4122, loss = 25.18436038\n",
      "Validation score: 0.454347\n",
      "Iteration 4123, loss = 25.17730554\n",
      "Validation score: 0.454591\n",
      "Iteration 4124, loss = 25.16570577\n",
      "Validation score: 0.454697\n",
      "Iteration 4125, loss = 25.15707620\n",
      "Validation score: 0.454849\n",
      "Iteration 4126, loss = 25.14517284\n",
      "Validation score: 0.454761\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 4127, loss = 25.13296317\n",
      "Validation score: 0.454752\n",
      "Iteration 4128, loss = 25.12309039\n",
      "Validation score: 0.454868\n",
      "Iteration 4129, loss = 25.11357330\n",
      "Validation score: 0.454949\n",
      "Iteration 4130, loss = 25.10314123\n",
      "Validation score: 0.454975\n",
      "Iteration 4131, loss = 25.09473140\n",
      "Validation score: 0.455069\n",
      "Iteration 4132, loss = 25.08576093\n",
      "Validation score: 0.455386\n",
      "Iteration 4133, loss = 25.07389093\n",
      "Validation score: 0.455485\n",
      "Iteration 4134, loss = 25.06344163\n",
      "Validation score: 0.455673\n",
      "Iteration 4135, loss = 25.05470915\n",
      "Validation score: 0.455818\n",
      "Iteration 4136, loss = 25.04346783\n",
      "Validation score: 0.455964\n",
      "Iteration 4137, loss = 25.03332597\n",
      "Validation score: 0.456079\n",
      "Iteration 4138, loss = 25.02323012\n",
      "Validation score: 0.456334\n",
      "Iteration 4139, loss = 25.01214275\n",
      "Validation score: 0.456478\n",
      "Iteration 4140, loss = 25.00286711\n",
      "Validation score: 0.456575\n",
      "Iteration 4141, loss = 24.99278630\n",
      "Validation score: 0.456673\n",
      "Iteration 4142, loss = 24.98236952\n",
      "Validation score: 0.456834\n",
      "Iteration 4143, loss = 24.97214159\n",
      "Validation score: 0.456932\n",
      "Iteration 4144, loss = 24.96325745\n",
      "Validation score: 0.457066\n",
      "Iteration 4145, loss = 24.95359877\n",
      "Validation score: 0.457202\n",
      "Iteration 4146, loss = 24.94394915\n",
      "Validation score: 0.457299\n",
      "Iteration 4147, loss = 24.93568587\n",
      "Validation score: 0.457432\n",
      "Iteration 4148, loss = 24.92598279\n",
      "Validation score: 0.457603\n",
      "Iteration 4149, loss = 24.91561184\n",
      "Validation score: 0.457705\n",
      "Iteration 4150, loss = 24.90606592\n",
      "Validation score: 0.457808\n",
      "Iteration 4151, loss = 24.89660392\n",
      "Validation score: 0.457923\n",
      "Iteration 4152, loss = 24.88796981\n",
      "Validation score: 0.458031\n",
      "Iteration 4153, loss = 24.87958577\n",
      "Validation score: 0.458177\n",
      "Iteration 4154, loss = 24.86967747\n",
      "Validation score: 0.458251\n",
      "Iteration 4155, loss = 24.85907308\n",
      "Validation score: 0.458361\n",
      "Iteration 4156, loss = 24.85167287\n",
      "Validation score: 0.458465\n",
      "Iteration 4157, loss = 24.84179934\n",
      "Validation score: 0.458393\n",
      "Iteration 4158, loss = 24.83103553\n",
      "Validation score: 0.458504\n",
      "Iteration 4159, loss = 24.82258355\n",
      "Validation score: 0.458618\n",
      "Iteration 4160, loss = 24.81450553\n",
      "Validation score: 0.458737\n",
      "Iteration 4161, loss = 24.80436456\n",
      "Validation score: 0.458880\n",
      "Iteration 4162, loss = 24.79532912\n",
      "Validation score: 0.458866\n",
      "Iteration 4163, loss = 24.78634377\n",
      "Validation score: 0.459063\n",
      "Iteration 4164, loss = 24.77680068\n",
      "Validation score: 0.459242\n",
      "Iteration 4165, loss = 24.76867378\n",
      "Validation score: 0.459454\n",
      "Iteration 4166, loss = 24.75893165\n",
      "Validation score: 0.459577\n",
      "Iteration 4167, loss = 24.75017522\n",
      "Validation score: 0.459812\n",
      "Iteration 4168, loss = 24.73976896\n",
      "Validation score: 0.459957\n",
      "Iteration 4169, loss = 24.73098648\n",
      "Validation score: 0.460073\n",
      "Iteration 4170, loss = 24.72140000\n",
      "Validation score: 0.460194\n",
      "Iteration 4171, loss = 24.71333776\n",
      "Validation score: 0.460316\n",
      "Iteration 4172, loss = 24.70422102\n",
      "Validation score: 0.460440\n",
      "Iteration 4173, loss = 24.69537558\n",
      "Validation score: 0.460512\n",
      "Iteration 4174, loss = 24.68534058\n",
      "Validation score: 0.460527\n",
      "Iteration 4175, loss = 24.67653864\n",
      "Validation score: 0.460609\n",
      "Iteration 4176, loss = 24.67100873\n",
      "Validation score: 0.460832\n",
      "Iteration 4177, loss = 24.66021286\n",
      "Validation score: 0.460847\n",
      "Iteration 4178, loss = 24.64880157\n",
      "Validation score: 0.460895\n",
      "Iteration 4179, loss = 24.64249163\n",
      "Validation score: 0.461003\n",
      "Iteration 4180, loss = 24.63405246\n",
      "Validation score: 0.461134\n",
      "Iteration 4181, loss = 24.62257558\n",
      "Validation score: 0.461194\n",
      "Iteration 4182, loss = 24.61623613\n",
      "Validation score: 0.461245\n",
      "Iteration 4183, loss = 24.60852251\n",
      "Validation score: 0.461554\n",
      "Iteration 4184, loss = 24.59801703\n",
      "Validation score: 0.461866\n",
      "Iteration 4185, loss = 24.58948666\n",
      "Validation score: 0.461986\n",
      "Iteration 4186, loss = 24.58035085\n",
      "Validation score: 0.462104\n",
      "Iteration 4187, loss = 24.57118734\n",
      "Validation score: 0.462186\n",
      "Iteration 4188, loss = 24.56391970\n",
      "Validation score: 0.462214\n",
      "Iteration 4189, loss = 24.55472393\n",
      "Validation score: 0.462393\n",
      "Iteration 4190, loss = 24.54809525\n",
      "Validation score: 0.462438\n",
      "Iteration 4191, loss = 24.53735831\n",
      "Validation score: 0.462494\n",
      "Iteration 4192, loss = 24.52923053\n",
      "Validation score: 0.462476\n",
      "Iteration 4193, loss = 24.52008619\n",
      "Validation score: 0.462583\n",
      "Iteration 4194, loss = 24.51307839\n",
      "Validation score: 0.462533\n",
      "Iteration 4195, loss = 24.50295337\n",
      "Validation score: 0.462623\n",
      "Iteration 4196, loss = 24.49491324\n",
      "Validation score: 0.462830\n",
      "Iteration 4197, loss = 24.48627248\n",
      "Validation score: 0.462962\n",
      "Iteration 4198, loss = 24.47748800\n",
      "Validation score: 0.463065\n",
      "Iteration 4199, loss = 24.47065108\n",
      "Validation score: 0.463308\n",
      "Iteration 4200, loss = 24.46101183\n",
      "Validation score: 0.463403\n",
      "Iteration 4201, loss = 24.45481656\n",
      "Validation score: 0.463625\n",
      "Iteration 4202, loss = 24.44410941\n",
      "Validation score: 0.463594\n",
      "Iteration 4203, loss = 24.43542188\n",
      "Validation score: 0.463731\n",
      "Iteration 4204, loss = 24.42654483\n",
      "Validation score: 0.463714\n",
      "Iteration 4205, loss = 24.42011882\n",
      "Validation score: 0.463814\n",
      "Iteration 4206, loss = 24.41020471\n",
      "Validation score: 0.463946\n",
      "Iteration 4207, loss = 24.40368508\n",
      "Validation score: 0.464224\n",
      "Iteration 4208, loss = 24.39452564\n",
      "Validation score: 0.464372\n",
      "Iteration 4209, loss = 24.38579514\n",
      "Validation score: 0.464165\n",
      "Iteration 4210, loss = 24.37668650\n",
      "Validation score: 0.464095\n",
      "Iteration 4211, loss = 24.36914747\n",
      "Validation score: 0.464146\n",
      "Validation score did not improve more than tol=0.000000 for two consecutive epochs. Stopping.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5144374000192167"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_sel_incomplete= train_data[selected_feature_cols].values\n",
    "X_sel =  KNN(k=k).fit_transform(X_sel_incomplete)\n",
    "X_sel = RobustScaler(quantile_range=(10, 90)).fit_transform(X_sel)\n",
    "\n",
    "y_sel = train_data[\"y\"].values\n",
    "\n",
    "\n",
    "#pca = PCA(n_components=100, whiten=False)\n",
    "#X_sel = pca.fit_transform(X)\n",
    "#y_sel = y\n",
    "\n",
    "estimator = MLPRegressor(learning_rate='constant', \n",
    "                        hidden_layer_sizes=(60, 40),\n",
    "                         activation='logistic', \n",
    "                         learning_rate_init=0.0001, \n",
    "                         max_iter=15000, \n",
    "                         early_stopping =True,\n",
    "                         validation_fraction=0.1,\n",
    "                         tol=0.000000001,\n",
    "                        alpha=0.8,\n",
    "                         #n_iter_no_change=10,\n",
    "                         verbose=True)\n",
    "\n",
    "estimator.fit(X_sel,y_sel)\n",
    "estimator.score(X_sel,y_sel)\n",
    "\n",
    "#score = cross_val_score((estimator), X_sel, y_sel, scoring='r2', cv=4)\n",
    "#print(score.mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sel_incomplete= train_data[selected_feature_cols].values\n",
    "\n",
    "train_mean_values = train_data.mean()\n",
    "train_data_mean =  train_data.fillna(train_mean_values)\n",
    "X_sel = train_data_mean[selected_feature_cols].values\n",
    "\n",
    "\n",
    "#k = 10\n",
    "X_sel =  KNN(k=k).fit_transform(X_sel_incomplete)\n",
    "\n",
    "y_sel = train_data[\"y\"].values\n",
    "\n",
    "X_sel = RobustScaler(quantile_range=(10, 90)).fit_transform(X_sel)\n",
    "\n",
    "score = cross_val_score(RandomForestRegressor(n_jobs=-1, n_estimators=200), X_sel, y_sel, scoring='r2', cv=12)\n",
    "print(score.mean())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bayesian Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def svr_model(gamma, C, epsilon):\n",
    "    score = cross_val_score(\n",
    "                SVR(gamma=gamma, C=C, epsilon=epsilon, kernel='poly'), \n",
    "                X, y, scoring='r2').mean()\n",
    "    #score = np.array(score)\n",
    "    return score  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bayesian Optimization\n",
    "\n",
    "from bayes_opt import BayesianOptimization\n",
    "\n",
    "bo = BayesianOptimization(svr_model,{'gamma': (0.01, 5.0), 'C': (0.1, 100), 'epsilon': (0.0001, 1)})\n",
    "\n",
    "# Once we are satisfied with the initialization conditions\n",
    "# we let the algorithm do its magic by calling the maximize()\n",
    "# method.\n",
    "bo.maximize(init_points=5, n_iter=15, kappa=10)\n",
    "\n",
    "# The output values can be accessed with self.res\n",
    "print(bo.res['max'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Official Metric\n",
    "score = r2_score(y, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prep.dataset.write_submission(test_data, \"nku\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
