{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import csv\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_selection import RFE, f_regression\n",
    "from sklearn.linear_model import (LinearRegression, Ridge, Lasso, RandomizedLasso)\n",
    "from sklearn.preprocessing import (MinMaxScaler, RobustScaler)\n",
    "from sklearn.ensemble import (RandomForestRegressor, IsolationForest)\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LeakyReLU\n",
    "from keras.optimizers import Adam\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "from fancyimpute import KNN,  SoftImpute, IterativeImputer, BiScaler, MatrixFactorization\n",
    "import util.data\n",
    "rng = np.random.RandomState(42)\n",
    "n_features_to_use = 50\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data: \n",
      "  Amount of features: 888\n",
      "  Amount of observations: 1212\n",
      "  Min age: 42.0 Max age: 96.0\n",
      "\n",
      "Test Data: \n",
      "  Amount of observations: 776\n"
     ]
    }
   ],
   "source": [
    "train_data, test_data = util.data.load()\n",
    "# Define dictionary to store our rankings\n",
    "ranks = {}\n",
    "\n",
    "# Create our function which stores the feature rankings to the ranks dictionary\n",
    "def ranking(ranks, names, order=1):\n",
    "    minmax = MinMaxScaler()\n",
    "    ranks = minmax.fit_transform(order*np.array([ranks]).T).T[0]\n",
    "    ranks = map(lambda x: round(x,2), ranks)\n",
    "    return dict(zip(names, ranks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ax/miniconda3/envs/aml/lib/python3.6/site-packages/sklearn/utils/deprecation.py:58: DeprecationWarning: Class RandomizedLasso is deprecated; The class RandomizedLasso is deprecated in 0.19 and will be removed in 0.21.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rLasso done\n",
      "LinReg done\n",
      "RFE done\n",
      "Ridge done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ax/miniconda3/envs/aml/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lasso done\n",
      "RF done\n"
     ]
    }
   ],
   "source": [
    "X_incomplete = train_data.drop([\"id\", \"y\"], axis=1).values\n",
    "# use mean values\n",
    "train_mean_values = train_data.mean()\n",
    "train_data_mean =  train_data.fillna(train_mean_values)\n",
    "test_data_mean = test_data.fillna(train_mean_values)\n",
    "X = train_data_mean.drop([\"id\", \"y\"], axis=1).values\n",
    "X_test = test_data_mean.drop([\"id\"], axis=1).values\n",
    "y = train_data[\"y\"].values\n",
    "\n",
    "# remove outliers \n",
    "isoForest = IsolationForest(behaviour='new', max_samples=100, random_state=rng, contamination='auto')\n",
    "outliers = isoForest.fit_predict(X)\n",
    "\n",
    "X = X[np.where(outliers > 0)]\n",
    "y = y[np.where(outliers > 0)]\n",
    "\n",
    "# scale the data\n",
    "transformer = RobustScaler().fit(X)\n",
    "X = transformer.transform(X)\n",
    "X_test = transformer.transform(X_test)\n",
    "\n",
    "# selected most important features\n",
    "colnames = train_data.drop([\"id\", \"y\"], axis=1).columns\n",
    "\n",
    "rlasso = RandomizedLasso(alpha=0.04)\n",
    "lr = LinearRegression(normalize=True)\n",
    "ridge = Ridge(alpha = 7)\n",
    "lasso = Lasso(alpha=.05)\n",
    "rf = RandomForestRegressor(n_jobs=-1, n_estimators=50)\n",
    "\n",
    "rlasso.fit(X, y)\n",
    "ranks[\"rlasso/Stability\"] = ranking(np.abs(rlasso.scores_), colnames)\n",
    "print(\"rLasso done\")\n",
    "# Construct our Linear Regression model\n",
    "\n",
    "lr.fit(X, y)\n",
    "ranks[\"LinReg\"] = ranking(np.abs(lr.coef_), colnames)\n",
    "print(\"LinReg done\")\n",
    "\n",
    "#stop the search when only the last feature is left\n",
    "rfe = RFE(lr, n_features_to_select=1 )\n",
    "rfe.fit(X, y)\n",
    "ranks[\"RFE\"] = ranking(list(map(float, rfe.ranking_)), colnames, order=-1)\n",
    "print(\"RFE done\")\n",
    "\n",
    "ridge.fit(X,y)\n",
    "ranks['Ridge'] = ranking(np.abs(ridge.coef_), colnames)\n",
    "print(\"Ridge done\")\n",
    "\n",
    "lasso.fit(X, y)\n",
    "ranks[\"Lasso\"] = ranking(np.abs(lasso.coef_), colnames)\n",
    "print(\"Lasso done\")\n",
    "\n",
    "rf.fit(X, y)\n",
    "ranks[\"RF\"] = ranking(rf.feature_importances_, colnames);\n",
    "print(\"RF done\")\n",
    "\n",
    "# Create empty dictionary to store the mean value calculated from all the scores\n",
    "r = {}\n",
    "meanplot = {}\n",
    "for name in colnames:\n",
    "    r[name] = round(np.mean([ranks[method][name] for method in ranks.keys()]), 2)\n",
    "\n",
    "# Put the mean scores into a Pandas dataframe\n",
    "meanplot = pd.DataFrame(list(r.items()), columns= ['Feature','Mean Ranking'])\n",
    "\n",
    "# Sort the dataframe\n",
    "meanplot = meanplot.sort_values('Mean Ranking', ascending=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features_to_use = 50\n",
    "feature_list = list(meanplot.head(n_features_to_use)[\"Feature\"].values)\n",
    "X_reduced_dim = pd.DataFrame(X, columns=colnames)\n",
    "X_reduced_dim = X_reduced_dim[feature_list]\n",
    "\n",
    "X_test_reduced_dim = pd.DataFrame(X_test, columns=colnames)\n",
    "X_test_reduced_dim = X_test_reduced_dim[feature_list]\n",
    "\n",
    "X_reduced_dim[\"y\"] = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ax/miniconda3/envs/aml/lib/python3.6/site-packages/ipykernel_launcher.py:3: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(40, input_dim=40, kernel_initializer=\"RandomUniform\")`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/home/ax/miniconda3/envs/aml/lib/python3.6/site-packages/ipykernel_launcher.py:5: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(50, kernel_initializer=\"RandomUniform\")`\n",
      "  \"\"\"\n",
      "/home/ax/miniconda3/envs/aml/lib/python3.6/site-packages/ipykernel_launcher.py:7: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(100, kernel_initializer=\"RandomUniform\")`\n",
      "  import sys\n",
      "/home/ax/miniconda3/envs/aml/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(1, activation=\"sigmoid\", kernel_initializer=\"RandomUniform\")`\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "# create model\n",
    "model = Sequential()\n",
    "model.add(Dense(n_features_to_use, input_dim=n_features_to_use, init='RandomUniform'))\n",
    "model.add(LeakyReLU(alpha=0.1))\n",
    "model.add(Dense(50, init='RandomUniform'))\n",
    "model.add(LeakyReLU(alpha=0.1))\n",
    "model.add(Dense(100, init='RandomUniform'))\n",
    "model.add(LeakyReLU(alpha=0.1))\n",
    "model.add(Dense(1, init='RandomUniform', activation='sigmoid'))\n",
    "# Compile model\n",
    "optimizer = Adam(lr=0.000005, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
    "\n",
    "model.compile(loss='mean_absolute_error', optimizer=optimizer)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load test data and compute same preprocessin steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1088 samples, validate on 121 samples\n",
      "Epoch 1/150\n",
      " 44/100 [============>.................] - ETA: 0s - loss: 0.0505"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ax/miniconda3/envs/aml/lib/python3.6/site-packages/ipykernel_launcher.py:1: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 0s 4ms/step - loss: 0.0505 - val_loss: 0.0563\n",
      "Epoch 2/150\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.0504 - val_loss: 0.0563\n",
      "Epoch 3/150\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.0503 - val_loss: 0.0563\n",
      "Epoch 4/150\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.0502 - val_loss: 0.0563\n",
      "Epoch 5/150\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.0501 - val_loss: 0.0563\n",
      "Epoch 6/150\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.0501 - val_loss: 0.0563\n",
      "Epoch 7/150\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.0500 - val_loss: 0.0563\n",
      "Epoch 8/150\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.0499 - val_loss: 0.0563\n",
      "Epoch 9/150\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.0498 - val_loss: 0.0563\n",
      "Epoch 10/150\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.0497 - val_loss: 0.0563\n",
      "Epoch 11/150\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.0497 - val_loss: 0.0563\n",
      "Epoch 12/150\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.0496 - val_loss: 0.0563\n",
      "Epoch 13/150\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.0495 - val_loss: 0.0563\n",
      "Epoch 14/150\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.0494 - val_loss: 0.0563\n",
      "Epoch 15/150\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.0493 - val_loss: 0.0564\n",
      "Epoch 16/150\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.0493 - val_loss: 0.0564\n",
      "Epoch 17/150\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.0492 - val_loss: 0.0564\n",
      "Epoch 18/150\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.0491 - val_loss: 0.0564\n",
      "Epoch 19/150\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.0490 - val_loss: 0.0564\n",
      "Epoch 20/150\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.0489 - val_loss: 0.0564\n",
      "Epoch 21/150\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.0489 - val_loss: 0.0563\n",
      "Epoch 22/150\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.0488 - val_loss: 0.0563\n",
      "Epoch 23/150\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.0487 - val_loss: 0.0563\n",
      "Epoch 24/150\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.0486 - val_loss: 0.0563\n",
      "Epoch 25/150\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.0485 - val_loss: 0.0563\n",
      "Epoch 26/150\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.0485 - val_loss: 0.0563\n",
      "Epoch 27/150\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.0484 - val_loss: 0.0563\n",
      "Epoch 28/150\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.0483 - val_loss: 0.0563\n",
      "Epoch 29/150\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.0482 - val_loss: 0.0563\n",
      "Epoch 30/150\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.0482 - val_loss: 0.0562\n",
      "Epoch 31/150\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.0481 - val_loss: 0.0562\n",
      "Epoch 32/150\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.0480 - val_loss: 0.0562\n",
      "Epoch 33/150\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.0480 - val_loss: 0.0562\n",
      "Epoch 34/150\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.0479 - val_loss: 0.0562\n",
      "Epoch 35/150\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.0478 - val_loss: 0.0562\n",
      "Epoch 36/150\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.0477 - val_loss: 0.0562\n",
      "Epoch 37/150\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.0477 - val_loss: 0.0562\n",
      "Epoch 38/150\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.0476 - val_loss: 0.0562\n",
      "Epoch 39/150\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.0475 - val_loss: 0.0562\n",
      "Epoch 40/150\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.0474 - val_loss: 0.0562\n",
      "Epoch 41/150\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.0474 - val_loss: 0.0562\n",
      "Epoch 42/150\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.0473 - val_loss: 0.0562\n",
      "Epoch 43/150\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.0472 - val_loss: 0.0562\n",
      "Epoch 44/150\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.0471 - val_loss: 0.0562\n",
      "Epoch 45/150\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.0471 - val_loss: 0.0562\n",
      "Epoch 46/150\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.0470 - val_loss: 0.0562\n",
      "Epoch 47/150\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.0469 - val_loss: 0.0561\n",
      "Epoch 48/150\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.0468 - val_loss: 0.0561\n",
      "Epoch 49/150\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.0467 - val_loss: 0.0561\n",
      "Epoch 50/150\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.0467 - val_loss: 0.0561\n",
      "Epoch 51/150\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.0466 - val_loss: 0.0561\n",
      "Epoch 52/150\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.0465 - val_loss: 0.0561\n",
      "Epoch 53/150\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.0464 - val_loss: 0.0561\n",
      "Epoch 54/150\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.0463 - val_loss: 0.0561\n",
      "Epoch 55/150\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.0463 - val_loss: 0.0561\n",
      "Epoch 56/150\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.0462 - val_loss: 0.0560\n",
      "Epoch 57/150\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.0461 - val_loss: 0.0560\n",
      "Epoch 58/150\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.0460 - val_loss: 0.0560\n",
      "Epoch 59/150\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.0459 - val_loss: 0.0560\n",
      "Epoch 60/150\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.0459 - val_loss: 0.0560\n",
      "Epoch 61/150\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.0458 - val_loss: 0.0560\n",
      "Epoch 62/150\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.0457 - val_loss: 0.0560\n",
      "Epoch 63/150\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.0456 - val_loss: 0.0560\n",
      "Epoch 64/150\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.0455 - val_loss: 0.0559\n",
      "Epoch 65/150\n",
      "100/100 [==============================] - 0s 5ms/step - loss: 0.0455 - val_loss: 0.0559\n",
      "Epoch 66/150\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.0454 - val_loss: 0.0559\n",
      "Epoch 67/150\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.0453 - val_loss: 0.0559\n",
      "Epoch 68/150\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.0452 - val_loss: 0.0559\n",
      "Epoch 69/150\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.0452 - val_loss: 0.0558\n",
      "Epoch 70/150\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.0451 - val_loss: 0.0558\n",
      "Epoch 71/150\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.0450 - val_loss: 0.0558\n",
      "Epoch 72/150\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.0449 - val_loss: 0.0558\n",
      "Epoch 73/150\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.0449 - val_loss: 0.0558\n",
      "Epoch 74/150\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.0448 - val_loss: 0.0558\n",
      "Epoch 75/150\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.0447 - val_loss: 0.0558\n",
      "Epoch 76/150\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.0446 - val_loss: 0.0558\n",
      "Epoch 77/150\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.0446 - val_loss: 0.0557\n",
      "Epoch 78/150\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.0445 - val_loss: 0.0557\n",
      "Epoch 79/150\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.0444 - val_loss: 0.0557\n",
      "Epoch 80/150\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.0444 - val_loss: 0.0557\n",
      "Epoch 81/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 0s 4ms/step - loss: 0.0443 - val_loss: 0.0557\n",
      "Epoch 82/150\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.0443 - val_loss: 0.0557\n",
      "Epoch 83/150\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.0442 - val_loss: 0.0556\n",
      "Epoch 84/150\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.0441 - val_loss: 0.0556\n",
      "Epoch 85/150\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.0441 - val_loss: 0.0556\n",
      "Epoch 86/150\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.0440 - val_loss: 0.0556\n",
      "Epoch 87/150\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.0439 - val_loss: 0.0556\n",
      "Epoch 88/150\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.0439 - val_loss: 0.0556\n",
      "Epoch 89/150\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.0438 - val_loss: 0.0555\n",
      "Epoch 90/150\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.0437 - val_loss: 0.0555\n",
      "Epoch 91/150\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.0436 - val_loss: 0.0555\n",
      "Epoch 92/150\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.0436 - val_loss: 0.0555\n",
      "Epoch 93/150\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.0435 - val_loss: 0.0554\n",
      "Epoch 94/150\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.0434 - val_loss: 0.0554\n",
      "Epoch 95/150\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.0434 - val_loss: 0.0554\n",
      "Epoch 96/150\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.0433 - val_loss: 0.0553\n",
      "Epoch 97/150\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.0432 - val_loss: 0.0553\n",
      "Epoch 98/150\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.0432 - val_loss: 0.0553\n",
      "Epoch 99/150\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.0431 - val_loss: 0.0553\n",
      "Epoch 100/150\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.0430 - val_loss: 0.0552\n",
      "Epoch 101/150\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.0430 - val_loss: 0.0552\n",
      "Epoch 102/150\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.0429 - val_loss: 0.0552\n",
      "Epoch 103/150\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.0428 - val_loss: 0.0552\n",
      "Epoch 104/150\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.0428 - val_loss: 0.0551\n",
      "Epoch 105/150\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.0427 - val_loss: 0.0551\n",
      "Epoch 106/150\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.0426 - val_loss: 0.0551\n",
      "Epoch 107/150\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.0426 - val_loss: 0.0551\n",
      "Epoch 108/150\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.0425 - val_loss: 0.0551\n",
      "Epoch 109/150\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.0424 - val_loss: 0.0550\n",
      "Epoch 110/150\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.0424 - val_loss: 0.0550\n",
      "Epoch 111/150\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.0423 - val_loss: 0.0550\n",
      "Epoch 112/150\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.0422 - val_loss: 0.0550\n",
      "Epoch 113/150\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.0422 - val_loss: 0.0550\n",
      "Epoch 114/150\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.0421 - val_loss: 0.0550\n",
      "Epoch 115/150\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.0420 - val_loss: 0.0549\n",
      "Epoch 116/150\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.0420 - val_loss: 0.0549\n",
      "Epoch 117/150\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.0419 - val_loss: 0.0549\n",
      "Epoch 118/150\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.0418 - val_loss: 0.0549\n",
      "Epoch 119/150\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.0417 - val_loss: 0.0549\n",
      "Epoch 120/150\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.0417 - val_loss: 0.0549\n",
      "Epoch 121/150\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.0416 - val_loss: 0.0548\n",
      "Epoch 122/150\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.0415 - val_loss: 0.0548\n",
      "Epoch 123/150\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.0415 - val_loss: 0.0548\n",
      "Epoch 124/150\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.0414 - val_loss: 0.0548\n",
      "Epoch 125/150\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.0413 - val_loss: 0.0548\n",
      "Epoch 126/150\n",
      "100/100 [==============================] - 0s 5ms/step - loss: 0.0413 - val_loss: 0.0547\n",
      "Epoch 127/150\n",
      "100/100 [==============================] - 1s 5ms/step - loss: 0.0412 - val_loss: 0.0547\n",
      "Epoch 128/150\n",
      "100/100 [==============================] - 0s 5ms/step - loss: 0.0411 - val_loss: 0.0547\n",
      "Epoch 129/150\n",
      "100/100 [==============================] - 0s 5ms/step - loss: 0.0410 - val_loss: 0.0547\n",
      "Epoch 130/150\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.0410 - val_loss: 0.0546\n",
      "Epoch 131/150\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.0409 - val_loss: 0.0546\n",
      "Epoch 132/150\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.0408 - val_loss: 0.0546\n",
      "Epoch 133/150\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.0408 - val_loss: 0.0546\n",
      "Epoch 134/150\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.0407 - val_loss: 0.0546\n",
      "Epoch 135/150\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.0406 - val_loss: 0.0546\n",
      "Epoch 136/150\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.0406 - val_loss: 0.0546\n",
      "Epoch 137/150\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.0405 - val_loss: 0.0546\n",
      "Epoch 138/150\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.0404 - val_loss: 0.0546\n",
      "Epoch 139/150\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.0404 - val_loss: 0.0546\n",
      "Epoch 140/150\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.0403 - val_loss: 0.0546\n",
      "Epoch 141/150\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.0402 - val_loss: 0.0546\n",
      "Epoch 142/150\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.0401 - val_loss: 0.0547\n",
      "Epoch 143/150\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.0401 - val_loss: 0.0547\n",
      "Epoch 144/150\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.0400 - val_loss: 0.0547\n",
      "Epoch 145/150\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.0399 - val_loss: 0.0547\n",
      "Epoch 146/150\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.0399 - val_loss: 0.0547\n",
      "Epoch 147/150\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.0398 - val_loss: 0.0547\n",
      "Epoch 148/150\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.0397 - val_loss: 0.0547\n",
      "Epoch 149/150\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.0397 - val_loss: 0.0547\n",
      "Epoch 150/150\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.0396 - val_loss: 0.0547\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ax/miniconda3/envs/aml/lib/python3.6/site-packages/ipykernel_launcher.py:9: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "model.fit(x=X_reduced_dim.drop([\"y\"], axis=1).as_matrix(), \n",
    "          y=X_reduced_dim[\"y\"].values / 100.0, epochs=150, \n",
    "          verbose=1, \n",
    "          validation_split=0.1, \n",
    "          shuffle=True, \n",
    "          steps_per_epoch=100, initial_epoch=0, validation_steps=10)\n",
    "    # calculate predictions\n",
    "    \n",
    "predictions = model.predict(X_test_reduced_dim.as_matrix()) * 100.0\n",
    "    \n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission =  pd.DataFrame(data={\"id\": list(range(776)), \"y\": np.squeeze(list(predictions))}) \n",
    "submission.to_csv(\"submissions/mean_NN_f{}.csv\".format(n_features_to_use), index= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ax/miniconda3/envs/aml/lib/python3.6/site-packages/ipykernel_launcher.py:1: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "[Parallel(n_jobs=-1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   4 out of   4 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   6 out of   6 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   7 out of   7 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n",
      "8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   8 out of   8 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   9 out of   9 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  11 out of  11 | elapsed:    0.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  12 out of  12 | elapsed:    0.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  12 out of  12 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  13 out of  13 | elapsed:    0.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  14 out of  14 | elapsed:    0.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  14 out of  14 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:    0.4s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  15 out of  15 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  16 out of  16 | elapsed:    0.4s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  16 out of  16 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  17 out of  17 | elapsed:    0.4s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  17 out of  17 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  18 out of  18 | elapsed:    0.4s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  18 out of  18 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  19 out of  19 | elapsed:    0.4s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  19 out of  19 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  20 out of  20 | elapsed:    0.4s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  21 out of  21 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  21 out of  21 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  22 out of  22 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  22 out of  22 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  23 out of  23 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  23 out of  23 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  24 out of  24 | elapsed:    0.6s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  24 out of  24 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  25 out of  25 | elapsed:    0.6s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  25 out of  25 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  26 out of  26 | elapsed:    0.6s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  26 out of  26 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  27 out of  27 | elapsed:    0.7s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  27 out of  27 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  28 out of  28 | elapsed:    0.6s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  28 out of  28 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  29 out of  29 | elapsed:    0.7s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  29 out of  29 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed:    0.7s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  31 out of  31 | elapsed:    0.7s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  31 out of  31 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  32 out of  32 | elapsed:    0.7s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  32 out of  32 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  33 out of  33 | elapsed:    0.7s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  33 out of  33 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  34 out of  34 | elapsed:    0.8s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  34 out of  34 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  35 out of  35 | elapsed:    0.8s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  35 out of  35 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  36 out of  36 | elapsed:    0.8s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  36 out of  36 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  37 out of  37 | elapsed:    0.8s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  37 out of  37 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  38 out of  38 | elapsed:    0.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  38 out of  38 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  39 out of  39 | elapsed:    0.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  39 out of  39 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:    0.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  40 out of  40 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  41 out of  41 | elapsed:    0.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  41 out of  41 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  42 out of  42 | elapsed:    0.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  42 out of  42 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  43 out of  43 | elapsed:    0.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  43 out of  43 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  44 out of  44 | elapsed:    1.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  44 out of  44 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  45 out of  45 | elapsed:    1.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  45 out of  45 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  46 out of  46 | elapsed:    1.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  46 out of  46 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  47 out of  47 | elapsed:    1.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  47 out of  47 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  48 out of  48 | elapsed:    1.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  48 out of  48 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  49 out of  49 | elapsed:    1.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  49 out of  49 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:    1.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  51 out of  51 | elapsed:    1.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  51 out of  51 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  52 out of  52 | elapsed:    1.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  52 out of  52 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  53 out of  53 | elapsed:    1.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  53 out of  53 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  54 out of  54 | elapsed:    1.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  54 out of  54 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  55 out of  55 | elapsed:    1.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  55 out of  55 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  56 out of  56 | elapsed:    1.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  56 out of  56 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  57 out of  57 | elapsed:    1.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  57 out of  57 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  58 out of  58 | elapsed:    1.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  58 out of  58 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  59 out of  59 | elapsed:    1.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  59 out of  59 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  60 out of  60 | elapsed:    1.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  60 out of  60 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  61 out of  61 | elapsed:    1.4s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  61 out of  61 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  62 out of  62 | elapsed:    1.4s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  62 out of  62 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  63 out of  63 | elapsed:    1.4s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  63 out of  63 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  64 out of  64 | elapsed:    1.5s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  64 out of  64 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  65 out of  65 | elapsed:    1.5s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  65 out of  65 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  66 out of  66 | elapsed:    1.5s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  66 out of  66 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  67 out of  67 | elapsed:    1.5s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  67 out of  67 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  68 out of  68 | elapsed:    1.6s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  68 out of  68 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  69 out of  69 | elapsed:    1.6s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  69 out of  69 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  70 out of  70 | elapsed:    1.7s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  70 out of  70 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  71 out of  71 | elapsed:    1.7s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  71 out of  71 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  72 out of  72 | elapsed:    1.6s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  72 out of  72 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  73 out of  73 | elapsed:    1.6s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  73 out of  73 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  74 out of  74 | elapsed:    1.7s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  74 out of  74 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  75 out of  75 | elapsed:    1.7s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  75 out of  75 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  76 out of  76 | elapsed:    1.7s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  76 out of  76 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  77 out of  77 | elapsed:    1.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  77 out of  77 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  78 out of  78 | elapsed:    2.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  78 out of  78 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  79 out of  79 | elapsed:    1.8s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  79 out of  79 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  80 out of  80 | elapsed:    1.8s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  80 out of  80 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  81 out of  81 | elapsed:    1.8s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  81 out of  81 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  82 out of  82 | elapsed:    1.8s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  82 out of  82 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  83 out of  83 | elapsed:    1.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  83 out of  83 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  84 out of  84 | elapsed:    1.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  84 out of  84 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  85 out of  85 | elapsed:    1.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  85 out of  85 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  86 out of  86 | elapsed:    1.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  86 out of  86 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  87 out of  87 | elapsed:    2.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  87 out of  87 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  88 out of  88 | elapsed:    2.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  88 out of  88 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  89 out of  89 | elapsed:    2.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  89 out of  89 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  90 out of  90 | elapsed:    2.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  90 out of  90 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  91 out of  91 | elapsed:    2.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  91 out of  91 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  92 out of  92 | elapsed:    2.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  92 out of  92 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  93 out of  93 | elapsed:    2.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  93 out of  93 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  94 out of  94 | elapsed:    2.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  94 out of  94 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  95 out of  95 | elapsed:    2.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  95 out of  95 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  96 out of  96 | elapsed:    2.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  96 out of  96 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  97 out of  97 | elapsed:    2.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  97 out of  97 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  98 out of  98 | elapsed:    2.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  98 out of  98 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  99 out of  99 | elapsed:    2.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  99 out of  99 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f9da6102400>]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "rf_X = X_reduced_dim.drop([\"y\"], axis=1).as_matrix()\n",
    "rf_y = X_reduced_dim[\"y\"].values\n",
    "scores = []\n",
    "for i in range(1, 100):\n",
    "    print(i)\n",
    "    rf = RandomForestRegressor(n_jobs=-1, n_estimators=i, verbose=1)\n",
    "    rf.fit(rf_X, rf_y)\n",
    "    scores.append(rf.score(rf_X, rf_y))\n",
    "    \n",
    "plt.plot(scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82\n"
     ]
    }
   ],
   "source": [
    "print(np.argmax(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  25 out of  25 | elapsed:    0.6s finished\n",
      "/home/ax/miniconda3/envs/aml/lib/python3.6/site-packages/ipykernel_launcher.py:4: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  after removing the cwd from sys.path.\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  25 out of  25 | elapsed:    0.0s finished\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestRegressor(n_jobs=-1, n_estimators=25, verbose=1)\n",
    "rf.fit(rf_X, rf_y)\n",
    "\n",
    "y_pred = rf.predict(X_test_reduced_dim.as_matrix())\n",
    "submission =  pd.DataFrame(data={\"id\": list(range(776)), \"y\": y_pred}) \n",
    "submission.to_csv(\"submissions/mean_RFR25_f{}.csv\".format(n_features_to_use), index= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n"
     ]
    }
   ],
   "source": [
    "mlp_scores = []\n",
    "index = 0\n",
    "for i in range(10, 50):\n",
    "    mlp_scores.append([])\n",
    "    print(i)\n",
    "    for j in range(1, 50):\n",
    "    \n",
    "        modelMLP = MLPRegressor(learning_rate='constant', \n",
    "                                 hidden_layer_sizes=(i, j),\n",
    "                                 activation='logistic', \n",
    "                                 learning_rate_init=0.001,\n",
    "                                 max_iter=15000, \n",
    "                                 random_state=42,\n",
    "                                 early_stopping =True,\n",
    "                                 validation_fraction=0.1,\n",
    "                                 tol=0.00000000001,\n",
    "                                 alpha=0.1,\n",
    "                                 #n_iter_no_change=100,\n",
    "                                 verbose=False)\n",
    "        modelMLP.fit(rf_X, rf_y)\n",
    "        mlp_scores[index].append(modelMLP.best_validation_score_)\n",
    "    index = index + 1\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i=4, j=37, val=0.6542349024019642\n"
     ]
    }
   ],
   "source": [
    "min_index = []\n",
    "for i in range(0, 40):\n",
    "    min_index.append(np.max(mlp_scores[i]))\n",
    "\n",
    "min_i = np.argmax(min_index)\n",
    "min_j = np.argmax(mlp_scores[min_i])\n",
    "\n",
    "print('i={}, j={}, val={}'.format(min_i, min_j, mlp_scores[min_i][min_j]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ax/miniconda3/envs/aml/lib/python3.6/site-packages/ipykernel_launcher.py:14: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "modelMLP = MLPRegressor(learning_rate='constant', \n",
    "                             hidden_layer_sizes=(4, 37),\n",
    "                             activation='logistic', \n",
    "                             learning_rate_init=0.001,\n",
    "                             max_iter=15000, \n",
    "                             random_state=42,\n",
    "                             early_stopping =True,\n",
    "                             validation_fraction=0.1,\n",
    "                             tol=0.00000000001,\n",
    "                             alpha=0.1,\n",
    "                             #n_iter_no_change=100,\n",
    "                             verbose=False)\n",
    "modelMLP.fit(rf_X, rf_y)\n",
    "y_pred = modelMLP.predict(X_test_reduced_dim.as_matrix())\n",
    "submission =  pd.DataFrame(data={\"id\": list(range(776)), \"y\": y_pred}) \n",
    "submission.to_csv(\"submissions/mean_MP_4_37_f{}.csv\".format(n_features_to_use), index= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (aml-3)",
   "language": "python",
   "name": "myenv1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
