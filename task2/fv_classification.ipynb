{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import csv\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_selection import RFE, f_regression\n",
    "from sklearn.linear_model import (LinearRegression, Ridge, Lasso, RandomizedLasso)\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.ensemble import (RandomForestRegressor,RandomForestClassifier, IsolationForest)\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.feature_selection import f_regression, f_classif\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import random as rn\n",
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import math\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.feature_selection import chi2\n",
    "\n",
    "\n",
    "#Keras import\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LeakyReLU\n",
    "from keras.optimizers import *\n",
    "from keras.layers import Dropout\n",
    "from keras import regularizers\n",
    "from keras import initializers\n",
    "from keras.losses import *\n",
    "\n",
    "\n",
    "TRAIN_FILE_PATH = \"data/X_train.csv\"\n",
    "TARGET_FILE_PATH =  \"data/y_train.csv\"\n",
    "TEST_FILE_PATH = \"data/X_test.csv\"\n",
    "\n",
    "seed=42\n",
    "np.random.seed(seed)\n",
    "rn.seed(seed)\n",
    "session_conf = tf.ConfigProto(intra_op_parallelism_threads=1,\n",
    "                              inter_op_parallelism_threads=1)\n",
    "\n",
    "\n",
    "\n",
    "# The below tf.set_random_seed() will make random number generation\n",
    "# in the TensorFlow backend have a well-defined initial state.\n",
    "# For further details, see:\n",
    "# https://www.tensorflow.org/api_docs/python/tf/set_random_seed\n",
    "\n",
    "tf.set_random_seed(seed)\n",
    "\n",
    "sess = tf.Session(graph=tf.get_default_graph(), config=session_conf)\n",
    "K.set_session(sess)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load train and test set\n",
    "\n",
    "X_train = pd.read_csv(TRAIN_FILE_PATH)\n",
    "X_train.drop(X_train.columns[0], axis=1, inplace=True)\n",
    "\n",
    "Y_train = pd.read_csv(TARGET_FILE_PATH)\n",
    "Y_train.drop(Y_train.columns[0], axis=1, inplace = True)\n",
    "\n",
    "X_test =  pd.read_csv(TEST_FILE_PATH)\n",
    "id_test = X_test.columns[0]\n",
    "X_test.drop(X_test.columns[0], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Helper functions\n",
    "\n",
    "def from_class_to_vec(y_list):\n",
    "\n",
    "    Y_vec_list = []\n",
    "    print(\"Length of list passed: \",len(y_list))\n",
    "    \n",
    "    for value in y_list:\n",
    "        if value == 0.0:\n",
    "            Y_vec_list.append([1,0,0])\n",
    "        if value == 1.0:\n",
    "            Y_vec_list.append([0,1,0])\n",
    "        if value == 2.0:\n",
    "            Y_vec_list.append([0,0,1])\n",
    "\n",
    "    #print(\"Example binary vector \",Y_vec_0_vs_all)\n",
    "    return np.array(Y_vec_list)\n",
    "\n",
    "\n",
    "def count_labels(labels_list):\n",
    "    zeros = 0\n",
    "    ones = 0\n",
    "    twos = 0\n",
    "    for value in labels:\n",
    "        if value == 0:\n",
    "            zeros = zeros + 1\n",
    "        if value == 1:\n",
    "            ones = ones + 1\n",
    "        if value == 2:\n",
    "            twos = twos + 1\n",
    "        \n",
    "    print(zeros)\n",
    "    print(ones)\n",
    "    print(twos)\n",
    "    \n",
    "def make_submission(filename, predictions):\n",
    "    test_data =  pd.read_csv(TEST_FILE_PATH)\n",
    "    test_data[\"y\"] = predictions\n",
    "    test_data[[\"id\", \"y\"]].to_csv(\"submissions/\"+filename, index= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of list passed:  4800\n",
      "Probabilistc vector Y shape:  (4800, 3)\n"
     ]
    }
   ],
   "source": [
    "#Y_train_new = Y_train_balanced['y'].tolist()\n",
    "Y_vec_train = from_class_to_vec(Y_train['y'].tolist())\n",
    "\n",
    "print(\"Probabilistc vector Y shape: \",Y_vec_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Zero mean unit variance for train and test data\n",
    "def scale_data(train, test):\n",
    "    \n",
    "    print(\"Train shape: \", train.shape)\n",
    "    print(\"Test shape: \",test.shape)\n",
    "    \n",
    "    scaler = StandardScaler().fit(train, Y_train)\n",
    "    train = scaler.transform(train)\n",
    "    test = scaler.transform(test)\n",
    "   \n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape:  (4800, 1000)\n",
      "Test shape:  (4100, 1000)\n"
     ]
    }
   ],
   "source": [
    "#X_train_balanced_scaled, X_test_scaled = scale_data(X_train_balanced, X_test)\n",
    "X_train_scaled, X_test_scaled = scale_data(X_train, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input dimensions:  1000\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "input_dimensions = 1000\n",
    "lambda_reg = 0.1\n",
    "dropout = 0\n",
    "\n",
    "\n",
    "def coeff_determination(y_true, y_pred):\n",
    "    from keras import backend as K\n",
    "    SS_res =  K.sum(K.square( y_true-y_pred ))\n",
    "    SS_tot = K.sum(K.square( y_true - K.mean(y_true) ) )\n",
    "    return ( 1 - SS_res/(SS_tot + K.epsilon()) )\n",
    "\n",
    "def weighted_loss(y_true, y_pred):\n",
    "    from keras import backend as K\n",
    "    #weights = [0.7,1,0.7]\n",
    "    weights = [2,1,2]    \n",
    "    weights = K.variable(value=weights)\n",
    "    return K.sum(K.exp((y_true - y_pred)* weights))\n",
    "\n",
    "def bmac(y_true, y_pred):\n",
    "    y_true_labels = K.cast(x = K.argmax(y_true, axis = -1),dtype = 'float32')\n",
    "    y_pred_labels = K.cast(x = K.argmax(y_pred, axis = -1),dtype = 'float32')\n",
    "\n",
    "    # reshape in case it's in shape (num_samples, 1) instead of (num_samples,)\n",
    "    #if K.ndim(y_true) == K.ndim(y_pred):\n",
    "    #    y_true = K.squeeze(y_true, -1)\n",
    "    # convert dense predictions to labels\n",
    "    #y_pred_labels = K.argmax(y_pred, axis=-1)\n",
    "    #y_pred_labels = K.cast(y_pred_labels, K.floatx())\n",
    "    #y_true_labels = K.argmax(y_true, axis=-1)    \n",
    "    #y_pred_labels = K.cast(y_true_labels, K.floatx())\n",
    "    \n",
    "    return tf.metrics.mean_per_class_accuracy(y_true_labels, y_pred_labels, num_classes = 3)\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "def exponetial_loss(y_true, y_pred)\n",
    "    #loss = sum(loss_vec)\n",
    "    loss = math.exp(y_true[0]-y_pred[0]*weights[0])+math.exp(y_true[1]-y_pred[1]*weights[1])+math.exp(y_true[2]-y_pred[2]*weights[2])\n",
    "    return loss\n",
    "\"\"\"\n",
    "\n",
    "optimizer = Adam(lr=0.001)\n",
    "print(\"Input dimensions: \", input_dimensions)\n",
    "\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(300, input_dim= input_dimensions, kernel_regularizer = regularizers.l2(lambda_reg)))\n",
    "model.add(LeakyReLU(alpha=1))\n",
    "model.add(Dropout(rate = dropout))\n",
    "model.add(Dense(300, input_dim= input_dimensions, kernel_regularizer = regularizers.l2(lambda_reg)))\n",
    "model.add(LeakyReLU(alpha=1))\n",
    "model.add(Dropout(rate = dropout))\n",
    "model.add(Dense(300, input_dim= input_dimensions, kernel_regularizer = regularizers.l2(lambda_reg)))\n",
    "model.add(LeakyReLU(alpha=1))\n",
    "model.add(Dropout(rate = dropout))\n",
    "model.add(Dense(300, input_dim= input_dimensions, kernel_regularizer = regularizers.l2(lambda_reg)))\n",
    "model.add(LeakyReLU(alpha=1))\n",
    "model.add(Dropout(rate = dropout))\n",
    "\"\"\"model.add(Dense(500, input_dim= input_dimensions, kernel_regularizer = regularizers.l2(lambda_reg)))\n",
    "model.add(LeakyReLU(alpha=1))\n",
    "model.add(Dropout(rate = dropout))\n",
    "model.add(Dense(500, input_dim= input_dimensions, kernel_regularizer = regularizers.l2(lambda_reg)))\n",
    "model.add(LeakyReLU(alpha=1))\n",
    "model.add(Dropout(rate = dropout))\"\"\"\n",
    "\n",
    "\n",
    "    \n",
    "model.add(Dense(3, kernel_regularizer = regularizers.l2(lambda_reg), activation = 'softmax'))\n",
    "\n",
    "model.compile(loss=weighted_loss, optimizer=optimizer, metrics=['accuracy'])#[bmac])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4320 samples, validate on 480 samples\n",
      "Epoch 1/20\n",
      "50/50 [==============================] - 10s 191ms/step - loss: 17231.0000 - acc: 0.5456 - val_loss: 2021.7157 - val_acc: 0.5833\n",
      "Epoch 2/20\n",
      "50/50 [==============================] - 7s 149ms/step - loss: 16466.7872 - acc: 0.6086 - val_loss: 1894.7380 - val_acc: 0.6646\n",
      "Epoch 3/20\n",
      "50/50 [==============================] - 7s 146ms/step - loss: 15262.5457 - acc: 0.7210 - val_loss: 1935.1818 - val_acc: 0.6396\n",
      "Epoch 4/20\n",
      "50/50 [==============================] - 8s 151ms/step - loss: 14934.7428 - acc: 0.7510 - val_loss: 1861.6353 - val_acc: 0.6958\n",
      "Epoch 5/20\n",
      "50/50 [==============================] - 7s 146ms/step - loss: 14399.2456 - acc: 0.8056 - val_loss: 1871.6598 - val_acc: 0.7188\n",
      "Epoch 6/20\n",
      "50/50 [==============================] - 8s 151ms/step - loss: 14236.0436 - acc: 0.8242 - val_loss: 1829.7190 - val_acc: 0.7188\n",
      "Epoch 7/20\n",
      "50/50 [==============================] - 7s 150ms/step - loss: 14367.9402 - acc: 0.8156 - val_loss: 1861.9683 - val_acc: 0.7333\n",
      "Epoch 8/20\n",
      "50/50 [==============================] - 8s 152ms/step - loss: 14116.7484 - acc: 0.8455 - val_loss: 1864.1191 - val_acc: 0.7292\n",
      "Epoch 9/20\n",
      "50/50 [==============================] - 8s 155ms/step - loss: 14106.1833 - acc: 0.8449 - val_loss: 1848.9486 - val_acc: 0.7500\n",
      "Epoch 10/20\n",
      "50/50 [==============================] - 7s 147ms/step - loss: 14116.7754 - acc: 0.8379 - val_loss: 1829.8069 - val_acc: 0.7417\n",
      "Epoch 11/20\n",
      "50/50 [==============================] - 8s 151ms/step - loss: 14018.1057 - acc: 0.8575 - val_loss: 1812.4551 - val_acc: 0.7521\n",
      "Epoch 12/20\n",
      "50/50 [==============================] - 7s 150ms/step - loss: 14203.3292 - acc: 0.8523 - val_loss: 1845.5225 - val_acc: 0.7542\n",
      "Epoch 13/20\n",
      "50/50 [==============================] - 7s 149ms/step - loss: 13983.2828 - acc: 0.8714 - val_loss: 1840.7537 - val_acc: 0.7604\n",
      "Epoch 14/20\n",
      "50/50 [==============================] - 8s 154ms/step - loss: 13960.0393 - acc: 0.8741 - val_loss: 1854.2000 - val_acc: 0.7563\n",
      "Epoch 15/20\n",
      "50/50 [==============================] - 8s 154ms/step - loss: 13940.2140 - acc: 0.8754 - val_loss: 1852.3689 - val_acc: 0.7583\n",
      "Epoch 16/20\n",
      "50/50 [==============================] - 8s 154ms/step - loss: 13920.7696 - acc: 0.8763 - val_loss: 1837.0529 - val_acc: 0.7604\n",
      "Epoch 17/20\n",
      "50/50 [==============================] - 8s 159ms/step - loss: 14043.3783 - acc: 0.8561 - val_loss: 1842.6666 - val_acc: 0.7479\n",
      "Epoch 18/20\n",
      "50/50 [==============================] - 8s 157ms/step - loss: 13883.3229 - acc: 0.8775 - val_loss: 1820.8075 - val_acc: 0.7667\n",
      "Epoch 19/20\n",
      "50/50 [==============================] - 8s 156ms/step - loss: 13825.1965 - acc: 0.8821 - val_loss: 1800.4435 - val_acc: 0.7646\n",
      "Epoch 20/20\n",
      "50/50 [==============================] - 8s 152ms/step - loss: 13996.7898 - acc: 0.8693 - val_loss: 1820.3251 - val_acc: 0.7458\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f43002d4470>"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_epochs = 20\n",
    "\n",
    "model.fit(x=X_train_scaled, y=Y_vec_train, epochs=num_epochs, verbose=1, validation_split=0.1, shuffle=True, \n",
    "          steps_per_epoch=50, initial_epoch=0, validation_steps=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4100\n",
      "920\n",
      "2554\n",
      "626\n",
      "[0, 0, 1, 1, 0, 1, 1, 2, 1, 1, 0, 1, 1, 1, 1, 2, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 2, 0, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 2, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 2, 1, 1, 2, 0, 0, 1, 1, 1, 1, 1, 1, 2, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 2, 0, 1, 0, 1, 2, 0, 2, 1, 1, 1, 0, 2, 2, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 2, 1, 0, 1, 1, 2, 1, 1, 1, 2, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 2, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 2, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 2, 1, 1, 0, 0, 1, 1, 2, 1, 0, 2, 1, 1, 2, 1, 2, 0, 0, 1, 0, 2, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 2, 0, 1, 0, 1, 1, 1, 1, 1, 2, 1, 1, 2, 2, 1, 1, 2, 1, 0, 1, 1, 0, 1, 1, 2, 1, 2, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 2, 2, 1, 1, 1, 1, 1, 1, 2, 2, 1, 1, 1, 2, 1, 2, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 2, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 2, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 2, 1, 1, 2, 1, 1, 1, 2, 1, 0, 1, 1, 1, 1, 2, 2, 1, 1, 0, 0, 2, 0, 1, 2, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 2, 1, 1, 2, 0, 0, 1, 1, 1, 0, 2, 1, 1, 1, 0, 1, 2, 1, 1, 1, 1, 0, 2, 1, 0, 0, 1, 0, 1, 1, 0, 1, 2, 0, 1, 1, 2, 1, 2, 1, 0, 0, 2, 1, 1, 0, 1, 0, 1, 1, 1, 2, 0, 1, 2, 1, 0, 1, 1, 1, 2, 0, 1, 2, 1, 1, 1, 2, 1, 1, 0, 1, 1, 1, 1, 1, 0, 2, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 2, 0, 1, 1, 1, 2, 2, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 2, 1, 1, 1, 1, 2, 0, 0, 0, 1, 1, 1, 1, 0, 2, 2, 1, 1, 1, 0, 0, 2, 2, 1, 1, 0, 0, 1, 1, 1, 1, 2, 2, 0, 1, 0, 2, 0, 2, 1, 2, 0, 1, 2, 1, 1, 1, 0, 1, 2, 0, 2, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 2, 0, 0, 0, 2, 0, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 0, 2, 1, 0, 1, 2, 2, 1, 2, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 2, 0, 1, 2, 0, 0, 0, 1, 1, 0, 0, 0, 1, 2, 0, 0, 1, 1, 1, 1, 2, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 2, 2, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 0, 1, 1, 1, 1, 2, 1, 2, 1, 2, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 2, 0, 0, 1, 1, 1, 2, 1, 1, 2, 2, 1, 1, 1, 1, 2, 0, 1, 0, 1, 1, 1, 1, 0, 2, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 2, 2, 0, 2, 0, 2, 1, 1, 2, 0, 1, 0, 1, 2, 0, 1, 1, 1, 1, 0, 1, 2, 2, 0, 2, 0, 0, 2, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 2, 1, 0, 0, 1, 1, 1, 0, 2, 1, 1, 1, 1, 2, 1, 1, 0, 1, 0, 2, 2, 2, 1, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 1, 1, 1, 2, 1, 2, 1, 0, 1, 1, 2, 0, 0, 1, 2, 0, 1, 1, 2, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 2, 1, 2, 1, 1, 1, 1, 1, 0, 2, 1, 1, 1, 2, 1, 0, 1, 1, 1, 2, 0, 0, 1, 2, 1, 1, 1, 1, 0, 1, 1, 1, 0, 2, 1, 1, 0, 1, 2, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 2, 1, 1, 1, 2, 2, 1, 1, 1, 2, 1, 2, 0, 1, 1, 1, 1, 2, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 2, 1, 1, 1, 0, 1, 2, 0, 2, 1, 1, 1, 0, 1, 0, 2, 0, 1, 1, 1, 1, 2, 1, 1, 1, 1, 0, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 2, 1, 1, 0, 1, 1, 0, 0, 1, 2, 0, 1, 1, 1, 0, 1, 0, 1, 0, 2, 2, 2, 0, 2, 1, 2, 2, 2, 1, 1, 1, 0, 1, 1, 0, 2, 2, 1, 1, 1, 1, 1, 1, 2, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 2, 2, 2, 1, 1, 2, 2, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 2, 2, 1, 2, 1, 0, 1, 1, 0, 1, 1, 1, 1, 2, 1, 1, 1, 0, 2, 2, 0, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 2, 1, 0, 2, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 2, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 2, 0, 0, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 2, 0, 2, 2, 1, 1, 1, 2, 1, 1, 0, 1, 2, 1, 1, 0, 0, 0, 2, 0, 2, 2, 1, 0, 2, 1, 1, 2, 1, 1, 0, 1, 2, 0, 2, 1, 1, 0, 2, 1, 1, 1, 1, 0, 2, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 2, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 2, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 2, 1, 1, 2, 0, 1, 1, 1, 1, 1, 2, 2, 1, 1, 2, 1, 1, 1, 1, 1, 2, 1, 0, 1, 1, 1, 2, 1, 1, 2, 0, 2, 1, 1, 1, 2, 2, 0, 2, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 0, 2, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 2, 1, 0, 1, 1, 1, 1, 0, 1, 1, 2, 1, 1, 0, 0, 0, 1, 2, 1, 1, 1, 0, 1, 1, 0, 2, 1, 1, 1, 1, 2, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 2, 0, 1, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 2, 1, 1, 1, 2, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 0, 1, 1, 1, 0, 1, 0, 1, 2, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 2, 1, 2, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 2, 0, 2, 1, 1, 1, 1, 0, 1, 0, 2, 0, 1, 1, 1, 1, 1, 1, 0, 2, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 0, 1, 1, 2, 0, 1, 1, 0, 1, 0, 1, 0, 1, 2, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 2, 1, 0, 2, 1, 1, 1, 1, 0, 1, 1, 2, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 2, 1, 1, 2, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 2, 0, 1, 1, 0, 0, 1, 1, 1, 1, 2, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 2, 0, 1, 1, 1, 1, 0, 1, 1, 1, 2, 1, 0, 1, 2, 1, 1, 0, 0, 0, 2, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 0, 0, 2, 0, 2, 1, 1, 2, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 2, 0, 1, 0, 1, 1, 1, 2, 1, 2, 1, 1, 1, 1, 0, 0, 1, 2, 1, 1, 1, 0, 1, 2, 0, 0, 1, 1, 1, 1, 1, 1, 2, 1, 2, 1, 2, 0, 1, 1, 1, 2, 1, 1, 1, 2, 2, 1, 1, 2, 0, 0, 1, 2, 1, 2, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 2, 1, 2, 1, 1, 0, 0, 1, 2, 1, 1, 1, 1, 2, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 2, 0, 1, 1, 0, 1, 2, 1, 0, 1, 0, 1, 1, 1, 2, 0, 2, 1, 2, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 2, 1, 1, 1, 1, 2, 1, 0, 2, 1, 1, 0, 1, 1, 2, 1, 1, 0, 0, 1, 1, 1, 0, 1, 2, 2, 1, 0, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 2, 1, 2, 1, 1, 1, 1, 1, 1, 0, 1, 0, 2, 1, 1, 1, 0, 1, 0, 2, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 2, 1, 1, 1, 1, 0, 2, 0, 0, 2, 1, 2, 1, 1, 1, 1, 1, 1, 0, 0, 2, 0, 1, 0, 1, 2, 2, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 2, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 2, 2, 1, 1, 2, 1, 1, 1, 1, 1, 1, 2, 2, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 2, 1, 1, 0, 2, 1, 2, 1, 2, 1, 1, 1, 0, 1, 1, 1, 2, 2, 0, 0, 0, 1, 1, 1, 1, 1, 2, 0, 1, 0, 0, 1, 1, 2, 0, 0, 1, 1, 0, 1, 1, 1, 2, 1, 2, 2, 0, 1, 1, 0, 1, 1, 1, 1, 1, 2, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 2, 1, 1, 0, 2, 1, 1, 1, 0, 1, 1, 2, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 2, 2, 1, 1, 1, 1, 0, 1, 0, 0, 2, 0, 0, 0, 2, 1, 1, 1, 2, 0, 0, 1, 0, 1, 1, 1, 0, 2, 0, 1, 1, 1, 1, 0, 2, 1, 0, 0, 0, 1, 1, 0, 1, 1, 2, 1, 0, 1, 1, 2, 0, 1, 2, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 2, 1, 1, 0, 1, 0, 1, 1, 1, 1, 2, 1, 1, 2, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 2, 1, 2, 0, 2, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 2, 0, 0, 1, 0, 2, 1, 0, 0, 0, 1, 2, 1, 1, 1, 0, 1, 2, 0, 1, 1, 1, 1, 0, 1, 2, 1, 1, 2, 1, 1, 1, 1, 0, 1, 1, 1, 0, 2, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 2, 1, 1, 0, 2, 1, 1, 0, 1, 1, 2, 2, 0, 1, 2, 1, 1, 1, 1, 2, 1, 2, 1, 1, 1, 2, 2, 1, 1, 1, 1, 2, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 2, 2, 0, 0, 0, 1, 0, 0, 1, 2, 2, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 2, 0, 1, 1, 2, 2, 0, 2, 2, 1, 1, 2, 1, 0, 1, 0, 1, 2, 1, 1, 1, 0, 1, 1, 1, 2, 0, 0, 1, 0, 1, 2, 0, 0, 0, 1, 2, 0, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 2, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 2, 1, 1, 2, 2, 0, 1, 0, 0, 1, 2, 0, 1, 1, 1, 1, 0, 1, 2, 1, 1, 2, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 2, 0, 1, 1, 1, 1, 2, 1, 1, 1, 1, 2, 1, 1, 1, 2, 1, 2, 1, 1, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 2, 1, 0, 1, 2, 2, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 2, 1, 1, 1, 2, 1, 1, 0, 1, 1, 0, 0, 0, 1, 2, 0, 0, 0, 1, 1, 1, 0, 2, 1, 1, 0, 2, 2, 1, 1, 1, 1, 1, 2, 1, 0, 1, 1, 2, 1, 1, 1, 2, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 2, 2, 1, 1, 1, 1, 1, 2, 2, 1, 0, 1, 2, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 2, 1, 1, 2, 1, 1, 0, 1, 0, 1, 2, 1, 2, 1, 1, 1, 1, 2, 1, 1, 0, 1, 1, 0, 1, 1, 2, 1, 1, 1, 2, 2, 1, 1, 1, 0, 1, 2, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 2, 1, 2, 1, 0, 1, 1, 2, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 2, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 1, 2, 1, 1, 0, 2, 2, 0, 1, 1, 2, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 2, 1, 1, 1, 1, 1, 2, 2, 1, 2, 1, 0, 2, 1, 0, 1, 1, 1, 1, 1, 1, 1, 2, 1, 0, 1, 0, 1, 0, 2, 0, 1, 2, 1, 1, 1, 0, 1, 0, 2, 0, 2, 0, 2, 0, 1, 0, 2, 1, 1, 2, 1, 1, 1, 0, 0, 1, 1, 1, 2, 2, 1, 1, 2, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 2, 1, 1, 1, 1, 1, 2, 2, 0, 0, 1, 0, 2, 2, 0, 1, 1, 1, 0, 2, 1, 0, 2, 0, 2, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 2, 2, 1, 0, 1, 1, 0, 2, 1, 1, 2, 1, 1, 1, 2, 0, 1, 1, 2, 1, 2, 1, 1, 1, 1, 0, 0, 1, 1, 2, 0, 2, 1, 1, 1, 2, 1, 0, 2, 0, 1, 2, 1, 2, 0, 2, 1, 1, 0, 1, 1, 1, 2, 1, 0, 1, 1, 1, 0, 1, 0, 2, 1, 1, 1, 1, 0, 1, 0, 1, 1, 2, 1, 1, 1, 1, 2, 1, 1, 2, 1, 1, 1, 1, 0, 2, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 2, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 2, 0, 0, 2, 1, 0, 1, 1, 1, 1, 1, 1, 0, 2, 0, 1, 1, 1, 2, 1, 0, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 2, 0, 1, 1, 1, 1, 0, 1, 2, 1, 1, 1, 1, 2, 1, 2, 1, 1, 1, 1, 2, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 2, 1, 1, 0, 2, 1, 0, 0, 2, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 2, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 2, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 2, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 2, 1, 2, 1, 1, 1, 1, 2, 1, 1, 2, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 2, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 2, 1, 0, 1, 2, 2, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 2, 1, 1, 1, 1, 0, 2, 1, 1, 1, 1, 1, 1, 1, 2, 2, 1, 2, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 2, 1, 0, 1, 1, 2, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 2, 1, 1, 0, 1, 0, 1, 2, 2, 1, 0, 1, 0, 1, 2, 0, 0, 0, 1, 1, 1, 0, 1, 2, 1, 1, 1, 1, 1, 1, 2, 1, 1, 0, 1, 0, 1, 2, 1, 1, 1, 0, 1, 1, 1, 1, 1, 2, 1, 2, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 2, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 2, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 2, 1, 1, 1, 2, 1, 2, 0, 0, 0, 2, 2, 1, 1, 1, 1, 1, 2, 1, 0, 1, 2, 1, 0, 1, 1, 0, 1, 0, 2, 2, 1, 0, 1, 1, 0, 2, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 2, 2, 1, 1, 2, 0, 1, 1, 2, 2, 1, 2, 1, 1, 2, 0, 2, 1, 1, 1, 1, 2, 1, 1, 2, 0, 1, 2, 1, 1, 1, 0, 1, 0, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 2, 1, 2, 2, 1, 1, 2, 1, 1, 2, 0, 1, 1, 1, 0, 2, 1, 0, 1, 1, 1, 1, 0, 2, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 2, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 2, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 0, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 2, 0, 1, 1, 1, 1, 1, 2, 1, 0, 1, 1, 1, 0, 0, 1, 2, 0, 1, 1, 1, 0, 0, 1, 1, 1, 2, 0, 1, 2, 2, 1, 1, 1, 2, 2, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 2, 1, 0, 2, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 0, 0, 2, 0, 1, 1, 1, 0, 1, 2, 0, 1, 0, 1, 2, 0, 0, 1, 1, 1, 1, 1, 2, 1, 1, 2, 1, 1, 1, 1, 2, 1, 1, 1, 1, 0, 0, 1, 1, 2, 0, 1, 1, 1, 1, 2, 1, 1, 2, 0, 0, 1, 0, 1, 1, 0, 2, 0, 1, 1, 1, 0, 2, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 0, 0, 2, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 2, 2, 0, 0, 2, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 2, 1, 1, 1, 1, 2, 2, 2, 1, 1, 1, 2, 1, 2, 0, 2, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 2, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 2, 1, 0, 1, 2, 1, 1, 0, 2, 1, 1, 1, 0, 1, 1, 2, 1, 0, 2, 1, 1, 1, 1, 2, 1, 1, 1, 1, 2, 0, 2, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 2, 1, 1, 1, 1, 0, 1, 1, 2, 0, 2, 1, 2, 1, 2, 1, 0, 1, 1, 1, 0, 0, 2, 2, 1, 1, 1, 2, 0, 1, 2, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 2, 1, 2, 1, 1, 2, 1, 2, 2, 2, 2, 1, 1, 1, 2, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 2, 2, 2, 1, 2, 1, 1, 2, 1, 1, 0, 2, 1, 1, 1, 0, 1, 1, 2, 1, 1, 2, 1, 1, 1, 1, 1, 2, 2, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 1, 1, 0, 0, 1, 1, 0, 0, 2, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 2, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 2, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 0, 1, 2, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 2, 2, 1, 1, 0, 1, 1, 0, 0, 1, 0, 2, 1, 1, 0, 1, 1, 1, 1, 0, 1, 2, 1, 1, 1, 2, 0, 1, 2, 1, 1, 2, 2, 2, 1, 0, 1, 1, 2, 0, 1, 1, 2, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "p = model.predict(X_test_scaled)\n",
    "\n",
    "labels = []\n",
    "for vec in p:\n",
    "    val = np.argmax(vec)\n",
    "    labels.append(val)\n",
    "print(len(labels))\n",
    "count_labels(labels)\n",
    "print(labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_submission(\"NN_4layer_300units_weight09109_077val_acc.csv\", labels)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
