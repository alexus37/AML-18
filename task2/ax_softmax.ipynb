{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python: 3.6.6 |Anaconda, Inc.| (default, Jun 28 2018, 17:14:51) \n",
      "[GCC 7.2.0]\n",
      "scipy: 1.1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "# packages to load \n",
    "# Check the versions of libraries\n",
    "# Python version\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import sys\n",
    "print('Python: {}'.format(sys.version))\n",
    "\n",
    "import scipy\n",
    "print('scipy: {}'.format(scipy.__version__))\n",
    "\n",
    "import csv\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "\n",
    "# Importing metrics for evaluation\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn import svm\n",
    "import random as rn\n",
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LeakyReLU\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers import Dropout\n",
    "from keras import regularizers\n",
    "from keras import initializers\n",
    "from keras.callbacks import (TensorBoard, EarlyStopping, ReduceLROnPlateau, ModelCheckpoint)\n",
    "\n",
    "import math\n",
    "from itertools import product\n",
    "TRAIN_FILE_PATH = \"data/X_train.csv\"\n",
    "TARGET_FILE_PATH =  \"data/y_train.csv\"\n",
    "TEST_FILE_PATH = \"data/X_test.csv\"\n",
    "\n",
    "seed=42\n",
    "np.random.seed(seed)\n",
    "rn.seed(seed)\n",
    "session_conf = tf.ConfigProto(intra_op_parallelism_threads=1,\n",
    "                              inter_op_parallelism_threads=1)\n",
    "\n",
    "\n",
    "\n",
    "# The below tf.set_random_seed() will make random number generation\n",
    "# in the TensorFlow backend have a well-defined initial state.\n",
    "# For further details, see:\n",
    "# https://www.tensorflow.org/api_docs/python/tf/set_random_seed\n",
    "\n",
    "tf.set_random_seed(seed)\n",
    "\n",
    "sess = tf.Session(graph=tf.get_default_graph(), config=session_conf)\n",
    "K.set_session(sess)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load train and test set\n",
    "\n",
    "train_data = pd.read_csv(TRAIN_FILE_PATH)\n",
    "train_data.drop(\"id\", axis=1, inplace=True)\n",
    "\n",
    "Y_train = pd.read_csv(TARGET_FILE_PATH)\n",
    "Y_train.drop(\"id\", axis=1, inplace = True)\n",
    "\n",
    "test_data =  pd.read_csv(TEST_FILE_PATH)\n",
    "id_test = test_data.columns[0]\n",
    "test_data.drop(\"id\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ================ FUNCTION DEFS ================ ##\n",
    "\n",
    "#Zero mean unit variance for train and test data\n",
    "def scale_data(train, test):\n",
    "    \n",
    "    print(\"Train shape: \", train.shape)\n",
    "    print(\"Test shape: \",test.shape)\n",
    "    \n",
    "    scaler = StandardScaler().fit(train, Y_train)\n",
    "    train = scaler.transform(train)\n",
    "    test = scaler.transform(test)\n",
    "   \n",
    "    return train, test\n",
    "\n",
    "def make_submission(filename, predictions):\n",
    "    test_data =  pd.read_csv(TEST_FILE_PATH)\n",
    "    test_data[\"y\"] = predictions\n",
    "    test_data[[\"id\", \"y\"]].to_csv(\"submissions/\"+filename, index= False)\n",
    "    \n",
    "def as_keras_metric(method):\n",
    "    import functools\n",
    "    from keras import backend as K\n",
    "    import tensorflow as tf\n",
    "    @functools.wraps(method)\n",
    "    def wrapper(self, args, **kwargs):\n",
    "        \"\"\" Wrapper for turning tensorflow metrics into keras metrics \"\"\"\n",
    "        value, update_op = method(self, args, **kwargs)\n",
    "        K.get_session().run(tf.local_variables_initializer())\n",
    "        with tf.control_dependencies([update_op]):\n",
    "            value = tf.identity(value)\n",
    "        return value\n",
    "    return wrapper\n",
    "\n",
    "def weighted_categorical_crossentropy(weights):\n",
    "    \"\"\"\n",
    "    A weighted version of keras.objectives.categorical_crossentropy\n",
    "    \n",
    "    Variables:\n",
    "        weights: numpy array of shape (C,) where C is the number of classes\n",
    "    \n",
    "    Usage:\n",
    "        weights = np.array([0.5,2,10]) # Class one at 0.5, class 2 twice the normal weights, class 3 10x.\n",
    "        loss = weighted_categorical_crossentropy(weights)\n",
    "        model.compile(loss=loss,optimizer='adam')\n",
    "    \"\"\"\n",
    "    \n",
    "    weights = K.variable(weights)\n",
    "        \n",
    "    def loss(y_true, y_pred):\n",
    "        # scale predictions so that the class probas of each sample sum to 1\n",
    "        y_pred /= K.sum(y_pred, axis=-1, keepdims=True)\n",
    "        # clip to prevent NaN's and Inf's\n",
    "        y_pred = K.clip(y_pred, K.epsilon(), 1 - K.epsilon())\n",
    "        # calc\n",
    "        loss = y_true * K.log(y_pred) * weights\n",
    "        loss = -K.sum(loss, -1)\n",
    "        return loss\n",
    "    \n",
    "    return loss\n",
    "\n",
    "@as_keras_metric\n",
    "def bmac_metric(Y_true, Y_pred):\n",
    "    return tf.metrics.mean_per_class_accuracy(Y_true, Y_pred, 3)\n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.tight_layout()\n",
    "\n",
    "# define baseline model\n",
    "def baseline_model(weights=[], dropout=0.5, lambda_reg=2.0):\n",
    "    # create model\n",
    "    optimizer = Adam(lr=0.01, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
    "    #model.add(LeakyReLU(alpha=0.1))\n",
    "    # model.add(Dropout(rate = dropout))\n",
    "\n",
    "    #model.add(Dense(1, kernel_regularizer = regularizers.l1(lambda_reg)))\n",
    "    \n",
    "    \n",
    "    nn = Sequential()\n",
    "    \n",
    "    nn.add(Dense(32, input_dim=1000, activation='relu', kernel_regularizer = regularizers.l2(lambda_reg)))\n",
    "    #nn.add(LeakyReLU(alpha=0.1))\n",
    "    #nn.add(Dropout(rate = dropout))\n",
    "    \n",
    "    nn.add(Dense(16, activation='relu'))\n",
    "    #nn.add(LeakyReLU(alpha=0.1))\n",
    "    #nn.add(Dropout(rate = dropout))\n",
    "    \n",
    "    nn.add(Dense(8, activation='relu'))\n",
    "    #nn.add(LeakyReLU(alpha=0.1))\n",
    "    #nn.add(Dropout(rate = dropout))\n",
    "    \n",
    "    nn.add(Dense(4,activation='relu'))\n",
    "    #nn.add(LeakyReLU(alpha=0.1))\n",
    "    #nn.add(Dropout(rate = dropout))\n",
    "    \n",
    "    nn.add(Dense(3, activation='softmax'))\n",
    "    # Compile model\n",
    "   \n",
    "\n",
    "    nn.compile(loss=\"categorical_crossentropy\", #weighted_categorical_crossentropy(weights), \n",
    "               optimizer=optimizer, \n",
    "               metrics=[bmac_metric])\n",
    "    nn.summary()\n",
    "    return nn\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape:  (4800, 1000)\n",
      "Test shape:  (4100, 1000)\n"
     ]
    }
   ],
   "source": [
    "X_train_scaled, X_test_scaled = scale_data(train_data, test_data)\n",
    "# encode class values as integers\n",
    "encoder = OneHotEncoder(handle_unknown='ignore')\n",
    "encoder.fit(Y_train.values)\n",
    "encoded_Y = encoder.transform(Y_train.values).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ax/miniconda3/envs/aml/lib/python3.6/site-packages/sklearn/utils/validation.py:752: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-ac1119d89774>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mkernel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'rbf'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     )\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/aml/lib/python3.6/site-packages/sklearn/svm/base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m         \u001b[0mseed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrnd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miinfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'i'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 212\u001b[0;31m         \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msolver_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_seed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    213\u001b[0m         \u001b[0;31m# see comment on the other call to np.iinfo in this file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/aml/lib/python3.6/site-packages/sklearn/svm/base.py\u001b[0m in \u001b[0;36m_dense_fit\u001b[0;34m(self, X, y, sample_weight, solver_type, kernel, random_seed)\u001b[0m\n\u001b[1;32m    269\u001b[0m                 \u001b[0mcache_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcache_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoef0\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoef0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m                 \u001b[0mgamma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gamma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepsilon\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 271\u001b[0;31m                 max_iter=self.max_iter, random_seed=random_seed)\n\u001b[0m\u001b[1;32m    272\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_warn_from_fit_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "clf = svm.SVC(\n",
    "        class_weight={0: 6, 1: 1, 2: 6},\n",
    "        decision_function_shape='ovr',\n",
    "        kernel='rbf'\n",
    "    )\n",
    "clf.fit(train_data.values, Y_train.values)\n",
    "    \n",
    "predicted = clf.predict(test_data.values)\n",
    "make_submission('ax_SVC_ovr_rbf.csv', predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4320, 1000)\n",
      "(4320, 1)\n",
      "Current BMAC score 0.6611111111111111\n",
      "(4320, 1000)\n",
      "(4320, 1)\n",
      "Current BMAC score 0.6861111111111112\n",
      "(4320, 1000)\n",
      "(4320, 1)\n",
      "Current BMAC score 0.7064814814814815\n",
      "(4320, 1000)\n",
      "(4320, 1)\n",
      "Current BMAC score 0.6953703703703704\n",
      "(4320, 1000)\n",
      "(4320, 1)\n",
      "Current BMAC score 0.7259259259259259\n",
      "(4320, 1000)\n",
      "(4320, 1)\n",
      "Current BMAC score 0.7157407407407407\n",
      "(4320, 1000)\n",
      "(4320, 1)\n",
      "Current BMAC score 0.686111111111111\n",
      "(4320, 1000)\n",
      "(4320, 1)\n",
      "Current BMAC score 0.6972222222222223\n",
      "(4320, 1000)\n",
      "(4320, 1)\n",
      "Current BMAC score 0.7268518518518517\n",
      "(4320, 1000)\n",
      "(4320, 1)\n",
      "Current BMAC score 0.6351851851851852\n",
      "AVG: BMAC score: 0.6936 (+/- 0.0272)\n"
     ]
    }
   ],
   "source": [
    "kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=seed)\n",
    "BMAC = []\n",
    "\n",
    "for train, test in kfold.split(X_train_scaled, Y_train.values):\n",
    "    X = train_data.values[train]\n",
    "    Y = Y_train.values[train]\n",
    "    X_test = train_data.values[test]\n",
    "    Y_valid = Y_train.values[test]\n",
    "    \n",
    "    clf = svm.SVC(\n",
    "        class_weight={0: 6, 1: 1, 2: 6}\n",
    "    )\n",
    "    clf.fit(X, Y)\n",
    "    \n",
    "    Y_pred = clf.predict(X_test)\n",
    "    Y_true = Y_train.values[test]\n",
    "    cur_BMAC = balanced_accuracy_score(Y_true, Y_pred)\n",
    "    print(f\"Current BMAC score {cur_BMAC}\")\n",
    "    BMAC.append(cur_BMAC)\n",
    "\n",
    "print(\"AVG: BMAC score: %.4f (+/- %.4f)\" % (np.mean(BMAC), np.std(BMAC)))\n",
    "\n",
    "#predicted= clf.predict(X_test_scaled)\n",
    "#make_submission('ax_SVC_scaled.csv', predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ax/miniconda3/envs/aml/lib/python3.6/site-packages/keras/callbacks.py:928: UserWarning: `epsilon` argument is deprecated and will be removed, use `min_delta` insted.\n",
      "  warnings.warn('`epsilon` argument is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "540\n",
      "3240\n",
      "540\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 32)                32032     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 8)                 136       \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 4)                 36        \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 3)                 15        \n",
      "=================================================================\n",
      "Total params: 32,747\n",
      "Trainable params: 32,747\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 4320 samples, validate on 480 samples\n",
      "Epoch 1/70\n",
      "100/100 [==============================] - 2s 24ms/step - loss: 8.3463 - bmac_metric: 0.3489 - val_loss: 1.1459 - val_bmac_metric: 0.3507\n",
      "Epoch 2/70\n",
      "100/100 [==============================] - 2s 19ms/step - loss: 2.7260 - bmac_metric: 0.3472 - val_loss: 2.0046 - val_bmac_metric: 0.3443\n",
      "Epoch 3/70\n",
      "100/100 [==============================] - 2s 19ms/step - loss: 3.2436 - bmac_metric: 0.3454 - val_loss: 1.4527 - val_bmac_metric: 0.3451\n",
      "Epoch 4/70\n",
      "100/100 [==============================] - 2s 21ms/step - loss: 3.0310 - bmac_metric: 0.3480 - val_loss: 8.6690 - val_bmac_metric: 0.3473\n",
      "Epoch 5/70\n",
      "100/100 [==============================] - 2s 19ms/step - loss: 4.3173 - bmac_metric: 0.3487 - val_loss: 1.1373 - val_bmac_metric: 0.3473\n",
      "Epoch 6/70\n",
      "100/100 [==============================] - 2s 19ms/step - loss: 3.0349 - bmac_metric: 0.3474 - val_loss: 1.9919 - val_bmac_metric: 0.3474\n",
      "Epoch 7/70\n",
      "100/100 [==============================] - 2s 19ms/step - loss: 2.3800 - bmac_metric: 0.3470 - val_loss: 1.0890 - val_bmac_metric: 0.3467\n",
      "Epoch 8/70\n",
      "100/100 [==============================] - 2s 19ms/step - loss: 2.6181 - bmac_metric: 0.3465 - val_loss: 1.1090 - val_bmac_metric: 0.3466\n",
      "\n",
      "Epoch 00008: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
      "Epoch 9/70\n",
      "100/100 [==============================] - 2s 19ms/step - loss: 1.7347 - bmac_metric: 0.3458 - val_loss: 0.7972 - val_bmac_metric: 0.3451\n",
      "Epoch 10/70\n",
      "100/100 [==============================] - 2s 19ms/step - loss: 1.5447 - bmac_metric: 0.3445 - val_loss: 0.7571 - val_bmac_metric: 0.3439\n",
      "Epoch 11/70\n",
      "100/100 [==============================] - 2s 19ms/step - loss: 1.4716 - bmac_metric: 0.3434 - val_loss: 0.7890 - val_bmac_metric: 0.3430\n",
      "Epoch 12/70\n",
      "100/100 [==============================] - 2s 19ms/step - loss: 1.3903 - bmac_metric: 0.3425 - val_loss: 0.8144 - val_bmac_metric: 0.3422\n",
      "Epoch 13/70\n",
      "100/100 [==============================] - 2s 19ms/step - loss: 1.3421 - bmac_metric: 0.3418 - val_loss: 0.9127 - val_bmac_metric: 0.3415\n",
      "Epoch 14/70\n",
      "100/100 [==============================] - 2s 20ms/step - loss: 1.2546 - bmac_metric: 0.3412 - val_loss: 1.0078 - val_bmac_metric: 0.3409\n",
      "Epoch 15/70\n",
      "100/100 [==============================] - 2s 19ms/step - loss: 1.3134 - bmac_metric: 0.3407 - val_loss: 1.0492 - val_bmac_metric: 0.3405\n",
      "\n",
      "Epoch 00015: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n",
      "Epoch 16/70\n",
      "100/100 [==============================] - 2s 19ms/step - loss: 0.9648 - bmac_metric: 0.3403 - val_loss: 0.7699 - val_bmac_metric: 0.3401\n",
      "Epoch 17/70\n",
      "100/100 [==============================] - 2s 19ms/step - loss: 0.8923 - bmac_metric: 0.3399 - val_loss: 0.7650 - val_bmac_metric: 0.3397\n",
      "Epoch 18/70\n",
      "100/100 [==============================] - 2s 22ms/step - loss: 0.8677 - bmac_metric: 0.3395 - val_loss: 0.7648 - val_bmac_metric: 0.3393\n",
      "Epoch 19/70\n",
      "100/100 [==============================] - 2s 19ms/step - loss: 0.8478 - bmac_metric: 0.3392 - val_loss: 0.7679 - val_bmac_metric: 0.3390\n",
      "Epoch 20/70\n",
      "100/100 [==============================] - 2s 19ms/step - loss: 0.8289 - bmac_metric: 0.3389 - val_loss: 0.7699 - val_bmac_metric: 0.3387\n",
      "Epoch 21/70\n",
      "100/100 [==============================] - 2s 19ms/step - loss: 0.8097 - bmac_metric: 0.3386 - val_loss: 0.7746 - val_bmac_metric: 0.3385\n",
      "Epoch 22/70\n",
      "100/100 [==============================] - 2s 19ms/step - loss: 0.7907 - bmac_metric: 0.3384 - val_loss: 0.7806 - val_bmac_metric: 0.3382\n",
      "\n",
      "Epoch 00022: ReduceLROnPlateau reducing learning rate to 9.999999019782991e-06.\n",
      "Epoch 23/70\n",
      "100/100 [==============================] - 2s 19ms/step - loss: 0.7798 - bmac_metric: 0.3381 - val_loss: 0.7804 - val_bmac_metric: 0.3380\n",
      "Epoch 24/70\n",
      "100/100 [==============================] - 2s 19ms/step - loss: 0.7779 - bmac_metric: 0.3379 - val_loss: 0.7808 - val_bmac_metric: 0.3378\n",
      "Epoch 25/70\n",
      "100/100 [==============================] - 2s 19ms/step - loss: 0.7759 - bmac_metric: 0.3377 - val_loss: 0.7812 - val_bmac_metric: 0.3376\n",
      "Epoch 26/70\n",
      "100/100 [==============================] - 2s 19ms/step - loss: 0.7740 - bmac_metric: 0.3376 - val_loss: 0.7818 - val_bmac_metric: 0.3375\n",
      "Epoch 27/70\n",
      "100/100 [==============================] - 2s 20ms/step - loss: 0.7720 - bmac_metric: 0.3374 - val_loss: 0.7822 - val_bmac_metric: 0.3373\n",
      "Epoch 28/70\n",
      "100/100 [==============================] - 2s 20ms/step - loss: 0.7700 - bmac_metric: 0.3373 - val_loss: 0.7825 - val_bmac_metric: 0.3372\n",
      "Epoch 29/70\n",
      "100/100 [==============================] - 2s 21ms/step - loss: 0.7680 - bmac_metric: 0.3371 - val_loss: 0.7831 - val_bmac_metric: 0.3371\n",
      "\n",
      "Epoch 00029: ReduceLROnPlateau reducing learning rate to 9.99999883788405e-07.\n",
      "Epoch 30/70\n",
      "100/100 [==============================] - 3s 29ms/step - loss: 0.7668 - bmac_metric: 0.3370 - val_loss: 0.7832 - val_bmac_metric: 0.3369\n",
      "Epoch 31/70\n",
      "100/100 [==============================] - 2s 21ms/step - loss: 0.7666 - bmac_metric: 0.3369 - val_loss: 0.7832 - val_bmac_metric: 0.3368\n",
      "Epoch 32/70\n",
      "100/100 [==============================] - 2s 16ms/step - loss: 0.7664 - bmac_metric: 0.3368 - val_loss: 0.7833 - val_bmac_metric: 0.3367\n",
      "Epoch 33/70\n",
      "100/100 [==============================] - 2s 17ms/step - loss: 0.7662 - bmac_metric: 0.3367 - val_loss: 0.7833 - val_bmac_metric: 0.3366\n",
      "Epoch 34/70\n",
      "100/100 [==============================] - 2s 20ms/step - loss: 0.7659 - bmac_metric: 0.3366 - val_loss: 0.7834 - val_bmac_metric: 0.3365\n",
      "Epoch 35/70\n",
      "100/100 [==============================] - 2s 21ms/step - loss: 0.7657 - bmac_metric: 0.3365 - val_loss: 0.7834 - val_bmac_metric: 0.3364\n",
      "Epoch 36/70\n",
      "100/100 [==============================] - 2s 19ms/step - loss: 0.7655 - bmac_metric: 0.3364 - val_loss: 0.7835 - val_bmac_metric: 0.3363\n",
      "\n",
      "Epoch 00036: ReduceLROnPlateau reducing learning rate to 9.99999883788405e-08.\n",
      "Epoch 37/70\n",
      "100/100 [==============================] - 2s 17ms/step - loss: 0.7653 - bmac_metric: 0.3363 - val_loss: 0.7835 - val_bmac_metric: 0.3362\n",
      "Epoch 38/70\n",
      "100/100 [==============================] - 2s 16ms/step - loss: 0.7653 - bmac_metric: 0.3362 - val_loss: 0.7835 - val_bmac_metric: 0.3362\n",
      "Epoch 39/70\n",
      "100/100 [==============================] - 2s 17ms/step - loss: 0.7653 - bmac_metric: 0.3361 - val_loss: 0.7835 - val_bmac_metric: 0.3361\n",
      "Epoch 40/70\n",
      "100/100 [==============================] - 2s 20ms/step - loss: 0.7652 - bmac_metric: 0.3361 - val_loss: 0.7835 - val_bmac_metric: 0.3361\n",
      "Epoch 41/70\n",
      "100/100 [==============================] - 2s 21ms/step - loss: 0.7652 - bmac_metric: 0.3361 - val_loss: 0.7835 - val_bmac_metric: 0.3361\n",
      "Epoch 42/70\n",
      "100/100 [==============================] - 3s 25ms/step - loss: 0.7652 - bmac_metric: 0.3361 - val_loss: 0.7835 - val_bmac_metric: 0.3361\n",
      "Epoch 43/70\n",
      "100/100 [==============================] - 2s 22ms/step - loss: 0.7652 - bmac_metric: 0.3361 - val_loss: 0.7835 - val_bmac_metric: 0.3361\n",
      "\n",
      "Epoch 00043: ReduceLROnPlateau reducing learning rate to 9.999998695775504e-09.\n",
      "Epoch 44/70\n",
      "100/100 [==============================] - 2s 21ms/step - loss: 0.7651 - bmac_metric: 0.3361 - val_loss: 0.7835 - val_bmac_metric: 0.3361\n",
      "Epoch 45/70\n",
      "100/100 [==============================] - 2s 21ms/step - loss: 0.7651 - bmac_metric: 0.3361 - val_loss: 0.7835 - val_bmac_metric: 0.3361\n",
      "Epoch 46/70\n",
      "100/100 [==============================] - 2s 19ms/step - loss: 0.7651 - bmac_metric: 0.3361 - val_loss: 0.7835 - val_bmac_metric: 0.3361\n",
      "Epoch 47/70\n",
      "100/100 [==============================] - 2s 18ms/step - loss: 0.7651 - bmac_metric: 0.3361 - val_loss: 0.7835 - val_bmac_metric: 0.3361\n",
      "Epoch 48/70\n",
      "100/100 [==============================] - 2s 17ms/step - loss: 0.7651 - bmac_metric: 0.3361 - val_loss: 0.7835 - val_bmac_metric: 0.3361\n",
      "Epoch 49/70\n",
      "100/100 [==============================] - 2s 17ms/step - loss: 0.7651 - bmac_metric: 0.3361 - val_loss: 0.7835 - val_bmac_metric: 0.3361\n",
      "Epoch 50/70\n",
      "100/100 [==============================] - 2s 19ms/step - loss: 0.7651 - bmac_metric: 0.3361 - val_loss: 0.7835 - val_bmac_metric: 0.3361\n",
      "\n",
      "Epoch 00050: ReduceLROnPlateau reducing learning rate to 9.99999905104687e-10.\n",
      "Epoch 51/70\n",
      "100/100 [==============================] - 2s 22ms/step - loss: 0.7651 - bmac_metric: 0.3361 - val_loss: 0.7835 - val_bmac_metric: 0.3361\n",
      "Epoch 52/70\n",
      "100/100 [==============================] - 2s 21ms/step - loss: 0.7651 - bmac_metric: 0.3361 - val_loss: 0.7835 - val_bmac_metric: 0.3361\n",
      "Epoch 53/70\n",
      "100/100 [==============================] - 2s 21ms/step - loss: 0.7651 - bmac_metric: 0.3361 - val_loss: 0.7835 - val_bmac_metric: 0.3361\n",
      "Epoch 54/70\n",
      "100/100 [==============================] - 2s 21ms/step - loss: 0.7651 - bmac_metric: 0.3361 - val_loss: 0.7835 - val_bmac_metric: 0.3361\n",
      "Epoch 55/70\n",
      "100/100 [==============================] - 2s 21ms/step - loss: 0.7651 - bmac_metric: 0.3361 - val_loss: 0.7835 - val_bmac_metric: 0.3361\n",
      "Epoch 56/70\n",
      "100/100 [==============================] - 2s 22ms/step - loss: 0.7651 - bmac_metric: 0.3361 - val_loss: 0.7835 - val_bmac_metric: 0.3361\n",
      "Epoch 57/70\n",
      "100/100 [==============================] - 2s 25ms/step - loss: 0.7651 - bmac_metric: 0.3361 - val_loss: 0.7835 - val_bmac_metric: 0.3361\n",
      "\n",
      "Epoch 00057: ReduceLROnPlateau reducing learning rate to 9.999998606957661e-11.\n",
      "Epoch 58/70\n",
      "100/100 [==============================] - 2s 24ms/step - loss: 0.7651 - bmac_metric: 0.3361 - val_loss: 0.7835 - val_bmac_metric: 0.3361\n",
      "Epoch 59/70\n",
      "100/100 [==============================] - 2s 22ms/step - loss: 0.7651 - bmac_metric: 0.3361 - val_loss: 0.7835 - val_bmac_metric: 0.3361\n",
      "Epoch 60/70\n",
      "100/100 [==============================] - 2s 24ms/step - loss: 0.7651 - bmac_metric: 0.3361 - val_loss: 0.7835 - val_bmac_metric: 0.3361\n",
      "Epoch 61/70\n",
      "100/100 [==============================] - 2s 24ms/step - loss: 0.7651 - bmac_metric: 0.3361 - val_loss: 0.7835 - val_bmac_metric: 0.3361\n",
      "Epoch 62/70\n",
      "100/100 [==============================] - 2s 22ms/step - loss: 0.7651 - bmac_metric: 0.3361 - val_loss: 0.7835 - val_bmac_metric: 0.3361\n",
      "Epoch 63/70\n",
      "100/100 [==============================] - 2s 22ms/step - loss: 0.7651 - bmac_metric: 0.3361 - val_loss: 0.7835 - val_bmac_metric: 0.3361\n",
      "Epoch 64/70\n",
      "100/100 [==============================] - 2s 23ms/step - loss: 0.7651 - bmac_metric: 0.3361 - val_loss: 0.7835 - val_bmac_metric: 0.3361\n",
      "\n",
      "Epoch 00064: ReduceLROnPlateau reducing learning rate to 9.99999874573554e-12.\n",
      "Epoch 65/70\n",
      "100/100 [==============================] - 2s 21ms/step - loss: 0.7651 - bmac_metric: 0.3361 - val_loss: 0.7835 - val_bmac_metric: 0.3361\n",
      "Epoch 66/70\n",
      "100/100 [==============================] - 2s 21ms/step - loss: 0.7651 - bmac_metric: 0.3361 - val_loss: 0.7835 - val_bmac_metric: 0.3361\n",
      "Epoch 67/70\n",
      "100/100 [==============================] - 2s 21ms/step - loss: 0.7651 - bmac_metric: 0.3361 - val_loss: 0.7835 - val_bmac_metric: 0.3361\n",
      "Epoch 68/70\n",
      "100/100 [==============================] - 2s 22ms/step - loss: 0.7651 - bmac_metric: 0.3361 - val_loss: 0.7835 - val_bmac_metric: 0.3361\n",
      "Epoch 69/70\n",
      "100/100 [==============================] - 2s 21ms/step - loss: 0.7651 - bmac_metric: 0.3361 - val_loss: 0.7835 - val_bmac_metric: 0.3361\n",
      "Epoch 70/70\n",
      "100/100 [==============================] - 2s 22ms/step - loss: 0.7651 - bmac_metric: 0.3361 - val_loss: 0.7835 - val_bmac_metric: 0.3361\n",
      "Current BMAC score 0.5018518518518519\n",
      "AVG: BMAC score: 0.5019 (+/- 0.0000)\n",
      "Confusion matrix, without normalization\n",
      "[[ 55   5   0]\n",
      " [146 212   2]\n",
      " [ 57   3   0]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "BMAC = []\n",
    "cMat = None\n",
    "\n",
    "# tf board call back\n",
    "tbCallBack = TensorBoard(log_dir='./logs', histogram_freq=0, write_graph=True, write_images=True)\n",
    "earlyStop = EarlyStopping(monitor='val_bmac_metric', patience=10, verbose=1, mode='auto')\n",
    "mcp_save = ModelCheckpoint('.mdl_wts.hdf5', save_best_only=True, monitor='val_bmac_metric', mode='max')\n",
    "reduce_lr_loss = ReduceLROnPlateau(monitor='val_bmac_metric', factor=0.1, patience=7, verbose=1, epsilon=1e-4, mode='max')\n",
    "\n",
    "num_epochs = 70\n",
    "\n",
    "kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=seed)\n",
    "\n",
    "for train, test in kfold.split(X_train_scaled, Y_train.values):\n",
    "    X = X_train_scaled[train]\n",
    "    Y = encoded_Y[train]\n",
    "    X_test = X_train_scaled[test]\n",
    "    Y_valid = encoded_Y[test]\n",
    "    # compute the class weights\n",
    "    fac_0_2_class = 2\n",
    "    #class_weights = np.array([(np.sum(Y_train.values == 0) / X_train_scaled.shape[0]) * fac_0_2_class, \n",
    "    #                      np.sum(Y_train.values == 1) / X_train_scaled.shape[0], \n",
    "    #                      (np.sum(Y_train.values == 2) / X_train_scaled.shape[0]) * fac_0_2_class])\n",
    "    print(np.sum(Y_train.values[train] == 0))\n",
    "    print(np.sum(Y_train.values[train] == 1))\n",
    "    print(np.sum(Y_train.values[train] == 2))\n",
    "    model = baseline_model()\n",
    "    class_weight = {0: 6., 1: 1.,2: 6.}\n",
    "    \n",
    "    # Fit the model\n",
    "    model.fit(x=X, y=Y, epochs=num_epochs, verbose=1, validation_data=(X_test, Y_valid), shuffle=True, \n",
    "              steps_per_epoch=100, initial_epoch=0, validation_steps=5,\n",
    "              class_weight=class_weight,\n",
    "             callbacks=[\n",
    "             #tbCallBack,\n",
    "             #earlyStop, \n",
    "             mcp_save, \n",
    "             reduce_lr_loss])\n",
    "    \n",
    "    \n",
    "    \n",
    "    model.load_weights(filepath = '.mdl_wts.hdf5')\n",
    "    Y_pred = [[p] for p in  model.predict_classes(X_test)]\n",
    "    Y_true = Y_train.values[test]\n",
    "    cur_BMAC = balanced_accuracy_score(Y_true, Y_pred)\n",
    "    print(f\"Current BMAC score {cur_BMAC}\")\n",
    "    BMAC.append(cur_BMAC)\n",
    "    cMat = confusion_matrix(Y_true, Y_pred)\n",
    "    break # only do a single run\n",
    "    \n",
    "print(\"AVG: BMAC score: %.4f (+/- %.4f)\" % (np.mean(BMAC), np.std(BMAC)))\n",
    "plot_confusion_matrix(cMat, [\"0\", \"1\", \"2\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_121 (Dense)            (None, 32)                32032     \n",
      "_________________________________________________________________\n",
      "dense_122 (Dense)            (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dense_123 (Dense)            (None, 8)                 136       \n",
      "_________________________________________________________________\n",
      "dense_124 (Dense)            (None, 4)                 36        \n",
      "_________________________________________________________________\n",
      "dense_125 (Dense)            (None, 3)                 15        \n",
      "=================================================================\n",
      "Total params: 32,747\n",
      "Trainable params: 32,747\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 4320 samples, validate on 480 samples\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-38-6c2a83f7d172>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m              \u001b[0;31m#earlyStop,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m              \u001b[0mmcp_save\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m              reduce_lr_loss])\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'.mdl_wts.hdf5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/aml/lib/python3.6/site-packages/keras/models.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1000\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1001\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1002\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1003\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1004\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/miniconda3/envs/aml/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1703\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1704\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1705\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1706\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1707\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/miniconda3/envs/aml/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m   1153\u001b[0m             \u001b[0mcallback_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1155\u001b[0;31m         \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallback_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1156\u001b[0m         callbacks.set_params({\n\u001b[1;32m   1157\u001b[0m             \u001b[0;34m'batch_size'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/aml/lib/python3.6/site-packages/keras/callbacks.py\u001b[0m in \u001b[0;36mset_model\u001b[0;34m(self, model)\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mset_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m             \u001b[0mcallback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mon_epoch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/aml/lib/python3.6/site-packages/keras/callbacks.py\u001b[0m in \u001b[0;36mset_model\u001b[0;34m(self, model)\u001b[0m\n\u001b[1;32m    785\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite_graph\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    786\u001b[0m             self.writer = tf.summary.FileWriter(self.log_dir,\n\u001b[0;32m--> 787\u001b[0;31m                                                 self.sess.graph)\n\u001b[0m\u001b[1;32m    788\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    789\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwriter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFileWriter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/aml/lib/python3.6/site-packages/tensorflow/python/summary/writer/writer.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, logdir, graph, max_queue, flush_secs, graph_def, filename_suffix, session)\u001b[0m\n\u001b[1;32m    365\u001b[0m       event_writer = EventFileWriter(logdir, max_queue, flush_secs,\n\u001b[1;32m    366\u001b[0m                                      filename_suffix)\n\u001b[0;32m--> 367\u001b[0;31m     \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFileWriter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevent_writer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgraph_def\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    368\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    369\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__enter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/aml/lib/python3.6/site-packages/tensorflow/python/summary/writer/writer.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, event_writer, graph, graph_def)\u001b[0m\n\u001b[1;32m     81\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mgraph\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mgraph_def\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m       \u001b[0;31m# Calling it with both graph and graph_def for backward compatibility.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgraph_def\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgraph_def\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m       \u001b[0;31m# Also export the meta_graph_def in this case.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m       \u001b[0;31m# graph may itself be a graph_def due to positional arguments\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/aml/lib/python3.6/site-packages/tensorflow/python/summary/writer/writer.py\u001b[0m in \u001b[0;36madd_graph\u001b[0;34m(self, graph, global_step, graph_def)\u001b[0m\n\u001b[1;32m    211\u001b[0m                       \"or the deprecated `GraphDef`\")\n\u001b[1;32m    212\u001b[0m     \u001b[0;31m# Finally, add the graph_def to the summary writer.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 213\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_add_graph_def\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrue_graph_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglobal_step\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_write_plugin_assets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/aml/lib/python3.6/site-packages/tensorflow/python/summary/writer/writer.py\u001b[0m in \u001b[0;36m_add_graph_def\u001b[0;34m(self, graph_def, global_step)\u001b[0m\n\u001b[1;32m    156\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_add_graph_def\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgraph_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglobal_step\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 158\u001b[0;31m     \u001b[0mgraph_bytes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSerializeToString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    159\u001b[0m     \u001b[0mevent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevent_pb2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEvent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph_def\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgraph_bytes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_add_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglobal_step\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# use all data for training\n",
    "fac_0_2_class = 1\n",
    "num_epochs = 100\n",
    "class_weights = np.array([(np.sum(Y_train.values == 0) / X_train_scaled.shape[0]) * fac_0_2_class, \n",
    "                          np.sum(Y_train.values == 1) / X_train_scaled.shape[0], \n",
    "                          (np.sum(Y_train.values == 2) / X_train_scaled.shape[0]) * fac_0_2_class])\n",
    "\n",
    "model = baseline_model(class_weights)\n",
    "\n",
    "\n",
    "# Fit the model\n",
    "model.fit(x=X_train_scaled, y=encoded_Y, epochs=num_epochs, verbose=1, validation_split=0.1, shuffle=True, \n",
    "          steps_per_epoch=100, initial_epoch=0, validation_steps=5, \n",
    "         callbacks=[\n",
    "             tbCallBack,\n",
    "             #earlyStop, \n",
    "             mcp_save, \n",
    "             reduce_lr_loss])\n",
    "\n",
    "model.load_weights(filepath = '.mdl_wts.hdf5')\n",
    "pred = model.predict_classes(X_test_scaled)\n",
    "make_submission('ax_SOFTMAX.csv', pred)\n",
    "print(\"Process finsihed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (aml-3)",
   "language": "python",
   "name": "myenv1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
