{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nSame for all\\nMin: -0.0033\\nMax: 0.0033\\n\\n\\nRAT 0\\nClass 1: 11240\\nClass 2: 8653\\nClass 3: 1707\\nMean: -7.270247766565382e-06\\nStd: 0.00014033437213481842\\n\\nRAT 1\\nClass 1: 11849\\nClass 2: 8647\\nClass 3: 1104\\nMean: -4.883171278211801e-06\\nStd: 8.972252301644052e-05\\n\\nRAT 2\\nClass 1: 11025\\nClass 2: 9833\\nClass 3: 742\\nMean: -4.952989167390033e-06\\nStd: 0.00010911971573637134\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import natsort\n",
    "import random as rn\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import tensorflow as tf\n",
    "import pyeeg\n",
    "from scipy import signal\n",
    "from scipy.signal import welch\n",
    "from scipy.integrate import simps\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#Keras\n",
    "\n",
    "#Sklearn\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.svm import (SVC, SVR)\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import (RandomForestClassifier, GradientBoostingClassifier)\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import (StratifiedKFold, KFold)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "seed=42\n",
    "np.random.seed(seed)\n",
    "rn.seed(seed)\n",
    "tf.set_random_seed(seed)\n",
    "dir_path = os.getcwd()\n",
    "\n",
    "# https://en.wikipedia.org/wiki/Neural_oscillation\n",
    "SAMPLE_PER_SEC = 128\n",
    "ALPHA_WAVE = [7.5, 12.5]\n",
    "BETA_WAVE = [13, 30]\n",
    "THETA_WAVE = [4, 8]\n",
    "DELTA_WAVE = [1, 4]\n",
    "LOW_GAMMA_WAVE = [30, 70]\n",
    "HIGH_GAMMA_WAVE = [70, 150]\n",
    "EPSILON =  0.0002\n",
    "\n",
    "\"\"\"\n",
    "Same for all\n",
    "Min: -0.0033\n",
    "Max: 0.0033\n",
    "\n",
    "\n",
    "RAT 0\n",
    "Class 1: 11240\n",
    "Class 2: 8653\n",
    "Class 3: 1707\n",
    "Mean: -7.270247766565382e-06\n",
    "Std: 0.00014033437213481842\n",
    "\n",
    "RAT 1\n",
    "Class 1: 11849\n",
    "Class 2: 8647\n",
    "Class 3: 1104\n",
    "Mean: -4.883171278211801e-06\n",
    "Std: 8.972252301644052e-05\n",
    "\n",
    "RAT 2\n",
    "Class 1: 11025\n",
    "Class 2: 9833\n",
    "Class 3: 742\n",
    "Mean: -4.952989167390033e-06\n",
    "Std: 0.00010911971573637134\n",
    "\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_from_csv(csv_file):\n",
    "    '''\n",
    "    get a numpy array y of labels. the order follows the id of 4 second sample. \n",
    "    argument: relative path to the csv_file from the source folder.\n",
    "    '''\n",
    "    csv_file = os.path.join(dir_path, csv_file)\n",
    "    print(f\"Reading {csv_file}\")\n",
    "    with open(csv_file, 'r') as csvfile:\n",
    "        train_reader = pd.read_csv(csvfile)\n",
    "        train_reader.drop(labels=\"Id\", axis=1, inplace=True)\n",
    "        \n",
    "        \n",
    "    return train_reader.values\n",
    "\n",
    "def get_target_from_csv(csv_file):\n",
    "    '''\n",
    "    get a numpy array y of labels. the order follows the id of 4 second sample. \n",
    "    argument: relative path to the csv_file from the source folder.\n",
    "    '''\n",
    "    csv_file = os.path.join(dir_path,csv_file)\n",
    "    with open(csv_file, 'r') as csvfile:\n",
    "        label_reader = pd.read_csv(csvfile)\n",
    "        #print(\"Labels: \", label_reader['id'])\n",
    "        y = label_reader['y']\n",
    "        \n",
    "    y = np.array(y)\n",
    "    return y\n",
    "\n",
    "def get_features_emg_wavelet(X):\n",
    "    \"\"\"\n",
    "     absolute EEG power in the 1–4Hz\n",
    "    (delta), 5–9Hz (theta), 10–20Hz (low beta), and 30–40Hz (high beta) bands, absolute EMG\n",
    "    power in the 1–10Hz band, theta-to-delta ratio, and beta-to-delta ratio \n",
    "    \"\"\"\n",
    "    all_featues = []\n",
    "    for i in tqdm(range(X.shape[0])):\n",
    "        features = list()\n",
    "        x_i = X[i,:]\n",
    "        delta = bandpower(x_i, DELTA_WAVE)\n",
    "        features.append(delta)\n",
    "        \n",
    "        theta = bandpower(x_i, THETA_WAVE)\n",
    "        features.append(theta)\n",
    "        \n",
    "        beta = bandpower(x_i, BETA_WAVE)\n",
    "        features.append(beta)\n",
    "        \n",
    "        features.append(bandpower(x_i, ALPHA_WAVE))\n",
    "        \n",
    "        features.append(theta / delta)\n",
    "        features.append(beta / delta)\n",
    "    \n",
    "        all_featues.append(features)\n",
    "    return np.array(all_featues)\n",
    "\n",
    "def get_features_emg(X):\n",
    "    all_featues = []\n",
    "    for i in tqdm(range(X.shape[0])):\n",
    "        features = list()\n",
    "        # https://ieeexplore.ieee.org/document/7748960\n",
    "        x_i = X[i,:]\n",
    "        # Root Mean Square (RMS): RMS of EMG\n",
    "        #features.append(mean_squared_error(x_i, np.zeros(x_i.shape)))\n",
    "        \n",
    "        #Integrated Absolute Value (IAV)\n",
    "        #features.append(np.sum(np.abs(x_i)))\n",
    "        \n",
    "        # Mean Absolute Value (MAV): MAV feature can be expressed as\n",
    "        #features.append(np.mean(x_i))\n",
    "        \n",
    "        # TBD:\n",
    "        # Modified Mean Absolute Value type 1\n",
    "        # Modified Mean Absolute Value type 2\n",
    "        \n",
    "        # Simple Square Integral (SSI): SSI is calculated as\n",
    "        #features.append(np.sum(x_i ** 2))\n",
    "        \n",
    "        # Variance (VAR): VAR is calculated as\n",
    "        #features.append(np.var(x_i))\n",
    "        \n",
    "        #The 3rd, 4th and 5th temporal moments\n",
    "        #features.append(np.mean(x_i ** 3))\n",
    "        #features.append(np.mean(x_i ** 4))\n",
    "        #features.append(np.mean(x_i ** 5))\n",
    "        \n",
    "        # TBD\n",
    "        # v-Order \n",
    "        \n",
    "        # Waveform Length\n",
    "        #features.append(np.sum(np.abs(np.diff(x_i))))\n",
    "        \n",
    "        # Average Amplitude Change\n",
    "        #features.append(np.mean(np.abs(np.diff(x_i))))\n",
    "        \n",
    "        # Difference Absolute Standard Deviation Value\n",
    "        #features.append(np.sqrt(np.mean(np.power(np.diff(x_i), 2))))\n",
    "        \n",
    "        # AX BASIC FEATUERS\n",
    "        features.append(np.sum(np.abs(x_i) > EPSILON))\n",
    "        \n",
    "        \n",
    "        \n",
    "        all_featues.append(features)\n",
    "    return np.array(all_featues)\n",
    "\n",
    "def get_features_eeg(X):\n",
    "    all_featues = []\n",
    "    # NOT SURE ABOUT THIS VALUES \n",
    "    # LETS DOUBLE CHECK\n",
    "    K_MAX = 6\n",
    "    FREQ_BANDS = list(range(16))\n",
    "    TAU = 16\n",
    "    # embedding dimension\n",
    "    DE = 32\n",
    "    \n",
    "    for i in tqdm(range(X.shape[0])):\n",
    "        features = list()\n",
    "        # http://pyeeg.sourceforge.net/\n",
    "        x_i = X[i,:]\n",
    "        \n",
    "        ## !IMPORTANT! => \n",
    "        # Power Spectral Intensity (PSI) and Relative Intensity Ratio (RIR)\tbin_power()\tTwo 1-D vectors\n",
    "        \n",
    "        \n",
    "        # Petrosian Fractal Dimension (PFD)\tpdf()\tA scalar\n",
    "        features.append(pyeeg.pfd(x_i))\n",
    "        \n",
    "        # Higuchi Fractal Dimension (HFD)\thfd()\tA scalar\n",
    "        features.append(pyeeg.hfd(x_i, K_MAX))\n",
    "        \n",
    "        # Hjorth mobility and complexity\thjorth()\tTwo scalars\n",
    "        \n",
    "        # Spectral Entropy (Shannon's entropy of RIRs)\tspectral_entropy()\tA scalar\n",
    "        #features.append(pyeeg.spectral_entropy(x_i, FREQ_BANDS, SAMPLE_PER_SEC))\n",
    "        \n",
    "        # SVD Entropy\tsvd_entropy()\tA scalar\n",
    "        #features.append(pyeeg.svd_entropy(x_i, TAU, DE))\n",
    "        \n",
    "        # Fisher Information\tfisher_info()\tA scalar\n",
    "        features.append(pyeeg.fisher_info(x_i, TAU, DE))\n",
    "          \n",
    "        # Detrended Fluctuation Analysis (DFA)\tdfa()\tA scalar\n",
    "        features.append(pyeeg.dfa(x_i))\n",
    "        \n",
    "        # Hurst Exponent (Hurst)\thurst()\tA scalar\n",
    "        #features.append(pyeeg.hurst(x_i))\n",
    "        \n",
    "        # AX BASIC FEATUERS\n",
    "        features.append(np.mean(x_i))\n",
    "        features.append(np.std(x_i))\n",
    "        features.append(np.min(x_i))\n",
    "        features.append(np.max(x_i))\n",
    "        features.append(np.sum(np.abs(x_i) < 0.00005))\n",
    "        \n",
    "        \n",
    "        \n",
    "        all_featues.append(features)\n",
    "    return np.array(all_featues)\n",
    "\n",
    "def split_train_validation(X, y, valid=2):\n",
    "    \"\"\"\n",
    "    3 test subjects in train => split into 2|1\n",
    "    \"\"\"\n",
    "    sample_count_per_subject = int(X.shape[0] / 3)\n",
    "    X_train = X[:sample_count_per_subject * valid]\n",
    "    y_train = y[:sample_count_per_subject * valid]\n",
    "    X_valid = X[sample_count_per_subject * valid:]\n",
    "    y_valid = y[sample_count_per_subject * valid:]\n",
    "    \n",
    "    return X_train, y_train, X_valid, y_valid\n",
    "\n",
    "\n",
    "def bandpower(data, band, window_sec=4, relative=False):\n",
    "    \"\"\"Compute the average power of the signal x in a specific frequency band.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data : 1d-array\n",
    "        Input signal in the time-domain.\n",
    "    band : list\n",
    "        Lower and upper frequencies of the band of interest.\n",
    "    window_sec : float\n",
    "        Length of each window in seconds.\n",
    "        If None, window_sec = (1 / min(band)) * 2\n",
    "    relative : boolean\n",
    "        If True, return the relative power (= divided by the total power of the signal).\n",
    "        If False (default), return the absolute power.\n",
    "\n",
    "    Return\n",
    "    ------\n",
    "    bp : float\n",
    "        Absolute or relative band power.\n",
    "\n",
    "    Examples\n",
    "    ------\n",
    "    1. Absolute and relative power in the delta band\n",
    "        >>> delta = bandpower(data, 100, [0.5, 4])\n",
    "        >>> delta_relative = bandpower(data, 100, [0.5, 4], relative=True)\n",
    "\n",
    "    2. Delta / beta ratio\n",
    "        >>> window_sec = 4\n",
    "        >>> delta = bandpower(data, 100, [0.5, 4], window_sec)\n",
    "        >>> beta = bandpower(data, 100, [12, 30], window_sec)\n",
    "        >>> db_ratio = delta / beta\n",
    "    \"\"\"\n",
    "    \n",
    "    band = np.asarray(band)\n",
    "    low, high = band\n",
    "\n",
    "    # Compute the modified periodogram (Welch)\n",
    "    if window_sec is not None:\n",
    "        nperseg = window_sec * SAMPLE_PER_SEC\n",
    "    else:\n",
    "        nperseg = (2 / low) * SAMPLE_PER_SEC\n",
    "\n",
    "    freqs, psd = welch(data, SAMPLE_PER_SEC, nperseg=nperseg, scaling='density')\n",
    "\n",
    "    # Find closest indices of band in frequency vector\n",
    "    idx_band = np.logical_and(freqs >= low, freqs < high)\n",
    "\n",
    "    # Integral approximation of the spectrum using Simpson's rule.\n",
    "    bp = simps(psd[idx_band], freqs[idx_band])\n",
    "\n",
    "    if relative:\n",
    "        bp /= simps(psd, freqs)\n",
    "    return bp\n",
    "\n",
    "def plot_PCA_clusters(X, y_train):\n",
    "    pca = PCA(n_components=2)\n",
    "    pca.fit(X)\n",
    "    existing_2d = pca.transform(X)\n",
    "    awake_fold = existing_2d[y_train == 1]\n",
    "    sleep_fold_nrem = existing_2d[y_train == 2]\n",
    "    sleep_fold_rem = existing_2d[y_train == 3]\n",
    "\n",
    "    f, (ax1, ax2, ax3) = plt.subplots(1, 3)\n",
    "    ax1.plot(awake_fold[:, 0], awake_fold[:, 1], 'r.')\n",
    "    ax2.plot(sleep_fold_nrem[:, 0], sleep_fold_nrem[:, 1], 'b.')\n",
    "    ax3.plot(sleep_fold_rem[:, 0], sleep_fold_rem[:, 1], 'y.')\n",
    "    plt.show()\n",
    "\n",
    "    plt.plot(awake_fold[:, 0], awake_fold[:, 1], 'r.')\n",
    "    plt.plot(sleep_fold_nrem[:, 0], sleep_fold_nrem[:, 1], 'b.')\n",
    "    plt.plot(sleep_fold_rem[:, 0], sleep_fold_rem[:, 1], 'y.')\n",
    "    plt.show()\n",
    "    \n",
    "def plot_fct_spec(data):\n",
    "    time = np.arange(len(data)) / SAMPLE_PER_SEC\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(12, 4))\n",
    "    plt.plot(time, data, lw=1.5, color='k')\n",
    "    plt.xlabel('Time (seconds)')\n",
    "    plt.ylabel('Voltage')\n",
    "    plt.xlim([time.min(), time.max()])\n",
    "    plt.title('N3 sleep EEG data (F3)')\n",
    "\n",
    "    win = 4 * SAMPLE_PER_SEC\n",
    "    freqs, psd = signal.welch(data, SAMPLE_PER_SEC, nperseg=win, scaling='density')\n",
    "\n",
    "    # Plot the power spectrum\n",
    "\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    plt.plot(freqs, psd, color='k', lw=2)\n",
    "    plt.xlabel('Frequency (Hz)')\n",
    "    plt.ylabel('Power spectral density (V^2 / Hz)')\n",
    "    plt.ylim([0, psd.max() * 1.1])\n",
    "    plt.title(\"Welch's periodogram\")\n",
    "    plt.xlim([0, 20])\n",
    "    \n",
    "def plot_TSNE_clusters(X, y_train):\n",
    "    N_SAMPLES = 2500\n",
    "    random_index = np.random.choice(X.shape[0], N_SAMPLES)\n",
    "    X = X[random_index, :]\n",
    "    y_train = y[random_index]\n",
    "\n",
    "    existing_2d = TSNE(n_components=2).fit_transform(X)\n",
    "    awake_fold = existing_2d[y_train == 1]\n",
    "    sleep_fold_nrem = existing_2d[y_train == 2]\n",
    "    sleep_fold_rem = existing_2d[y_train == 3]\n",
    "\n",
    "    f, (ax1, ax2, ax3) = plt.subplots(1, 3)\n",
    "    ax1.plot(awake_fold[:, 0], awake_fold[:, 1], 'r.')\n",
    "    ax2.plot(sleep_fold_nrem[:, 0], sleep_fold_nrem[:, 1], 'b.')\n",
    "    ax3.plot(sleep_fold_rem[:, 0], sleep_fold_rem[:, 1], 'y.')\n",
    "    plt.show()\n",
    "\n",
    "    plt.plot(awake_fold[:, 0], awake_fold[:, 1], 'r.')\n",
    "    plt.plot(sleep_fold_nrem[:, 0], sleep_fold_nrem[:, 1], 'b.')\n",
    "    plt.plot(sleep_fold_rem[:, 0], sleep_fold_rem[:, 1], 'y.')\n",
    "    plt.show()\n",
    "    \n",
    "def plot_signal(data):\n",
    "    time = np.arange(len(data)) / SAMPLE_PER_SEC\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(12, 4))\n",
    "    plt.plot(time, data, lw=1.5, color='k')\n",
    "    plt.xlabel('Time (seconds)')\n",
    "    plt.ylabel('Voltage')\n",
    "    plt.xlim([time.min(), time.max()])\n",
    "    plt.title('N3 sleep EEG data (F3)')\n",
    "    \n",
    "def get_data_of_rat(X, y, i):\n",
    "    sample_cnt = int(X.shape[0] / 3)\n",
    "    if i == 0:\n",
    "        return X[:sample_cnt, :], y[:sample_cnt]\n",
    "    if i == 1:\n",
    "        return X[sample_cnt: 2 * sample_cnt, :], y[sample_cnt: 2 * sample_cnt]\n",
    "    if i == 2:\n",
    "        return X[2*sample_cnt:, :], y[2*sample_cnt:]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading /home/ax/master/2018_02/ml/task5/data/train/train_emg.csv\n",
      "Reading /home/ax/master/2018_02/ml/task5/data/train/train_eeg1.csv\n",
      "Reading /home/ax/master/2018_02/ml/task5/data/train/train_eeg2.csv\n",
      "Reading /home/ax/master/2018_02/ml/task5/data/test/test_emg.csv\n",
      "Reading /home/ax/master/2018_02/ml/task5/data/test/test_eeg1.csv\n",
      "Reading /home/ax/master/2018_02/ml/task5/data/test/test_eeg2.csv\n",
      "Class 1: 34114\n",
      "Class 2: 27133\n",
      "Class 3: 3553\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0275bd470a3f491a96b5d24ee75f2988",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=64800), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f22aabe3dc84ad8886eb6a2dbfd90fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=64800), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a71fa6f86f614822bc1a5e0a4920156e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=64800), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load the data\n",
    "# train\n",
    "train_emg = os.path.join(dir_path,\"data/train/train_emg.csv\")\n",
    "train_eeg_1 = os.path.join(dir_path,\"data/train/train_eeg1.csv\")\n",
    "train_eeg_2 = os.path.join(dir_path,\"data/train/train_eeg2.csv\")\n",
    "\n",
    "# trest\n",
    "test_emg = os.path.join(dir_path,\"data/test/test_emg.csv\")\n",
    "test_eeg_1 = os.path.join(dir_path,\"data/test/test_eeg1.csv\")\n",
    "test_eeg_2 = os.path.join(dir_path,\"data/test/test_eeg2.csv\")\n",
    "\n",
    "# labels\n",
    "train_target = os.path.join(dir_path,'data/train/train_labels.csv')\n",
    "\n",
    "x_train_emg = get_train_from_csv(train_emg) #List of numpy arrays\n",
    "x_train_eeg_1 = get_train_from_csv(train_eeg_1) #List of numpy arrays\n",
    "x_train_eeg_2 = get_train_from_csv(train_eeg_2) #List of numpy arrays\n",
    "y_train = get_target_from_csv(train_target) #Numpy array of labels\n",
    "\n",
    "x_test_emg = get_train_from_csv(test_emg) #List of numpy arrays\n",
    "x_test_eeg_1 = get_train_from_csv(test_eeg_1) #List of numpy arrays\n",
    "x_test_eeg_2 = get_train_from_csv(test_eeg_2) #List of numpy arrays\n",
    "\n",
    "print(f\"Class 1: {np.sum(y_train == 1)}\")\n",
    "print(f\"Class 2: {np.sum(y_train == 2)}\")\n",
    "print(f\"Class 3: {np.sum(y_train == 3)}\")\n",
    "# compute features\n",
    "x_train_emg_feat = get_features_emg(x_train_emg)\n",
    "x_train_eeg_1_feat = get_features_eeg(x_train_eeg_1) \n",
    "#x_train_emg_feat_spec = get_features_emg_wavelet(x_train_emg)\n",
    "x_train_eeg_1_feat_spec = get_features_emg_wavelet(x_train_eeg_1)\n",
    "x_test_emg_feat = get_features_emg(x_test_emg)\n",
    "x_test_eeg_1_feat = get_features_eeg(x_test_eeg_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d1ff0af329e4c4eb97055272c071553",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=43200), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2285b8d7ef584375b8cf92e774bf2415",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=43200), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x_test_emg_feat = get_features_emg(x_test_emg)\n",
    "x_test_eeg_1_feat = get_features_eeg(x_test_eeg_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start\n",
      "0: current balanced_accuracy_score: 0.8504817418247281\n",
      "1: current balanced_accuracy_score: 0.8122146011098764\n",
      "2: current balanced_accuracy_score: 0.8556966707903388\n",
      "========================================\n",
      "RFC BMAC avg score 0.8394643379083145 +/- 0.019385733374781958\n"
     ]
    }
   ],
   "source": [
    "# CROSS VALDATION\n",
    "X = x_train_eeg_1_\n",
    "scaler = StandardScaler().fit(X)\n",
    "\n",
    "kfold = KFold(n_splits=3, shuffle=False, random_state=seed)\n",
    "\n",
    "# classifiers\n",
    "\n",
    "\n",
    "print(\"Start\")\n",
    "bmac_scores = []\n",
    "\n",
    "for train, valid in kfold.split(X):\n",
    "    # get the folds\n",
    "    X_train_fold_emg = X[train]\n",
    "    y_train_fold = y_train[train]\n",
    "    \n",
    "    X_valid_fold_emg = X[valid]\n",
    "    y_valid_fold = y_train[valid]\n",
    "\n",
    "    # get the training for the awake/sleep clf\n",
    "    rem_fold = X_train_fold_emg[y_train_fold == 2]\n",
    "    nrem_fold = X_train_fold_emg[y_train_fold == 3]\n",
    "    X_train_fold_rem_nrem = np.concatenate((rem_fold, nrem_fold))\n",
    "    y_train_fold_rem_nrem = np.concatenate((np.ones(rem_fold.shape[0], dtype=np.int32) * 2, np.ones(nrem_fold.shape[0], dtype=np.int32) * 3))\n",
    "    \n",
    "    rem_fold = X_valid_fold_emg[y_valid_fold == 2]\n",
    "    nrem_fold = X_valid_fold_emg[y_valid_fold == 3]\n",
    "    X_valid_fold_rem_nrem = np.concatenate((rem_fold, nrem_fold))\n",
    "    y_valid_fold_rem_nrem = np.concatenate((np.ones(rem_fold.shape[0], dtype=np.int32) * 2, np.ones(nrem_fold.shape[0], dtype=np.int32) * 3))\n",
    "    \n",
    "    # scale \n",
    "    #X_train_fold_awake_sleep = scaler.transform(X_train_fold_awake_sleep)\n",
    "    #X_valid_fold_awake_sleep = scaler.transform(X_valid_fold_awake_sleep)\n",
    "    \n",
    "    # class weights\n",
    "    classes = np.array([2,3])\n",
    "    weights = compute_class_weight(\"balanced\", classes, y_train_fold_rem_nrem)\n",
    "    cw = dict(zip(classes, weights))\n",
    "\n",
    "# classifiers\n",
    "\n",
    "    rf_eeg = RandomForestClassifier(n_estimators=100, random_state=seed, n_jobs=-1, class_weight=cw, verbose=False)\n",
    "    \n",
    "    \n",
    "    # fit classifier\n",
    "    rf_eeg.fit(X_train_fold_rem_nrem, y_train_fold_rem_nrem)\n",
    "    \n",
    "    y_pred = rf_eeg.predict(X_valid_fold_rem_nrem)\n",
    "    \n",
    "    bmac_score = balanced_accuracy_score(y_valid_fold_rem_nrem, y_pred)\n",
    "    print(f\"{len(bmac_scores)}: current balanced_accuracy_score: {bmac_score}\")\n",
    "\n",
    "    bmac_scores.append(bmac_score)\n",
    "\n",
    "print(\"========================================\")\n",
    "print(f\"RFC BMAC avg score {np.mean(bmac_scores)} +/- {np.std(bmac_scores)}\" )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ax/miniconda3/envs/aml/lib/python3.6/site-packages/sklearn/utils/validation.py:590: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/home/ax/miniconda3/envs/aml/lib/python3.6/site-packages/sklearn/utils/validation.py:590: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/home/ax/miniconda3/envs/aml/lib/python3.6/site-packages/sklearn/utils/validation.py:590: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ax/miniconda3/envs/aml/lib/python3.6/site-packages/sklearn/utils/validation.py:590: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: current balanced_accuracy_score: 0.9015153753143077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ax/miniconda3/envs/aml/lib/python3.6/site-packages/sklearn/utils/validation.py:590: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/home/ax/miniconda3/envs/aml/lib/python3.6/site-packages/sklearn/utils/validation.py:590: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/home/ax/miniconda3/envs/aml/lib/python3.6/site-packages/sklearn/utils/validation.py:590: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1: current balanced_accuracy_score: 0.9636107703645397\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ax/miniconda3/envs/aml/lib/python3.6/site-packages/sklearn/utils/validation.py:590: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/home/ax/miniconda3/envs/aml/lib/python3.6/site-packages/sklearn/utils/validation.py:590: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/home/ax/miniconda3/envs/aml/lib/python3.6/site-packages/sklearn/utils/validation.py:590: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2: current balanced_accuracy_score: 0.9112481304578569\n",
      "========================================\n",
      "RFC BMAC avg score 0.9254580920455681 +/- 0.027269051784691307\n"
     ]
    }
   ],
   "source": [
    "# CROSS VALDATION\n",
    "scaler = StandardScaler().fit(x_train_emg_feat)\n",
    "\n",
    "kfold = KFold(n_splits=3, shuffle=False, random_state=seed)\n",
    "\n",
    "# classifiers\n",
    "rf_emg = RandomForestClassifier(n_estimators=5, random_state=seed, n_jobs=-1, verbose=False)\n",
    "\n",
    "print(\"Start\")\n",
    "bmac_scores = []\n",
    "\n",
    "for train, valid in kfold.split(x_train_emg_feat):\n",
    "    X_train_fold_emg = x_train_emg_feat[train]\n",
    "    X_train_fold_eeg = x_train_eeg_1_feat[train]\n",
    "    y_train_fold = y_train[train]\n",
    "    \n",
    "    X_valid_fold_emg = x_train_emg_feat[valid]\n",
    "    X_valid_fold_eeg = x_train_eeg_1_feat[valid]\n",
    "    y_valid_fold = y_train[valid]\n",
    "    \n",
    "    # train scalers\n",
    "    scaler = StandardScaler().fit(x_train_emg_feat)\n",
    "    scaler_eeg = StandardScaler().fit(x_train_eeg_1_feat)\n",
    "\n",
    "\n",
    "    # get the training for the awake/sleep clf\n",
    "    awake_fold = X_train_fold_emg[y_train_fold == 1]\n",
    "    sleep_fold = X_train_fold_emg[y_train_fold != 1]\n",
    "    X_train_fold_awake_sleep = np.concatenate((awake_fold, sleep_fold))\n",
    "    y_train_fold_awake_sleep = np.concatenate((np.ones(awake_fold.shape[0], dtype=np.int32), np.zeros(sleep_fold.shape[0], dtype=np.int32)))\n",
    "\n",
    "    # get the training for nrem and rem sleep\n",
    "    nrem_fold = X_train_fold_eeg[y_train_fold == 2]\n",
    "    rem_fold = X_train_fold_eeg[y_train_fold == 3]\n",
    "    X_train_fold_sleep_type = np.concatenate((nrem_fold, rem_fold))\n",
    "    y_train_sleep_type = np.concatenate((np.ones(nrem_fold.shape[0], dtype=np.int32) * 2, np.ones(rem_fold.shape[0], dtype=np.int32) * 3))\n",
    "\n",
    "    # scale \n",
    "    X_train_fold_awake_sleep = scaler.transform(X_train_fold_awake_sleep)\n",
    "    X_train_fold_sleep_type = scaler_eeg.transform(X_train_fold_sleep_type)\n",
    "\n",
    "    # class weights\n",
    "    classes = np.array([2,3])\n",
    "    weights = compute_class_weight(\"balanced\", classes, y_train_sleep_type)\n",
    "    cw = dict(zip(classes, weights))\n",
    "\n",
    "    # classifiers\n",
    "    rf_emg = RandomForestClassifier(n_estimators=100, random_state=seed, n_jobs=-1, verbose=False)\n",
    "    rf_eeg = RandomForestClassifier(n_estimators=100, random_state=seed, n_jobs=-1, class_weight=cw, verbose=False)\n",
    "\n",
    "    # fit classifier\n",
    "    rf_emg.fit(X_train_fold_awake_sleep, y_train_fold_awake_sleep)\n",
    "    rf_eeg.fit(X_train_fold_sleep_type, y_train_sleep_type)\n",
    "\n",
    "    # scale validation\n",
    "    X_valid_fold_emg = scaler.transform(X_valid_fold_emg)\n",
    "    X_valid_fold_eeg = scaler_eeg.transform(X_valid_fold_eeg)\n",
    "\n",
    "    y_pred = rf_emg.predict(X_valid_fold_emg)\n",
    "\n",
    "    # compute where y_pred is zero 0 => sleep\n",
    "    X_fold_valid_emg_sleep = X_valid_fold_eeg[y_pred == 0]\n",
    "    sleep_index = np.argwhere(y_pred == 0)\n",
    "\n",
    "    # predicted the type of sleep\n",
    "    y_sleep = rf_eeg.predict(X_fold_valid_emg_sleep)\n",
    "\n",
    "    # compute the final prediction vector\n",
    "    j = 0\n",
    "    for i in sleep_index:\n",
    "        y_pred[i] = y_sleep[j]\n",
    "        j +=1\n",
    "\n",
    "    \n",
    "    # get the folds\n",
    "    X_train_fold_emg = x_train_emg_feat[train]\n",
    "    y_train_fold = y_train[train]\n",
    "    \n",
    "    X_valid_fold_emg = x_train_emg_feat[valid]\n",
    "    y_valid_fold = y_train[valid]\n",
    "\n",
    "    # get the training for the awake/sleep clf\n",
    "    awake_fold = X_train_fold_emg[y_train_fold == 1]\n",
    "    sleep_fold = X_train_fold_emg[y_train_fold != 1]\n",
    "    X_train_fold_awake_sleep = np.concatenate((awake_fold, sleep_fold))\n",
    "    y_train_fold_awake_sleep = np.concatenate((np.ones(awake_fold.shape[0], dtype=np.int32), np.zeros(sleep_fold.shape[0], dtype=np.int32)))\n",
    "    \n",
    "    awake_fold = X_valid_fold_emg[y_valid_fold == 1]\n",
    "    sleep_fold = X_valid_fold_emg[y_valid_fold != 1]\n",
    "    X_valid_fold_awake_sleep = np.concatenate((awake_fold, sleep_fold))\n",
    "    y_valid_fold_awake_sleep = np.concatenate((np.ones(awake_fold.shape[0], dtype=np.int32), np.zeros(sleep_fold.shape[0], dtype=np.int32)))\n",
    "    \n",
    "    # scale \n",
    "    #X_train_fold_awake_sleep = scaler.transform(X_train_fold_awake_sleep)\n",
    "    #X_valid_fold_awake_sleep = scaler.transform(X_valid_fold_awake_sleep)\n",
    "    \n",
    "    # fit classifier\n",
    "    rf_emg.fit(X_train_fold_awake_sleep, y_train_fold_awake_sleep)\n",
    "    \n",
    "    y_pred = rf_emg.predict(X_valid_fold_awake_sleep)\n",
    "    \n",
    "    bmac_score = balanced_accuracy_score(y_valid_fold_awake_sleep, y_pred)\n",
    "    print(f\"{len(bmac_scores)}: current balanced_accuracy_score: {bmac_score}\")\n",
    "\n",
    "    bmac_scores.append(bmac_score)\n",
    "\n",
    "print(\"========================================\")\n",
    "print(f\"RFC BMAC avg score {np.mean(bmac_scores)} +/- {np.std(bmac_scores)}\" )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ax/miniconda3/envs/aml/lib/python3.6/site-packages/sklearn/utils/validation.py:590: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/home/ax/miniconda3/envs/aml/lib/python3.6/site-packages/sklearn/utils/validation.py:590: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/home/ax/miniconda3/envs/aml/lib/python3.6/site-packages/sklearn/utils/validation.py:590: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "# FINAL PREDICTION\n",
    "scaler = StandardScaler().fit(x_train_emg_feat)\n",
    "scaler_eeg = StandardScaler().fit(x_train_eeg_1_feat)\n",
    "\n",
    "# class weights\n",
    "nrem_fold = x_train_emg_feat[y_train == 2]\n",
    "rem_fold = x_train_emg_feat[y_train == 3]\n",
    "X_train_fold_sleep_type = np.concatenate((nrem_fold, rem_fold))\n",
    "y_train_sleep_type = np.concatenate((np.ones(nrem_fold.shape[0], dtype=np.int32) * 2, np.ones(rem_fold.shape[0], dtype=np.int32) * 3))\n",
    "classes = np.array([2,3])\n",
    "weights = compute_class_weight(\"balanced\", classes, y_train_sleep_type)\n",
    "cw = dict(zip(classes, weights))\n",
    "\n",
    "# classifiers\n",
    "rf_emg = RandomForestClassifier(n_estimators=100, random_state=seed, n_jobs=-1, verbose=False)\n",
    "rf_eeg = RandomForestClassifier(n_estimators=100, random_state=seed, n_jobs=-1, class_weight=cw, verbose=False)\n",
    "\n",
    "# get the training for the awake/sleep clf\n",
    "awake = x_train_emg_feat[y_train == 1]\n",
    "sleep = x_train_emg_feat[y_train != 1]\n",
    "X_train_awake_sleep = np.concatenate((awake, sleep))\n",
    "y_train_awake_sleep = np.concatenate((np.ones(awake.shape[0], dtype=np.int32), np.zeros(sleep.shape[0], dtype=np.int32)))\n",
    "\n",
    "\n",
    "# get the training for nrem and rem sleep\n",
    "nrem = x_train_eeg_1_feat[y_train == 2]\n",
    "rem = x_train_eeg_1_feat[y_train == 3]\n",
    "X_train_sleep_type = np.concatenate((nrem, rem))\n",
    "y_train_sleep_type = np.concatenate((np.ones(nrem.shape[0], dtype=np.int32) * 2, np.ones(rem.shape[0], dtype=np.int32) * 3))\n",
    "\n",
    "# scale \n",
    "X_train_awake_sleep = scaler.transform(X_train_awake_sleep)\n",
    "X_train_sleep_type = scaler_eeg.transform(X_train_sleep_type)\n",
    "X_test_emg = scaler.transform(x_test_emg_feat)\n",
    "X_test_eeg_1 = scaler_eeg.transform(x_test_eeg_1_feat)\n",
    "\n",
    "# fit classifier\n",
    "rf_emg.fit(X_train_awake_sleep, y_train_awake_sleep)\n",
    "rf_eeg.fit(X_train_sleep_type, y_train_sleep_type)\n",
    "\n",
    "# prediction\n",
    "y_pred = rf_emg.predict(X_test_emg)\n",
    "\n",
    "# compute where y_pred is zero 0 => sleep\n",
    "X_test_eeg_1_sleep = X_test_eeg_1[y_pred == 0]\n",
    "sleep_index = np.argwhere(y_pred == 0)\n",
    "\n",
    "# predicted the type of sleep\n",
    "y_sleep_type = rf_eeg.predict(X_test_eeg_1_sleep)\n",
    "\n",
    "# compute the final prediction vector\n",
    "j = 0\n",
    "for i in sleep_index:\n",
    "    y_pred[i] = y_sleep_type[j]\n",
    "    j +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 1: 21153\n",
      "Class 2: 21157\n",
      "Class 3: 890\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y</th>\n",
       "      <th>Id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43170</th>\n",
       "      <td>1</td>\n",
       "      <td>43170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43171</th>\n",
       "      <td>1</td>\n",
       "      <td>43171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43172</th>\n",
       "      <td>1</td>\n",
       "      <td>43172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43173</th>\n",
       "      <td>1</td>\n",
       "      <td>43173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43174</th>\n",
       "      <td>1</td>\n",
       "      <td>43174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43175</th>\n",
       "      <td>1</td>\n",
       "      <td>43175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43176</th>\n",
       "      <td>1</td>\n",
       "      <td>43176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43177</th>\n",
       "      <td>1</td>\n",
       "      <td>43177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43178</th>\n",
       "      <td>1</td>\n",
       "      <td>43178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43179</th>\n",
       "      <td>1</td>\n",
       "      <td>43179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43180</th>\n",
       "      <td>1</td>\n",
       "      <td>43180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43181</th>\n",
       "      <td>1</td>\n",
       "      <td>43181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43182</th>\n",
       "      <td>1</td>\n",
       "      <td>43182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43183</th>\n",
       "      <td>1</td>\n",
       "      <td>43183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43184</th>\n",
       "      <td>1</td>\n",
       "      <td>43184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43185</th>\n",
       "      <td>1</td>\n",
       "      <td>43185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43186</th>\n",
       "      <td>1</td>\n",
       "      <td>43186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43187</th>\n",
       "      <td>1</td>\n",
       "      <td>43187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43188</th>\n",
       "      <td>1</td>\n",
       "      <td>43188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43189</th>\n",
       "      <td>1</td>\n",
       "      <td>43189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43190</th>\n",
       "      <td>1</td>\n",
       "      <td>43190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43191</th>\n",
       "      <td>1</td>\n",
       "      <td>43191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43192</th>\n",
       "      <td>1</td>\n",
       "      <td>43192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43193</th>\n",
       "      <td>1</td>\n",
       "      <td>43193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43194</th>\n",
       "      <td>1</td>\n",
       "      <td>43194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43195</th>\n",
       "      <td>1</td>\n",
       "      <td>43195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43196</th>\n",
       "      <td>1</td>\n",
       "      <td>43196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43197</th>\n",
       "      <td>1</td>\n",
       "      <td>43197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43198</th>\n",
       "      <td>1</td>\n",
       "      <td>43198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43199</th>\n",
       "      <td>1</td>\n",
       "      <td>43199</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>43200 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       y     Id\n",
       "0      1      0\n",
       "1      1      1\n",
       "2      1      2\n",
       "3      1      3\n",
       "4      1      4\n",
       "5      1      5\n",
       "6      1      6\n",
       "7      1      7\n",
       "8      1      8\n",
       "9      1      9\n",
       "10     1     10\n",
       "11     1     11\n",
       "12     1     12\n",
       "13     1     13\n",
       "14     1     14\n",
       "15     1     15\n",
       "16     1     16\n",
       "17     1     17\n",
       "18     1     18\n",
       "19     1     19\n",
       "20     1     20\n",
       "21     1     21\n",
       "22     1     22\n",
       "23     1     23\n",
       "24     1     24\n",
       "25     1     25\n",
       "26     1     26\n",
       "27     1     27\n",
       "28     1     28\n",
       "29     1     29\n",
       "...   ..    ...\n",
       "43170  1  43170\n",
       "43171  1  43171\n",
       "43172  1  43172\n",
       "43173  1  43173\n",
       "43174  1  43174\n",
       "43175  1  43175\n",
       "43176  1  43176\n",
       "43177  1  43177\n",
       "43178  1  43178\n",
       "43179  1  43179\n",
       "43180  1  43180\n",
       "43181  1  43181\n",
       "43182  1  43182\n",
       "43183  1  43183\n",
       "43184  1  43184\n",
       "43185  1  43185\n",
       "43186  1  43186\n",
       "43187  1  43187\n",
       "43188  1  43188\n",
       "43189  1  43189\n",
       "43190  1  43190\n",
       "43191  1  43191\n",
       "43192  1  43192\n",
       "43193  1  43193\n",
       "43194  1  43194\n",
       "43195  1  43195\n",
       "43196  1  43196\n",
       "43197  1  43197\n",
       "43198  1  43198\n",
       "43199  1  43199\n",
       "\n",
       "[43200 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'\\nClass 1: 23933\\nClass 2: 18553\\nClass 3: 714\\n'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission_name = \"ax_multi_stage_v2.csv\"\n",
    "\n",
    "print(f\"Class 1: {np.sum(y_pred == 1)}\")\n",
    "print(f\"Class 2: {np.sum(y_pred == 2)}\")\n",
    "print(f\"Class 3: {np.sum(y_pred == 3)}\")\n",
    "\n",
    "y_pred_df = pd.DataFrame(y_pred)\n",
    "y_pred_df = y_pred_df.assign(Id=list(range(y_pred.shape[0])))\n",
    "y_pred_df.columns = ['y', 'Id']\n",
    "display(y_pred_df)\n",
    "\n",
    "\n",
    "submission_folder = os.path.join(dir_path,\"submissions/\")\n",
    "csv_file = submission_folder + submission_name\n",
    "\n",
    "with open(csv_file, 'w') as csv:\n",
    "    y_pred_df.to_csv(csv,index = False)\n",
    "\"\"\"\n",
    "Class 1: 23933\n",
    "Class 2: 18553\n",
    "Class 3: 714\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (aml-3)",
   "language": "python",
   "name": "myenv1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
