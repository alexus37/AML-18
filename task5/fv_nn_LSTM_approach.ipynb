{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "colab_type": "code",
    "id": "XSf4eqMffy_7",
    "outputId": "79231e9c-877c-46cc-beaa-65ec4a1e8541"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nSame for all\\nMin: -0.0033\\nMax: 0.0033\\n\\n\\nRAT 0\\nClass 1: 11240\\nClass 2: 8653\\nClass 3: 1707\\nMean: -7.270247766565382e-06\\nStd: 0.00014033437213481842\\n\\nRAT 1\\nClass 1: 11849\\nClass 2: 8647\\nClass 3: 1104\\nMean: -4.883171278211801e-06\\nStd: 8.972252301644052e-05\\n\\nRAT 2\\nClass 1: 11025\\nClass 2: 9833\\nClass 3: 742\\nMean: -4.952989167390033e-06\\nStd: 0.00010911971573637134\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import gc\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import natsort\n",
    "import random as rn\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import tensorflow as tf\n",
    "#import pyeeg\n",
    "from scipy import signal\n",
    "from scipy.signal import welch\n",
    "from scipy.integrate import simps\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#Keras\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, LSTM, Embedding, TimeDistributed, Dropout\n",
    "\n",
    "\n",
    "#Sklearn\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.svm import (SVC, SVR)\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import (RandomForestClassifier, GradientBoostingClassifier)\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "#from sklearn.metrics import balanced_accuracy_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "seed=42\n",
    "np.random.seed(seed)\n",
    "rn.seed(seed)\n",
    "tf.set_random_seed(seed)\n",
    "dir_path = os.getcwd()\n",
    "\n",
    "# https://en.wikipedia.org/wiki/Neural_oscillation\n",
    "SAMPLE_PER_SEC = 128\n",
    "ALPHA_WAVE = [7.5, 12.5]\n",
    "BETA_WAVE = [13, 30]\n",
    "THETA_WAVE = [4, 8]\n",
    "DELTA_WAVE = [1, 4]\n",
    "LOW_GAMMA_WAVE = [30, 70]\n",
    "HIGH_GAMMA_WAVE = [70, 150]\n",
    "\n",
    "\"\"\"\n",
    "Same for all\n",
    "Min: -0.0033\n",
    "Max: 0.0033\n",
    "\n",
    "\n",
    "RAT 0\n",
    "Class 1: 11240\n",
    "Class 2: 8653\n",
    "Class 3: 1707\n",
    "Mean: -7.270247766565382e-06\n",
    "Std: 0.00014033437213481842\n",
    "\n",
    "RAT 1\n",
    "Class 1: 11849\n",
    "Class 2: 8647\n",
    "Class 3: 1104\n",
    "Mean: -4.883171278211801e-06\n",
    "Std: 8.972252301644052e-05\n",
    "\n",
    "RAT 2\n",
    "Class 1: 11025\n",
    "Class 2: 9833\n",
    "Class 3: 742\n",
    "Mean: -4.952989167390033e-06\n",
    "Std: 0.00010911971573637134\n",
    "\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0hyzYi_qfzA6"
   },
   "outputs": [],
   "source": [
    "def get_train_from_csv(csv_file):\n",
    "    '''\n",
    "    get a numpy array y of labels. the order follows the id of 4 second sample. \n",
    "    argument: relative path to the csv_file from the source folder.\n",
    "    '''\n",
    "    csv_file = os.path.join(dir_path, csv_file)\n",
    "    print(f\"Reading {csv_file}\")\n",
    "    with open(csv_file, 'r') as csvfile:\n",
    "        train_reader = pd.read_csv(csvfile)\n",
    "        train_reader.drop(labels=\"Id\", axis=1, inplace=True)\n",
    "        \n",
    "        \n",
    "    return train_reader.values\n",
    "\n",
    "def get_target_from_csv(csv_file):\n",
    "    '''\n",
    "    get a numpy array y of labels. the order follows the id of 4 second sample. \n",
    "    argument: relative path to the csv_file from the source folder.\n",
    "    '''\n",
    "    csv_file = os.path.join(dir_path,csv_file)\n",
    "    with open(csv_file, 'r') as csvfile:\n",
    "        label_reader = pd.read_csv(csvfile)\n",
    "        #print(\"Labels: \", label_reader['id'])\n",
    "        y = label_reader['y']\n",
    "        \n",
    "    y = np.array(y)\n",
    "    return y\n",
    "\n",
    "def get_features_emg_wavelet(X):\n",
    "    \"\"\"\n",
    "     absolute EEG power in the 1–4Hz\n",
    "    (delta), 5–9Hz (theta), 10–20Hz (low beta), and 30–40Hz (high beta) bands, absolute EMG\n",
    "    power in the 1–10Hz band, theta-to-delta ratio, and beta-to-delta ratio \n",
    "    \"\"\"\n",
    "    all_featues = []\n",
    "    for i in tqdm(range(X.shape[0])):\n",
    "        features = list()\n",
    "        x_i = X[i,:]\n",
    "        delta = bandpower(x_i, DELTA_WAVE)\n",
    "        features.append(delta)\n",
    "        \n",
    "        theta = bandpower(x_i, THETA_WAVE)\n",
    "        features.append(theta)\n",
    "        \n",
    "        beta = bandpower(x_i, BETA_WAVE)\n",
    "        features.append(beta)\n",
    "        \n",
    "        features.append(bandpower(x_i, ALPHA_WAVE))\n",
    "        \n",
    "        features.append(theta / delta)\n",
    "        features.append(beta / delta)\n",
    "    \n",
    "        all_featues.append(features)\n",
    "    return np.array(all_featues)\n",
    "\n",
    "def get_features_emg(X):\n",
    "    all_featues = []\n",
    "    for i in tqdm(range(X.shape[0])):\n",
    "        features = list()\n",
    "        # https://ieeexplore.ieee.org/document/7748960\n",
    "        x_i = X[i,:]\n",
    "        # Root Mean Square (RMS): RMS of EMG\n",
    "        features.append(mean_squared_error(x_i, np.zeros(x_i.shape)))\n",
    "        \n",
    "        #Integrated Absolute Value (IAV)\n",
    "        features.append(np.sum(np.abs(x_i)))\n",
    "        \n",
    "        # Mean Absolute Value (MAV): MAV feature can be expressed as\n",
    "        features.append(np.mean(x_i))\n",
    "        \n",
    "        # TBD:\n",
    "        # Modified Mean Absolute Value type 1\n",
    "        # Modified Mean Absolute Value type 2\n",
    "        \n",
    "        # Simple Square Integral (SSI): SSI is calculated as\n",
    "        features.append(np.sum(x_i ** 2))\n",
    "        \n",
    "        # Variance (VAR): VAR is calculated as\n",
    "        features.append(np.var(x_i))\n",
    "        \n",
    "        #The 3rd, 4th and 5th temporal moments\n",
    "        features.append(np.mean(x_i ** 3))\n",
    "        features.append(np.mean(x_i ** 4))\n",
    "        features.append(np.mean(x_i ** 5))\n",
    "        \n",
    "        # TBD\n",
    "        # v-Order \n",
    "        \n",
    "        # Waveform Length\n",
    "        features.append(np.sum(np.abs(np.diff(x_i))))\n",
    "        \n",
    "        # Average Amplitude Change\n",
    "        features.append(np.mean(np.abs(np.diff(x_i))))\n",
    "        \n",
    "        # Difference Absolute Standard Deviation Value\n",
    "        features.append(np.sqrt(np.mean(np.power(np.diff(x_i), 2))))\n",
    "        \n",
    "        # AX BASIC FEATUERS\n",
    "        features.append(np.std(x_i))\n",
    "        features.append(np.min(x_i))\n",
    "        features.append(np.max(x_i))\n",
    "        features.append(np.sum(x_i < 0.0005))\n",
    "        \n",
    "        all_featues.append(features)\n",
    "    return np.array(all_featues)\n",
    "\n",
    "def get_features_eeg(X):\n",
    "    all_featues = []\n",
    "    # NOT SURE ABOUT THIS VALUES \n",
    "    # LETS DOUBLE CHECK\n",
    "    K_MAX = 6\n",
    "    FREQ_BANDS = list(range(16))\n",
    "    TAU = 16\n",
    "    # embedding dimension\n",
    "    DE = 32\n",
    "    \n",
    "    for i in tqdm(range(X.shape[0])):\n",
    "        features = list()\n",
    "        # http://pyeeg.sourceforge.net/\n",
    "        x_i = X[i,:]\n",
    "        \n",
    "        ## !IMPORTANT! => \n",
    "        # Power Spectral Intensity (PSI) and Relative Intensity Ratio (RIR)\tbin_power()\tTwo 1-D vectors\n",
    "        \n",
    "        \n",
    "        # Petrosian Fractal Dimension (PFD)\tpdf()\tA scalar\n",
    "        features.append(pyeeg.pfd(x_i))\n",
    "        \n",
    "        # Higuchi Fractal Dimension (HFD)\thfd()\tA scalar\n",
    "        features.append(pyeeg.hfd(x_i, K_MAX))\n",
    "        \n",
    "        # Hjorth mobility and complexity\thjorth()\tTwo scalars\n",
    "        \n",
    "        # Spectral Entropy (Shannon's entropy of RIRs)\tspectral_entropy()\tA scalar\n",
    "        #features.append(pyeeg.spectral_entropy(x_i, FREQ_BANDS, SAMPLE_PER_SEC))\n",
    "        \n",
    "        # SVD Entropy\tsvd_entropy()\tA scalar\n",
    "        #features.append(pyeeg.svd_entropy(x_i, TAU, DE))\n",
    "        \n",
    "        # Fisher Information\tfisher_info()\tA scalar\n",
    "        features.append(pyeeg.fisher_info(x_i, TAU, DE))\n",
    "          \n",
    "        # Detrended Fluctuation Analysis (DFA)\tdfa()\tA scalar\n",
    "        features.append(pyeeg.dfa(x_i))\n",
    "        \n",
    "        # Hurst Exponent (Hurst)\thurst()\tA scalar\n",
    "        #features.append(pyeeg.hurst(x_i))\n",
    "        \n",
    "        # AX BASIC FEATUERS\n",
    "        features.append(np.mean(x_i))\n",
    "        features.append(np.std(x_i))\n",
    "        features.append(np.min(x_i))\n",
    "        features.append(np.max(x_i))\n",
    "        features.append(np.sum(np.abs(x_i) < 0.00005))\n",
    "        \n",
    "        \n",
    "        \n",
    "        all_featues.append(features)\n",
    "    return np.array(all_featues)\n",
    "\n",
    "def split_train_validation(X, y, valid=2):\n",
    "    \"\"\"\n",
    "    3 test subjects in train => split into 2|1\n",
    "    \"\"\"\n",
    "    sample_count_per_subject = int(X.shape[0] / 3)\n",
    "    X_train = X[:sample_count_per_subject * valid]\n",
    "    y_train = y[:sample_count_per_subject * valid]\n",
    "    X_valid = X[sample_count_per_subject * valid:]\n",
    "    y_valid = y[sample_count_per_subject * valid:]\n",
    "    \n",
    "    return X_train, y_train, X_valid, y_valid\n",
    "\n",
    "\n",
    "def bandpower(data, band, window_sec=4, relative=False):\n",
    "    \"\"\"Compute the average power of the signal x in a specific frequency band.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data : 1d-array\n",
    "        Input signal in the time-domain.\n",
    "    band : list\n",
    "        Lower and upper frequencies of the band of interest.\n",
    "    window_sec : float\n",
    "        Length of each window in seconds.\n",
    "        If None, window_sec = (1 / min(band)) * 2\n",
    "    relative : boolean\n",
    "        If True, return the relative power (= divided by the total power of the signal).\n",
    "        If False (default), return the absolute power.\n",
    "\n",
    "    Return\n",
    "    ------\n",
    "    bp : float\n",
    "        Absolute or relative band power.\n",
    "\n",
    "    Examples\n",
    "    ------\n",
    "    1. Absolute and relative power in the delta band\n",
    "        >>> delta = bandpower(data, 100, [0.5, 4])\n",
    "        >>> delta_relative = bandpower(data, 100, [0.5, 4], relative=True)\n",
    "\n",
    "    2. Delta / beta ratio\n",
    "        >>> window_sec = 4\n",
    "        >>> delta = bandpower(data, 100, [0.5, 4], window_sec)\n",
    "        >>> beta = bandpower(data, 100, [12, 30], window_sec)\n",
    "        >>> db_ratio = delta / beta\n",
    "    \"\"\"\n",
    "    \n",
    "    band = np.asarray(band)\n",
    "    low, high = band\n",
    "\n",
    "    # Compute the modified periodogram (Welch)\n",
    "    if window_sec is not None:\n",
    "        nperseg = window_sec * SAMPLE_PER_SEC\n",
    "    else:\n",
    "        nperseg = (2 / low) * SAMPLE_PER_SEC\n",
    "\n",
    "    freqs, psd = welch(data, SAMPLE_PER_SEC, nperseg=nperseg, scaling='density')\n",
    "\n",
    "    # Find closest indices of band in frequency vector\n",
    "    idx_band = np.logical_and(freqs >= low, freqs < high)\n",
    "\n",
    "    # Integral approximation of the spectrum using Simpson's rule.\n",
    "    bp = simps(psd[idx_band], freqs[idx_band])\n",
    "\n",
    "    if relative:\n",
    "        bp /= simps(psd, freqs)\n",
    "    return bp\n",
    "\n",
    "def plot_PCA_clusters(X, y_train):\n",
    "    pca = PCA(n_components=2)\n",
    "    pca.fit(X)\n",
    "    existing_2d = pca.transform(X)\n",
    "    awake_fold = existing_2d[y_train == 1]\n",
    "    sleep_fold_nrem = existing_2d[y_train == 2]\n",
    "    sleep_fold_rem = existing_2d[y_train == 3]\n",
    "\n",
    "    f, (ax1, ax2, ax3) = plt.subplots(1, 3)\n",
    "    ax1.plot(awake_fold[:, 0], awake_fold[:, 1], 'r.')\n",
    "    ax2.plot(sleep_fold_nrem[:, 0], sleep_fold_nrem[:, 1], 'b.')\n",
    "    ax3.plot(sleep_fold_rem[:, 0], sleep_fold_rem[:, 1], 'y.')\n",
    "    plt.show()\n",
    "\n",
    "    plt.plot(awake_fold[:, 0], awake_fold[:, 1], 'r.')\n",
    "    plt.plot(sleep_fold_nrem[:, 0], sleep_fold_nrem[:, 1], 'b.')\n",
    "    plt.plot(sleep_fold_rem[:, 0], sleep_fold_rem[:, 1], 'y.')\n",
    "    plt.show()\n",
    "    \n",
    "def plot_fct_spec(data):\n",
    "    time = np.arange(len(data)) / SAMPLE_PER_SEC\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(12, 4))\n",
    "    plt.plot(time, data, lw=1.5, color='k')\n",
    "    plt.xlabel('Time (seconds)')\n",
    "    plt.ylabel('Voltage')\n",
    "    plt.xlim([time.min(), time.max()])\n",
    "    plt.title('N3 sleep EEG data (F3)')\n",
    "\n",
    "    win = 4 * SAMPLE_PER_SEC\n",
    "    freqs, psd = signal.welch(data, SAMPLE_PER_SEC, nperseg=win, scaling='density')\n",
    "\n",
    "    # Plot the power spectrum\n",
    "\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    plt.plot(freqs, psd, color='k', lw=2)\n",
    "    plt.xlabel('Frequency (Hz)')\n",
    "    plt.ylabel('Power spectral density (V^2 / Hz)')\n",
    "    plt.ylim([0, psd.max() * 1.1])\n",
    "    plt.title(\"Welch's periodogram\")\n",
    "    plt.xlim([0, 20])\n",
    "    \n",
    "def plot_TSNE_clusters(X, y_train):\n",
    "    N_SAMPLES = 2500\n",
    "    random_index = np.random.choice(X.shape[0], N_SAMPLES)\n",
    "    X = X[random_index, :]\n",
    "    y_train = y[random_index]\n",
    "\n",
    "    existing_2d = TSNE(n_components=2).fit_transform(X)\n",
    "    awake_fold = existing_2d[y_train == 1]\n",
    "    sleep_fold_nrem = existing_2d[y_train == 2]\n",
    "    sleep_fold_rem = existing_2d[y_train == 3]\n",
    "\n",
    "    f, (ax1, ax2, ax3) = plt.subplots(1, 3)\n",
    "    ax1.plot(awake_fold[:, 0], awake_fold[:, 1], 'r.')\n",
    "    ax2.plot(sleep_fold_nrem[:, 0], sleep_fold_nrem[:, 1], 'b.')\n",
    "    ax3.plot(sleep_fold_rem[:, 0], sleep_fold_rem[:, 1], 'y.')\n",
    "    plt.show()\n",
    "\n",
    "    plt.plot(awake_fold[:, 0], awake_fold[:, 1], 'r.')\n",
    "    plt.plot(sleep_fold_nrem[:, 0], sleep_fold_nrem[:, 1], 'b.')\n",
    "    plt.plot(sleep_fold_rem[:, 0], sleep_fold_rem[:, 1], 'y.')\n",
    "    plt.show()\n",
    "    \n",
    "def plot_signal(data):\n",
    "    time = np.arange(len(data)) / SAMPLE_PER_SEC\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(12, 4))\n",
    "    plt.plot(time, data, lw=1.5, color='k')\n",
    "    plt.xlabel('Time (seconds)')\n",
    "    plt.ylabel('Voltage')\n",
    "    plt.xlim([time.min(), time.max()])\n",
    "    plt.title('N3 sleep EEG data (F3)')\n",
    "    \n",
    "def get_data_of_rat(X, y, i):\n",
    "    sample_cnt = int(X.shape[0] / 3)\n",
    "    if i == 0:\n",
    "        return X[:sample_cnt, :], y[:sample_cnt]\n",
    "    if i == 1:\n",
    "        return X[sample_cnt: 2 * sample_cnt, :], y[sample_cnt: 2 * sample_cnt]\n",
    "    if i == 2:\n",
    "        return X[2*sample_cnt:, :], y[2*sample_cnt:]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 168
    },
    "colab_type": "code",
    "id": "NpgMV3WufzBG",
    "outputId": "e3c9bb9a-0ad1-475d-dba6-660724414638"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading /content/drive/data/data/train/train_emg.csv\n",
      "Reading /content/drive/data/data/train/train_eeg1.csv\n",
      "Reading /content/drive/data/data/train/train_eeg2.csv\n",
      "Reading /content/drive/data/data/test/test_emg.csv\n",
      "Reading /content/drive/data/data/test/test_eeg1.csv\n",
      "Reading /content/drive/data/data/test/test_eeg2.csv\n",
      "Class 1: 34114\n",
      "Class 2: 27133\n",
      "Class 3: 3553\n"
     ]
    }
   ],
   "source": [
    "# Load the data\n",
    "# train\n",
    "train_emg = os.path.join(\"/content/drive/data/data/train\", \"train_emg.csv\")\n",
    "train_eeg_1 = os.path.join(\"/content/drive/data/data/train\", \"train_eeg1.csv\")\n",
    "train_eeg_2 = os.path.join(\"/content/drive/data/data/train\", \"train_eeg2.csv\")\n",
    "\n",
    "# trest\n",
    "test_emg = os.path.join(\"/content/drive/data/data/test\", \"test_emg.csv\")\n",
    "test_eeg_1 = os.path.join(\"/content/drive/data/data/test\", \"test_eeg1.csv\")\n",
    "test_eeg_2 = os.path.join(\"/content/drive/data/data/test\", \"test_eeg2.csv\")\n",
    "\n",
    "# labels\n",
    "train_target = os.path.join(\"/content/drive/data/data/train\", \"train_labels.csv\")\n",
    "\n",
    "x_train_emg = get_train_from_csv(train_emg) #List of numpy arrays\n",
    "x_train_eeg_1 = get_train_from_csv(train_eeg_1) #List of numpy arrays\n",
    "x_train_eeg_2 = get_train_from_csv(train_eeg_2) #List of numpy arrays\n",
    "y_train = get_target_from_csv(train_target) #Numpy array of labels\n",
    "\n",
    "x_test_emg = get_train_from_csv(test_emg) #List of numpy arrays\n",
    "x_test_eeg_1 = get_train_from_csv(test_eeg_1) #List of numpy arrays\n",
    "x_test_eeg_2 = get_train_from_csv(test_eeg_2) #List of numpy arrays\n",
    "\n",
    "print(f\"Class 1: {np.sum(y_train == 1)}\")\n",
    "print(f\"Class 2: {np.sum(y_train == 2)}\")\n",
    "print(f\"Class 3: {np.sum(y_train == 3)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DhY7DesDfzBV"
   },
   "outputs": [],
   "source": [
    "def check_for_floats(Array):\n",
    "    for row in Array:\n",
    "        for el in row:\n",
    "            if isinstance(el, float):\n",
    "                print(el)\n",
    "                \n",
    "def from_label_to_vec(labels):\n",
    "    labels_vec = []\n",
    "    for l in labels:\n",
    "        if l == 1:\n",
    "            labels_vec.append([1,0,0])\n",
    "        elif l == 2:\n",
    "            labels_vec.append([0,1,0])\n",
    "        elif l == 3:\n",
    "            labels_vec.append([0,0,1])\n",
    "    return labels_vec\n",
    "\n",
    "                \n",
    "def from_vec_to_labels(vecs):\n",
    "    labels = []\n",
    "    for v in vecs:\n",
    "        if v[0] == 1:\n",
    "            labels.append(1)\n",
    "        elif v[1] == 1:\n",
    "            labels.append(2)\n",
    "        elif v[2] == 1:\n",
    "            labels.append(3)\n",
    "    return labels\n",
    "  \n",
    "def count_labels(labels):\n",
    "    classes = [0,0,0]\n",
    "    for l in labels:\n",
    "      classes[l-1]+=1\n",
    "    print(classes)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 118
    },
    "colab_type": "code",
    "id": "chdjSnfSzdtb",
    "outputId": "086683ae-c56f-4abd-e555-6885dfce074e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64800, 512)\n",
      "(64800, 512)\n",
      "(64800, 512)\n",
      "(64800,)\n",
      "(64800, 1536)\n",
      "(43200, 1536)\n"
     ]
    }
   ],
   "source": [
    "gc.collect() \n",
    "\n",
    "print(x_train_eeg_1.shape)\n",
    "print(x_train_eeg_2.shape)\n",
    "print(x_train_emg.shape)\n",
    "print(y_train.shape)\n",
    "\n",
    "X_total_train = np.concatenate((x_train_eeg_1,x_train_eeg_2, x_train_emg), axis=1)*1000000\n",
    "X_total_test = np.concatenate((x_test_eeg_1,x_test_eeg_2, x_test_emg), axis=1)*1000000\n",
    "\n",
    "print(X_total_train.shape)\n",
    "print(X_total_test.shape)\n",
    "\n",
    "\n",
    "sc = StandardScaler()\n",
    "sc.fit(np.concatenate((X_total_train,X_total_test)))\n",
    "\n",
    "X_total_train_scaled = sc.transform(X_total_train)\n",
    "X_total_test_scaled = sc.transform(X_total_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 202
    },
    "colab_type": "code",
    "id": "zP5fczAUfzBz",
    "outputId": "081259e6-d3d0-4290-e334-4490615ff8e6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(43200, 1536)\n",
      "(21600, 1536)\n",
      "(43200, 1, 1536)\n",
      "[[0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " ...\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]]\n",
      "[3 3 3 ... 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "gc.collect()\n",
    "\n",
    "#Labels needed as probability vectors for the softmax\n",
    "Y = from_label_to_vec(y_train)\n",
    "\n",
    "#Just selecting the train / validation set\n",
    "\n",
    "X_train = np.concatenate((X_total_train_scaled[0:21600],X_total_train_scaled[21600*2:]),axis=0)\n",
    "Y_train = np.concatenate((Y[0:21600],Y[21600*2:]),axis=0)\n",
    "\n",
    "X_valid = X_total_train_scaled[21600:21600*2]\n",
    "Y_valid = Y[21600:21600*2]\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_valid.shape)\n",
    "\n",
    "Y_train = np.array(Y_train)\n",
    "Y_valid = np.array(from_vec_to_labels(Y_valid))\n",
    "\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 420
    },
    "colab_type": "code",
    "id": "lTAmkBfn63mI",
    "outputId": "face75ae-0362-4577-9ac8-3508389334dd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 1000)              1537000   \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1000)              1001000   \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 3)                 3003      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 3)                 0         \n",
      "=================================================================\n",
      "Total params: 2,541,003\n",
      "Trainable params: 2,541,003\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "X_train = np.reshape(X_train, (43200,1536))\n",
    "X_valid = np.reshape(X_valid, (21600,1536))\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(1000, input_dim = num_steps))\n",
    "model.add(keras.layers.LeakyReLU(alpha=0.1))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(1000))\n",
    "model.add(keras.layers.LeakyReLU(alpha=0.1))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(3))\n",
    "model.add(Activation('softmax'))\n",
    "print(model.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 134
    },
    "colab_type": "code",
    "id": "fpiIueOd7LlQ",
    "outputId": "8c097d88-c062-416a-a69f-fe5faf55a948"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "43200/43200 [==============================] - 28s 646us/step - loss: 0.4161 - categorical_accuracy: 0.8326\n",
      "Epoch 2/3\n",
      "43200/43200 [==============================] - 26s 609us/step - loss: 0.1686 - categorical_accuracy: 0.9470\n",
      "Epoch 3/3\n",
      "43200/43200 [==============================] - 26s 609us/step - loss: 0.0793 - categorical_accuracy: 0.9785\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7faec4adfd30>"
      ]
     },
     "execution_count": 29,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['categorical_accuracy'])\n",
    "model.fit(x=X_train, y=Y_train, epochs=3, verbose=1, shuffle=False)\n",
    "#model.fit(x=X_total_train_scaled, y=np.array(Y), epochs=3, verbose=1, validation_split=0.1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "JBq893Mc2qai",
    "outputId": "9b4c55cc-cb16-45ad-a118-394c8b91e19c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3 2 3 ... 2 1 1]\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_valid)\n",
    "labels = []\n",
    "for p in preds:\n",
    "    labels.append(np.argmax(p)+1)\n",
    "labels = np.array(labels)\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 84
    },
    "colab_type": "code",
    "id": "CPI54TQEL9j9",
    "outputId": "4256db3a-ad99-4b7f-eb78-55b113316611"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8063888888888889\n",
      "[3 3 3 ... 1 1 1]\n",
      "[3 2 3 ... 2 1 1]\n",
      "[8443, 12020, 1137]\n"
     ]
    }
   ],
   "source": [
    "BMAC = accuracy_score(Y_valid, labels)\n",
    "print(BMAC)\n",
    "print(Y_valid)\n",
    "print(labels)\n",
    "count_labels(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 373
    },
    "colab_type": "code",
    "id": "mT7Mr1EqfzCI",
    "outputId": "ffd62228-4cd8-451f-d52f-f319ac2dee02"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:3: UserWarning: The `input_dim` and `input_length` arguments in recurrent layers are deprecated. Use `input_shape` instead.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:3: UserWarning: Update your `LSTM` call to the Keras 2 API: `LSTM(500, return_sequences=False, input_shape=(None, 153...)`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_2 (LSTM)                (None, 500)               4074000   \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 3)                 1503      \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 3)                 0         \n",
      "=================================================================\n",
      "Total params: 4,075,503\n",
      "Trainable params: 4,075,503\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "X_train = np.reshape(X_train, (43200,1,1536))\n",
    "X_valid = np.reshape(X_valid, (21600,1,1536))\n",
    "\n",
    "#LSTM parameters\n",
    "hidden_size = 500\n",
    "use_dropout = True\n",
    "num_steps = len(X_total_train_scaled[0])\n",
    "\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "#model.add(Embedding(input_length=num_steps, input_dim = (num_steps,), output_dim = hidden_size))\n",
    "model.add(LSTM(hidden_size, return_sequences=False, input_dim = num_steps))\n",
    "#model.add(LSTM(hidden_size, return_sequences=True))\n",
    "if use_dropout:\n",
    "    model.add(Dropout(0.2))\n",
    "model.add(Dense(3))\n",
    "model.add(Activation('softmax'))\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 67
    },
    "colab_type": "code",
    "id": "pzYtJ6vtfzCT",
    "outputId": "1a5a384d-62f4-4df0-83fd-6d65daa8c8c4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "43200/43200 [==============================] - 674s 16ms/step - loss: 0.5153 - categorical_accuracy: 0.7934\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7faec4adf8d0>"
      ]
     },
     "execution_count": 28,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['categorical_accuracy'])\n",
    "model.fit(x=X_train, y=Y_train, batch_size=1, epochs=1, verbose=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "oPWwvHVRpOej",
    "outputId": "14ec1b2f-99ae-4e5e-8625-03b40ab43687"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3 2 3 ... 2 1 1]\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_valid)\n",
    "labels = []\n",
    "for p in preds:\n",
    "    labels.append(np.argmax(p)+1)\n",
    "labels = np.array(labels)\n",
    "print(labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 558
    },
    "colab_type": "code",
    "id": "-VuoOt_IrHNy",
    "outputId": "fbdeb503-b3fa-475a-fe5b-2ea60dd5f500"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sklearn in /usr/local/lib/python3.6/dist-packages (0.0)\n",
      "Collecting metrics\n",
      "  Downloading https://files.pythonhosted.org/packages/01/ae/3ab18f2f3449f2e7931112c991ade9684eeddf96cea03ea7f662c01f0658/metrics-0.3.3.tar.gz\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from sklearn) (0.20.1)\n",
      "Collecting Pygments==2.2.0 (from metrics)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/02/ee/b6e02dc6529e82b75bb06823ff7d005b141037cb1416b10c6f00fc419dca/Pygments-2.2.0-py2.py3-none-any.whl (841kB)\n",
      "\u001b[K    100% |████████████████████████████████| 849kB 21.5MB/s \n",
      "\u001b[?25hCollecting pathspec==0.5.5 (from metrics)\n",
      "  Downloading https://files.pythonhosted.org/packages/9f/fb/5a901a3b1eeebf83af6da74ecca69d7daf5189e450f0f4cccf9c19132651/pathspec-0.5.5.tar.gz\n",
      "Collecting pathlib2>=2.3.0 (from metrics)\n",
      "  Downloading https://files.pythonhosted.org/packages/2a/46/c696dcf1c7aad917b39b875acdc5451975e3a9b4890dca8329983201c97a/pathlib2-2.3.3-py2.py3-none-any.whl\n",
      "Requirement already satisfied: numpy>=1.8.2 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->sklearn) (1.14.6)\n",
      "Requirement already satisfied: scipy>=0.13.3 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->sklearn) (1.1.0)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from pathlib2>=2.3.0->metrics) (1.11.0)\n",
      "Building wheels for collected packages: metrics, pathspec\n",
      "  Running setup.py bdist_wheel for metrics ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/38/e8/55/c4c648451a33a60920318eba4c5735088dbf78dc20d4277db0\n",
      "  Running setup.py bdist_wheel for pathspec ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/d1/2e/6b/c67842adf3b13ea33ca3fe6a2a963622821ad647db724688e2\n",
      "Successfully built metrics pathspec\n",
      "\u001b[31mjupyter-console 6.0.0 has requirement prompt-toolkit<2.1.0,>=2.0.0, but you'll have prompt-toolkit 1.0.15 which is incompatible.\u001b[0m\n",
      "\u001b[31mcufflinks 0.14.6 has requirement plotly>=3.0.0, but you'll have plotly 1.12.12 which is incompatible.\u001b[0m\n",
      "Installing collected packages: Pygments, pathspec, pathlib2, metrics\n",
      "  Found existing installation: Pygments 2.1.3\n",
      "    Uninstalling Pygments-2.1.3:\n",
      "      Successfully uninstalled Pygments-2.1.3\n",
      "Successfully installed Pygments-2.2.0 metrics-0.3.3 pathlib2-2.3.3 pathspec-0.5.5\n",
      "0.8063888888888889\n",
      "[3 3 3 ... 1 1 1]\n",
      "[3 2 3 ... 2 1 1]\n",
      "[8443, 12020, 1137]\n"
     ]
    }
   ],
   "source": [
    "BMAC = accuracy_score(Y_valid, labels)\n",
    "print(BMAC)\n",
    "print(Y_valid)\n",
    "print(labels)\n",
    "count_labels(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TuVCy1UqfzE-"
   },
   "outputs": [],
   "source": [
    "submission_name = \"fv_keras.csv\"\n",
    "\n",
    "print(f\"Class 1: {np.sum(y_pred == 1)}\")\n",
    "print(f\"Class 2: {np.sum(y_pred == 2)}\")\n",
    "print(f\"Class 3: {np.sum(y_pred == 3)}\")\n",
    "\n",
    "y_pred_df = pd.DataFrame(y_pred)\n",
    "y_pred_df = y_pred_df.assign(Id=list(range(y_pred.shape[0])))\n",
    "y_pred_df.columns = ['y', 'Id']\n",
    "display(y_pred_df)\n",
    "\n",
    "\n",
    "submission_folder = os.path.join(dir_path,\"submissions/\")\n",
    "csv_file = submission_folder + submission_name\n",
    "\n",
    "with open(csv_file, 'w') as csv:\n",
    "    y_pred_df.to_csv(csv,index = False)\n",
    "\"\"\"\n",
    "Class 1: 23933\n",
    "Class 2: 18553\n",
    "Class 3: 714\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "ax_data_vis-Copy1.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python (aml-3)",
   "language": "python",
   "name": "myenv1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
