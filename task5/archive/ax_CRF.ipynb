{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import natsort\n",
    "import random as rn\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import tensorflow as tf\n",
    "import pyeeg\n",
    "\n",
    "from scipy import signal\n",
    "from scipy.signal import welch\n",
    "from scipy.integrate import simps\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pycrfsuite\n",
    "import sklearn_crfsuite\n",
    "\n",
    "#Sklearn\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.svm import (SVC, SVR)\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import (RandomForestClassifier, GradientBoostingClassifier)\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import (StratifiedKFold, KFold)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "seed=42\n",
    "np.random.seed(seed)\n",
    "rn.seed(seed)\n",
    "tf.set_random_seed(seed)\n",
    "dir_path = os.getcwd()\n",
    "# https://en.wikipedia.org/wiki/Neural_oscillation\n",
    "SAMPLE_PER_SEC = 128\n",
    "DELTA_WAVE = [1, 4]\n",
    "THETA_WAVE = [4, 8]\n",
    "ALPHA_WAVE = [7.5, 12.5]\n",
    "BETA_WAVE = [13, 30]\n",
    "TOTAL_ENERGY = [0, 64]\n",
    "# not used\n",
    "LOW_GAMMA_WAVE = [30, 70]\n",
    "HIGH_GAMMA_WAVE = [70, 150]\n",
    "\n",
    "EPSILON =  0.0002"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_from_csv(csv_file):\n",
    "    '''\n",
    "    get a numpy array y of labels. the order follows the id of 4 second sample. \n",
    "    argument: relative path to the csv_file from the source folder.\n",
    "    '''\n",
    "    csv_file = os.path.join(dir_path, csv_file)\n",
    "    print(f\"Reading {csv_file}\")\n",
    "    with open(csv_file, 'r') as csvfile:\n",
    "        train_reader = pd.read_csv(csvfile)\n",
    "        train_reader.drop(labels=\"Id\", axis=1, inplace=True)\n",
    "        \n",
    "        \n",
    "    return train_reader.values\n",
    "\n",
    "def get_target_from_csv(csv_file):\n",
    "    '''\n",
    "    get a numpy array y of labels. the order follows the id of 4 second sample. \n",
    "    argument: relative path to the csv_file from the source folder.\n",
    "    '''\n",
    "    csv_file = os.path.join(dir_path,csv_file)\n",
    "    with open(csv_file, 'r') as csvfile:\n",
    "        label_reader = pd.read_csv(csvfile)\n",
    "        #print(\"Labels: \", label_reader['id'])\n",
    "        y = label_reader['y']\n",
    "        \n",
    "    y = np.array(y)\n",
    "    return y\n",
    "\n",
    "def get_features_emg(X):\n",
    "    all_featues = []\n",
    "    for i in tqdm(range(X.shape[0])):\n",
    "        features = list()\n",
    "        # https://ieeexplore.ieee.org/document/7748960\n",
    "        x_i = X[i,:]\n",
    "        # Root Mean Square (RMS): RMS of EMG\n",
    "        features.append(mean_squared_error(x_i, np.zeros(x_i.shape)))\n",
    "        \n",
    "        #Integrated Absolute Value (IAV)\n",
    "        features.append(np.sum(np.abs(x_i)))\n",
    "        \n",
    "        # Mean Absolute Value (MAV): MAV feature can be expressed as\n",
    "        features.append(np.mean(x_i))\n",
    "        \n",
    "        # TBD:\n",
    "        # Modified Mean Absolute Value type 1\n",
    "        # Modified Mean Absolute Value type 2\n",
    "        \n",
    "        # Simple Square Integral (SSI): SSI is calculated as\n",
    "        features.append(np.sum(x_i ** 2))\n",
    "        \n",
    "        # Variance (VAR): VAR is calculated as\n",
    "        features.append(np.var(x_i))\n",
    "        \n",
    "        #The 3rd, 4th and 5th temporal moments\n",
    "        features.append(np.mean(x_i ** 3))\n",
    "        features.append(np.mean(x_i ** 4))\n",
    "        features.append(np.mean(x_i ** 5))\n",
    "        \n",
    "        # TBD\n",
    "        # v-Order \n",
    "        \n",
    "        # Waveform Length\n",
    "        features.append(np.sum(np.abs(np.diff(x_i))))\n",
    "        \n",
    "        # Average Amplitude Change\n",
    "        features.append(np.mean(np.abs(np.diff(x_i))))\n",
    "        \n",
    "        # Difference Absolute Standard Deviation Value\n",
    "        features.append(np.sqrt(np.mean(np.power(np.diff(x_i), 2))))\n",
    "        \n",
    "        # AX BASIC FEATUERS\n",
    "        features.append(np.std(x_i))\n",
    "        features.append(np.min(x_i))\n",
    "        features.append(np.max(x_i))\n",
    "        features.append(np.sum(np.abs(x_i) > EPSILON))\n",
    "        \n",
    "        \n",
    "        \n",
    "        all_featues.append(features)\n",
    "    return np.array(all_featues)\n",
    "\n",
    "def get_features_eeg(X):\n",
    "    all_featues = []\n",
    "    # NOT SURE ABOUT THIS VALUES \n",
    "    # LETS DOUBLE CHECK\n",
    "    K_MAX = 6\n",
    "    SAMPLE_PER_SEC = 32\n",
    "    FREQ_BANDS = list(range(16))\n",
    "    TAU = 16\n",
    "    # embedding dimension\n",
    "    DE = 32\n",
    "    \n",
    "    for i in tqdm(range(X.shape[0])):\n",
    "        features = list()\n",
    "        # http://pyeeg.sourceforge.net/\n",
    "        x_i = X[i,:]\n",
    "        \n",
    "        # Power Spectral Intensity (PSI) and Relative Intensity Ratio (RIR)\tbin_power()\tTwo 1-D vectors\n",
    "        \n",
    "        \n",
    "        # Petrosian Fractal Dimension (PFD)\tpdf()\tA scalar\n",
    "        features.append(pyeeg.pfd(x_i))\n",
    "        \n",
    "        # Higuchi Fractal Dimension (HFD)\thfd()\tA scalar\n",
    "        features.append(pyeeg.hfd(x_i, K_MAX))\n",
    "        \n",
    "        # Hjorth mobility and complexity\thjorth()\tTwo scalars\n",
    "        \n",
    "        # Spectral Entropy (Shannon's entropy of RIRs)\tspectral_entropy()\tA scalar\n",
    "        #features.append(pyeeg.spectral_entropy(x_i, FREQ_BANDS, SAMPLE_PER_SEC))\n",
    "        \n",
    "        # SVD Entropy\tsvd_entropy()\tA scalar\n",
    "        #features.append(pyeeg.svd_entropy(x_i, TAU, DE))\n",
    "        \n",
    "        # Fisher Information\tfisher_info()\tA scalar\n",
    "        features.append(pyeeg.fisher_info(x_i, TAU, DE))\n",
    "          \n",
    "        # Detrended Fluctuation Analysis (DFA)\tdfa()\tA scalar\n",
    "        features.append(pyeeg.dfa(x_i))\n",
    "        \n",
    "        # Hurst Exponent (Hurst)\thurst()\tA scalar\n",
    "        #features.append(pyeeg.hurst(x_i))\n",
    "        \n",
    "        # AX BASIC FEATUERS\n",
    "        features.append(np.mean(x_i))\n",
    "        features.append(np.std(x_i))\n",
    "        features.append(np.min(x_i))\n",
    "        features.append(np.max(x_i))\n",
    "        features.append(np.sum(np.abs(x_i) > EPSILON))\n",
    "        \n",
    "        \"\"\"\n",
    "            DELTA_WAVE = [1, 4]\n",
    "            THETA_WAVE = [4, 8]\n",
    "            ALPHA_WAVE = [7.5, 12.5]\n",
    "            BETA_WAVE = [13, 30]\n",
    "        \"\"\"\n",
    "        delta = bandpower(x_i, DELTA_WAVE)\n",
    "        theta = bandpower(x_i, THETA_WAVE)\n",
    "        alpha = bandpower(x_i, ALPHA_WAVE)\n",
    "        beta = bandpower(x_i, BETA_WAVE)\n",
    "        total_energy = bandpower(x_i, TOTAL_ENERGY)\n",
    "        \n",
    "        \n",
    "        features.append(delta)\n",
    "        features.append(theta)\n",
    "        features.append(alpha)\n",
    "        features.append(beta)\n",
    "        \n",
    "        \n",
    "        features.append(delta / total_energy)\n",
    "        features.append(theta / total_energy)\n",
    "        features.append(alpha / total_energy)\n",
    "        features.append(beta / total_energy)\n",
    "        \n",
    "        \n",
    "        \n",
    "        all_featues.append(features)\n",
    "    return np.array(all_featues)\n",
    "\n",
    "\n",
    "def get_data_of_rat(X, y, i):\n",
    "    sample_cnt = int(X.shape[0] / 3)\n",
    "    if i == 0:\n",
    "        return X[:sample_cnt, :], y[:sample_cnt]\n",
    "    if i == 1:\n",
    "        return X[sample_cnt: 2 * sample_cnt, :], y[sample_cnt: 2 * sample_cnt]\n",
    "    if i == 2:\n",
    "        return X[2 * sample_cnt:, :], y[2 * sample_cnt:]\n",
    "    \n",
    "    \n",
    "def bandpower(data, band, window_sec=4, relative=False):\n",
    "    \"\"\"Compute the average power of the signal x in a specific frequency band.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data : 1d-array\n",
    "        Input signal in the time-domain.\n",
    "    band : list\n",
    "        Lower and upper frequencies of the band of interest.\n",
    "    window_sec : float\n",
    "        Length of each window in seconds.\n",
    "        If None, window_sec = (1 / min(band)) * 2\n",
    "    relative : boolean\n",
    "        If True, return the relative power (= divided by the total power of the signal).\n",
    "        If False (default), return the absolute power.\n",
    "\n",
    "    Return\n",
    "    ------\n",
    "    bp : float\n",
    "        Absolute or relative band power.\n",
    "\n",
    "    Examples\n",
    "    ------\n",
    "    1. Absolute and relative power in the delta band\n",
    "        >>> delta = bandpower(data, 100, [0.5, 4])\n",
    "        >>> delta_relative = bandpower(data, 100, [0.5, 4], relative=True)\n",
    "\n",
    "    2. Delta / beta ratio\n",
    "        >>> window_sec = 4\n",
    "        >>> delta = bandpower(data, 100, [0.5, 4], window_sec)\n",
    "        >>> beta = bandpower(data, 100, [12, 30], window_sec)\n",
    "        >>> db_ratio = delta / beta\n",
    "    \"\"\"\n",
    "    \n",
    "    band = np.asarray(band)\n",
    "    low, high = band\n",
    "\n",
    "    # Compute the modified periodogram (Welch)\n",
    "    if window_sec is not None:\n",
    "        nperseg = window_sec * SAMPLE_PER_SEC\n",
    "    else:\n",
    "        nperseg = (2 / low) * SAMPLE_PER_SEC\n",
    "\n",
    "    freqs, psd = welch(data, SAMPLE_PER_SEC, nperseg=nperseg, scaling='density')\n",
    "\n",
    "    # Find closest indices of band in frequency vector\n",
    "    idx_band = np.logical_and(freqs >= low, freqs < high)\n",
    "\n",
    "    # Integral approximation of the spectrum using Simpson's rule.\n",
    "    bp = simps(psd[idx_band], freqs[idx_band])\n",
    "\n",
    "    if relative:\n",
    "        bp /= simps(psd, freqs)\n",
    "    return bp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64800, 49)\n",
      "(43200, 49)\n"
     ]
    }
   ],
   "source": [
    "# Load the data\n",
    "# train\n",
    "train_feature_path = os.path.join(dir_path, \"features/all_combined_train.csv\")\n",
    "\n",
    "# trest\n",
    "test_feature_path = os.path.join(dir_path,\"features/all_combined_test.csv\")\n",
    "\n",
    "# labels\n",
    "train_target_path = os.path.join(dir_path, \"features/all_combined_label.csv\")\n",
    "\n",
    "X_train = pd.read_csv(train_feature_path).values\n",
    "y_train = pd.read_csv(train_target_path).values\n",
    "\n",
    "X_test = pd.read_csv(test_feature_path).values\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X total shape ->  (108000, 49)\n"
     ]
    }
   ],
   "source": [
    "#Fit scaler on all data\n",
    "X_total = np.concatenate((X_train, X_test))\n",
    "print(\"X total shape -> \",X_total.shape)\n",
    "\n",
    "scaler = StandardScaler().fit(X_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classifiers for CV\n",
    "\n",
    "crf = sklearn_crfsuite.CRF(\n",
    "    algorithm='lbfgs',\n",
    "    c1=0.1,\n",
    "    c2=0.1,\n",
    "    max_iterations=100,\n",
    "    all_possible_transitions=True\n",
    ")\n",
    "classifiers = [crf]\n",
    "classifiers_names =[\"conditional random fields\",  \"RandomForestClassifier\", \"SVC\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "object of type 'int' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-39-e933ee5812bc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0;31m# fit classifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m         \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_fold_scaled\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_fold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_valid_fold_scaled\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/aml/lib/python3.6/site-packages/sklearn_crfsuite/estimator.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, X_dev, y_dev)\u001b[0m\n\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mxseq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myseq\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 314\u001b[0;31m             \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxseq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myseq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    315\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpycrfsuite/_pycrfsuite.pyx\u001b[0m in \u001b[0;36mpycrfsuite._pycrfsuite.BaseTrainer.append\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpycrfsuite/_pycrfsuite.pyx\u001b[0m in \u001b[0;36mpycrfsuite._pycrfsuite.to_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpycrfsuite/_pycrfsuite.pyx\u001b[0m in \u001b[0;36mpycrfsuite._pycrfsuite.to_seq\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpycrfsuite/_pycrfsuite.pyx\u001b[0m in \u001b[0;36mpycrfsuite._pycrfsuite.to_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: object of type 'int' has no len()"
     ]
    }
   ],
   "source": [
    "def sent2features(S):\n",
    "    return dict(zip( range(S.shape[0]),  S.tolist() ) )\n",
    "\n",
    "def sent2labels(s):\n",
    "    if s[0] == 1:\n",
    "        return [\"1\"]\n",
    "    return [\"0\"]\n",
    "\n",
    "# CROSS VALDATION\n",
    "kfold = KFold(n_splits=3, shuffle=False, random_state=seed)\n",
    "\n",
    "print(\"Start\")\n",
    "bmac_scores_rf = []\n",
    "bmac_scores_svc = []\n",
    "clf_scores_avg = []\n",
    "clf_scores_std = []\n",
    "for clf in classifiers:\n",
    "    bmac_scores = []\n",
    "    for train, valid in kfold.split(X_train):\n",
    "        # get the folds\n",
    "        X_train_fold = X_train[train]\n",
    "        y_train_fold = y_train[train]\n",
    "\n",
    "        X_valid_fold = X_train[valid]\n",
    "        y_valid_fold = y_train[valid]\n",
    "\n",
    "        X_train_fold_scaled = scaler.transform(X_train_fold)\n",
    "        X_valid_fold_scaled = scaler.transform(X_valid_fold)\n",
    "        \n",
    "        X_train_fold_scaled = [sent2features(X_train_fold_scaled[s, :]) for s in range(X_train_fold_scaled.shape[0])]\n",
    "        y_train_fold = [sent2labels(y_train_fold[s, :]) for s in range(y_train_fold.shape[0])]\n",
    "\n",
    "        X_valid_fold = [sent2features(X_valid_fold_scaled[s, :]) for s in range(X_valid_fold_scaled.shape[0])]\n",
    "        y_valid_fold = [sent2labels(y_valid_fold[s, :]) for s in range(y_valid_fold.shape[0])]\n",
    "\n",
    "        # fit classifier\n",
    "        clf.fit(X_train_fold_scaled, y_train_fold)\n",
    "\n",
    "        y_pred = clf.predict(X_valid_fold_scaled)\n",
    "        \n",
    "\n",
    "        bmac_score_rf = balanced_accuracy_score(y_valid_fold, y_pred)\n",
    "        print(f\"{len(bmac_scores)}: current balanced_accuracy_score: {bmac_score_rf}\")\n",
    "\n",
    "        bmac_scores.append(bmac_score_rf)\n",
    "    \n",
    "    clf_scores_avg.append(np.mean(bmac_scores))\n",
    "    clf_scores_std.append(np.std(bmac_scores))\n",
    "\n",
    "print(\"================================================================================\")\n",
    "for i in range(len(classifiers)):\n",
    "    print(f\"{classifiers_names[i]} BMAC avg score {clf_scores_avg[i]} +/- {clf_scores_std[i]}\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "object of type 'int' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-42-56da7085a9ac>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0;31m#print(xseq)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0;31m#print(y_train_fold[i, 0])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m         \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxseq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"y\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"crf_{len(bmac_scores)}.model\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpycrfsuite/_pycrfsuite.pyx\u001b[0m in \u001b[0;36mpycrfsuite._pycrfsuite.BaseTrainer.append\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpycrfsuite/_pycrfsuite.pyx\u001b[0m in \u001b[0;36mpycrfsuite._pycrfsuite.to_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpycrfsuite/_pycrfsuite.pyx\u001b[0m in \u001b[0;36mpycrfsuite._pycrfsuite.to_seq\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpycrfsuite/_pycrfsuite.pyx\u001b[0m in \u001b[0;36mpycrfsuite._pycrfsuite.to_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: object of type 'int' has no len()"
     ]
    }
   ],
   "source": [
    "bmac_scores = []\n",
    "# CROSS VALDATION\n",
    "kfold = KFold(n_splits=3, shuffle=False, random_state=seed)\n",
    "for train, valid in kfold.split(X_train):\n",
    "    # get the folds\n",
    "    X_train_fold = X_train[train]\n",
    "    y_train_fold = y_train[train]\n",
    "\n",
    "    X_valid_fold = X_train[valid]\n",
    "    y_valid_fold = y_train[valid]\n",
    "\n",
    "    X_train_fold_scaled = scaler.transform(X_train_fold)\n",
    "    X_valid_fold_scaled = scaler.transform(X_valid_fold)\n",
    "\n",
    "    trainer = pycrfsuite.Trainer(verbose=True)\n",
    "    trainer.set_params({\n",
    "        'c1': 0.1,\n",
    "        'c2': 0.01,  \n",
    "        'max_iterations': 200,\n",
    "        'feature.possible_transitions': False\n",
    "    })\n",
    "\n",
    "\n",
    "    # Submit training data to the trainer\n",
    "    for i in range(X_train_fold_scaled.shape[0]):\n",
    "        xseq = dict(\n",
    "            zip(\n",
    "                range(X_train_fold_scaled.shape[1]), \n",
    "                X_train_fold_scaled[i, :].tolist()\n",
    "            )\n",
    "        )\n",
    "        #print(xseq)\n",
    "        #print(y_train_fold[i, 0])\n",
    "        trainer.append(xseq, \"y\")\n",
    "                       \n",
    "    trainer.train(f\"crf_{len(bmac_scores)}.model\")\n",
    "    tagger = pycrfsuite.Tagger()\n",
    "    tagger.open(f'crf_{len(bmac_scores)}.model')\n",
    "    y_pred = [tagger.tag(X_valid_fold_scaled[i, :]) for i in range(X_valid_fold_scaled.shape[0])]\n",
    "\n",
    "\n",
    "    bmac_score_rf = balanced_accuracy_score(y_valid_fold, y_pred)\n",
    "    print(f\"{len(bmac_scores)}: current balanced_accuracy_score: {bmac_score_rf}\")\n",
    "\n",
    "    bmac_scores.append(bmac_score_rf)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X total shape ->  (108000, 33)\n",
      "[1 1 1 ... 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "#Scale, fit, predict\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "svc = SVC(class_weight=\"balanced\")\n",
    "svc.fit(X_train_scaled, y_train)\n",
    "y_pred = svc.predict(X_test_scaled)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 1: 19527\n",
      "Class 2: 21259\n",
      "Class 3: 2414\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y</th>\n",
       "      <th>Id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43170</th>\n",
       "      <td>1</td>\n",
       "      <td>43170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43171</th>\n",
       "      <td>1</td>\n",
       "      <td>43171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43172</th>\n",
       "      <td>1</td>\n",
       "      <td>43172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43173</th>\n",
       "      <td>1</td>\n",
       "      <td>43173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43174</th>\n",
       "      <td>1</td>\n",
       "      <td>43174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43175</th>\n",
       "      <td>1</td>\n",
       "      <td>43175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43176</th>\n",
       "      <td>1</td>\n",
       "      <td>43176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43177</th>\n",
       "      <td>1</td>\n",
       "      <td>43177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43178</th>\n",
       "      <td>1</td>\n",
       "      <td>43178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43179</th>\n",
       "      <td>1</td>\n",
       "      <td>43179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43180</th>\n",
       "      <td>1</td>\n",
       "      <td>43180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43181</th>\n",
       "      <td>1</td>\n",
       "      <td>43181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43182</th>\n",
       "      <td>1</td>\n",
       "      <td>43182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43183</th>\n",
       "      <td>1</td>\n",
       "      <td>43183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43184</th>\n",
       "      <td>1</td>\n",
       "      <td>43184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43185</th>\n",
       "      <td>1</td>\n",
       "      <td>43185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43186</th>\n",
       "      <td>1</td>\n",
       "      <td>43186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43187</th>\n",
       "      <td>1</td>\n",
       "      <td>43187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43188</th>\n",
       "      <td>1</td>\n",
       "      <td>43188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43189</th>\n",
       "      <td>1</td>\n",
       "      <td>43189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43190</th>\n",
       "      <td>1</td>\n",
       "      <td>43190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43191</th>\n",
       "      <td>1</td>\n",
       "      <td>43191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43192</th>\n",
       "      <td>1</td>\n",
       "      <td>43192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43193</th>\n",
       "      <td>1</td>\n",
       "      <td>43193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43194</th>\n",
       "      <td>1</td>\n",
       "      <td>43194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43195</th>\n",
       "      <td>1</td>\n",
       "      <td>43195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43196</th>\n",
       "      <td>1</td>\n",
       "      <td>43196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43197</th>\n",
       "      <td>1</td>\n",
       "      <td>43197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43198</th>\n",
       "      <td>1</td>\n",
       "      <td>43198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43199</th>\n",
       "      <td>1</td>\n",
       "      <td>43199</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>43200 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       y     Id\n",
       "0      1      0\n",
       "1      1      1\n",
       "2      1      2\n",
       "3      1      3\n",
       "4      1      4\n",
       "5      1      5\n",
       "6      1      6\n",
       "7      1      7\n",
       "8      1      8\n",
       "9      1      9\n",
       "10     1     10\n",
       "11     1     11\n",
       "12     1     12\n",
       "13     1     13\n",
       "14     1     14\n",
       "15     1     15\n",
       "16     1     16\n",
       "17     1     17\n",
       "18     1     18\n",
       "19     1     19\n",
       "20     1     20\n",
       "21     1     21\n",
       "22     1     22\n",
       "23     1     23\n",
       "24     1     24\n",
       "25     1     25\n",
       "26     1     26\n",
       "27     1     27\n",
       "28     1     28\n",
       "29     1     29\n",
       "...   ..    ...\n",
       "43170  1  43170\n",
       "43171  1  43171\n",
       "43172  1  43172\n",
       "43173  1  43173\n",
       "43174  1  43174\n",
       "43175  1  43175\n",
       "43176  1  43176\n",
       "43177  1  43177\n",
       "43178  1  43178\n",
       "43179  1  43179\n",
       "43180  1  43180\n",
       "43181  1  43181\n",
       "43182  1  43182\n",
       "43183  1  43183\n",
       "43184  1  43184\n",
       "43185  1  43185\n",
       "43186  1  43186\n",
       "43187  1  43187\n",
       "43188  1  43188\n",
       "43189  1  43189\n",
       "43190  1  43190\n",
       "43191  1  43191\n",
       "43192  1  43192\n",
       "43193  1  43193\n",
       "43194  1  43194\n",
       "43195  1  43195\n",
       "43196  1  43196\n",
       "43197  1  43197\n",
       "43198  1  43198\n",
       "43199  1  43199\n",
       "\n",
       "[43200 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'\\nClass 1: 23933\\nClass 2: 18553\\nClass 3: 714\\n'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission_name = \"fv_allfeat.csv\"\n",
    "\n",
    "print(f\"Class 1: {np.sum(y_pred == 1)}\")\n",
    "print(f\"Class 2: {np.sum(y_pred == 2)}\")\n",
    "print(f\"Class 3: {np.sum(y_pred == 3)}\")\n",
    "\n",
    "y_pred_df = pd.DataFrame(y_pred)\n",
    "y_pred_df = y_pred_df.assign(Id=list(range(y_pred.shape[0])))\n",
    "y_pred_df.columns = ['y', 'Id']\n",
    "display(y_pred_df)\n",
    "\n",
    "\n",
    "submission_folder = os.path.join(dir_path,\"submissions/\")\n",
    "csv_file = submission_folder + submission_name\n",
    "\n",
    "with open(csv_file, 'w') as csv:\n",
    "    y_pred_df.to_csv(csv,index = False)\n",
    "\"\"\"\n",
    "Class 1: 23933\n",
    "Class 2: 18553\n",
    "Class 3: 714\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (aml-3)",
   "language": "python",
   "name": "myenv1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
