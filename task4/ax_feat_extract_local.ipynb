{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import natsort\n",
    "import random as rn\n",
    "import skvideo.io\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import tensorflow as tf\n",
    "import cv2 as cv\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#Keras\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, Flatten\n",
    "from keras import optimizers\n",
    "\n",
    "#Sklearn\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.svm import (SVC, SVR)\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import (AdaBoostRegressor, RandomForestRegressor, RandomForestClassifier, GradientBoostingRegressor, BaggingRegressor)\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Support function from the given repo for the project\n",
    "def get_videos_from_folder(data_folder):\n",
    "    '''\n",
    "    get a list of video x wehre each video is a numpy array in the format [n_frames,width,height] \n",
    "    with uint8 elements.\n",
    "    argument: relative path to the data_folder from the source folder.\n",
    "    '''\n",
    "    data_folder = os.path.join(dir_path,data_folder)\n",
    "    x = []\n",
    "    file_names = []\n",
    "    \n",
    "    if os.path.isdir(data_folder):\n",
    "        for dirpath, dirnames, filenames in os.walk(data_folder):\n",
    "            filenames = natsort.natsorted(filenames,reverse=False)\n",
    "            for filename in filenames:\n",
    "                file_path = os.path.join(dirpath, filename)\n",
    "                statinfo = os.stat(file_path)\n",
    "                if statinfo.st_size != 0:\n",
    "                    video = skvideo.io.vread(file_path, outputdict={\"-pix_fmt\": \"gray\"})[:, :, :, 0]\n",
    "                    x.append(video)\n",
    "                    file_names.append(int(filename.split(\".\")[0]))\n",
    "\n",
    "    indices = sorted(range(len(file_names)), key=file_names.__getitem__)\n",
    "    x = np.take(x,indices)\n",
    "    return x\n",
    "\n",
    "def get_target_from_csv(csv_file):\n",
    "    '''\n",
    "    get a numpy array y of labels. the order follows the id of video. \n",
    "    argument: relative path to the csv_file from the source folder.\n",
    "    '''\n",
    "    csv_file = os.path.join(dir_path,csv_file)\n",
    "    with open(csv_file, 'r') as csvfile:\n",
    "        label_reader = pd.read_csv(csvfile)\n",
    "        #print(\"Labels: \", label_reader['id'])\n",
    "        y = label_reader['y']\n",
    "        \n",
    "    y = np.array(y)\n",
    "    return y\n",
    "\n",
    "\n",
    "def save_solution(csv_file,prob_positive_class):\n",
    "    with open(csv_file, 'w') as csv:\n",
    "        df = pd.DataFrame.from_dict({'id':range(len(prob_positive_class)),'y': prob_positive_class})\n",
    "        df.to_csv(csv,index = False)\n",
    "def _int64_feature(value):\n",
    "    return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n",
    "\n",
    "def _bytes_feature(value):\n",
    "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
    "\n",
    "def save_tf_record(x,file_name,y = None):\n",
    "    writer = tf.python_io.TFRecordWriter(file_name)\n",
    "    if y is None:\n",
    "        for video in x:\n",
    "            sys.stdout.flush()\n",
    "            feature = {'len': _int64_feature(video.shape[0]),\n",
    "                       'height': _int64_feature(video.shape[1]),\n",
    "                       'width': _int64_feature(video.shape[2]),\n",
    "                       'video': _bytes_feature(tf.compat.as_bytes(video.tostring()))}\n",
    "            example = tf.train.Example(features=tf.train.Features(feature=feature))\n",
    "            writer.write(example.SerializeToString())\n",
    "    else:\n",
    "        for video,label in zip(x,y):\n",
    "            sys.stdout.flush()\n",
    "            feature = {'len': _int64_feature(video.shape[0]),\n",
    "                       'height': _int64_feature(video.shape[1]),\n",
    "                       'width': _int64_feature(video.shape[2]),\n",
    "                       'video': _bytes_feature(tf.compat.as_bytes(video.tostring())),\n",
    "                       'label': _int64_feature(label)}\n",
    "            example = tf.train.Example(features=tf.train.Features(feature=feature))\n",
    "            writer.write(example.SerializeToString())\n",
    "    \n",
    "    writer.close()\n",
    "    sys.stdout.flush()\n",
    "\n",
    "def prob_positive_class_from_prediction(pred):\n",
    "    return np.array([p['probabilities'][1] for p in pred])\n",
    "\n",
    "def decode(serialized_example):\n",
    "    features = tf.parse_single_example(\n",
    "        serialized_example,\n",
    "        features={\n",
    "            'len': tf.FixedLenFeature([], tf.int64),\n",
    "            'height': tf.FixedLenFeature([], tf.int64),\n",
    "            'width': tf.FixedLenFeature([], tf.int64),\n",
    "            'label': tf.FixedLenFeature([], tf.int64,default_value = 0),\n",
    "            'video': tf.FixedLenFeature([], tf.string),\n",
    "        })\n",
    "    video = tf.decode_raw(features['video'], tf.uint8)\n",
    "    height = features['height']\n",
    "    width = features['width']\n",
    "    length = features['len']\n",
    "    shape = tf.stack([length,height,width])\n",
    "    video = tf.reshape(video,shape)\n",
    "    label = features['label']\n",
    "    features = {'video':video}\n",
    "    return features,label\n",
    "\n",
    "def input_fn_from_dataset(files,batch_size = 1,num_epochs = None,shuffle = True):\n",
    "    data_set = tf.data.TFRecordDataset(files)\n",
    "    if shuffle:\n",
    "        data_set = data_set.shuffle(buffer_size=len(files)) \n",
    "    data_set = data_set.map(decode)\n",
    "    data_set = data_set.padded_batch(batch_size,padded_shapes= ({'video':[212,100,100]},[]))\n",
    "    data_set = data_set.repeat(num_epochs)\n",
    "    data_set = data_set.prefetch(batch_size)\n",
    "    \n",
    "    return data_set\n",
    "\n",
    "def decode_frame(serialized_example):\n",
    "    features = tf.parse_single_example(\n",
    "        serialized_example,\n",
    "        features={\n",
    "            'len': tf.FixedLenFeature([], tf.int64),\n",
    "            'height': tf.FixedLenFeature([], tf.int64),\n",
    "            'width': tf.FixedLenFeature([], tf.int64),\n",
    "            'label': tf.FixedLenFeature([], tf.int64,default_value = 0),\n",
    "            'video': tf.FixedLenFeature([], tf.string),\n",
    "        })\n",
    "    video = tf.decode_raw(features['video'], tf.uint8)\n",
    "    height = features['height']\n",
    "    width = features['width']\n",
    "    length = features['len']\n",
    "    shape = tf.stack([length,height,length])\n",
    "    video = tf.reshape(video,shape)\n",
    "    label = features['label']\n",
    "    label = tf.expand_dims(label,axis=-1)\n",
    "    label = tf.tile(label,tf.expand_dims(length,axis=-1))\n",
    "    features = {'frame':video}\n",
    "    return features,label\n",
    "\n",
    "def input_fn_frame_from_dataset(files,batch_size = 1,num_epochs = None):\n",
    "    data_set = tf.data.TFRecordDataset(files)\n",
    "    data_set = data_set.shuffle(buffer_size=len(files)) \n",
    "    data_set = data_set.map(decode_frame)\n",
    "    data_set = data_set.shuffle(buffer_size=batch_size)\n",
    "    data_set = data_set.apply(tf.contrib.data.unbatch())\n",
    "    data_set = data_set.batch(batch_size)\n",
    "    data_set = data_set.repeat(num_epochs)\n",
    "    data_set = data_set.prefetch(batch_size)\n",
    "    \n",
    "    return data_set\n",
    "#Custom support functions\n",
    "\n",
    "#Count for the minimum number of frames video among the list_array of videos\n",
    "def count_min_number_frames(list_array):\n",
    "    min_frames = 999\n",
    "    for sample in list_array:\n",
    "        if sample.shape[0] < min_frames:\n",
    "            min_frames = sample.shape[0]\n",
    "            \n",
    "    return min_frames\n",
    "\n",
    "#Count number of subsamples given the min_frames\n",
    "def count_new_subsamples(list_array, min_frames, train_set=True, labels=[]):\n",
    "    \"\"\"Params:\n",
    "       - list array: list of videos (list of numpy array)\n",
    "       - min_frames: number of frames per subsample (equal to the minimum number fo frames among training and test videos)\n",
    "       - train_set: set to false if the dataset passed is the test set\n",
    "       - labels: pass the labels for the train set\n",
    "       Return:\n",
    "       - n_new_subsamples \n",
    "         if train set == true -> int(video frames/min_frames)\n",
    "         if test set == false -> len(list_array) just pick one subsample of min_frames per video and discard the other frames\n",
    "    \"\"\"\n",
    "    classes = [0,0]\n",
    "    i = 0\n",
    "    n_new_samples = 0\n",
    "    for sample in list_array:\n",
    "        n_new_samples += int(sample.shape[0]/min_frames)\n",
    "        if train_set:\n",
    "            classes[labels[i]] += int(sample.shape[0]/min_frames)\n",
    "        i+=1\n",
    "    print(\"Train set\" if train_set==True else \"Test set\")\n",
    "    print(n_new_samples)\n",
    "    print(\"Labels per class ->\",classes if train_set==True else \"\")\n",
    "    return n_new_samples\n",
    "\n",
    "\n",
    "# =========== OPTICAL FLOW PART ================\n",
    "def get_velocity_vec_frames(prev, next):\n",
    "    flow = cv.calcOpticalFlowFarneback(\n",
    "        prev.astype(np.uint8), \n",
    "        next.astype(np.uint8),\n",
    "        None,\n",
    "        0.5,    \n",
    "        int(3),      \n",
    "        int(10),      \n",
    "        int(3),           \n",
    "        int(5),    \n",
    "        1.2,         \n",
    "        0)\n",
    "    u = flow[...,0]\n",
    "    v = flow[...,1]\n",
    "    \n",
    "    delta_avg = np.sum(np.sqrt(np.square(u) + np.square(v))) / (100 * 100)\n",
    "    vu_frac = np.divide(v, u)\n",
    "    # x/0 => inf setting inf to zero and 0/ 0 is nan => set to zero as well\n",
    "    vu_frac[vu_frac == np.inf] = 0\n",
    "    vu_frac = np.nan_to_num(vu_frac)\n",
    "    \n",
    "    theta_avg = np.sum(np.arctan(vu_frac)) / (100 * 100)\n",
    "    \n",
    "    return delta_avg, theta_avg\n",
    "    \n",
    "def get_parametric_velocity_curve(avg_velocities):\n",
    "    curve = list()\n",
    "    x_prev = 0\n",
    "    y_prev = 0\n",
    "    curve.append([x_prev, y_prev])\n",
    "    \n",
    "    for (delta, theta) in avg_velocities:\n",
    "        x_next = x_prev + delta * np.cos(theta)\n",
    "        y_next = y_prev + delta * np.sin(theta)\n",
    "        curve.append([x_next, y_next])\n",
    "        x_prev = x_next\n",
    "        y_prev = y_next\n",
    "    return curve\n",
    "    \n",
    "def get_avg_velocity_vec(video):\n",
    "    avg_velocities = []\n",
    "    N=5\n",
    "    frame_index = list(range(len(video)))[0::N]\n",
    "    prev = video[frame_index[0]]\n",
    "    for i in frame_index:\n",
    "        next = video[i]\n",
    "        avg_velocities.append(get_velocity_vec_frames(prev, next))\n",
    "        prev = next\n",
    "        \n",
    "    avg_velocity_curve = get_parametric_velocity_curve(avg_velocities)\n",
    "    \n",
    "    return avg_velocity_curve\n",
    "\n",
    "def get_avg_velocity_from_videos(videos):\n",
    "    avg_velo = []\n",
    "    for video in tqdm(videos):\n",
    "        avg_velo.append(get_avg_velocity_vec(video))\n",
    "    return avg_velo\n",
    "\n",
    "\n",
    "def get_feature_from_curve(curve):\n",
    "    features = []\n",
    "    N = len(curve)\n",
    "    \n",
    "    X = np.array([c[0] for c in curve])\n",
    "    Y = np.array([c[1] for c in curve])\n",
    "    M_X = np.mean(X)\n",
    "    M_Y = np.mean(Y)\n",
    "    \n",
    "    X_plus = np.sum(X >= M_X)\n",
    "    X_minus = np.sum(X <=  M_X)\n",
    "    \n",
    "    Y_plus = np.sum(Y >= M_Y)\n",
    "    Y_minus = np.sum(Y <=  M_Y)\n",
    "    \n",
    "    V_avg = 0.5 * ( (X_plus / X_minus) + (Y_plus / Y_minus))\n",
    "    \n",
    "    # the first order difference is given by out[n] = a[n+1] - a[n] along the given axis,\n",
    "    X_diff = np.diff(X)\n",
    "    Y_diff = np.diff(Y)\n",
    "    \n",
    "    delta_max_x = np.max(np.abs(X_diff)) * 0.125 # factor from the paper\n",
    "    delta_max_y = np.max(np.abs(Y_diff)) * 0.125\n",
    "    \n",
    "    F_X = np.sum(X_diff < delta_max_x)\n",
    "    F_Y = np.sum(Y_diff < delta_max_y)\n",
    "    \n",
    "    F_avg =(1.0 / (2.0 * N)) * (F_X + F_Y) \n",
    "    \n",
    "    \n",
    "    return [V_avg, F_avg]\n",
    "\n",
    "def extract_features_ax(X_videos):\n",
    "    total_videos = len(X_videos)\n",
    "    #Extracting features\n",
    "    \n",
    "    all_features = list()\n",
    "    for video in tqdm(X_videos):\n",
    "        feature_vec = list()\n",
    "        \n",
    "        # get the avg velocity curve\n",
    "        avg_velo = get_avg_velocity_vec(video)\n",
    "        curve_feature = get_feature_from_curve(avg_velo)\n",
    "        \n",
    "        #feature_vec += curve_feature\n",
    "        #feature_vec.append(np.min(avg_velo))\n",
    "        #feature_vec.append(np.max(avg_velo))\n",
    "        #feature_vec.append(np.mean(avg_velo))\n",
    "        #feature_vec.append(np.std(avg_velo))\n",
    "        \n",
    "        \n",
    "        # compute the sum of pixels per frame\n",
    "        #heartBeatApprox = np.sum(np.sum(video, axis=1), axis=1)\n",
    "        #feature_vec.append(np.min(heartBeatApprox))\n",
    "        #feature_vec.append(np.max(heartBeatApprox))\n",
    "        #feature_vec.append(np.mean(heartBeatApprox))\n",
    "        #feature_vec.append(np.std(heartBeatApprox))\n",
    "        #heartBeatApprox = heartBeatApprox - heartBeatApprox.mean()\n",
    "        #feature_vec += heartBeatApprox[:22].tolist()\n",
    "        \n",
    "        # gradient\n",
    "        grad = np.diff(video)\n",
    "        gradApprox = np.sum(np.sum(grad, axis=1), axis=1)\n",
    "        feature_vec.append(np.min(gradApprox))\n",
    "        feature_vec.append(np.max(gradApprox))\n",
    "        feature_vec.append(np.mean(gradApprox))\n",
    "        feature_vec.append(np.std(gradApprox))\n",
    "        heartBeatApprox = gradApprox - gradApprox.mean()\n",
    "        feature_vec += np.nan_to_num(gradApprox[:22]).tolist()\n",
    "        \n",
    "        \n",
    "    \n",
    "    \n",
    "        \n",
    "        total_features = len(feature_vec)\n",
    "        all_features.append(feature_vec)\n",
    "        \n",
    "    X_features = np.zeros((total_videos,total_features))\n",
    "    \n",
    "    for i in range(total_videos):\n",
    "        X_features[i,:] = all_features[i]\n",
    "        \n",
    "    return X_features\n",
    "\n",
    "def extract_ids(data_folder):\n",
    "    \n",
    "    print(\"Extracting ids from test set videos\")\n",
    "    data_folder = os.path.join(dir_path,data_folder)\n",
    "    x = []\n",
    "    file_names = []\n",
    "    \n",
    "    if os.path.isdir(data_folder):\n",
    "        for dirpath, dirnames, filenames in os.walk(data_folder):\n",
    "            filenames = natsort.natsorted(filenames,reverse=False)\n",
    "            ids = []\n",
    "            for filename in filenames:\n",
    "              ids.append(int(filename.split(\".\")[0]))\n",
    "    return ids\n",
    "\n",
    "def make_submission(filename, predictions):\n",
    "    ids = extract_ids(test_folder)\n",
    "    df = pd.DataFrame({'id':ids, 'y':predictions})\n",
    "    df[[\"id\", \"y\"]].to_csv(\"submissions/\"+filename, index= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current dir ->  /home/ax/master/2018_02/ml/task4\n",
      "Train folder ->  /home/ax/master/2018_02/ml/task4/data/train/\n",
      "Train target ->  /home/ax/master/2018_02/ml/task4/data/train_target.csv\n",
      "Test folder ->  /home/ax/master/2018_02/ml/task4/data/test/\n",
      "Train Data\n",
      "\n",
      "Test Data\n",
      "\n"
     ]
    }
   ],
   "source": [
    "seed=42\n",
    "np.random.seed(seed)\n",
    "rn.seed(seed)\n",
    "tf.set_random_seed(seed)\n",
    "dir_path = os.getcwd()\n",
    "\n",
    "train_folder = os.path.join(dir_path,\"data/train/\")\n",
    "test_folder = os.path.join(dir_path,\"data/test/\")\n",
    "\n",
    "train_target = os.path.join(dir_path,'data/train_target.csv')\n",
    "\n",
    "print(\"Current dir -> \", dir_path)\n",
    "print(\"Train folder -> \",train_folder)\n",
    "print(\"Train target -> \",train_target)\n",
    "print(\"Test folder -> \",test_folder)\n",
    "\n",
    "#Load data from csv file\n",
    "print(\"Train Data\\n\")\n",
    "x_train = get_videos_from_folder(train_folder) #List of numpy arrays\n",
    "y_train = get_target_from_csv(train_target) #Numpy array of labels\n",
    "print(\"Test Data\\n\")\n",
    "x_test = get_videos_from_folder(test_folder) #List of numpy arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02e6fe5059084d3d986cab914c5661ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=158), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ax/miniconda3/envs/aml/lib/python3.6/site-packages/ipykernel_launcher.py:197: RuntimeWarning: invalid value encountered in sqrt\n",
      "/home/ax/miniconda3/envs/aml/lib/python3.6/site-packages/ipykernel_launcher.py:198: RuntimeWarning: invalid value encountered in true_divide\n",
      "/home/ax/miniconda3/envs/aml/lib/python3.6/site-packages/ipykernel_launcher.py:198: RuntimeWarning: divide by zero encountered in true_divide\n",
      "/home/ax/miniconda3/envs/aml/lib/python3.6/site-packages/ipykernel_launcher.py:203: RuntimeWarning: overflow encountered in arctan\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "(158, 26)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a1bc769701648c4a1fdb2ebdeb5f108",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=69), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ax/miniconda3/envs/aml/lib/python3.6/site-packages/ipykernel_launcher.py:197: RuntimeWarning: invalid value encountered in sqrt\n",
      "/home/ax/miniconda3/envs/aml/lib/python3.6/site-packages/ipykernel_launcher.py:198: RuntimeWarning: invalid value encountered in true_divide\n",
      "/home/ax/miniconda3/envs/aml/lib/python3.6/site-packages/ipykernel_launcher.py:198: RuntimeWarning: divide by zero encountered in true_divide\n",
      "/home/ax/miniconda3/envs/aml/lib/python3.6/site-packages/ipykernel_launcher.py:203: RuntimeWarning: overflow encountered in arctan\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "(69, 26)\n"
     ]
    }
   ],
   "source": [
    "X_train_features = extract_features_ax(x_train)\n",
    "\n",
    "X_train_scaled = preprocessing.scale(X_train_features)\n",
    "print(X_train_scaled.shape)\n",
    "\n",
    "\n",
    "X_test_features = extract_features_ax(x_test)\n",
    "X_test_scaled = preprocessing.scale(X_test_features)\n",
    "print(X_test_scaled.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using: 26 features\n"
     ]
    }
   ],
   "source": [
    "# Create a feature selctor base on a random forest\n",
    "sfm = SelectFromModel(RandomForestClassifier(n_estimators=2000, random_state=seed, n_jobs=-1), threshold=0.0001)\n",
    "\n",
    "# Train the classifier\n",
    "sfm.fit(X_train_scaled, y_train)\n",
    "print(f\"Using: {np.sum(sfm.get_support())} features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using: 1 features\n",
      "1\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create a feature selctor base on a random forest\n",
    "sfm = SelectFromModel(RandomForestClassifier(n_estimators=10000, random_state=seed, n_jobs=-1), threshold=0.1125)\n",
    "\n",
    "# Train the classifier\n",
    "sfm.fit(X_train_scaled, y_train)\n",
    "print(f\"Using: {np.sum(sfm.get_support())} features\")\n",
    "n_features = sfm.transform(X_train_scaled).shape[1]\n",
    "\n",
    "# Reset the threshold till the number of features equals two.\n",
    "# Note that the attribute can be set directly instead of repeatedly\n",
    "# fitting the metatransformer.\n",
    "while n_features > 2:\n",
    "    sfm.threshold += 0.0001\n",
    "    X_transform = sfm.transform(X_train_scaled)\n",
    "    n_features = X_transform.shape[1]\n",
    "print(n_features)\n",
    "# Plot the selected two features from X.\n",
    "plt.title(\"Features selected with threshold %0.3f.\" % sfm.threshold)\n",
    "feature1 = X_transform[:, 0]\n",
    "feature2 = X_transform[:, 1]\n",
    "plt.plot(feature1, feature2, 'r.')\n",
    "plt.xlabel(\"Feature number 1\")\n",
    "plt.ylabel(\"Feature number 2\")\n",
    "plt.ylim([np.min(feature2), np.max(feature2)])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestRegressor(n_estimators=2000,\n",
    "                                       random_state=seed,\n",
    "                                       n_jobs=-1,\n",
    "                                       verbose=False)\n",
    "\n",
    "rfc = RandomForestClassifier(n_estimators=2000, \n",
    "                             criterion='gini', \n",
    "                             max_depth=None, \n",
    "                             min_samples_split=2, \n",
    "                             min_samples_leaf=1,\n",
    "                             min_weight_fraction_leaf=0.0, \n",
    "                             max_features='auto', \n",
    "                             max_leaf_nodes=None, \n",
    "                             min_impurity_decrease=0.0, \n",
    "                             min_impurity_split=None, \n",
    "                             bootstrap=True, \n",
    "                             oob_score=False, n_jobs=-1, \n",
    "                             random_state=seed, \n",
    "                             verbose=0, \n",
    "                             warm_start=False, \n",
    "                             class_weight=None)\n",
    "\n",
    "classifiers = [rf]\n",
    "classifiers_names = [\"RandomForestRegressor\", \"RandomForestClassifier\"  ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start\n",
      "0: current roc_auc score: 0.5\n",
      "1: current roc_auc score: 0.34375\n",
      "2: current roc_auc score: 0.59375\n",
      "3: current roc_auc score: 0.40625\n",
      "4: current roc_auc score: 0.484375\n",
      "5: current roc_auc score: 0.34375\n",
      "6: current roc_auc score: 0.359375\n",
      "7: current roc_auc score: 0.5625\n",
      "8: current roc_auc score: 0.609375\n",
      "9: current roc_auc score: 0.5102040816326531\n",
      "========================================\n",
      "RandomForestRegressor roc_auc avg score 0.47133290816326534 +/- 0.097046908046165\n"
     ]
    }
   ],
   "source": [
    "kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=seed)\n",
    "clf_scores_avg = []\n",
    "clf_scores_std = []\n",
    "\n",
    "\n",
    "print(\"Start\")\n",
    "for clf in classifiers:\n",
    "    roc_auc_scores = []\n",
    "    for train, test in kfold.split(X_train_scaled, y_train):\n",
    "        X_fold = X_train_scaled[train]\n",
    "        y_fold = y_train[train]\n",
    "        X_fold_test = X_train_scaled[test]\n",
    "        y_valid = y_train[test]\n",
    "        # use only important features\n",
    "        X_important_train = sfm.transform(X_fold)\n",
    "        X_important_test = sfm.transform(X_fold_test)\n",
    "        \n",
    "        # fit classifier\n",
    "        clf.fit(X_important_train, y_fold)\n",
    "        \n",
    "        y_pred = clf.predict(X_important_test)\n",
    "        y_true = y_train[test]\n",
    "        \n",
    "        roc_auc = roc_auc_score(y_true, y_pred)\n",
    "        print(f\"{len(roc_auc_scores)}: current roc_auc score: {roc_auc}\")\n",
    "\n",
    "        roc_auc_scores.append(roc_auc)\n",
    "        \n",
    "    clf_scores_avg.append(np.mean(roc_auc_scores))\n",
    "    clf_scores_std.append(np.std(roc_auc_scores))\n",
    "    print(\"========================================\")\n",
    "for i in range(len(classifiers)):\n",
    "    print(f\"{classifiers_names[i]} roc_auc avg score {clf_scores_avg[i]} +/- {clf_scores_std[i]}\" )\n",
    "    \n",
    "# RandomForestRegressor roc_auc avg score 0.9351475279106859 +/- 0.0373456711654917 with 2000 estimators\n",
    "# RandomForestRegressor roc_auc avg score 0.9357589048378522 +/- 0.038307405172097714 with 5000 estimators\n",
    "# RandomForestRegressor roc_auc avg score 0.941208133971292 +/- 0.03181291905225851 with min max features 2000 estimators\n",
    "# RandomForestRegressor roc_auc avg score 0.9365297713981926 +/- 0.0370342614578307 with pixel sum feature 2000 estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start fitting\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "           max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=1, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=2000, n_jobs=-1,\n",
       "           oob_score=False, random_state=42, verbose=False,\n",
       "           warm_start=False)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Predict with one classifiers\n",
    "X_train_importance = sfm.transform(X_train_scaled)\n",
    "X_test_importance = sfm.transform(X_test_scaled)\n",
    "print(\"start fitting\")\n",
    "rf.fit(X_train_importance, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.421  0.6045 0.798  0.6605 0.4745 0.39   0.6235 0.725  0.784  0.806\n",
      " 0.187  0.0935 0.4935 0.347  0.1665 0.823  0.516  0.7005 0.803  0.544\n",
      " 0.517  0.687  0.7335 0.3085 0.6805 0.5605 0.2265 0.675  0.4035 0.31\n",
      " 0.4145 0.5035 0.4345 0.416  0.44   0.6675 0.6805 0.608  0.8005 0.697\n",
      " 0.215  0.41   0.325  0.431  0.362  0.787  0.258  0.5635 0.662  0.655\n",
      " 0.281  0.4345 0.307  0.447  0.278  0.372  0.6435 0.792  0.7915 0.4625\n",
      " 0.215  0.658  0.8095 0.765  0.7625 0.915  0.5565 0.785  0.6365]\n",
      "Extracting ids from test set videos\n"
     ]
    }
   ],
   "source": [
    "p_rf = rf.predict(X_test_importance)\n",
    "print(p_rf)\n",
    "make_submission(\"ax_rf_pixelSum_only_feature_2000.csv\", p_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (aml-3)",
   "language": "python",
   "name": "myenv1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
