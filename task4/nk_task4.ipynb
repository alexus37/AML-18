{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "cellView": "form",
    "colab": {},
    "colab_type": "code",
    "id": "xidLmtskWIiE"
   },
   "outputs": [],
   "source": [
    "#@title Import Data\n",
    "#@markdown - upload the folder aml-task4 into your google drive\n",
    "#@markdown - change the runtime to gpu (is faster than tpu)\n",
    "#@markdown - run this cell to import the data (to see the code: right mouse click / form / show code )\n",
    "\n",
    "\n",
    "# First remember to change runtime to GPU !!\n",
    "\n",
    "!apt-get install -y -qq software-properties-common python-software-properties module-init-tools\n",
    "!add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n",
    "!apt-get update -qq 2>&1 > /dev/null\n",
    "!apt-get -y install -qq google-drive-ocamlfuse fuse\n",
    "from google.colab import auth\n",
    "auth.authenticate_user()\n",
    "from oauth2client.client import GoogleCredentials\n",
    "creds = GoogleCredentials.get_application_default()\n",
    "import getpass\n",
    "!google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL\n",
    "vcode = getpass.getpass()\n",
    "!echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}\n",
    "\n",
    "#COLAB\n",
    "!mkdir -p drive\n",
    "!google-drive-ocamlfuse drive\n",
    "import os\n",
    "#Upload on drive fist the data folder called \"data\"\n",
    "os.chdir(\"/content/drive/aml-task4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "cellView": "form",
    "colab": {},
    "colab_type": "code",
    "id": "vYBYwCL1Yswr"
   },
   "outputs": [],
   "source": [
    "#@title Install Packages\n",
    "#@markdown this cell installs all required packages using pip\n",
    "\n",
    "!pip install sk-video\n",
    "!pip install natsort\n",
    "!apt-get install ffmpeg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LXceY_CEnRDU"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import natsort\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import skvideo.io\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, MaxPool2D, Flatten, Dropout\n",
    "from keras import optimizers\n",
    "from keras.optimizers import Adam\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from keras.utils import np_utils\n",
    "from keras.callbacks import Callback, EarlyStopping, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "cellView": "form",
    "colab": {},
    "colab_type": "code",
    "id": "vOIgLBZKNqvu"
   },
   "outputs": [],
   "source": [
    "#@title Provided Helper Functions\n",
    "def _int64_feature(value):\n",
    "\treturn tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n",
    "\n",
    "def _bytes_feature(value):\n",
    "\treturn tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
    "\n",
    "def _bytes_feature(value):\n",
    "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
    "\n",
    "def save_tf_record(x,file_name,y = None):\n",
    "    writer = tf.python_io.TFRecordWriter(file_name)\n",
    "    if y is None:\n",
    "        for video in x:\n",
    "            sys.stdout.flush()\n",
    "            feature = {'len': _int64_feature(video.shape[0]),\n",
    "                       'height': _int64_feature(video.shape[1]),\n",
    "                       'width': _int64_feature(video.shape[2]),\n",
    "                       'video': _bytes_feature(tf.compat.as_bytes(video.tostring()))}\n",
    "            example = tf.train.Example(features=tf.train.Features(feature=feature))\n",
    "            writer.write(example.SerializeToString())\n",
    "    else:\n",
    "        for video,label in zip(x,y):\n",
    "            sys.stdout.flush()\n",
    "            feature = {'len': _int64_feature(video.shape[0]),\n",
    "                       'height': _int64_feature(video.shape[1]),\n",
    "                       'width': _int64_feature(video.shape[2]),\n",
    "                       'video': _bytes_feature(tf.compat.as_bytes(video.tostring())),\n",
    "                       'label': _int64_feature(label)}\n",
    "            example = tf.train.Example(features=tf.train.Features(feature=feature))\n",
    "            writer.write(example.SerializeToString())\n",
    "    \n",
    "    writer.close()\n",
    "    sys.stdout.flush()\n",
    "\n",
    "def prob_positive_class_from_prediction(pred):\n",
    "    return np.array([p['probabilities'][1] for p in pred])\n",
    "\n",
    "def decode(serialized_example):\n",
    "    features = tf.parse_single_example(\n",
    "        serialized_example,\n",
    "        features={\n",
    "            'len': tf.FixedLenFeature([], tf.int64),\n",
    "            'height': tf.FixedLenFeature([], tf.int64),\n",
    "            'width': tf.FixedLenFeature([], tf.int64),\n",
    "            'label': tf.FixedLenFeature([], tf.int64,default_value = 0),\n",
    "            'video': tf.FixedLenFeature([], tf.string),\n",
    "        })\n",
    "    video = tf.decode_raw(features['video'], tf.uint8)\n",
    "    height = features['height']\n",
    "    width = features['width']\n",
    "    length = features['len']\n",
    "    shape = tf.stack([length,height,width])\n",
    "    video = tf.reshape(video,shape)\n",
    "    label = features['label']\n",
    "    features = {'video':video}\n",
    "    return features,label\n",
    "\n",
    "def input_fn_from_dataset(files,batch_size = 1,num_epochs = None,shuffle = True):\n",
    "    data_set = tf.data.TFRecordDataset(files)\n",
    "    if shuffle:\n",
    "        data_set = data_set.shuffle(buffer_size=len(files)) \n",
    "    data_set = data_set.map(decode)\n",
    "    data_set = data_set.padded_batch(batch_size,padded_shapes= ({'video':[212,100,100]},[]))\n",
    "    data_set = data_set.repeat(num_epochs)\n",
    "    data_set = data_set.prefetch(batch_size)\n",
    "    \n",
    "    return data_set\n",
    "\n",
    "def decode_frame(serialized_example):\n",
    "    features = tf.parse_single_example(\n",
    "        serialized_example,\n",
    "        features={\n",
    "            'len': tf.FixedLenFeature([], tf.int64),\n",
    "            'height': tf.FixedLenFeature([], tf.int64),\n",
    "            'width': tf.FixedLenFeature([], tf.int64),\n",
    "            'label': tf.FixedLenFeature([], tf.int64,default_value = 0),\n",
    "            'video': tf.FixedLenFeature([], tf.string),\n",
    "        })\n",
    "    video = tf.decode_raw(features['video'], tf.uint8)\n",
    "    height = features['height']\n",
    "    width = features['width']\n",
    "    length = features['len']\n",
    "    shape = tf.stack([length,height,length])\n",
    "    video = tf.reshape(video,shape)\n",
    "    label = features['label']\n",
    "    label = tf.expand_dims(label,axis=-1)\n",
    "    label = tf.tile(label,tf.expand_dims(length,axis=-1))\n",
    "    features = {'frame':video}\n",
    "    return features,label\n",
    "\n",
    "def input_fn_frame_from_dataset(files,batch_size = 1,num_epochs = None):\n",
    "\tdata_set = tf.data.TFRecordDataset(files)\n",
    "\tdata_set = data_set.shuffle(buffer_size=len(files)) \n",
    "\tdata_set = data_set.map(decode_frame)\n",
    "\tdata_set = data_set.apply(tf.contrib.data.unbatch())\n",
    "\tdata_set = data_set.shuffle(buffer_size=batch_size)\n",
    "\tdata_set = data_set.batch(batch_size)\n",
    "\tdata_set = data_set.repeat(num_epochs)\n",
    "\tdata_set = data_set.prefetch(batch_size)\n",
    "\t\n",
    "\treturn data_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "cellView": "form",
    "colab": {},
    "colab_type": "code",
    "id": "rIH7wr6SjH6h"
   },
   "outputs": [],
   "source": [
    "#@title Data Loading/Saving Functions\n",
    "\n",
    "\n",
    "\n",
    "def get_videos_from_folder(data_folder):\n",
    "    '''\n",
    "    get a list of video x wehre each video is a numpy array in the format [n_frames,width,height] \n",
    "    with uint8 elements.\n",
    "    argument: relative path to the data_folder from the source folder.\n",
    "    '''\n",
    "    data_folder = os.path.join(dir_path,data_folder)\n",
    "    x = []\n",
    "    file_names = []\n",
    "    \n",
    "    if os.path.isdir(data_folder):\n",
    "        for dirpath, dirnames, filenames in os.walk(data_folder):\n",
    "            #print(filenames)\n",
    "            filenames = natsort.natsorted(filenames,reverse=False)\n",
    "            #filenames.sort(key=lambda f: int(filter(str.isdigit, f)))\n",
    "            #print(filenames)\n",
    "            for filename in filenames:\n",
    "                file_path = os.path.join(dirpath, filename)\n",
    "                statinfo = os.stat(file_path)\n",
    "                if statinfo.st_size != 0:\n",
    "                    video = skvideo.io.vread(file_path, outputdict={\"-pix_fmt\": \"gray\"})[:, :, :, 0]\n",
    "                    x.append(video)\n",
    "                    file_names.append(int(filename.split(\".\")[0]))\n",
    "\n",
    "    indices = sorted(range(len(file_names)), key=file_names.__getitem__)\n",
    "    x = np.take(x,indices)\n",
    "    return x\n",
    "\n",
    "def get_target_from_csv(csv_file):\n",
    "    '''\n",
    "    get a numpy array y of labels. the order follows the id of video. \n",
    "    argument: relative path to the csv_file from the source folder.\n",
    "    '''\n",
    "    csv_file = os.path.join(dir_path,csv_file)\n",
    "    with open(csv_file, 'r') as csvfile:\n",
    "        label_reader = pd.read_csv(csvfile)\n",
    "        y = label_reader['y']\n",
    "        \n",
    "    y = np.array(y)\n",
    "    return y\n",
    "\n",
    "  \n",
    "def save_solution(csv_file,prob_positive_class):\n",
    "    with open(csv_file, 'w') as csv:\n",
    "        df = pd.DataFrame.from_dict({'id':range(len(prob_positive_class)),'y': prob_positive_class})\n",
    "        df.to_csv(csv,index = False)\n",
    "        \n",
    "\n",
    "def to_frame_based(X, y=None, random_state=None):\n",
    "  \"\"\"\n",
    "  X: array of videos each [n_frames, width, height]\n",
    "  y: array of video labels\n",
    "  \"\"\" \n",
    "\n",
    "  n_videos = X.shape[0]\n",
    "  \n",
    "  if y is not None:\n",
    "    assert(y.shape[0]==n_videos)\n",
    "    \n",
    "  # X.shape[1] == n_frames in respective video\n",
    "  assert(X[0].shape[1]==100)\n",
    "  assert(X[0].shape[2]==100)\n",
    "  \n",
    "  \n",
    "  frames = []\n",
    "  frame_labels = []\n",
    "  idxs = []\n",
    "  \n",
    "  for v_id in range(n_videos):\n",
    "    frames.append(X[v_id])\n",
    "    \n",
    "    n_frames = X[v_id].shape[0]\n",
    "    \n",
    "    if y is not None:\n",
    "      labels = np.repeat(y[v_id], n_frames)\n",
    "      frame_labels.append(labels)\n",
    "    \n",
    "    idx = [f\"{v_id}_{frame_id}\" for frame_id in range(n_frames)]\n",
    "    idxs.append(idx)\n",
    "    \n",
    "  X_frame = np.concatenate(frames)\n",
    "  idx_frame = np.concatenate(idxs)\n",
    "  \n",
    "  s = np.arange(X_frame.shape[0])\n",
    "  if random_state is not None:\n",
    "    np.random.RandomState(seed=random_state).shuffle(s)\n",
    "  \n",
    "  if y is not None:\n",
    "    y_frame = np.concatenate(frame_labels)\n",
    "    return X_frame[s], y_frame[s], idx_frame[s]\n",
    "  else:\n",
    "    return X_frame[s], idx_frame[s]\n",
    "\n",
    "\n",
    "def combine_frame_based_pred(y_pred, idx_frame, reducer_fn):\n",
    "  assert(y_pred.shape[0]==idx_frame.shape[0])\n",
    "  \n",
    "  \n",
    "  d = {}\n",
    "  \n",
    "  for i in range(idx_frame.shape[0]):\n",
    "    v_id = idx_frame[i].split(\"_\")[0]\n",
    "    if v_id not in d:\n",
    "       d[v_id] = []\n",
    "    d[v_id].append(y_pred[i])\n",
    "  \n",
    "  \n",
    "  predictions = []\n",
    "  for v_id, preds in d.items():\n",
    "  \n",
    "    pred = reducer_fn(preds)\n",
    "  \n",
    "    predictions.append({\"id\":int(v_id), \"y\":pred})\n",
    "    \n",
    "  return pd.DataFrame(predictions).sort_values(\"id\")\n",
    "\n",
    "    \n",
    "def avg_reducer_fn(pred_lst):\n",
    "  return sum(pred_lst)[0]/len(pred_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 141
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 57150,
     "status": "ok",
     "timestamp": 1543158577017,
     "user": {
      "displayName": "Nicolas Küchler",
      "photoUrl": "",
      "userId": "14773896024539807174"
     },
     "user_tz": -60
    },
    "id": "MfhXS1b_waAv",
    "outputId": "6a169b33-3ee8-4df7-caa5-371b57e7670c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current dir ->  /content/drive/aml-task4\n",
      "Train folder ->  /content/drive/aml-task4/data/train/\n",
      "Train target ->  /content/drive/aml-task4/data/train_target.csv\n",
      "Test folder ->  /content/drive/aml-task4/data/test/\n",
      "X_train: (158,)\n",
      "y_train: (158,)\n",
      "X_test: (69,)\n"
     ]
    }
   ],
   "source": [
    "#@title Loading data (videos) into numpy array\n",
    "dir_path = os.getcwd()\n",
    "\n",
    "train_folder = os.path.join(dir_path,\"data/train/\")\n",
    "test_folder = os.path.join(dir_path,\"data/test/\")\n",
    "train_target = os.path.join(dir_path,'data/train_target.csv')\n",
    "\n",
    "print(\"Current dir -> \", dir_path)\n",
    "print(\"Train folder -> \",train_folder)\n",
    "print(\"Train target -> \",train_target)\n",
    "print(\"Test folder -> \",test_folder)\n",
    "\n",
    "X_train = get_videos_from_folder(train_folder)\n",
    "y_train = get_target_from_csv(train_target)\n",
    "X_test = get_videos_from_folder(test_folder)\n",
    "\n",
    "print(f\"X_train: {X_train.shape}\")\n",
    "print(f\"y_train: {y_train.shape}\")\n",
    "print(f\"X_test: {X_test.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "cellView": "form",
    "colab": {},
    "colab_type": "code",
    "id": "QNfWXsqiI-bz"
   },
   "outputs": [],
   "source": [
    "#@title Splitting data into training, validation and test set and converting them to frame based approach\n",
    "\n",
    "\n",
    "random_state = 42\n",
    "\n",
    "\n",
    "print(f\"Splitting Data into Training and Validation Set: \")\n",
    "X_train_split, X_valid_split, y_train_split, y_valid_split = train_test_split(X_train, y_train, test_size=16, random_state=random_state)\n",
    "\n",
    "\n",
    "print(f\"X_train_split: {X_train_split.shape}\")\n",
    "print(f\"y_train_split: {y_train_split.shape}\")\n",
    "print(f\"X_valid_split: {X_valid_split.shape}\")\n",
    "print(f\"y_valid_split: {y_valid_split.shape}\")\n",
    "\n",
    "print(f\"\\nTraining Set Video: Class 0: {y_train_split.shape[0] - sum(y_train_split)} Class 1: {sum(y_train_split)}\")\n",
    "print(f\"Validation Set Video: Class 0: {y_valid_split.shape[0] - sum(y_valid_split)} Class 1: {sum(y_valid_split)}\")\n",
    "\n",
    "\n",
    "print(f\"\\n\\nConverting Training and Validation Set into shuffled Frame Based Sets: \")\n",
    "X_train_frame, y_train_frame, _ = to_frame_based(X=X_train_split, y=y_train_split, random_state=random_state)\n",
    "X_valid_frame, y_valid_frame, idx_valid_frame = to_frame_based(X=X_valid_split, y=y_valid_split, random_state=random_state)\n",
    "\n",
    "\n",
    "print(f\"X_train_frame: {X_train_frame.shape}\")\n",
    "print(f\"y_train_frame: {y_train_frame.shape}\")\n",
    "\n",
    "print(f\"\\nX_valid_frame: {X_valid_frame.shape}\")\n",
    "print(f\"y_valid_frame: {y_valid_frame.shape}\")\n",
    "print(f\"idx_valid_frame: {idx_valid_frame.shape}\")\n",
    "\n",
    "\n",
    "print(f\"\\nTraining Set Frame: Class 0: {y_train_frame.shape[0] - sum(y_train_frame)} Class 1: {sum(y_train_frame)}\")\n",
    "print(f\"Validation Set Frame: Class 0: {y_valid_frame.shape[0] - sum(y_valid_frame)} Class 1: {sum(y_valid_frame)}\")\n",
    "\n",
    "\n",
    "\n",
    "print(\"\\n\\nTest Set Frame: \")\n",
    "X_test_frame, idx_test_frame  = to_frame_based(X=X_test, random_state=random_state)\n",
    "\n",
    "print(f\"X_test_frame: {X_test_frame.shape}\")\n",
    "print(f\"idx_test_frame: {idx_test_frame.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IVYlw8O6fDiT"
   },
   "outputs": [],
   "source": [
    "# Don't think this is working as expected\n",
    "\n",
    "#from https://stackoverflow.com/a/46844409\n",
    "# define roc_callback, inspired by https://github.com/keras-team/keras/issues/6050#issuecomment-329996505\n",
    "def auc_roc(y_true, y_pred):\n",
    "    # any tensorflow metric\n",
    "    value, update_op = tf.metrics.auc(labels=y_true, predictions=y_pred, num_thresholds=200, curve='ROC', summation_method='trapezoidal')\n",
    "\n",
    "    # find all variables created for this metric\n",
    "    metric_vars = [i for i in tf.local_variables() if 'auc_roc' in i.name.split('/')[1]]\n",
    "\n",
    "    # Add metric variables to GLOBAL_VARIABLES collection.\n",
    "    # They will be initialized for new session.\n",
    "    for v in metric_vars:\n",
    "        tf.add_to_collection(tf.GraphKeys.GLOBAL_VARIABLES, v)\n",
    "\n",
    "    # force to update metric values\n",
    "    with tf.control_dependencies([update_op]):\n",
    "        value = tf.identity(value)\n",
    "        return value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rihRYAcKxGIq"
   },
   "outputs": [],
   "source": [
    "best_weights_filepath = './best_weights.hdf5'\n",
    "\n",
    "print(\"ATTENTION: Roc Auc Metric not correctly working (I think it somehow would need to be reset for validation and new epoch)\")\n",
    "\n",
    "\n",
    "X_train_frame = X_train_frame.reshape(-1,100,100,1)\n",
    "X_valid_frame = X_valid_frame.reshape(-1,100,100,1)\n",
    "\n",
    "#create model\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(40, kernel_size=5, padding=\"same\",input_shape=(100, 100, 1), activation = 'relu'))\n",
    "model.add(MaxPool2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(70, kernel_size=3, padding=\"same\", activation = 'relu'))\n",
    "model.add(Conv2D(500, kernel_size=3, padding=\"same\", activation = 'relu'))\n",
    "model.add(MaxPool2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(1024, kernel_size=3, padding=\"valid\", activation = 'relu'))\n",
    "model.add(MaxPool2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(units=100, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(units=100, activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(units=100, activation='relu'))\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "model.add(Dense(1, kernel_initializer='normal', activation='sigmoid'))\n",
    "\n",
    "adam = optimizers.Adam(lr=0.0001)\n",
    "model.compile(loss='binary_crossentropy', optimizer=adam, metrics=['accuracy', auc_roc])\n",
    "\n",
    "saveBestModel = ModelCheckpoint(best_weights_filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='auto')\n",
    "early_stopping = EarlyStopping(monitor='val_acc', patience=0, verbose=1, mode='max')\n",
    "callbacks = [early_stopping, saveBestModel]\n",
    "\n",
    "history = model.fit(x=X_train_frame, y=y_train_frame, batch_size=32,\n",
    "          validation_split=0.0, validation_data=(X_valid_frame, y_valid_frame), # use the explicitly defined validation set\n",
    "          initial_epoch=0, epochs=5, shuffle=True , steps_per_epoch=None, validation_steps=None, # do epochs number of passes through the complete training dataset shuffling it each time\n",
    "          class_weight=None, sample_weight=None,\n",
    "          verbose=1, callbacks=callbacks)\n",
    "\n",
    "#reload best weights\n",
    "model.load_weights(best_weights_filepath)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 87
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4979,
     "status": "ok",
     "timestamp": 1543157483484,
     "user": {
      "displayName": "Nicolas Küchler",
      "photoUrl": "",
      "userId": "14773896024539807174"
     },
     "user_tz": -60
    },
    "id": "c9jMHzs7fnF6",
    "outputId": "fb31f2ad-03df-481d-ef8c-811abab933a4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test that the roc auc metric used in keras is correct\n",
      "943/943 [==============================] - 2s 2ms/step\n",
      "Scores: [0.4749480928684469, 0.8939554613569508, 0.975812877918478]\n",
      "Roc Auc: 0.9527256767994088\n"
     ]
    }
   ],
   "source": [
    "print(\"Test that the roc auc metric used in keras is correct\")\n",
    "\n",
    "scores = model.evaluate(x=X_valid_frame, y=y_valid_frame, batch_size=32, verbose=1, sample_weight=None, steps=None)\n",
    "print(f\"Scores: {scores}\")\n",
    "\n",
    "y_valid_frame_pred = model.predict(x=X_valid_frame, batch_size=32, verbose=0, steps=None)\n",
    "\n",
    "roc_auc = roc_auc_score(y_valid_frame, y_valid_frame_pred)\n",
    "print(f\"Roc Auc: {roc_auc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 545
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1726,
     "status": "ok",
     "timestamp": 1543157490677,
     "user": {
      "displayName": "Nicolas Küchler",
      "photoUrl": "",
      "userId": "14773896024539807174"
     },
     "user_tz": -60
    },
    "id": "XEkoKP1k-aNc",
    "outputId": "7c9e2f1b-3564-45f9-e651-3a23f20086a9"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.349912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.999995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2</td>\n",
       "      <td>0.853118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>0.268156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.000236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5</td>\n",
       "      <td>0.999538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>6</td>\n",
       "      <td>0.015090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>7</td>\n",
       "      <td>0.999996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0.999685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>9</td>\n",
       "      <td>0.966540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10</td>\n",
       "      <td>0.998108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>11</td>\n",
       "      <td>0.999454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>12</td>\n",
       "      <td>0.226529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>13</td>\n",
       "      <td>0.040374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14</td>\n",
       "      <td>0.999773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>15</td>\n",
       "      <td>0.155825</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id         y\n",
       "3    0  0.349912\n",
       "0    1  0.999995\n",
       "14   2  0.853118\n",
       "1    3  0.268156\n",
       "4    4  0.000236\n",
       "6    5  0.999538\n",
       "12   6  0.015090\n",
       "15   7  0.999996\n",
       "7    8  0.999685\n",
       "10   9  0.966540\n",
       "5   10  0.998108\n",
       "9   11  0.999454\n",
       "13  12  0.226529\n",
       "11  13  0.040374\n",
       "2   14  0.999773\n",
       "8   15  0.155825"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Roc Auc of Videos: 0.9375\n"
     ]
    }
   ],
   "source": [
    "df = combine_frame_based_pred(y_valid_frame_pred, idx_valid_frame, avg_reducer_fn)\n",
    "display(df)\n",
    "\n",
    "roc_auc = roc_auc_score(y_valid_split, df[\"y\"].values)\n",
    "print(f\"Roc Auc of Videos: {roc_auc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "E2Tx54_MjXHf"
   },
   "outputs": [],
   "source": [
    "submission_name = \"nk_frame_based_cnn_more_dropout_earlystopping_loadbestweights.csv\"\n",
    "\n",
    "X_test_frame = X_test_frame.reshape(-1,100,100,1)\n",
    "y_test_frame_pred = model.predict(x=X_test_frame, batch_size=32, verbose=0, steps=None)\n",
    "\n",
    "df = combine_frame_based_pred(y_test_frame_pred, idx_test_frame, avg_reducer_fn)\n",
    "df[\"y\"] = df[\"y\"].round(2)\n",
    "#display(df)\n",
    "\n",
    "submission_folder = os.path.join(dir_path,\"submissions/\")\n",
    "csv_file = submission_folder + submission_name\n",
    "\n",
    "with open(csv_file, 'w') as csv:\n",
    "  df.to_csv(csv,index = False)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "nk_task4.ipynb",
   "provenance": [
    {
     "file_id": "1EG8aLDaJRXZHLQUThvlPHOd0zxksHS7D",
     "timestamp": 1543056695915
    }
   ],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
